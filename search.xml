<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ts格式解析]]></title>
    <url>%2F2018%2F02%2F11%2Fm-f-ts%2F</url>
    <content type="text"><![CDATA[ts是日本高清摄像机拍摄下进行的封装格式，全称为MPEG2-TS。ts即”Transport Stream”的缩写。MPEG2-TS格式的特点就是要求从视频流的任一片段开始都是可以独立解码的。MPEG2-TS主要应用于实时传送的节目，比如实时广播的电视节目。 发展简要随着从HDTV录制的高清节目在网上的流传，发烧友们现在对TS这个名词大概已经不陌生了，但随之而来就是如何播放、如何添加字幕等等的一系列问题，本文将重点介绍一下这方面的应用操作。 先来简要介绍一下什么是MPEG2-TS吧。MPEG2格式大家都通过对DVD的接触而多多少少了解了一些，DVD节目中的MPEG2格式，确切地说是MPEG2-PS，全称是Program Stream，而TS的全称则是Transport Stream。MPEG2-PS主要应用于存储的具有固定时长的节目，如DVD电影，而MPEG-TS则主要应用于实时传送的节目，比如实时广播的电视节目。这两种格式的主要区别是什么呢？简单地打个比喻说，你将DVD上的VOB文件的前面一截cut掉（或者干脆就是数据损坏），那么就会导致整个文件无法解码了，而电视节目是你任何时候打开电视机都能解码（收看）的，所以，MPEG2-TS格式的特点就是要求从视频流的任一片段开始都是可以独立解码的。 学习多媒体容器格式的目的主要是为了回答以下问题： 该容器中数据是如何组织的？ 该容器包含哪些编码格式的数据？这些数据是如何存储的？ 该容器包含哪些元数据信息？包含哪些节目信息？ 对于支持多节目的容器格式，如何找到对应的音频流、视频流、字幕流？ 如何确定该容器的节目播放时长？ 如何从该容器中提取音频、视频、字幕数据，并交给解码器解码，有时间戳否？ 该容器是否支持seek？有哪些辅助信息？ 是否支持直接流化？ 哪里可以找到该容器格式最标准的文档资料？ 有哪些可用的工具，方便分析容器格式异常或者错误？ TS流生成和解析的过程TS流的形成过程： 将原始音视频数据压缩之后，压缩结果组成一个基本码流（ES）。 对ES（基本码流）进行打包形成PES。 在PES包中加入时间戳信息(PTS/DTS)。 将PES包内容分配到一系列固定长度的传输包（TS Packet）中。 在传输包中加入定时信息(PCR)。 在传输包中加入节目专用信息(PSI) 。 连续输出传输包形成具有恒定比特率的MPEG-TS流。 TS流的解析过程，可以说是生成的逆过程： 从复用的MPEG-TS流中解析出TS包； 从TS包中获取PAT及对应的PMT（PSI中的表格）； 从而获取特定节目的音视频PID； 通过PID筛选出特定音视频相关的TS包，并解析出PES； 从PES中读取到PTS/DTS，并从PES中解析出基本码流ES； 将ES交给解码器，获得压缩前的原始音视频数据。 TS码流整体结构MPEG-2中规定TS传输包的长度为188 字节，包头为4个字节，负载为184个字节。但通信媒介会为包添加错误校验字节，从而有了不同于188字节的包长。例如： DVB 规定中，使用204字节作为包长: 通过调制器时，在每个传输包后增加了16 字节的里德所罗门前向纠错码，因而形成了204字节的数据包。调制后总存在204 字节的数据包。 调制之前存复用器插入RS码或虚构的RS码。 ATSC规定中，使用208字节作为包长：添加20 字节的 RS（Reed-Solomon）前向纠错码。与DVB不同,ATSC规定RS码只能出现在调制的TS流中。 所有的TS包都分为包头和净荷部分。TS包中可以填入很多东西（填入的东西都是填入到净荷部分），有：视频、音频、数据（包括PSI、SI以及其它任何形式的数据）。 1、TS包包头TS包的包头提供关于传输方面的信息：同步、有无差错、有无加扰、PCR（节目参考时钟）等标志。TS包的包头长度不固定，前32比特（4个字节）固定，后面可能跟有自适应字段（适配域）。32个比特（4个字节）是最小包头。 sync_byte （同步字节）：固定为0100 0111 (0x47)；该字节由解码器识别，使包头和有效负载可相互分离。 transport_error_indicator（传输错误指示）：‘1’表示在相关的传输包中至少有一个不可纠正的错误位。当被置1后，在错误被纠正之前不能重置为0。 payload_unit_start_indicator（开始指示）：为1时，在前4个字节之后会有一个调整字节，其的数值为后面调整字段的长度length。因此有效载荷开始的位置应再偏移1+[length]个字节。 transport_priority（传输优先级）：‘1’表明优先级比其他具有相同PID 但此位没有被置‘1’的分组高。 PID：指示存储与分组有效负载中数据的类型。PID 值 0x0000—0x000F 保留。其中0x0000为PAT保留；0x0001为CAT保留；0x1fff为分组保留，即空包。 transport_scrambling_control（加扰控制）：表示TS流分组有效负载的加密模式。空包为‘00’，如果传输包包头中包括调整字段，不应被加密。 adaptation_field_control（适配域控制）：表示包头是否有调整字段或有效负载。‘00’为ISO/IEC未来使用保留；‘01’仅含有效载荷，无调整字段；‘10’ 无有效载荷，仅含调整字段；‘11’ 调整字段后为有效载荷，调整字段中的前一个字节表示调整字段的长度length，有效载荷开始的位置应再偏移[length]个字节。空包应为‘10’。 continuity_counter（连续性计数器）：随着每一个具有相同PID的TS流分组而增加，当它达到最大值后又回复到0。范围为0~15。 adaptation_field （自适应字段 ）：根据自适应控制字段填充负载。 2、节目专用信息PSI。然，TS包也可以是空包。空包用来填充TS流，可能在重新进行多路复用时被插入或删除。 在系统复用时，视频、音频的ES流需进行打包形成视频、音频的 PES流，辅助数据（如图文电视信息）不需要打成PES包。PES包非定长，音频的PES包小于等于64K，视频的一般为一帧一个PES包。一帧图象的PES包通常要由许多个TS包来传输。MPEG-2中规定，一个PES包必须由整数个TS包来传输。如果承载一个PES包的最后一个TS包没能装满，则用填充字节来填满；当下一个新的PES包形成时，需用新的TS包来开始传输。 节目专用信息PSI(Program Specific Information） 管理各种类型的TS数据包，需要有些特殊的TS包来确立各个TS数据包之间的关系。这些特殊的TS包里所包含的信息就是节目专用信息。在不同的标准中它有不同的名字： MPEG-2中称为PSI； DVB标准根据实际需要，对PSI扩展，称为SI信息； ATSC标准中为PSIP信息 MPEG-2中，规定的对PSI信息的描述方法有以下几种： 1、表Table： 节目信息的结构性的描述； 节目关联表Program Association Table (PAT) 0x0000 节目映射表Program Map Tables (PMT) PAT指定 条件接收表Conditional Access Table (CAT) 0x0001 网络信息表Network Information Table(NIT) 0x0010 传送流描述表Transport Stream Description Table (TSDT)2、节Section： 将表格的内容映射到TS流中；专用段 Private_ section 3、描述符Descriptor：提供有关节目构成（视频流、音频流、语言、层次、系统时钟和码率等多方面）的信息；ITU-T Rec.H.222.0|ISO /IEC 13818-1 中定义的 PSI表可被分成一段或多段置于传输流分组中。一段就是一个语法结构，用来将 ITU-T Rec.H.222.0|ISO /IEC 13818-1 中定义的 PSI表映射到传输流分组中。 PAT表TS流中包含一个或者多个PAT表。PAT表由PID为0x0000的TS包传送，其作用是为复用的每一路传送流提供出所包含的节目和节目编号，以及对应节目的PMT的位置即PMT的TS包的PID值，同时还提供NIT的位置，即NIT的TS包的PID的值。 table_id：固定为0x00，标志该表是PAT表。 section_syntax_indicator：段语法标志位，固定为1。 section_length：表示这个字节后面有用的字节数，包括CRC32。节目套数：（section length-9）/4 transport_stream_id：16位字段，表示该TS流的ID，区别于同一个网络中其它多路复用流。 version_number：表示PAT的版本号。 current_next_indicator：表示发送的PAT表是当前有效还是下一个PAT有效。 section_number：表示分段的号码。PAT可能分为多段传输，第一段为0，以后每个分段加1，最多可能有256个分段。 last_section_number：表示PAT最后一个分段的号码。 Program number：节目号 network_PID：网络信息表（NIT）的PID,节目号为0时对应ID为network_PID。 Program map PID：节目映射表（PMT）的PID号，节目号为大于等于1时，对应的ID为program_map_PID。一个PAT中可以有多个program_map_PID。 CRC_32：32位字段，CRC32校验码Cyclic RedundancyCheck。PMT表 PMT在传送流中用于指示组成某一套节目的视频、音频和数据在传送流中的位置，即对应的TS包的PID值，以及每路节目的节目时钟参考（PCR）字段的位置。 Table id ：固定为0x02，标志该表是PMT 表。 Section syntax indicator：对于PMT表，设置为1 。 Section length：表示这个字节后面有用的字节数，包括CRC32 。 Program number：它指出该节目对应于可应用的Program map PID 。 Version number：指出PMT 的版本号。 Current next indicator：当该位置’1’时，当前传送的Program map section可用；当该位置’0’时，指示当前传送的Program map section不可用，下一个TS流的Programmap section 有效。 Section number：总是置为0x00（因为PMT表里表示一个service的信息，一个section 的长度足够）。 Last section number：该域的值总是0x00 。 PCR PID：节目中包含有效PCR字段的传送流中PID 。 Program info length：12bit域，前两位为00。该域指出跟随其后对节目信息的描述的byte 数。 Stream type：8bit域，指示特定PID的节目元素包的类型。该处PID由elementary PID 指定。 HLSHTTP Live Streaming（缩写是HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。是苹果公司QuickTime X和iPhone软件系统的一部分。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8)playlist文件，用于寻找可用的媒体流。 HLS只请求基本的HTTP报文，与实时传输协议（RTP)不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。 苹果公司把HLS协议作为一个互联网草案（逐步提交），在第一阶段中已作为一个非正式的标准提交到IETF。但是，即使苹果偶尔地提交一些小的更新，IETF却没有关于制定此标准的有关进一步的动作。 HLS协议规定： 视频的封装格式是TS。 视频的编码格式为H264,音频编码格式为MP3、AAC或者AC-3。 除了TS视频文件本身，还定义了用来控制播放的m3u8文件（文本文件）。 为什么苹果要提出HLS这个协议，其实他的主要是为了解决RTMP协议存在的一些问题。比如RTMP协议不使用标准的HTTP接口传输数据，所以在一些特殊的网络环境下可能被防火墙屏蔽掉。但是HLS由于使用的HTTP协议传输数据，不会遇到被防火墙屏蔽的情况（该不会有防火墙连80接口都不放过吧）。 另外于负载，RTMP是一种有状态协议，很难对视频服务器进行平滑扩展，因为需要为每一个播放视频流的客户端维护状态。而HLS基于无状态协议（HTTP），客户端只是按照顺序使用下载存储在服务器的普通TS文件，做负责均衡如同普通的HTTP文件服务器的负载均衡一样简单。 另外HLS协议本身实现了码率自适应，不同带宽的设备可以自动切换到最适合自己码率的视频播放。其实HLS最大的优势就是他的亲爹是苹果。苹果在自家的iOS设备上只提供对HLS的原生支持，并且放弃了flash。Android也迫于平果的“淫威”原生支持了HLS。这样一来flv，rtmp这些Adobe的视频方案要想在移动设备上播放需要额外下点功夫。当然flash对移动设备造成很大的性能压力确实也是自身的问题。 但HLS也有一些无法跨越的坑，比如采用HLS协议直播的视频延迟时间无法下到10秒以下，而RTMP协议的延迟最低可以到3、4秒左右。所以说对直播延迟比较敏感的服务请慎用HLS。 播放模式 点播VOD的特点就是当前时间点可以获取到所有index文件和ts文件，二级index文件中记录了所有ts文件的地址。这种模式允许客户端访问全部内容。上面的例子中就是一个点播模式下的m3u8的结构。 Live 模式就是实时生成M3u8和ts文件。它的索引文件一直处于动态变化的，播放的时候需要不断下载二级index文件，以获得最新生成的ts文件播放视频。如果一个二级index文件的末尾没有#EXT-X-ENDLIST标志，说明它是一个Live视频流。 TS码流分析 多媒体文件格式之TS ISO/IEC 13818-1:2015]]></content>
      <categories>
        <category>音视频封装</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>format</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPEG]]></title>
    <url>%2F2018%2F02%2F08%2Fmedia-mpeg%2F</url>
    <content type="text"><![CDATA[MPEGMPEG（Moving Picture Experts Group，动态图像专家组）是ISO（International Standardization Organization，国际标准化组织）与IEC（International Electrotechnical Commission，国际电工委员会）于1988年成立的专门针对运动图像和语音压缩制定国际标准的组织。 MPEG标准主要有以下五个，MPEG-1、MPEG-2、MPEG-4、MPEG-7及MPEG-21等。该专家组建于1988年，专门负责为CD建立视频和音频标准，而成员都是为视频、音频及系统领域的技术专家。及后，他们成功将声音和影像的记录脱离了传统的模拟方式，建立了ISO/IEC11172压缩编码标准，并制定出MPEG-格式，令视听传播方面进入了数码化时代。因此，大家现时泛指的MPEG-X版本，就是由ISO(International Organization for Standardization）所制定而发布的视频、音频、数据的压缩标准。 MPEG标准的视频压缩编码技术主要利用了具有运动补偿的帧间压缩编码技术以减小时间冗余度，利用DCT技术以减小图像的空间冗余度，利用熵编码则在信息表示方面减小了统计冗余度。这几种技术的综合运用，大大增强了压缩性能。 MPEG的缔造者们原先打算开发四个版本：MPEG1-MPEG4，以适用于不同带宽和数字影像质量的要求。后由于MPEG3被放弃，所以现存只有三个版本的MPEG：MPEG-1，MPEG-2，MPEG-4。总体来说，MPEG在三方面优于其他压缩/解压缩方案。首先，由于在一开始它就是做为一个国际化的标准来研究制定，所以，MPEG具有很好的兼容性。其次，MPEG能够比其他算法提供更好的压缩比，最高可达200:1。更重要的是，MPEG在提供高压缩比的同时，对数据的损失很小。 MPEG-1MPEG-1制定于1992年，为工业级标准而设计，可适用于不同带宽的设备，如CD-ROM、Video-CD、CD-i。它可针对SIF标准分辨率（对于NTSC制为352X240；对于PAL制为352X288）的图象进行压缩，传输速率为1.5Mbits/sec，每秒播放30帧，具有CD（指激光唱盘）音质，质量级别基本与VHS相当。MPEG的编码速率最高可达4-5Mbits/sec，但随着速率的提高，其解码后的图象质量有所降低。 M PEG-1也被用于数字电话网络上的视频传输，如非对称数字用户线路(ADSL），视频点播（VOD），以及教育网络等。同时，MPEG-1也可被用做记录媒体或是在INTERNET上传输音频。 MPEG-2MPEG-2制定于1994年，设计目标是高级工业标准的图象质量以及更高的传输率。MPEG-2所能提供的传输率在3-10Mbits/sec间，其在NTSC制式下的分辨率可达720X486，MPEG-2也可提供并能够提供广播级的视像和CD级的音质。MPEG-2的音频编码可提供左右中及两个环绕声道，以及一个加重低音声道，和多达7个伴音声道（DVD可有8种语言配音的原因）。由于MPEG-2在设计时的巧妙处理，使得大多数MPEG-2解码器也可播放MPEG-1格式的数据，如VCD。 同时，由于MPEG-2的出色性能表现，已能适用于HDTV，使得原打算为HDTV设计的MPEG-3，还没出世就被抛弃了。（MPEG-3要求传输速率在20Mbits/sec-40Mbits/sec间，但这将使画面有轻度扭曲）。除了做为DVD的指定标准外，MPEG-2还可用于为广播，有线电视网，电缆网络以及卫星直播(DirectBroadcastSatellite）提供广播级的数字视频。 MPEG-2的另一特点是，其可提供一个较广的范围改变压缩比，以适应不同画面质量，存储容量，以及带宽的要求。 对于最终用户来说，由于现存电视机分辨率限制，MPEG-2所带来的高清晰度画面质量（如DVD画面）在电视上效果并不明显，到是其音频特性（如加重低音，多伴音声道等）更引人注目。 MPEG-4MPEG专家组的专家们正在为MPEG-4的制定努力工作。MPEG-4标准主要应用于视像电话（videophone），视像电子邮件（VideoEmail）和电子新闻（Electronicnews）等，其传输速率要求较低，在4800-64000bits/sec之间，分辨率176X144。MPEG-4利用很窄的带宽，通过帧重建技术，压缩和传输数据，以求以最少的数据获得最佳的图象质量。 与MPEG-1和MPEG-2相比，MPEG-4的特点是其更适于交互AV服务以及远程监控。MPEG-4是第一个使你由被动变为主动（不再只是观看，允许你加入其中，即有交互性）的动态图象标准；它的另一个特点是其综合性；从根源上说，MPEG-4试图将自然物体与人造物体相溶合（视觉效果意义上的）。MPEG-4的设计目标还有更广的适应性和可扩展性。 MPEG-1MPEG-1是MPEG组织制定的第一个视频和音频有损压缩标准。视频压缩算法于1990年定义完成。1992年底，MPEG-1正式被批准成为国际标准。MPEG-1是为CD光碟介质定制的的视频和音频压缩格式。一张70分钟的CD光碟传输速率大约在1.4Mbps。而MPEG-1采用了块方式的运动补偿、离散余弦变换（DCT）、量化等技术，并为1.2Mbps传输速率进行了优化。MPEG-1随后被Video CD采用作为核心技术。MPEG-1的输出质量大约和传统录像机VCR，信号质量相当，这也许是Video CD在发达国家未获成功的原因。 特点MPEG-1是为CD光盘介质定制的视频和音频压缩格式。一张70分钟的CD光盘传输速率大约在1.4Mbps。而MPEG-1采用了块方式的运动补偿、离散余弦变换（DCT）、量化等技术，并为1.2Mbps传输速率进行了优化。MPEG-1随后被Video CD采用作为核心技术。VCD的分辨率只有约352×240，并使用固定的比特率（1.15Mbps），因此在播放快速动作的视频时，由于数据量不足，令压缩时宏区块无法全面调整，结果使视频画面出现模糊的方块。因此MPEG-1的输出质量大约和传统录像机VCR相当，这也许是Video CD在发达国家未获成功的原因。MPEG-1音频分三代，其中最著名的第三代协议被称为MPEG-1 Layer 3，简称MP3，已经成为广泛流传的音频压缩技术。MPEG-1音频技术在每一代之间，在保留相同的输出质量之外，压缩率都比上一代高。第一代协议MP1被应用在LD作为记录数字音频以及飞利浦公司的DGC上；而第二代协议MP2后来被应用于欧洲版的DVD音频层之一。 MPEG-1具有以下特点： 随机访问 灵活的帧率 可变的图像尺寸 定义了I-帧、P-帧和B-帧 运动补偿可跨越多个帧 半像素精度的运动向量 量化矩阵 GOF结构 slice结构 音频分层MPEG-1音频分三层，分别为MPEG-1 Layer1，MPEG-Layer2以及MPEG-Layer3，并且高层兼容低层。其中第三层协议被称为MPEG-1 Layer 3，简称MP3。MP3已经成为广泛流传的的音频压缩技术。 MPEG-1 Layer1采用每声道192kbit/s，每帧384个样本，32个等宽子带，固定分割数据块。子带编码用DCT(离散余弦变换)和(快速傅立叶变换)计算子带信号量化bit数。采用基于频域掩蔽效应的心理声学模型，使量化噪声低于掩蔽值。量化采用带死区的线性量化器，主要用于数字盒式磁带(DCC)。 MPEG-1 Layer2采用每声道128kbit/s，每帧1152个样本，32个子带，属不同分帧方式。采用共同频域和时域掩蔽效应的心理声学模型，并对高、中，低频段的比特分配进行限制，并对比特分配、比例因子，取样进行附加编码。Layer2 广泛用于数字电视，CD-ROM，CD-I和VCD等。 MPEG-1 Layer3采用每声道64kbit/s，用混合滤波器组提高频率分辨率，按信号分辨率分成6X32或18X32个子带，克服平均32个子带的Layer1，Layer2在中低频段分辨率偏低的缺点。采用心理声学模型2，增设不均匀量化器，量化值进行熵编码。主要用于ISDN(综合业务数字网)音频编码。 MPEG-1制定于1992年，为工业级标准而设计，它可针对SIF标准分辨率(对于NTSC制为352X240；对于PAL制为352X288)的图像进行压缩，传输速率为1.5Mbits/sec，每秒播放30帧，具有CD(指激光唱盘)音质，质量级别基本与VHS相当。MPEG的编码速率最高可达4- 5Mbits/sec，但随着速率的提高，其解码后的图象质量有所降低。 MPEG-1也被用于数字电话网络上的视频传输，如非对称数字用户线路(ADSL)，视频点播(VOD)，以及教育网络等。同时，MPEG-1也可被用做记录媒体或是在INTERNET上传输音频。 MPEG-2MPEG-2是MPEG（Moving Picture Experts Group，运动图像专家组）组织制定的视频和音频有损压缩标准之一，它的正式名称为“基于数字存储媒体运动图像和语音的压缩标准”。与MPEG-1标准相比，MPEG-2标准具有更高的图像质量、更多的图像格式和传输码率的图像压缩标准。MPEG-2标准不是MPEG-1的简单升级，而是在传输和系统方面做了更加详细的规定和进一步的完善。它是针对标准数字电视和高清晰电视在各种应用下的压缩方案，编码率从3 Mbit/s~100 Mbit/s。 MPEG-2音频是在1994年11月为数字电视而提出来的，其发展分为三个阶段： 第一阶段是对MPEG-1增加了低采样频率，有16KHZ，22.05KHZ，以及24KHZ。 第二阶段是对MPEG-1实施了向后兼容的多声道扩展，将其称为MPEG-2 BC。支持单声道，双声道，多声道等编码。并附加“低频加重”扩展声道，从而达到五声道编码。 第三阶段是向后不兼容，将其称为MPEG-2 AAC先进音频编码。采样频率可以低至8KHZ；而高至96KHZ范围内的1-48个通道可选的高音质音频编码。 分部MPEG-2标准目前分为9个部分，统称为ISO/IEC13818国际标准。各部分的内容描述如下： 一部分－ISO/IEC13818-1，System：系统，描述多个视频，音频和数据基本码流合成传输码流和节目码流的方式。 二部分－ISO/IEC13818-2，Video：视频，描述视频编码方法。 三部分－ISO/IEC13818-3，Audio：音频，描述与MPEG-1音频标准反向兼容的音频编码方法。 四部分－ISO/IEC13818-4，Compliance：符合测试，描述测试一个编码码流是否符合MPEG-2码流的方法。 五部分－ISO/IEC13818-5，Software：软件，描述了MPEG-2标准的第一、二、三部分的软件实现方法。 六部分－ISO/IEC13818-6，DSM-CC：数字存储媒体-命令与控制，描述交互式多媒体网络中服务器与用户间的会话信令集。 上六个部分均已获得通过，成为正式的国际标准，并在数字电视等领域中得到了广泛的实际应用。此外，MPEG-2标准还有三个部分： 第七部分规定不与MPEG-1音频反向兼容的多通道音频编码； 第八部分现已停止； 第九部分规定了传送码流的实时接口。 1990年成立的ATM视频编码专家组与MPEG在ISO/IEC13818标准的第一和第二两个部分进行了合作，因此上述两个部分也成为ITU-T的 标准，分别为：ITU-T H.222.0和ITU-T H.262视频。 MPEG-4MPEG-4，于MP4是一套用于音频、视频信息的压缩编码标准，由国际标准化组织（ISO）和国际电工委员会（IEC）下属的“动态图像专家组（Moving Picture Experts即MPEG制定，第一版在1998年10月通过，第二版在1999年12月通过。MPEG-4格式的主要用途在于网上流、光盘、语音发送（视频电话），以及电视广播。MPEG-4包含了MPEG-1及MPEG-2的绝大部份功能及其他格式的长处，并加入及扩充对虚拟现实模型语言（VRML，VirtualReality Modeling Language）的支持，面向对象的合成档案（包括音效，视讯及VRML对象），以及数字版权管理（DRM）及其他互动功能。而MPEG-4比MPEG-2更先进的其中一个特点，就是不再使用宏区块做影像分析，而是以影像上个体为变化记录，因此尽管影像变化速度很快、码率不足时，也不会出现方块画面。 分部MPEG-4由一系列的子标准组成，被称为部(part)（有时也译为卷），包括以下的部分： 第一部分（ISO/IEC14496-1）：系统：描述视讯和音频数据流的控制、同步以及混合方式（即混流Multiplexing，简写为MUX）。 第二部分（ISO/IEC14496-2）：视讯：定义了一个对各种视觉讯息（包括自然视讯、静止纹理、计算机合成图形等等）的编译码器。（例如XviD编码就属于MPEG-4Part2） 第三部分（ISO/IEC14496-3）：音讯：定义了一个对各种音频讯号进行编码的编译码器的集合。包括高阶音频编码（AdvancedAudioCoding，缩写为AAC）的若干变形和其他一些音频/语音编码工具。 第四部分（ISO/IEC14496-4）：一致性：定义了对本标准其他的部分进行一致性测试的程序。 第五部分（ISO/IEC4496-5）：参考软件：提供了用于演示功能和说明本标准其他部分功能的软件。 第六部分（ISO/IEC14496-6）：多媒体传输整合框架（DMIF for Delivery Multimedia IntegrationFramework） 第七部分（ISO/IEC14496-7）：优化的参考软件：提供了对实作进行优化的例子（这里的实作指的是第五部分）。 第八部分（ISO/IEC14496-8）：在IP网络上传输：定义了在IP网络上传输MPEG-4内容的方式。 第九部分（ISO/IEC14496-9）：参考硬件：提供了用于演示怎样在硬件上实作本标准其他部分功能的硬件设计方案。 第十部分（ISO/IEC14496-10）：进阶视讯编码或称高阶视讯编码（Advanced Video Coding，缩写为AVC）：定义了一个视讯编译码器（codec）。AVC和XviD都属于MPEG-4编码，但由于AVC属于MPEG-4Part10，在技术特性上比属于MPEG-4Part2的XviD要先进。另外，它和ITU-TH.264标准是一致的，故又称为H.264。 第十二部分（ISO/IEC14496-12）：基于ISO的媒体文件格式：定义了一个储存媒体内容的文件格式。 第十三部分（ISO/IEC14496-13）：知识产权管理和保护（IPMP for Intellectual Property Management andProtection）拓展。 第十四部分（ISO/IEC14496-14）：MPEG-4文件格式：定义了基于第十二部分的用于储存MPEG-4内容的视讯文件格式。 第十五部分（ISO/IEC14496-15）：AVC文件格式：定义了基于第十二部分的用于储存第十部分的视讯内容的文件格式。 第十六部分（ISO/IEC14496-16）：动画框架扩充功能（AFX:Animation Framework eXtension）。 第十七部分（ISO/IEC14496-17）：同步文字字幕格式。 第十八部分（ISO/IEC14496-18）：字型压缩和串流传输（针对开放字型格式 Open Font Format）。 第十九部分（ISO/IEC14496-19）：合成材质流（Synthesized Texture Stream）。 第二十部分（ISO/IEC14496-20）：简单场景表示（LASeR for Lightweight Scene Representation。 第二十一部分（ISO/IEC14496-21）：用于描绘（Rendering）的MPEG-J拓展。 第二十二部分（ISO/IEC14496-22）：开放字型格式（Open Font Format）。 第二十三部分（ISO/IEC14496-23）：符号化音乐表示（Symbolic Music Representation）。 第二十四部分（ISO/IEC14496-24）：音频与系统互动作用（Audio and systems interaction）。 第二十五部分（ISO/IEC14496-25）：3D图形压缩模型（3D GraphicsCompression Model）。 第二十六部分（ISO/IEC14496-26）：音讯一致性检查：定义了测试音频数据与ISO/IEC 14496-3是否一致的方法（Audioconformance）。 第二十七部分（ISO/IEC14496-27）：3D图形一致性检查：定义了测试3D图形数据与ISO/IEC14496-11:2005,ISO/IEC 14496-16:2006,ISO/IEC14496-21:2006,和ISO/IEC14496-25:2009是否一致的方法（3D Graphicsconformance）。 Profiles是在每个部分内定义的，所以对某个部分的一个实作通常不是对该部分的完整实作。 特点 对于不同的对象可采用不同的编码算法，从而进一步提高压缩效率； 对象各自相对独立，提高了多媒体数据的可重用性； 允许用户对单个的对象操作，提供前所未有的交互性； 允许在不同的对象之间灵活分配码率，对重要的对象可分配较多的字节，对次要的对象可分配较少的字节，从而能在低码率下获得较好的效果； 可以方便的集成自然音视频对象和合成音视频对象。 MPEG-7引用 Moving Picture Experts Group ISO/IEC JTC 1/SC 29 MPEG-1 MPEG-2 MPEG-4 MP3]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习的自动抠图]]></title>
    <url>%2F2018%2F01%2F25%2Ftips-ml-about-backgroundremoval%2F</url>
    <content type="text"><![CDATA[资源 原文:Background removal with deep learning 译文:自拍抠图抠到手软？详解如何用深度学习消除背景 server代码地址 acGAN-Paper-Implementation:acGAN paper implementation and adaptation by KJeanclaude &amp; Gidi Shperber fast.ai course 作者:Alon Burg ,Gidi Shperber]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tips</tag>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep-photo-styletransfer介绍]]></title>
    <url>%2F2018%2F01%2F21%2Ftips-ml-dpst%2F</url>
    <content type="text"><![CDATA[1.介绍deep-photo-styletransfer: 2.安装环境为mac10.13.2 2.1安装依赖2.1.1 TorchTorch是基于Lua语言的深度学习框架. 安装: 123curl -s https://raw.githubusercontent.com/torch/ezinstall/master/install-deps | bashgit clone https://github.com/torch/distro.git ~/torch --recursivecd ~/torch; ./install.sh 第一条命令安装了LuaJIT 和 Torch的依赖库。第二条命令安装LuaJIT, LuaRocks，然后用 LuaRocks （lua 包管理工具）安装核心包：torch, nn and paths, 和其它包。上面命令把 torch 加入到了你的PATH环境变量中了，用 source 更新一下让环境变量生效： 123456# 在 Linux 上source ~/.bashrc# 在 OSX 上source ~/.profile或source ~/.bash_profile 如果你想要卸载 torch，执行： 1rm -rf ~/torch 现在在你可以用 Luarocks 安装新的包 12luarocks install imageluarocks list 安装完之后，你可以在终端用 th 命令运行 torch，现在进入了 torch 的交互模式，类似Python的交互模式。 123456789101112131415$ th ______ __ | Torch7 /_ __/__ ________/ / | Scientific computing for Lua. / / / _ / __/ __/ _ | /_/ ___/_/ __/_//_/ | https://github.com/torch | http://torch.chth&gt; torch.Tensor&#123;1,2,3&#125; 1 2 3[torch.DoubleTensor of dimension 3]th&gt; 要退出交互模式，两次Ctrl+C，或输入 os.exit()。 要执行 file.lua, 写 th&gt; dofile “file.lua”。 在非交互模式下执行文件： 1th file.lua th 命令有很多选项，类似 perl 和 ruby。 12345678910111213$ th -hUsage: th [options] [script.lua [arguments]]Options: -l name load library name -e statement execute statement -h,--help print this help -a,--async preload async (libuv) and start async repl (BETA) -g,--globals monitor global variables (print a warning on creation/access) -gg,--gglobals monitor global variables (throw an error on creation/access) -x,--gfx start gfx server and load gfx env -i,--interactive enter the REPL after executing a scriptShare the post &quot;Mac OS X／Ubuntu 安装 Torch&quot; 安装deep-photo-styletransfer所需依赖: matio-ffi:luarocks install matio-ffi loadcaffe:luarocks install loadcaffe 2.1.2Matlab or OctaveMatlab较大,而且是商用软件,所以选择了octave Octave是一款用于数值计算和绘图的开源软件, 精于矩阵运算:求解联立方程组、计算矩阵特征值和特征向量等等,并能够通过多种形式将数据可视化。Octave最简单的使用方式就是像使用一个计算器一样在命令提示符下输入相应的计算式。Octave能识别通常的计算表达式。例如,在终端输入 1octave:##&gt;2+2 mac下首先确保自己的Mac安装了Xcode和Command Line Tool，通过以下命令安装Command Line Tool， 1xcode-select --install 之后安装Mac下的包管理神器Homebrew，命令如下， 1curl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local --strip 1 通过以下命令升级Homebrew: 1sudo brew update &amp;&amp; sudo brew upgrade 之后通过以下命令安装gcc、XQuartz，最后就可以通过Homebrew安装Octave了， 123sudo brew install gccsudo brew install Caskroom/cask/xquartzsudo brew install octave mac下使用brew安装的octave是4.2版本,使用imread等函数时会提示: 12345error: Magick++ exception: octave-cli-4.2: Unable to access configuration file (delegates.mgk) reported by magick/blob.c:2101 (GetConfigureBlob)error: called from __imread__ at line 80 column 10 imageIO at line 117 column 26 imread at line 106 column 30 未找到原因,最后在https://wiki.octave.org/Octave_for_macOS#Simple_Installation_Instructions_2中下载[Mac OS X Bundle](https://sourceforge.net/projects/octave/files/Octave%20MacOSX%20Binary/2016-07-11-binary-octave-4.0.3/octave_gui_403_appleblas.dmg/download)中下载[4.0.3-gui](https://jaist.dl.sourceforge.net/project/octave/Octave%20MacOSX%20Binary/2016-07-11-binary-octave-4.0.3/octave_gui_403_appleblas.dmg)及[4.0.2 command line](https://jaist.dl.sourceforge.net/project/octave/Octave%20MacOSX%20Binary/2016-06-06-binary-octave-4.0.2/octave_cli_402.dmg)执行imread会出现: 1warning: your version of GraphicsMagick limits images to &lt;16&gt; bits per pixel 根据GraphicsMagick中介绍是GraphicsMagick编译是参数不对,后下载(地址)使用 1234./configure --with-quantum-depth=16 --enable-shared --disable-static --with-magick-plus-plus=yesmakemake checksudo make install 仍然不对,好像bound包依赖的库不是默认安装路径的. 使用最新的GraphicsMagick为1.3.27,命令行下可以使用gm命令: 1234567891011121314151617181920$ gmGraphicsMagick 1.3.27 Q32 http://www.GraphicsMagick.org/Copyright (C) 2002-2017 GraphicsMagick Group.Additional copyrights and licenses apply to this software.See http://www.GraphicsMagick.org/www/Copyright.html for details.Usage: gm command [options ...]Where commands include: batch - issue multiple commands in interactive or batch mode benchmark - benchmark one of the other commands compare - compare two images composite - composite images together conjure - execute a Magick Scripting Language (MSL) XML script convert - convert an image or sequence of images help - obtain usage message for named command identify - describe an image or image sequence mogrify - transform an image or sequence of images montage - create a composite image (in a grid) from separate images time - time one of the other commands version - obtain release version 可以使用pkg install -forge package安装Octave-Forge 中的包,如默认使用的image包: 1pkg install -forge image 也可以下载其他版本的image包到本地执行pkg install image-2.4.1.tar.gz pkg list可列出已安装的包,安装好后不能直接使用，使用前要load 1warning: the &apos;col2im&apos; function belongs to the image package from Octave Forge which you have installed but not loaded. To load the package, run &apos;pkg load image&apos; from the Octave prompt. 有人使用docker容器解决了这个问题:https://github.com/martinbenson/deep-photo-styletransfer, 但是未尝试 GraphicsMagick UNIX/Cygwin/MinGW Compilation octave-devel 3.6.3 GraphicsMagick limits images to 8 bits per pixel Octave教程 Octave Tutorial Octave requirements Is removing the Matlab dependency possible? Added Matlab dependency alternative Re: [GM-apis] PythonMagick 2.1.3CUDA cudnn从NVIDIA cuDNN官网下载,文档地址 7.5下载地址 9.1下载地址 使用不同版本有兼容性问题 2.1.4下载VGG-191sh models/download_models.sh 2.1.5Compile cuda_utils.cu (Adjust PREFIX and NVCC_PREFIX in makefile for your machine)遇到问题: 1THC.h includes THCGeneral.h, does not exist 解决: 1234I&apos;ve fixed this issue by executing the following commands in terminal:cd to you torch directory, and execute the update.sh scriptsecond, execute &quot;luarocks install cutorch&quot; 可能有xcode Command Line Tool版本不兼容问题: 1nvcc fatal : The version (&apos;80100&apos;) of the host compiler (&apos;Apple clang&apos;) is not supported 替换版本即可: 12345登录 https://developer.apple.com/downloads/下载Xcode CLT (Command Line Tools) 8.2安装 CLT执行 sudo xcode-select --switch /Library/Developer/CommandLineTools输入命令行查看clang版本 clang --version THC.h includes THCGeneral.h, does not exist 相关资源 深度摄影风格转换–Deep Photo Style Transfer cuDNN CUDA从入门到精通 VGG论文笔记 deep-photo-styletransfer-tf:Tensorflow (Python API) implementation of Deep Photo Style Transfer floydhub/deep-photo-styletransfer:Jupyter Notebook to train photorealistic style transfer How do I rebuild Octave and link in GraphicsMagick? /gnu/octave/ 的索引 相关问题 configure :error: No usable version of sed found: I did ./configure to make a makefile but it ran into an error: configure :error: No usable version of sed found: I then typed which see it shows /usr/bin/sed. so, what’s wrong? why can’t ./configure find sed? I happened to have this problem on my mac. This is because OS X uses an old version of sed. Installing gnu-sed by brew install gnu-sed and alias gsed=sed solved this problem. You may install gnu-sed with other method. https://stackoverflow.com/questions/26351285/configure-error-no-usable-version-of-sed-found gm-bin convert: Unable to access configuration file (delegates.mgk) [No such file or directory]. I am attempting to install GraphicsMagick in a hosting account… I used this info to get it to work in most cases: How do you specify the location of libraries to a binary? (linux) However, it still cannot find the delegates.mgk (which is in ./lib/GraphicsMagick-1.3.14/delegates.mgk) as witnessed in this error: gm-bin convert: Unable to access configuration file (delegates.mgk) [No such file or directory]. Either, a) how do find out where the binary thinks this file should be, or b) how do I extend the wrapper script to help it out? Figured it out after looking through the binary for /PATH/ The binaries require these additional path variables: 123$MAGICK_CONFIG_PATH$MAGICK_CODER_MODULE_PATH$MAGICK_FILTER_MODULE_PATH …here is the resulting script modification form my setup: 1234567891011#!/bin/shif [ -n &quot;$LD_LIBRARY_PATH&quot; ]; then LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/USER/libelse LD_LIBRARY_PATH=/home/USER/libfi[ -z &quot;$&#123;MAGICK_CONFIGURE_PATH&#125;&quot; ] &amp;&amp; export MAGICK_CONFIGURE_PATH=/home/USER/lib/GraphicsMagick-1.3.14/config[ -z &quot;$&#123;MAGICK_CODER_MODULE_PATH&#125;&quot; ] &amp;&amp; export MAGICK_CODER_MODULE_PATH=/home/USER/lib/GraphicsMagick-1.3.14/modules-Q8/coders[ -z &quot;$&#123;MAGICK_FILTER_MODULE_PATH&#125;&quot; ] &amp;&amp; export MAGICK_FILTER_MODULE_PATH=/home/USER/lib/GraphicsMagick-1.3.14/modules-Q8/filtersexport LD_LIBRARY_PATHexec /home/USER/bin/gm-bin &quot;$@&quot;]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tips</tag>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常见问题]]></title>
    <url>%2F2018%2F01%2F16%2Fissue-python%2F</url>
    <content type="text"><![CDATA[OSError: [Errno 1] Operation not permitted: &#39;/tmp/pip-g3bg0s-uninstall/System/Library/Frameworks/Pyt在用下列名字安装时 12sudo -H pip install Scrapysudo pip install virtualenvwrapper 出现下列错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Found existing installation: six 1.4.1 DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project. Uninstalling six-1.4.1:Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py&quot;, line 215, in main status = self.run(options, args) File &quot;/Library/python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py&quot;, line 342, in run prefix=options.prefix_path, File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py&quot;, line 778, in install requirement.uninstall(auto_confirm=True) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py&quot;, line 754, in uninstall paths_to_remove.remove(auto_confirm) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py&quot;, line 115, in remove renames(path, new_path) File &quot;/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py&quot;, line 267, in renames shutil.move(old, new) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 302, in move copy2(src, real_dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 131, in copy2 copystat(src, dst) File &quot;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py&quot;, line 103, in copystat os.chflags(dst, st.st_flags)OSError: [Errno 1] Operation not permitted: &apos;/tmp/pip-g3bg0s-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info&apos; Scrapy，virtualenvwrapper需要依赖six，在安装six的时候发现系统已经有一个six-1.4.1，但是virtualenvwrapper需要six-1.9.0，于是想先卸载老版本的six，此时问题来了，发现没有权限卸载，此时我就纳闷，加上sudo，还是没权限。于是Google之，最终还是在万能的GitHub找到答案。six-1.4.1是系统内置的packages，因 系统集成保护 你是没有权限去修改/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info目录的。因此在安装virtualenvwrapper的时候需要选择忽略six的安装： 12sudo pip install virtualenvwrapper --upgrade --ignore-installed sixsudo pip install Scrapy --upgrade --ignore-installed six 如果使用requirements安装,也使用:sudo -H pip install -r requirements.txt --upgrade --ignore-installed six]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android逆向(1)之root方式注入apk]]></title>
    <url>%2F2018%2F01%2F16%2Ftips-android-inject1%2F</url>
    <content type="text"><![CDATA[第一步,注入动态库到目标进程 启动注入程序,入口main函数中输入将被注入的进程名称以及欲注入动态库路径; 根据进程名获取进程id:打开/proc目录,读取/proc/%d/cmdline; attach到目标进程:ptrace(PTRACE_ATTACH, pid, NULL, 0)并暂停目前进程; 读取寄存器值:ptrace(PTRACE_GETREGS, pid, NULL, regs),并保持读取到的寄存器; 获取被加载的动态库中mmap函数地址,获取被加载动态库中函数地址的方法是,获取本地libc.so模块和被加载动态库中libc.so模块中各自起始地址,local_addr-local_handle的值为指定函数(如mmap)在该模块中的偏移量，然后再加上remote_handle，结果就为指定函数在目的进程的虚拟地址,获取模块起始地址的方法是读取进程对应的/proc/self/maps或/proc/%d/maps文件; 调用被加载库的mmap方法申请空间:ptrace_call(target_pid, (uint32_t)func_addr, parameters, param_num, regs); 获取申请空间时的R0寄存器,arm中R0~R3作为传递参数的寄存器,R0可以获取到申请空间的起始地址; 获取被加载库中dlopen,dlsym,dlclose,dlerror函数地址; 将被加载动态库的路径写入到mmap分配的栈空间:ptrace(PTRACE_PEEKTEXT, pid, dest, 0);; 调用远程函数的dlopen函数打开要被注入的动态库; 调用dlsym获取加载动态库目标函数符号对应地址,并调用目标函数,完成注入; 调用dlclose关闭被注入库; 完成注入; 动态库中加载目标apk(aar) 入口函数中启动新线程,并调用pthread_detach(tid)将新线程设置为detach状态,可自动回收资源; 新线程中调用AndroidRuntime::getJavaVM();获取JavaVM对象并Attach当前线程到JavaVM:jvm-&gt;AttachCurrentThread(&amp;jni_env, NULL);获取到jni env; 找到dalvik/system/DexClassLoader类,并获取其构造方法public DexClassLoader(String dexPath, String optimizedDirectory, String librarySearchPath, ClassLoader parent)的methodid及public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException的methodid; 找到类java/lang/ClassLoader,获取其静态方法Gpublic static ClassLoader getSystemClassLoader()的MethodID,调用静态方法getSystemClassLoader获取系统ClassLoader; 基于系统ClassLoader,以及DexClassClassLoader构造方法MethodID创建DexClassLoader对象:jni_env-&gt;NewObject(dexloader_claxx, dexloader_init_method, apk_path, dex_out_path, lib_path, class_loader);,要传入DexClassloader jclass,DexClassLoader构造方法id,要被加载的apk路径,dex输出路径,动态库路径,以及父(即系统)ClassLoader; 调用DexClassLoader的loadClass方法id加载apk中被调起的类:jclass entry_class = static_cast&lt;jclass&gt;(jni_env-&gt;CallObjectMethod(dex_loader_obj, loadClass_method, class_name));; 调用动态加载到的apk中类的方法:jclass entry_class = static_cast&lt;jclass&gt;(jni_env-&gt;CallObjectMethod(dex_loader_obj, loadClass_method, class_name));; 线程与JavaVM脱离:jvm-&gt;DetachCurrentThread();; java中获取context]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker简介及环境搭建]]></title>
    <url>%2F2018%2F01%2F15%2Fdocker-env-create%2F</url>
    <content type="text"><![CDATA[docker是什么Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 Docker 三个基本概念 镜像（Image）:Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 容器（Container）:镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 仓库（Repository）:镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest作为默认标签。用 Docker 的时候，需要经常从官方获取镜像，但是由于显而易见的网络原因，拉取镜像的过程非常耗时，严重影响使用 Docker 的体验。因此 DaoCloud等加速器服务商 推出了加速器工具解决这个难题，通过智能路由和缓存机制，极大提升了国内网络访问 Docker Hub 的速度，目前已经拥有了广泛的用户群体，并得到了 Docker 官方的大力推荐。如果您是在国内的网络环境使用 Docker，那么 Docker 加速器一定能帮助到您。docker常用仓库:https://hub.docker.com/explore/ docker daocloud加速器: linux:curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://311e425f.m.daocloud.io,该脚本可以将 –registry-mirror 加入到你的 Docker 配置文件 /etc/docker/daemon.json 中。适用于 Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同 Mac:右键点击桌面顶栏的 docker 图标，选择 Preferences ，在 Daemon 标签（Docker 17.03 之前版本为 Advanced 标签）下的 Registry mirrors 列表中加入下面的镜像地址:http://311e425f.m.daocloud.io,点击 Apply &amp; Restart 按钮使设置生效。 Windows: 在桌面右下角状态栏中右键 docker 图标，修改在 Docker Daemon 标签页中的 json ，把下面的地址:http://311e425f.m.daocloud.io,加到”registry-mirrors”的数组里。点击 Apply 。 环境搭建mac下安装docker官方mac的安装步骤 下载docker.dmg文件，然后点击，一步步操作 检测Docker Engine, Docker Compose, 和Docker Machine的版本: 1234567891011121314151617181920212223docker versionClient: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Tue Mar 28 00:40:02 2017 OS/Arch: darwin/amd64Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Fri Mar 24 00:00:50 2017 OS/Arch: linux/amd64 Experimental: truedocker-compose --versiondocker-compose version 1.11.2, build dfed245docker-machine --versiondocker-machine version 0.10.0, build 76ed2a6 运行官网提供的二个简单列子拉取hello-world镜像 1docker pull hello-world 查看hello-world镜像信息： 123docker images hello-worldREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest 1815c82652c0 5 days ago 1.84 kB 根据镜像生成对应容器 1docker run hello-world ps不加参数只会把当前运行的Community打印出来，查看当前所有的Community，加上-a参数。 1docker ps -a 当然也可以根据镜像生成一个具体名称的镜像，先删除当前容器 1docker rm 60 当然如果当前容器正在运行，要删除这个容器，则使用命令 1docker rm -f 60 使用镜像生成具体名称的容器： 1docker run --name miaozhihao hello-world 于更多的docker run的命令可以使用来查看 1docker run --help 第二个examples，启动docker的web服务 12docker pull nginxdocker run -d -p 80:80 --name webserver nginx -p参数是使用宿主机的80映射容器的80端口 1234567891011121314151617181920212223242526curl localhost:80&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 交互式终端方式进入 webserver容器， 1docker exec -it webserver bash 修改nginx的显示页面： 123root@41b6804c716e:/# echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.htmlroot@41b6804c716e:/# exitexit 修改了容器的文件，也就是改动了容器的存储层。我们可以通过 docker diff 123456789101112docker diff webserverC /rootA /root/.bash_historyC /runA /run/nginx.pidC /usr/share/nginx/html/index.htmlC /var/cache/nginxA /var/cache/nginx/client_tempA /var/cache/nginx/fastcgi_tempA /var/cache/nginx/proxy_tempA /var/cache/nginx/scgi_tempA /var/cache/nginx/uwsgi_temp 使用docker commit生成镜像 12docker commit --author &quot;zhihao.miao &lt;1026145686@qq.com&gt;&quot; --message &quot;修改了默认网页&quot; webserver nginx:v2sha256:0a34c054b8a826d85dddf4d1dbdd3028ab890feff4c8a0844e9b98dd146c2e07 –autho 指定作者 –message表示容器的一些信息 查看当前nginx镜像： 1234docker images nginxREPOSITORY TAG IMAGE ID CREATED SIZEnginx v2 0a34c054b8a8 11 seconds ago 109 MBnginx latest 958a7ae9e569 4 weeks ago 109 MB 查看当前所有的容器，包括运行的和停止的 1234567docker ps -a\CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES41b6804c716e nginx &quot;nginx -g &apos;daemon ...&quot; 3 minutes ago Up 3 minutes 0.0.0.0:80-&gt;80/tcp webserver85612b405cda miaozhihao001dockerhub/commit_test1 &quot;nginx -g &apos;daemon ...&quot; 20 hours ago Exited (0) 3 hours ago nginx_web9ef1fb35d7aa ubuntu:14.04 &quot;/bin/bash&quot; 20 hours ago Exited (0) 20 hours ago commit_testbf8320b9e445 ubuntu:14.04 &quot;/bin/bash&quot; 24 hours ago Exited (0) 24 hours ago sharp_curie9f9767eb8aaf hello-world &quot;/hello&quot; 10 days ago Exited (0) 10 days ago miaozhihao 启动新的容器 1234docker run --name newwebserver -d -p 80:80 nginx:v23619b34ed347cf1ae2ee3ab32c419140871f3084b9a1325ab5d8c6155d43bf06➜ curl localhost:80&lt;h1&gt;Hello, Docker!&lt;/h1&gt; 创建自己的docker镜像编辑Dockerfile文件，填入以下内容： 123FROM docker/whalesay:latestRUN apt-get -y update &amp;&amp; apt-get install -y fortunesCMD /usr/games/fortune -a | cowsay 运行以下命令创建名为docker-whale的镜像： 1docker build -t docker-whale . -t： 给tag命令 .： Dockerfile文件所在路径 docker tag push pull1docker tag 8e15421920b1 xulingfeng/docker-whale:latest 上传操作 1docker push xulingfeng/docker-whale 下载操作 1docker pull centos 交互式的操作1docker run -t -i ubuntu /bin/bash t 分配了一个终端在新的容器中 -i 允许你和容器进行交互操作 /bin/bash 启动容器中的Bash shell docker的守护状态，也就是后台运行1docker run -d ubuntu /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; docker run 运行容器 -d 让容器在后台运行 ubuntu 你希望运行容器的镜像 查看docker容器运行日志1docker logs -f 容器名 -f 类似与 tail -f 使用docker运行web应用1docker run -d -P training/webapp python app.py -d：代表后台运行该容器 -P：映射容器中的web应用端口号到你的主机上32768-61000中的某一个端口。这样你可以访问该容器中的web应用 training/webapp： 一个已经构建好的镜像，包含一个简单的python flask框架web应用 python app.py：这个命令用来启动容器中的web 成功运行以上命令后，运行： docker ps 查看到容器的5000端口号映射到了本地的32768，浏览器访问http://127.0.0.1:32768 看到helloworld 成功提示 自定义主机端口号1docker run -d -p 80:5000 training/webapp python app.py -p 80:5000 将本机的80端口绑定容器内的5000端口，本地直接访问 http://127.0.0.1 即可 查看容器的进程1docker top 容器名 检查容器的状态信息1docker inspect 容器名 镜像搜索1docker search 内容 创建一个给pycharm开发用的镜像，包含python3，Django， Flask， requests， PyMySQL， ldap3， jira，celery， simplejsoncentos镜像，分解步骤如下 首先添加额外源:yum install -y epel-release 安装编译环境:yum install -y gcc automake autoconf libtool make gcc-c++ 安装wget命令:yum install -y wget 安装openssl-devel python的pip命令依赖:yum install -y openssl-devel 下载python3.5.2最新包:wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz -P /software/ 解压python3.5.2压缩包并编译安装:tar -zxvf /software/Python-3.5.2.tgz -C /software/与./configure &amp;&amp; make -j2&amp;&amp; make install -j2 更新pip:pip install --upgrade pip与pip install --upgrade setuptools 安装所需的第三方包:pip install Django Flask requests PyMySQL ldap3 jira celery simplejson 通过Dockerfile构建镜像Dockerfile: 1234567891011FROM centos:latestRUN yum install -y epel-releaseRUN yum install -y gcc automake autoconf libtool make gcc-c++RUN yum install -y wgetRUN yum install -y openssl-develRUN wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz -P /software/RUN tar -zxvf /software/Python-3.5.2.tgz -C /software/RUN cd /software/Python-3.5.2/ &amp;&amp; ./configure python3 &amp;&amp; make -j2&amp;&amp; make install -j2RUN pip install --upgrade pipRUN pip install --upgrade setuptoolsRUN pip install Django Flask requests PyMySQL ldap3 jira celery simplejson 在Dockerfile目录中执行：docker build -t 名字:版本 . 兼容docker for mac 和 pycharm12brew install socatsocat TCP-LISTEN:2376,reuseaddr,fork,bind=127.0.0.1 UNIX-CLIENT:/var/run/docker.sock 一些docker命令总结 docker images :查看当前宿主机的所有镜像。 docker images ubuntu：根据仓库名列出镜像 docker images ubuntu:14.04:指定仓库名和标签 docker build -t webservice .:表示使用当前目录下的DockerFile来生成镜像，-t参数的值表示镜像的tagname，如果DockerFile在当前路径下则使用.，如果不在当前路径下则使用相对路径。 docker ps -a: 没有-a参数表示显示当前宿主机的正在运行的容器，加上-a表示显示当前宿主机所有的容器，包括已经退出的容器。 docker run -d -p 2222:22 –name base centos:7.1 表示根据指定的镜像后台运行容器，容器的名字是base（–name就是指定容器的名字)，centos:7.1表示镜像的名字，-p参数表示当前宿主机的2222端口对应容器的22端口。-d参数表示（Run container in background and print container ID） docker exec -it base /bin/bash 以交互式命令进入base容器并且执行/bin/bash命令 docker rmi webservice:删除webservice镜像 docker rm base: 删除base容器，如果base正在运行，则可以使用docker rm -f base进行强行删除 docker start 启动容器 docker stop 停止容器]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(六)基础之Binder]]></title>
    <url>%2F2018%2F01%2F14%2Ftips-android-pluggable-7%2F</url>
    <content type="text"></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(五)基础之用到Android源码类探讨]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-6%2F</url>
    <content type="text"><![CDATA[PackageManager获取:通过Context的getPackageManager() 常用方法: getInstalledPackages(int flags):可以得到所有安装在机器上的程序的包信息类对象List，PackageInfo类中有一值applicationInfo可以得到Application的对象。 getPackageArchiveInfo(dexPath, PackageManager.GET_ACTIVITIES | PackageManager.GET_SERVICES):取自身应用以外其他apk的信息方法 getInstalledApplications(int flags):得到所有安装在机器上的程序的application对象List； getApplicationIcon(String packageName),getApplicationIcon(ApplicationInfo info):获得应用程序的图片 getApplicationLabel(ApplicationInfo info):方法可以获得应用程序的名字]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(四)基础之文件存储]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-5%2F</url>
    <content type="text"><![CDATA[android文件存储解析安卓中提供了Context中的方法与Environment类来操作文件。 Context文件操作方法1234567891011121314public File getFileStreamPath(String name)public String[] fileList()public File getFilesDir()public File getNoBackupFilesDir()public File getExternalFilesDir(String type)public File[] getExternalFilesDirs(String type)public File getObbDir()public File[] getObbDirs()public File getCacheDir()public File getCodeCacheDir()public File getExternalCacheDir()public File[] getExternalCacheDirs()public File[] getExternalMediaDirs()public File getDir(String name, int mode) 用Log把它们都显示出来 1234567891011121314151617181920212223242526272829303132333435363738Log.d(&quot;context&quot;, &quot;context.getFileStreamPath--&gt;&quot; + this.getFileStreamPath(&quot;test&quot;).toString());Log.d(&quot;context&quot;, &quot;context.getDir--&gt;&quot; + this.getDir(&quot;test&quot;, Context.MODE_PRIVATE).toString());Log.d(&quot;context&quot;, &quot;context.getFilesDir--&gt;&quot; + this.getFilesDir().toString());Log.d(&quot;context&quot;, &quot;context.getNoBackupFilesDir&quot; + this.getNoBackupFilesDir().toString());Log.d(&quot;context&quot;, &quot;context.getCacheDir--&gt;&quot; + this.getCacheDir().toString());Log.d(&quot;context&quot;, &quot;context.getCodeCacheDir&quot; + this.getCodeCacheDir().toString());Log.d(&quot;context&quot;, &quot;context.getDatabasePath--&gt;&quot; + this.getDatabasePath(&quot;test&quot;).toString());Log.d(&quot;context&quot;, &quot;context.getObbDir--&gt;&quot; + this.getObbDir().toString());File[] files1 = this.getObbDirs();for (File file : files1) &#123; Log.d(&quot;context&quot;, &quot;context.getObbDirs--&gt;&quot; + file.toString());&#125;File[] files2 = this.getExternalMediaDirs();for (File file : files2) &#123; Log.d(&quot;context&quot;, &quot;context.getExternalMediaDirs&quot; + file.toString());&#125;Log.d(&quot;context&quot;, &quot;context.getExternalCacheDir--&gt;&quot; + this.getExternalCacheDir().toString());File[] files3 = this.getExternalCacheDirs();for (File file : files3) &#123; Log.d(&quot;context&quot;, &quot;context.getExternalCacheDirs--&gt;&quot; + file.toString());&#125;Log.d(&quot;context&quot;, &quot;context.getExternalFilesDir--&gt;&quot; + this.getExternalFilesDir(Environment.DIRECTORY_ALARMS).toString());File[] files4 = this.getExternalFilesDirs(Environment.DIRECTORY_ALARMS);for (File file : files4) &#123; Log.d(&quot;context&quot;, &quot;context.getExternalFilesDirs--&gt;&quot; + file.toString());&#125; og输出结果(不同版本的安卓系统，目录可能也不相同): 1234567891011121314context.getFileStreamPath--&gt;/data/data/cn.hufeifei.environmenttest/files/testcontext.getDir--&gt;/data/data/cn.hufeifei.environmenttest/app_testcontext.getFilesDir--&gt;/data/data/cn.hufeifei.environmenttest/filescontext.getNoBackupFilesDir/data/data/cn.hufeifei.environmenttest/no_backupcontext.getCacheDir--&gt;/data/data/cn.hufeifei.environmenttest/cachecontext.getCodeCacheDir/data/data/cn.hufeifei.environmenttest/code_cachecontext.getDatabasePath--&gt;/data/data/cn.hufeifei.environmenttest/databases/testcontext.getObbDir--&gt;/storage/emulated/0/Android/obb/cn.hufeifei.environmenttestcontext.getObbDirs--&gt;/storage/emulated/0/Android/obb/cn.hufeifei.environmenttestcontext.getExternalMediaDirs/storage/emulated/0/Android/media/cn.hufeifei.environmenttestcontext.getExternalCacheDir--&gt;/storage/emulated/0/Android/data/cn.hufeifei.environmenttest/cachecontext.getExternalCacheDirs--&gt;/storage/emulated/0/Android/data/cn.hufeifei.environmenttest/cachecontext.getExternalFilesDir--&gt;/storage/emulated/0/Android/data/cn.hufeifei.environmenttest/files/Alarmscontext.getExternalFilesDirs--&gt;/storage/emulated/0/Android/data/cn.hufeifei.environmenttest/files/Alarms Environment工具类中提供了以下几个方法：12345678Environment.getDataDirectory();Environment.getRootDirectory();Environment.getDownloadCacheDirectory();Environment.getExternalStoragePublicDirectory(String type);Environment.getExternalStorageDirectory();Environment.getExternalStorageState();Environment.getExternalStorageState(File path)Environment.getStorageState();//已被getExternalStorageState取代 1.前三个方法用Log输出来： 1234//IS标识内部存储Log.d(&quot;Environment-IS&quot;, Environment.getDataDirectory().toString());Log.d(&quot;Environment-IS&quot;, Environment.getDownloadCacheDirectory().toString());Log.d(&quot;Environment-IS&quot;, Environment.getRootDirectory().toString()); 输出结果为： 123D/Environment-IS: /dataD/Environment-IS: /cacheD/Environment-IS: /system 2.getExternalStoragePublicDirectory方法getExternalStoragePublicDirectory方法用来获取安卓外部存储中系统应用经常用到的公共文件夹， 在Environment中定义了这些文件夹的名字： 12345678910Environment.DIRECTORY_MUSIC = &quot;Music&quot;Environment.DIRECTORY_PODCASTS = &quot;Podcasts&quot;Environment.DIRECTORY_RINGTONES = &quot;Ringtones&quot;Environment.DIRECTORY_ALARMS = &quot;Alarms&quot;Environment.DIRECTORY_NOTIFICATIONS = &quot;Notifications&quot;Environment.DIRECTORY_PICTURES = &quot;Pictures&quot;Environment.DIRECTORY_MOVIES = &quot;Movies&quot;Environment.DIRECTORY_DOWNLOADS = &quot;Download&quot;Environment.DIRECTORY_DCIM = &quot;DCIM&quot;Environment.DIRECTORY_DOCUMENTS = &quot;Documents&quot; 它们的目录一般在/storage/emulated/0/ (dir_name就是Environment中定义的这些字符串常量) 3.最后的三个方法最后面三个方法是用来获取挂载点的状态(在Linux中把一些特殊目录称为所谓的挂载点，有点类似于Windows中的分区)： 1234567891011Environment.MEDIA_REMOVED;//媒体存储已经移除了Environment.MEDIA_UNMOUNTED;//存储媒体没有挂载Environment.MEDIA_CHECKING;//正在检查存储媒体Environment.MEDIA_NOFS;//存储媒体是空白或是不支持的文件系统no_file_systemEnvironment.MEDIA_MOUNTED;//存储媒体已经挂载，并且挂载点可读/写Environment.MEDIA_MOUNTED_READ_ONLY;//存储媒体已经挂载，挂载点只读Environment.MEDIA_SHARED;//存储媒体正在通过USB共享Environment.MEDIA_BAD_REMOVAL;//在没有挂载前存储媒体已经被移除Environment.MEDIA_UNMOUNTABLE;//存储媒体无法挂载,可能是文件系统损坏了Environment.MEDIA_EJECTING;//存储媒体正在移除Environment.MEDIA_UNKNOWN;//未知的存储状态 下面图片大概地概括了上面的方法 总结: Context中的方法或得到的路径都与应用包名相关* Environment中的方法与整个系统有关* /storage/sdcard0， /sdcard， /mnt/sdcard ，/storage/emulated/legacy 的区别关于android的4.2的0文件夹的详解 android 4.0在galaxy nexus（GN）手机上userdata分区很大，被挂在/data目录，用户的数据通常是放在sd卡上，然而gn是没有sd卡的，所以google想了一个办法，就是虚拟一个。 所以，在userdata分区下有个目录叫media，是内置sd卡的数据存储位置，使用fuse技术将/data/media虚拟成为一个叫做/dev/fuse的设备，为了让程序能认出来，被同时挂载在 /mnt/sdcard 目录， 又为了兼容以前的程序，做了一个快捷方式（linux系统里叫软连接） /sdcard指向的是 /mnt/sdcard . 当然，这些都是4.0的做法。 android 4.1在4.1里，同样也会使用fuse技术，/dev/fuse 会被同时挂载到/storage/sdcard0 目录，这个sdcard0表示第一个sd卡（如果有外置sd卡，那会多一个 /storage/sdcard1，比如我的xoom）， /sdcard 软连接会指向 /storage/sdcard0 ，此时/mnt/sdcard 也是个软连接，会指向/storage/sdcard0。 如果你通过otg线接U盘，会被挂载到 /storage/usb0目录，stickmount这个软件为了让图库、快图、mx player等软件，能看到u盘里的数据，又同时挂载到 /storage/sdcard0/usStorage/sda1. 也许你会问，为什么不是usb0，而是sda1，这是linux的对硬盘的命名方式，如果你的u盘有多个分区，就分别是sda1,sda2这样一直排下去了。 android 4.2谷歌是不是没事干啊，非要给android搞个多用户，你想想啊，在中国，可能因为经济问题，家里不是每人一个电脑，在美国，几乎需要用电脑的人，都会自己有一台或多台，一台电脑多人用的情况少之又少，这就是为什么叫PC了，顾名思义，个人电脑。像手机和平板这些东西，更加私人化了，很少公用了吧，我想在中国也是如此吧。 当然，谷歌也不完全是抽风，因为他有更大的战略部署，而且平板也的确有多人用的可能。 所以谷歌搞出来一个多用户，那每个人的应用、数据、个性配置都要分开吧。 应用和个性配置好弄，想想啊，通过权限控制，每人只能看自己的应用就行了，桌面也可以用自己的。 那数据怎么办？？？？ 好吧，调整用户数据的挂载结构。android 4.2，同样也会使用fuse技术/dev/fuse 会被挂载到/storage/emulated/0 目录，为什么是0呢，你还记得上边的sdcard0吧，第一个的意思。（如果有第二个，应该就是/storage/emulated/1，我们的三儿子没有外置sd卡，所以没法验证） 为了兼容以前，同时挂载到 /storage/emulated/legacy （故名思议，传统的），还建立三个软连接 /storage/sdcard0 ，/sdcard，/mnt/sdcard ，都指向 /storage/emulated/legacy 还有值得一提的是，4.2刚出来，这块变动又比较大，所以stickmount要升级到2.2之后，才可以通过otg挂载u盘了。 也许你会问，这个0和多用户有什么关系呢，那是因为多用户这个新特性，只在平板上才启用，在手机上会被禁用的。但是底层实现是一致的。 /mnt/shell/emulated 目录和 /storage/emulated 下的文件夹是一样的。（注意，这个/mnt/shell/emulated 不是挂载出来的） /mnt/shell/是为了多用户准备的，因为linux的多用户是基于shell实现的。 4.2在平板上的多用户 我前一段时间给XOOM Wifi刷上了CM10.1的4.2.1，成功开启多用户特性。新建的用户id从10开始。 默认用户的sdcard目录： /storage/emulated/0 新建的第一个用户的sdcard目录： /storage/emulated/10 新建的第二个用户的sdcard目录： /storage/emulated/11]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(四)基础之Hook]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-4%2F</url>
    <content type="text"><![CDATA[1、寻找Hook点的原则Android中主要是依靠分析系统源码类来做到的，首先我们得找到被Hook的对象，我称之为Hook点；什么样的对象比较好Hook呢？一般来说，静态变量和单例变量是相对不容易改变，是一个比较好的hook点，而普通的对象有易变的可能，每个版本都不一样，处理难度比较大。我们根据这个原则找到所谓的Hook点。 2、寻找Hook点通常点击一个Button就开始Activity跳转了，这中间发生了什么，我们如何Hook,来实现Activity启动的拦截呢？ 1234public void start(View view) &#123; Intent intent = new Intent(this, OtherActivity.class); startActivity(intent); &#125; 我们的目的是要拦截startActivity方法，跟踪源码，发现最后启动Activity是由Instrumentation类的execStartActivity做到的。其实这个类相当于启动Activity的中间者，启动Activity中间都是由它来操作的 1234567891011121314151617181920212223public ActivityResult execStartActivity( Context who, IBinder contextThread, IBinder token, Activity target, Intent intent, int requestCode, Bundle options) &#123; IApplicationThread whoThread = (IApplicationThread) contextThread; .... try &#123; intent.migrateExtraStreamToClipData(); intent.prepareToLeaveProcess(who); //通过ActivityManagerNative.getDefault()获取一个对象，开始启动新的Activity int result = ActivityManagerNative.getDefault() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); checkStartActivityResult(result, intent); &#125; catch (RemoteException e) &#123; throw new RuntimeException(&quot;Failure from system&quot;, e); &#125; return null; &#125; 对于ActivityManagerNative这个东东，熟悉Activity/Service启动过程的都不陌生 1public abstract class ActivityManagerNative extends Binder implements IActivityManager 继承了Binder，实现了一个IActivityManager接口，这就是为了远程服务通信做准备的”Stub”类，一个完整的AID L有两部分，一个是个跟服务端通信的Stub,一个是跟客户端通信的Proxy。ActivityManagerNative就是Stub,阅读源码发现在ActivityManagerNative 文件中还有个ActivityManagerProxy，这里就多不扯了。 123static public IActivityManager getDefault() &#123; return gDefault.get();&#125; ActivityManagerNative.getDefault()获取的是一个IActivityManager对象，由IActivityManager去启动Activity，IActivityManager的实现类是ActivityManagerService，ActivityManagerService是在另外一个进程之中，所有Activity 启动是一个跨进程的通信的过程，所以真正启动Activity的是通过远端服务ActivityManagerService来启动的。 123456789101112private static final Singleton&lt;IActivityManager&gt; gDefault = new Singleton&lt;IActivityManager&gt;() &#123; protected IActivityManager create() &#123; IBinder b = ServiceManager.getService(&quot;activity&quot;); if (false) &#123; Log.v(&quot;ActivityManager&quot;, &quot;default service binder = &quot; + b); &#125; IActivityManager am = asInterface(b); if (false) &#123; Log.v(&quot;ActivityManager&quot;, &quot;default service = &quot; + am); &#125; return am; &#125; 实gDefalut借助Singleton实现的单例模式，而在内部可以看到先从ServiceManager中获取到AMS远端服务的Binder对象，然后使用asInterface方法转化成本地化对象，我们目的是拦截startActivity,所以改变IActivityManager对象可以做到这个一点，这里gDefault又是静态的，根据Hook原则，这是一个比较好的Hook点。 3、Hook掉startActivity，输出日志我们先实现一个小需求，启动Activity的时候打印一条日志，写一个工具类HookUtil。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class HookUtil &#123; private Class&lt;?&gt; proxyActivity; private Context context; public HookUtil(Class&lt;?&gt; proxyActivity, Context context) &#123; this.proxyActivity = proxyActivity; this.context = context; &#125; public void hookAms() &#123; //一路反射，直到拿到IActivityManager的对象 try &#123; Class&lt;?&gt; ActivityManagerNativeClss = Class.forName(&quot;android.app.ActivityManagerNative&quot;); Field defaultFiled = ActivityManagerNativeClss.getDeclaredField(&quot;gDefault&quot;); defaultFiled.setAccessible(true); Object defaultValue = defaultFiled.get(null); //反射SingleTon Class&lt;?&gt; SingletonClass = Class.forName(&quot;android.util.Singleton&quot;); Field mInstance = SingletonClass.getDeclaredField(&quot;mInstance&quot;); mInstance.setAccessible(true); //到这里已经拿到ActivityManager对象 Object iActivityManagerObject = mInstance.get(defaultValue); //开始动态代理，用代理对象替换掉真实的ActivityManager，瞒天过海 Class&lt;?&gt; IActivityManagerIntercept = Class.forName(&quot;android.app.IActivityManager&quot;); AmsInvocationHandler handler = new AmsInvocationHandler(iActivityManagerObject); Object proxy = Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class&lt;?&gt;[]&#123;IActivityManagerIntercept&#125;, handler); //现在替换掉这个对象 mInstance.set(defaultValue, proxy); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private class AmsInvocationHandler implements InvocationHandler &#123; private Object iActivityManagerObject; private AmsInvocationHandler(Object iActivityManagerObject) &#123; this.iActivityManagerObject = iActivityManagerObject; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Log.i(&quot;HookUtil&quot;, method.getName()); //我要在这里搞点事情 if (&quot;startActivity&quot;.contains(method.getName())) &#123; Log.e(&quot;HookUtil&quot;,&quot;Activity已经开始启动&quot;); Log.e(&quot;HookUtil&quot;,&quot;小弟到此一游！！！&quot;); &#125; return method.invoke(iActivityManagerObject, args); &#125; &#125;&#125; 结合注释应该很容易看懂，在Application中配置一下 123456789public class MyApplication extends Application &#123; @Override public void onCreate() &#123; super.onCreate(); HookUtil hookUtil=new HookUtil(SecondActivity.class, this); hookUtil.hookAms()； &#125;&#125; 可以看到，我们成功的Hook掉了startActivity，输出了一条日志。有了上面的基础，现在我们开始来点有用的东西，Activity不用在清单文件中注册，就可以启动起来，这个怎么搞呢？ 4、无需注册，启动Activity如下，TargetActivity没有在清单文件中注册，怎么去启动TargetActivity？ 1234public void start(View view) &#123; Intent intent = new Intent(this, TargetActivity.class); startActivity(intent); &#125; 这个思路可以是这样，上面已经拦截了启动Activity流程，在invoke中我们可以得到启动参数intent信息，那么就在这里，我们可以自己构造一个假的Activity信息的intent，这个Intent启动的Activity是在清单文件中注册的，当真正启动的时候（ActivityManagerService校验清单文件之后），用真实的Intent把代理的Intent在调换过来，然后启动即可。 首先获取真实启动参数intent信息 1234567891011121314151617181920212223242526@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (&quot;startActivity&quot;.contains(method.getName())) &#123; //换掉 Intent intent = null; int index = 0; for (int i = 0; i &lt; args.length; i++) &#123; Object arg = args[i]; if (arg instanceof Intent) &#123; //说明找到了startActivity的Intent参数 intent = (Intent) args[i]; //这个意图是不能被启动的，因为Acitivity没有在清单文件中注册 index = i; &#125; &#125; //伪造一个代理的Intent，代理Intent启动的是proxyActivity Intent proxyIntent = new Intent(); ComponentName componentName = new ComponentName(context, proxyActivity); proxyIntent.setComponent(componentName); proxyIntent.putExtra(&quot;oldIntent&quot;, intent); args[index] = proxyIntent; &#125; return method.invoke(iActivityManagerObject, args); &#125; 有了上面的两个步骤,这个代理的Intent是可以通过ActivityManagerService检验的，因为我在清单文件中注册过 1&lt;activity android:name=&quot;.ProxyActivity&quot; /&gt; 为了不启动ProxyActivity，现在我们需要找一个合适的时机，把真实的Intent换过了来，启动我们真正想启动的Activity。看过Activity的启动流程的朋友，我们都知道这个过程是由Handler发送消息来实现的，可是通过Handler处理消息的代码来看，消息的分发处理是有顺序的，下面是Handler处理消息的代码: 123456789101112public void dispatchMessage(Message msg) &#123; if (msg.callback != null) &#123; handleCallback(msg); &#125; else &#123; if (mCallback != null) &#123; if (mCallback.handleMessage(msg)) &#123; return; &#125; &#125; handleMessage(msg); &#125; &#125; handler处理消息的时候，首先去检查是否实现了callback接口，如果有实现的话，那么会直接执行接口方法，然后才是handleMessage方法，最后才是执行重写的handleMessage方法，我们一般大部分时候都是重写了handleMessage方法,而ActivityThread主线程用的正是重写的方法，这种方法的优先级是最低的，我们完全可以实现接口来替换掉系统Handler的处理过程。 12345678910111213141516171819202122public void hookSystemHandler() &#123; try &#123; Class&lt;?&gt; activityThreadClass = Class.forName(&quot;android.app.ActivityThread&quot;); Method currentActivityThreadMethod = activityThreadClass.getDeclaredMethod(&quot;currentActivityThread&quot;); currentActivityThreadMethod.setAccessible(true); //获取主线程对象 Object activityThread = currentActivityThreadMethod.invoke(null); //获取mH字段 Field mH = activityThreadClass.getDeclaredField(&quot;mH&quot;); mH.setAccessible(true); //获取Handler Handler handler = (Handler) mH.get(activityThread); //获取原始的mCallBack字段 Field mCallBack = Handler.class.getDeclaredField(&quot;mCallback&quot;); mCallBack.setAccessible(true); //这里设置了我们自己实现了接口的CallBack对象 mCallBack.set(handler, new ActivityThreadHandlerCallback(handler)) ; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 自定义Callback类 12345678910111213141516171819202122232425262728293031323334353637private class ActivityThreadHandlerCallback implements Handler.Callback &#123; private Handler handler; private ActivityThreadHandlerCallback(Handler handler) &#123; this.handler = handler; &#125; @Override public boolean handleMessage(Message msg) &#123; Log.i(&quot;HookAmsUtil&quot;, &quot;handleMessage&quot;); //替换之前的Intent if (msg.what ==100) &#123; Log.i(&quot;HookAmsUtil&quot;,&quot;lauchActivity&quot;); handleLauchActivity(msg); &#125; handler.handleMessage(msg); return true; &#125; private void handleLauchActivity(Message msg) &#123; Object obj = msg.obj;//ActivityClientRecord try&#123; Field intentField = obj.getClass().getDeclaredField(&quot;intent&quot;); intentField.setAccessible(true); Intent proxyInent = (Intent) intentField.get(obj); Intent realIntent = proxyInent.getParcelableExtra(&quot;oldIntent&quot;); if (realIntent != null) &#123; proxyInent.setComponent(realIntent.getComponent()); &#125; &#125;catch (Exception e)&#123; Log.i(&quot;HookAmsUtil&quot;,&quot;lauchActivity falied&quot;); &#125; &#125; &#125; 最后在application中注入 12345678910public class MyApplication extends Application &#123; @Override public void onCreate() &#123; super.onCreate(); //这个ProxyActivity在清单文件中注册过，以后所有的Activitiy都可以用ProxyActivity无需声明，绕过监测 HookAmsUtil hookAmsUtil = new HookAmsUtil(ProxyActivity.class, this); hookAmsUtil.hookSystemHandler(); hookAmsUtil.hookAms(); &#125;&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(三)基础之Android应用程序资源的编译和打包过程分析]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-3%2F</url>
    <content type="text"><![CDATA[Android Apk打包流程 打包资源文件,生成R.java文件; 处理aidl文件,生成相应java文件; 编译工程源文件,生成相应class文件; 转换所有class文件,生成classes.dex文件; 打包生成apk文件; 对apk文件进行签名; 对签名后的apk文件进行对齐处理; 打包过程使用的工具 名称 功能介绍 在操作系统中的路径 源码路径 aapt（Android Asset Package Tool） Android资源打包工具 ${ANDROID_SDK_HOME} /build-tools/ ANDROID_VERSION/aapt frameworks\base\tools\aap aidl（android interface definition language） Android接口描述语言，将aidl转化为.java文件的工具 ${ANDROID_SDK_HOME}/build-tools/ ANDROID_VERSION/aidl frameworks\base\tools\aidl javac Java Compiler ${JDK_HOME}/javac或/usr/bin/javac dex 转化.class文件为Davik VM能识别的.dex文件 ${ANDROID_SDK_HOME}/build-tools/ ANDROID_VERSION/dx apkbuilder 生成apk包 ${ANDROID_SDK_HOME}/tools/apkbuilder sdk\sdkmanager\libs\sdklib\ src\com\android\sdklib\build\ApkBuilderMain.java jarsigner .jar文件的签名工具 ${JDK_HOME}/jarsigner或/usr/bin/jarsigner zipalign 字节码对齐工具 ${ANDROID_SDK_HOME}/tools和/zipalign 第一步: 打包资源文件,生成R.java文件【输入】Resource文件（就是工程中res中的文件）、Assets文件（相当于另外一种资源，这种资源Android系统并不像对res中的文件那样优化它）、AndroidManifest.xml文件（包名就是从这里读取的，因为生成R.java文件需要包名）、Android基础类库（Android.jar文件） 【工具】aapt工具 【输出】打包好的资源（bin目录中的resources.ap文件）、R.java文件（gen目录中） 打包资源的工具aapt，大部分文本格式的XML资源文件会被编译成二进制格式的XML资源文件，除了assets和res/raw资源被原装不动地打包进APK之外，其它的资源都会被编译或者处理。 。 生成过程主要是调用了aapt源码目录下的Resource.cpp文件中的buildResource（）函数，该函数首先检查AndroidManifest.xml的合法性，然后对res目录下的资源子目录进行处理，处理的函数为makeFileResource（），处理的内容包括资源文件名的合法性检查，向资源表table添加条目等，处理完后调用compileResourceFile（）函数编译res与asserts目录下的资源并生成resources.arsc文件，compileResourceFile（）函数位于aapt源码目录的ResourceTable.cpp文件中，该函数最后会调用parseAndAddEntry（）函数生成R.java文件，完成资源编译后，接下来调用compileXmlfile()函数对res目录的子目录下的xml文件分别进行编译，这样处理过的xml文件就简单的被“加密”了，最后将所有的资源与编译生成的resorces.arsc文件以及“加密”过的AndroidManifest.xml文件打包压缩成resources.ap文件（使用Ant工具命令行编译则会生成与build.xml中“project name”指定的属性同名的ap_文件）。 关于这一步更详细的流程可阅读http://blog.csdn.net/luoshengyang/article/details/8744683 res目录有9种目录 –animator。这类资源以XML文件保存在res/animator目录下，用来描述属性动画。 –anim。这类资源以XML文件保存在res/anim目录下，用来描述补间动画。 –color。这类资源以XML文件保存在res/color目录下，用描述对象颜色状态选择子。 –drawable。这类资源以XML或者Bitmap文件保存在res/drawable目录下，用来描述可绘制对象。例如，我们可以在里面放置一些图片（.png, .9.png, .jpg, .gif），来作为程序界面视图的背景图。注意，保存在这个目录中的Bitmap文件在打包的过程中，可能会被优化的。例如，一个不需要多于256色的真彩色PNG文件可能会被转换成一个只有8位调色板的PNG面板，这样就可以无损地压缩图片，以减少图片所占用的内存资源。 –layout。这类资源以XML文件保存在res/layout目录下，用来描述应用程序界面布局。 –menu。这类资源以XML文件保存在res/menu目录下，用来描述应用程序菜单。 –raw。这类资源以任意格式的文件保存在res/raw目录下，它们和assets类资源一样，都是原装不动地打包在apk文件中的，不过它们会被赋予资源ID，这样我们就可以在程序中通过ID来访问它们。例如，假设在res/raw目录下有一个名称为filename的文件，并且它在编译的过程，被赋予的资源ID为R.raw.filename，那么就可以使用以下代码来访问它：Resources res = getResources(); InputStream is = res .openRawResource(R.raw.filename); –values。这类资源以XML文件保存在res/values目录下，用来描述一些简单值，例如，数组、颜色、尺寸、字符串和样式值等，一般来说，这六种不同的值分别保存在名称为arrays.xml、colors.xml、dimens.xml、strings.xml和styles.xml文件中。 –xml。这类资源以XML文件保存在res/xml目录下，一般就是用来描述应用程序的配置信息。 第二步：处理aidl文件，生成相应的java文件。输入】源码文件、aidl文件、framework.aidl文件 【工具】aidl工具 【输出】对应的.java文件 对于没有使用到aidl的android工程，这一步可以跳过。aidl工具解析接口定义文件并生成相应的java代码供程序调用。 第三步：编译工程源代码，生成下相应的class文件。【输入】源码文件（包括R.java和AIDL生成的.java文件）、库文件（.jar文件） 【工具】javac工具 【输出】.class文件 这一步调用了javac编译工程src目录下所有的java源文件，生成的class文件位于工程的bin\classes目录下，上图假定编译工程源代码时程序是基于android SDK开发的，实际开发过程中，也有可能会使用android NDK来编译native代码，因此，如果可能的话，这一步还需要使用android NDK编译C/C++代码，当然，编译C/C++代码的步骤也可以提前到第一步或第二步。 第四步：转换所有的class文件，生成classes.dex文件。【输入】 .class文件（包括Aidl生成.class文件，R生成的.class文件，源文件生成的.class文件），库文件（.jar文件） 【工具】javac工具 【输出】.dex文件 前面多次提到，android系统dalvik虚拟机的可执行文件为dex格式，程序运行所需的classes.dex文件就是在这一步生成的，使用的工具为dx，dx工具主要的工作是将java字节码转换为dalvik字节码、压缩常量池、消除冗余信息等。 第五步：打包生成apk。【输入】打包后的资源文件、打包后类文件（.dex文件）、libs文件（包括.so文件，当然很多工程都没有这样的文件，如果你不使用C/C++开发的话） 【工具】apkbuilder工具 【输出】未签名的.apk文件 打包工具为apkbuilder，apkbuilder为一个脚本文件，实际调用的是android-sdk\tools\lib\sdklib.jar文件中的com.android.sdklib.build.ApkBuilderMain类。它的代码实现位于android系统源码的sdk\sdkmanager\libs\sdklib\src\com\android\sdklib\build\ApkBuilderMain.java文件，代码构建了一个ApkBuilder类，然后以包含resources.arsc的文件为基础生成apk文件，这个文件一般为ap_结尾，接着调用addSourceFolder()函数添加工程资源，addSourceFolder()会调用processFileForResource（）函数往apk文件中添加资源，处理的内容包括res目录与asserts目录中的文件，添加完资源后调用addResourceFromJar（）函数往apk文件中写入依赖库，接着调用addNativeLibraries()函数添加工程libs目录下的Native库（通过android NDK编译生成的so或bin文件），最后调用sealApk（）关闭apk文件。 第六步：对apk文件进行签名。【输入】未签名的.apk文件 【工具】jarsigner 【输出】签名的.apk文件 android的应用程序需要签名才能在android设备上安装，签名apk文件有两种情况：一种是在调试程序时进行签名，使用eclipse开发android程序时，在编译调试程序时会自己使用一个debug.keystore对apk进行签名；另一种是打包发布时对程序进行签名，这种情况下需要提供一个符合android开发文档中要求的签名文件。签名的方法也分两种：一种是使用jdk中提供的jarsigner工具签名；另一种是使用android源码中提供的signapk工具，它的代码位于android系统源码build\tools\signapk目录下。 第七步：对签名后的apk文件进行对齐处理。【输入】签名后的.apk文件 【工具】zipalign工具 【输出】对齐后的.apk文件 这一步需要使用的工具为zipalign，它位于android-sdk\tools目录，源码位于android系统源码的build\tools\zipalign目录，它的主要工作是将spk包进行对齐处理，使spk包中的所有资源文件距离文件起始偏移为4字节整数倍，这样通过内存映射访问apk文件时速度会更快，验证apk文件是否对齐过的工作由ZipAlign.cpp文件的verify()函数完成，处理对齐的工作则由process（）函数完成。 以一个具体项目中包含的具体文件为例作图如下： APK文件内容解析android的项目经过编译和打包，形成了: .dex 文件 resources.arsc uncompiled resources AndroidManifest.xml 解压一个普通的apk文件,解压出来的文件如下: META-INF文件夹 res文件夹 AndroidManifest.xml classes.dex resources.arsc classes.dex 是.dex文件。 resources.arsc是resources resources文件。 AndroidManifest.xml是AndroidManifest.xml文件。 res是uncompiled resources。 META-INF是签名文件夹。 META-INF其中有三个文件： CERT.RSA CERT.SF MANIFEST.MF MANIFEST.MF文件 版本号以及每一个文件的哈希值（BASE64）。包括资源文件。这个是对每个文件的整体进行SHA1(hash)。 12345678Manifest-Version: 1.0Built-By: Generated-by-ADTCreated-By: Android Gradle 2.2.0Name: res/drawable-xhdpi-v4/abc_scrubber_control_to_pressed_mtrl_005.pngSHA1-Digest: I9s6aQ5VyOLrNo4odqSij549Oyo=Name: res/drawable-mdpi-v4/abc_textfield_search_default_mtrl_alpha.9.pngSHA1-Digest: D6dilO+UMcglambujyMOhNbLZuY=…… CERT.SF 这个是对每个文件的头3行进行SHA1 hash。 123456789Signature-Version: 1.0X-Android-APK-Signed: 2SHA1-Digest-Manifest: QxOfCCAuQtZnHh0YRNnoxmiHT80=Created-By: 1.0 (Android)Name: res/drawable-xhdpi-v4/abc_scrubber_control_to_pressed_mtrl_005.pngSHA1-Digest: I9s6aQ5VyOLrNo4odqSij549Oyo=Name: res/drawable-mdpi-v4/abc_textfield_search_default_mtrl_alpha.9.pngSHA1-Digest: D6dilO+UMcglambujyMOhNbLZuY=…… CERT.RSA 这个文件保存了签名和公钥证书。 插件化中资源冲突解决如果需要宿主、插件之间使用同一套资源管理器，那么我们需要将插件的资源路径添加到宿主的AssetManager中。 我们知道，apk包括代码和资源，在apk编译过程中，dex工具将代码打包成.dex文件，资源文件会由aapt工具生成对应的ID，aapt在打包的时候组织成resources.arsc文件，resources.arsc文件是用来描述资源ID和资源位置配置信息，从18个维度描述了一个资源ID的配置信息（语言、分辨率等），就是资源ID和资源的索引表。资源的ID生成是有规则的，规则：0xPPTTNNNN，由8位16进制组成，其中： PP段：表示资源的包空间：0x01表示系统资源空间，0x7f表示应用资源空间。 TT段：表示资源类型。 NNNN段：4个16进制表示资源id，一个apk中同一类型资源从0000开始递增。 例如： 123456789nt anim pop_dialog_in 0x7f040000int anim pop_dialog_out 0x7f040001int anim slide_left_in 0x7f040002int anim slide_left_out 0x7f040003int anim slide_right_in 0x7f040004int anim slide_right_out 0x7f040005int anim update_loading_progressbar_anim 0x7f040006int array indicator_tab_icon 0x7f050001int array indicator_tab_titlt 0x7f050000 现在问题来了，宿主apk和插件apk是独立编译出来的两个独立的apk，那么其中就有资源ID相同的情况出现，从而产生资源ID冲突。如何解决这个问题？看了一些开源框架，解决的办法就是修改资源ID的PP段，大体有两种做法： 修改aapt源码，定制aapt工具编译期间修改PP段。 DynamicAPK的做法就是如此，定制aapt，替换google的原始aapt，在编译的时候可以传入参数修改PP段：例如传入0x05编译得到的资源的PP段就是0x05。个人觉得这个做法不是太灵活，入侵了原有的开发编译流程，不好维护。 修改aapt的产物，即，编译后期重新整理插件Apk的资源，编排ID。 前面说过apk编译之后会生成ID以及对应的索引表resorce.arsc，那么我们能不能后期修改相关ID及索引表呢？答案是肯定的，个人比较赞同这种思路，不用入侵原有编译流程。 插件可能是 Apk 也可能是 so 格式，不管哪一种，都不会生成 R.id ，从而没办法使用。这个问题有好几种解决方案。一种是是重写 Context 的 getAsset 、 getResource 之类的方法，偷换概念，让插件读取插件里的资源，但缺点就是宿主和插件的资源 id 会冲突，需要重写 AAPT 。另一种是重写 AMS中保存的插件列表，从而让宿主和插件分别去加载各自的资源而不会冲突。第三种方法，就是打包后，执行一个脚本，修改生成包中资源id。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(三)基础之反射与代理]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-2%2F</url>
    <content type="text"><![CDATA[1.反射反射机制中的类： java.lang.Class; java.lang.reflect.Constructor; java.lang.reflect.Field; java.lang.reflect.Method; java.lang.reflect.Modifier; 获取Class的三种方式: 12345678910/第一种方式： Classc1 = Class.forName(&quot;Employee&quot;); //第二种方式： //java中每个类型都有class 属性. Classc2 = Employee.class; //第三种方式： //java语言中任何一个java对象都有getClass 方法 Employeee = new Employee(); Classc3 = e.getClass(); //c3是运行时类 (e的运行时类是Employee) 创建对象 1234Class c =Class.forName(&quot;Employee&quot;); //创建此Class 对象所表示的类的一个新实例 Objecto = c.newInstance(); //调用了Employee的无参数构造方法. 获取属性：分为所有的属性和指定的属性 12345678910111213141516171819202122232425262728293031323334//获取整个类 Class c = Class.forName(&quot;java.lang.Integer&quot;); //获取所有的属性? Field[] fs = c.getDeclaredFields(); //定义可变长的字符串，用来存储属性 StringBuffer sb = new StringBuffer(); //通过追加的方法，将每个属性拼接到此字符串中 //最外边的public定义 sb.append(Modifier.toString(c.getModifiers()) + &quot; class &quot; + c.getSimpleName() +&quot;&#123;\n&quot;); //里边的每一个属性 for(Field field:fs)&#123; sb.append(&quot;\t&quot;);//空格 sb.append(Modifier.toString(field.getModifiers())+&quot; &quot;);//获得属性的修饰符，例如public，static等等 sb.append(field.getType().getSimpleName() + &quot; &quot;);//属性的类型的名字 sb.append(field.getName()+&quot;;\n&quot;);//属性的名字+回车 &#125; sb.append(&quot;&#125;&quot;); System.out.println(sb); //获取特定属性//获取类 Class c = Class.forName(&quot;User&quot;); //获取id属性 Field idF = c.getDeclaredField(&quot;id&quot;); //实例化这个类赋给o Object o = c.newInstance(); //打破封装 idF.setAccessible(true); //使用反射机制可以打破封装性，导致了java对象的属性不安全。 //给o对象的id属性赋值&quot;110&quot; idF.set(o, &quot;110&quot;); //set //get System.out.println(idF.get(o)); 关键字 方法关键字 含义 getDeclaredMethods() 获取所有的方法 getReturnType() 获得方法的放回类型 getParameterTypes() 获得方法的传入参数类型 getDeclaredMethod(“方法名”,参数类型.class,……) 获得特定的方法 构造方法关键字 含义 getDeclaredConstructors() 获取所有的构造方法 getDeclaredConstructor(参数类型.class,……) 获取特定的构造方法 父类和父接口 含义 getSuperclass() 获取某类的父类 getInterfaces() 获取某类实现的接口 2.代理模式定义：给某个对象提供一个代理对象，并由代理对象控制对于原对象的访问，即客户不直接操控原对象，而是通过代理对象间接地操控原对象。 RealSubject 是原对象（本文把原对象称为”委托对象”），Proxy 是代理对象。 Subject 是委托对象和代理对象都共同实现的接口。 Request() 是委托对象和代理对象共同拥有的方法。 Java 实现上面的UML图的代码（即实现静态代理）为： 1234567891011121314151617181920212223242526272829public class ProxyDemo &#123; public static void main(String args[])&#123; RealSubject subject = new RealSubject(); Proxy p = new Proxy(subject); p.request(); &#125;&#125;interface Subject&#123; void request();&#125;class RealSubject implements Subject&#123; public void request()&#123; System.out.println(&quot;request&quot;); &#125;&#125;class Proxy implements Subject&#123; private Subject subject; public Proxy(Subject subject)&#123; this.subject = subject; &#125; public void request()&#123; System.out.println(&quot;PreProcess&quot;); subject.request(); System.out.println(&quot;PostProcess&quot;); &#125;&#125; 代理的实现分为： 静态代理：代理类是在编译时就实现好的。也就是说 Java 编译完成后代理类是一个实际的 class 文件。 动态代理：代理类是在运行时生成的。也就是说 Java 编译完之后并没有实际的 class 文件，而是在运行时动态生成的类字节码，并加载到JVM中。 2.1Java 实现动态代理首先先说明几个词： 委托类和委托对象：委托类是一个类，委托对象是委托类的实例。 代理类和代理对象：代理类是一个类，代理对象是代理类的实例。 Java实现动态代理的大致步骤如下： 定义一个委托类和公共接口。 自己定义一个类（调用处理器类，即实现 InvocationHandler 接口），这个类的目的是指定运行时将生成的代理类需要完成的具体任务（包括Preprocess和Postprocess），即代理类调用任何方法都会经过这个调用处理器类（在本文最后一节对此进行解释）。 生成代理对象（当然也会生成代理类），需要为他指定(1)委托对象(2)实现的一系列接口(3)调用处理器类的实例。因此可以看出一个代理对象对应一个委托对象，对应一个调用处理器实例。 Java 实现动态代理主要涉及以下几个类： java.lang.reflect.Proxy: 这是生成代理类的主类，通过 Proxy 类生成的代理类都继承了 Proxy 类，即 DynamicProxyClass extends Proxy。 java.lang.reflect.InvocationHandler: 这里称他为”调用处理器”，他是一个接口，我们动态生成的代理类需要完成的具体内容需要自己定义一个类，而这个类必须实现 InvocationHandler 接口。 Proxy 类主要方法为： 12//创建代理对象 static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) 这个静态函数的第一个参数是类加载器对象（即哪个类加载器来加载这个代理类到 JVM 的方法区），第二个参数是接口（表明你这个代理类需要实现哪些接口），第三个参数是调用处理器类实例（指定代理类中具体要干什么）。这个函数是 JDK 为了程序员方便创建代理对象而封装的一个函数，因此你调用newProxyInstance()时直接创建了代理对象（略去了创建代理类的代码）。其实他主要完成了以下几个工作： 123456789static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler handler)&#123; //1. 根据类加载器和接口创建代理类 Class clazz = Proxy.getProxyClass(loader, interfaces); //2. 获得代理类的带参数的构造函数 Constructor constructor = clazz.getConstructor(new Class[] &#123; InvocationHandler.class &#125;); //3. 创建代理对象，并制定调用处理器实例为参数传入 Interface Proxy = (Interface)constructor.newInstance(new Object[] &#123;handler&#125;);&#125; Proxy 类还有一些静态方法，比如： 12InvocationHandler getInvocationHandler(Object proxy): 获得代理对象对应的调用处理器对象。Class getProxyClass(ClassLoader loader, Class[] interfaces): 根据类加载器和实现的接口获得代理类。 Proxy 类中有一个映射表，映射关系为：(,(,) )，可以看出一级key为类加载器，根据这个一级key获得二级映射表，二级key为接口数组，因此可以看出：一个类加载器对象和一个接口数组确定了一个代理类。 我们写一个简单的例子来阐述 Java 实现动态代理的整个过程： 123456789101112131415161718192021222324252627282930313233343536373839404142public class DynamicProxyDemo01 &#123; public static void main(String[] args) &#123; RealSubject realSubject = new RealSubject(); //1.创建委托对象 ProxyHandler handler = new ProxyHandler(realSubject); //2.创建调用处理器对象 Subject proxySubject = (Subject)Proxy.newProxyInstance(RealSubject.class.getClassLoader(), RealSubject.class.getInterfaces(), handler); //3.动态生成代理对象 proxySubject.request(); //4.通过代理对象调用方法 &#125;&#125;/** * 接口 */interface Subject&#123; void request();&#125;/** * 委托类 */class RealSubject implements Subject&#123; public void request()&#123; System.out.println(&quot;====RealSubject Request====&quot;); &#125;&#125;/** * 代理类的调用处理器 */class ProxyHandler implements InvocationHandler&#123; private Subject subject; public ProxyHandler(Subject subject)&#123; this.subject = subject; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;====before====&quot;);//定义预处理的工作，当然你也可以根据 method 的不同进行不同的预处理工作 Object result = method.invoke(subject, args); System.out.println(&quot;====after====&quot;); return result; &#125;&#125; InvocationHandler 接口中有方法： 1invoke(Object proxy, Method method, Object[] args) 这个函数是在代理对象调用任何一个方法时都会调用的，方法不同会导致第二个参数method不同，第一个参数是代理对象（表示哪个代理对象调用了method方法），第二个参数是 Method 对象（表示哪个方法被调用了），第三个参数是指定调用方法的参数。 动态生成的代理类具有几个特点： 继承 Proxy 类，并实现了在Proxy.newProxyInstance()中提供的接口数组。 public final。 命名方式为 $ProxyN，其中N会慢慢增加，一开始是 $Proxy1，接下来是$Proxy2… 有一个参数为 InvocationHandler 的构造函数。这个从 Proxy.newProxyInstance() 函数内部的clazz.getConstructor(new Class[] { InvocationHandler.class }) 可以看出。 Java 实现动态代理的缺点：因为 Java 的单继承特性（每个代理类都继承了 Proxy 类），只能针对接口创建代理类，不能针对类创建代理类。 不难发现，代理类的实现是有很多共性的（重复代码），动态代理的好处在于避免了这些重复代码，只需要关注操作。 2.2Java 动态代理的内部实现现在我们就会有一个问题： Java 是怎么保证代理对象调用的任何方法都会调用 InvocationHandler 的 invoke() 方法的？ 这就涉及到动态代理的内部实现。假设有一个接口 Subject，且里面有 int request(int i) 方法，则生成的代理类大致如下： 1234567891011public final class $Proxy1 extends Proxy implements Subject&#123; private InvocationHandler h; private $Proxy1()&#123;&#125; public $Proxy1(InvocationHandler h)&#123; this.h = h; &#125; public int request(int i)&#123; Method method = Subject.class.getMethod(&quot;request&quot;, new Class[]&#123;int.class&#125;); //创建method对象 return (Integer)h.invoke(this, method, new Object[]&#123;new Integer(i)&#125;); //调用了invoke方法 &#125;&#125; 通过上面的方法就成功调用了 invoke() 方法。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(二)基础之类加载器]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable-1%2F</url>
    <content type="text"><![CDATA[1.什么是ClassLoader当我们写好一个Java程序之后，不是管是CS还是BS应用，都是由若干个.class文件组织而成的一个完整的Java应用程序，当程序在运行时，即会调用该程序的一个入口函数来调用系统的相关功能，而这些功能都被封装在不同的class文件当中，所以经常要从这个class文件中要调用另外一个class文件中的方法，如果另外一个文件不存在的，则会引发系统异常。而程序在启动的时候，并不会一次性加载程序所要用的所有class文件，而是根据程序的需要，通过Java的类加载机制（ClassLoader）来动态加载某个class文件到内存当中的，从而只有class文件被载入到了内存之后，才能被其它class所引用。所以ClassLoader就是用来动态加载class文件到内存当中用的。 2.Java ClassLoader2.1.Java默认提供的三个ClassLoader BootStrap ClassLoader： 称为启动类加载器，是Java类加载层次中最顶层的类加载器，负责加载JDK中的核心类库，如：rt.jar、resources.jar、charsets.jar等，可通过如下程序获得该类加载器从哪些地方加载了相关的jar或class文件：1234URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs(); for (int i = 0; i &lt; urls.length; i++) &#123; System.out.println(urls[i].toExternalForm()); &#125; 以下内容是上述程序从本机JDK环境所获得的结果： 12345678file:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/resources.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/rt.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/sunrsasign.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jsse.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jce.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/charsets.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jfr.jarfile:/Applications/Android%20Studio.app/Contents/jre/jdk/Contents/Home/jre/classes 其实上述结果也是通过查找sun.boot.class.path这个系统属性所得知的。 1System.out.println(System.getProperty(&quot;sun.boot.class.path&quot;)); 打印结果: 1/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/resources.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/rt.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/sunrsasign.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jsse.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jce.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/charsets.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/lib/jfr.jar:/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home/jre/classes Extension ClassLoader： 称为扩展类加载器，负责加载Java的扩展类库，默认加载JAVA_HOME/jre/lib/ext/目下的所有jar。 App ClassLoader： 称为系统类加载器，负责加载应用程序classpath目录下的所有jar和class文件。 除了Java默认提供的三个ClassLoader之外，用户还可以根据需要定义自已的ClassLoader，而这些自定义的ClassLoader都必须继承自java.lang.ClassLoader类，也包括Java提供的另外二个ClassLoader（Extension ClassLoader和App ClassLoader）在内，但是Bootstrap ClassLoader不继承自ClassLoader，因为它不是一个普通的Java类，底层由C++编写，已嵌入到了JVM内核当中，当JVM启动后，Bootstrap ClassLoader也随着启动，负责加载完核心类库后，并构造Extension ClassLoader和App ClassLoader类加载器。 2.2ClassLoader加载类的原理ClassLoader使用的是双亲委托模型来搜索类的，每个ClassLoader实例都有一个父类加载器的引用（不是继承的关系，是一个包含的关系），虚拟机内置的类加载器（Bootstrap ClassLoader）本身没有父类加载器，但可以用作其它ClassLoader实例的的父类加载器。当一个ClassLoader实例需要加载某个类时，它会试图亲自搜索某个类之前，先把这个任务委托给它的父类加载器，这个过程是由上至下依次检查的，首先由最顶层的类加载器Bootstrap ClassLoader试图加载，如果没加载到，则把任务转交给Extension ClassLoader试图加载，如果也没加载到，则转交给App ClassLoader 进行加载，如果它也没有加载得到的话，则返回给委托的发起者，由它到指定的文件系统或网络等URL中加载该类。如果它们都没有加载到这个类时，则抛出ClassNotFoundException异常。否则将这个找到的类生成一个类的定义，并将它加载到内存当中，最后返回这个类在内存中的Class实例对象。 这样可以避免重复加载，当父亲已经加载了该类的时候，就没有必要子ClassLoader再加载一次。考虑到安全因素，我们试想一下，如果不使用这种委托模式，那我们就可以随时使用自定义的String来动态替代java核心api中定义的类型，这样会存在非常大的安全隐患，而双亲委托的方式，就可以避免这种情况，因为String已经在启动时就被引导类加载器（Bootstrcp ClassLoader）加载，所以用户自定义的ClassLoader永远也无法加载一个自己写的String，除非你改变JDK中ClassLoader搜索类的默认算法。 JVM在判定两个class是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM才认为这两个class是相同的。就算两个class是同一份class字节码，如果被两个不同的ClassLoader实例所加载，JVM也会认为它们是两个不同class。比如网络上的一个Java类org.classloader.simple.NetClassLoaderSimple，javac编译之后生成字节码文件NetClassLoaderSimple.class，ClassLoaderA和ClassLoaderB这两个类加载器并读取了NetClassLoaderSimple.class文件，并分别定义出了java.lang.Class实例来表示这个类，对于JVM来说，它们是两个不同的实例对象，但它们确实是同一份字节码文件，如果试图将这个Class实例生成具体的对象进行转换时，就会抛运行时异常java.lang.ClassCaseException，提示这是两个不同的类型。现在通过实例来验证上述所描述的是否正确: 在web服务器上建一个org.classloader.simple.NetClassLoaderSimple.java类12345678910package org.classloader.simple; public class NetClassLoaderSimple &#123; private NetClassLoaderSimple instance; public void setNetClassLoaderSimple(Object obj) &#123; this.instance = (NetClassLoaderSimple)obj; &#125; &#125; org.classloader.simple.NetClassLoaderSimple类的setNetClassLoaderSimple方法接收一个Object类型参数，并将它强制转换成org.classloader.simple.NetClassLoaderSimple类型。 测试两个class是否相同 NetWorkClassLoader.java:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package classloader;import java.io.ByteArrayOutputStream;import java.io.InputStream;import java.net.URL;/** * 加载网络class的ClassLoader */public class NetworkClassLoader extends ClassLoader &#123; private String rootUrl; public NetworkClassLoader(String rootUrl) &#123; this.rootUrl = rootUrl; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class clazz = null;//this.findLoadedClass(name); // 父类已加载 //if (clazz == null) &#123; //检查该类是否已被加载过 byte[] classData = getClassData(name); //根据类的二进制名称,获得该class文件的字节码数组 if (classData == null) &#123; throw new ClassNotFoundException(); &#125; clazz = defineClass(name, classData, 0, classData.length); //将class的字节码数组转换成Class类的实例 //&#125; return clazz; &#125; private byte[] getClassData(String name) &#123; InputStream is = null; try &#123; String path = classNameToPath(name); URL url = new URL(path); byte[] buff = new byte[1024*4]; int len = -1; is = url.openStream(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); while((len = is.read(buff)) != -1) &#123; baos.write(buff,0,len); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (is != null) &#123; try &#123; is.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125; private String classNameToPath(String name) &#123; return rootUrl + &quot;/&quot; + name.replace(&quot;.&quot;, &quot;/&quot;) + &quot;.class&quot;; &#125;&#125; 12345678910111213141516171819202122package classloader; public class NewworkClassLoaderTest &#123; public static void main(String[] args) &#123; try &#123; //测试加载网络中的class文件 String rootUrl = &quot;http://localhost:8080/httpweb/classes&quot;; String className = &quot;org.classloader.simple.NetClassLoaderSimple&quot;; NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); NetworkClassLoader ncl2 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Class&lt;?&gt; clazz2 = ncl2.loadClass(className); Object obj1 = clazz1.newInstance(); Object obj2 = clazz2.newInstance(); clazz1.getMethod(&quot;setNetClassLoaderSimple&quot;, Object.class).invoke(obj1, obj2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; 首先获得网络上一个class文件的二进制名称，然后通过自定义的类加载器NetworkClassLoader创建两个实例，并根据网络地址分别加载这份class，并得到这两个ClassLoader实例加载后生成的Class实例clazz1和clazz2，最后将这两个Class实例分别生成具体的实例对象obj1和obj2，再通过反射调用clazz1中的setNetClassLoaderSimple方法。 结果抛出java.lang.ClassCastgException,虽然是同一份class字节码文件，但是由于被两个不同的ClassLoader实例所加载，所以JVM认为它们就是两个不同的类。 2.3ClassLoader的体系架构： 打印ClassLoader类的层次结构: 123456ClassLoader loader = ClassLoaderTest.class.getClassLoader(); //获得加载ClassLoaderTest.class这个类的类加载器 while(loader != null) &#123; System.out.println(loader); loader = loader.getParent(); //获得父类加载器的引用 &#125; System.out.println(loader); 输出: 123sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@1540e19dnull 第一行结果说明：ClassLoaderTest的类加载器是AppClassLoader。 第二行结果说明：AppClassLoader的类加器是ExtClassLoader，即parent=ExtClassLoader。 第三行结果说明：ExtClassLoader的类加器是Bootstrap ClassLoader，因为Bootstrap ClassLoader不是一个普通的Java类，所以ExtClassLoader的parent=null，所以第三行的打印结果为null就是这个原因。 将ClassLoaderTest.class打包成ClassLoaderTest.jar，放到Extension ClassLoader的加载目录下（JAVA_HOME/jre/lib/ext）可以测试Extension ClassLoader 在jvm中添加-Xbootclasspath参数，指定Bootstrcp ClassLoader加载类的路径，并追加我们自已的jar（ClassTestLoader.jar）或 将class文件放到JAVA_HOME/jre/classes/目录下测试用Bootstrcp ClassLoader加载ClassLoaderTest.class. 2.4定义自己的ClassLoader:因为Java中提供的默认ClassLoader，只加载指定目录下的jar和class，如果我们想加载其它位置的类或jar时，比如：我要加载网络上的一个class文件，通过动态加载到内存之后，要调用这个类中的方法实现我的业务逻辑。在这样的情况下，默认的ClassLoader就不能满足我们的需求了，所以需要定义自己的ClassLoader。 定义自已的类加载器分为两步： 继承java.lang.ClassLoader 重写父类的findClass方法 参考:深入探讨 Java 类加载器 3.Android ClassLoaderAndroid ClassLoader种类： DexClassLoader：可以加载文件系统上的jar、dex、apk PathClassLoader：可以加载/data/app目录下的apk，这也意味着，它只能加载已经安装的apk URLClassLoader：可以加载java中的jar，但是由于dalvik不能直接识别jar，所以此方法在android中无法使用 Android开发和普通的java开发不同的地方是把class文件再重新打包成dex类型的文件，这种重新打包会对Class文件内部的各种函数表、变量表等进行优化。dex文件是一种经过android打包工具优化后的Class文件，因此加载这样特殊的Class文件就需要特殊的类装载器，所以android中提供了DexClassLoader类。加载流程如下： 通过PacageMangager获得指定的apk的安装的目录，dex的解压缩目录，c/c++库的目录 创建一个 DexClassLoader实例 加载指定的类返回一个Class 然后使用反射调用这个Class]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android插件化(一)技术调研]]></title>
    <url>%2F2018%2F01%2F12%2Ftips-android-pluggable%2F</url>
    <content type="text"><![CDATA[前言有关APK更新的技术比较多，例如：增量更新、插件式开发、热修复、RN、静默安装。 下面简单介绍一下： 更新方式 签名 增量更新 旧版本Apk（v1.0）和新（v2.0）、旧版本Apk（v1.0）生成的差分包（apk.patch 质量小）合并成为新版本Apk（v2.0）安装。 插件式开发 给宿主APK提供插件，扩展（需要的时候再下载），可以动态地替换。主要技术是动态代理的知识。 热修复 通过NDK底层去修复，也是C/C++的技术。 RN 通过JS脚本去修复APK。 静默安装 需要root权限，适配不同手机ROM很麻烦。 插件化、热修复（思想）的发展历程 2012年7月，AndroidDynamicLoader，大众点评，陶毅敏：思想是通过Fragment以及schema的方式实现的，这是一种可行的技术方案，但是还有限制太多，这意味这你的activity必须通过Fragment去实现，这在activity跳转和灵活性上有一定的不便，在实际的使用中会有一些很奇怪的bug不好解决，总之，这还是一种不是特别完备的动态加载技术。 2013年，23Code，自定义控件的动态下载：主要利用 Java ClassLoader 的原理，可动态加载的内容包括 apk、dex、jar等。 2014年初，Altas，阿里伯奎的技术分享：提出了插件化的思想以及一些思考的问题，相关资料比较少。 2014年底，Dynamic-load-apk，任玉刚：动态加载APK，通过Activity代理的方式给插件Activity添加生命周期。 2015年4月，OpenAltas/ACCD：Altas的开源项目，一款强大的Android非代理动态部署框架，目前已经处于稳定状态。 2015年8月，DroidPlugin，360的张勇：DroidPlugin 是360手机助手在 Android 系统上实现了一种新的插件机制：通过Hook思想来实现，它可以在无需安装、修改的情况下运行APK文件,此机制对改进大型APP的架构，实现多团队协作开发具有一定的好处。 2015年9月，AndFix，阿里：通过NDK的Hook来实现热修复。 2015年11月，Nuwa，大众点评：通过dex分包方案实现热修复。 2015年底，Small，林光亮：打通了宿主与插件之间的资源与代码共享。 2016年4月，ZeusPlugin，掌阅：ZeusPlugin最大特点是：简单易懂，核心类只有6个，类总数只有13个。 1.增量更新增量更新就是原有app的基础上只更新发生变化的地方，其余保持原样。 与原来每次更新都要下载完整apk包的做法相比，这样做的好处显而易见：每次变化的地方总是比较少，因此更新包的体积就会小很多。 1.1增量更新的流程 APP检测最新版本：把当前版本告诉服务端，服务端进行判断。 如果有新版本，服务端需要对当前版本的APK与最新版本的APK进行一次差分，产生patch差分文件。（或者新版本的APK上传到服务端的时候就已经差分好了） APP在后台下载差分文件，进行文件的MD5校验，在本地进行合并（跟本地的data目录下面的APK文件合并），合并出最新的APK之后，提示用户安装。 增量更新的最终目的：省流量地更新宿主APK。 差分的处理比较麻烦的地方就是要针对不同的应用市场渠道和众多不同版本进行差分。 注意：新版本有可能比旧版本小，差分只是把变化的部分记录下来。 1.2服务器端行为（后台工程师操作）1.2.1下载拆分和合并要用的第三方库（bsdiff、bzip2）我们使用到的第三方库是：Binary diff，简称bsdiff，这个库专门用来实现文件的差分和合并的，它的官网如下：http://www.daemonology.net/bsdiff/ 1.2.2Java代码调用:创建Web项目，用来做APP的服务端。创建工具类专门用于产生差分包： 12345678910111213public class BsDiff &#123; /** * 差分 * @param oldfile * @param newfile * @param patchfile */ public native static void diff(String oldfile,String newfile,String patchfile); static &#123; System.loadLibrary(&quot;bsdiff&quot;); &#125;&#125; 其中JNI的实现如下（该实现写在bsdiff.cpp中）： 1234567891011121314151617181920JNIEXPORT void JNICALL Java_com_haocai_bsdiff_BsDiff_diff(JNIEnv *env, jclass jcls, jstring oldfile_jstr, jstring newfile_jstr, jstring patchfile_jstr) &#123; int argc = 4; char* oldfile = (char*)env-&gt;GetStringUTFChars(oldfile_jstr, NULL); char* newfile = (char*)env-&gt;GetStringUTFChars(newfile_jstr, NULL); char* patchfile = (char*)env-&gt;GetStringUTFChars(patchfile_jstr, NULL); //参数(第一个参数无效) char *argv[4]; argv[0] = &#123; &quot;bsdiff&quot; &#125;; argv[1] = oldfile; argv[2] = newfile; argv[3] = patchfile; bsdiff_main(argc, argv); env-&gt;ReleaseStringUTFChars(oldfile_jstr, oldfile); env-&gt;ReleaseStringUTFChars(newfile_jstr, newfile); env-&gt;ReleaseStringUTFChars(patchfile_jstr, patchfile);&#125;; 通过研究bsdiff的源码，我们发现bsdiff.cpp里面的main函数就是入口函数，避免歧义把函数名main改为bsdiff_main，然后通过JNI去调用。根据bsdiff.cpp中bsdiff_main函数方法中有以下关键语句 1if (argc != 4) errx(1, &quot;usage: %s oldfile newfile patchfile\n&quot;, argv[0]); 根据提示需要传入4个参数： 1234argv[0] = &quot;bsdiff&quot;;//这个参数没用argv[1] = oldPath;//旧APK文件路径argv[2] = newPath;/新APK文件路径argv[3] = patchPath;//APK差分文件路径 然后我们准备两个APK文件，不同版本的，最好Java代码、资源都不一样。 写一个Java测试类生成差分包： 1234567891011package com.haocai.bsdiff;public class ConstantsWin &#123; //路径不能包含中文 public static final String OLD_APK_PATH = &quot;D:/android_apks/test_old.apk&quot;; public static final String NEW_APK_PATH = &quot;D:/android_apks/test_new.apk&quot;; public static final String PATCH_PATH = &quot;D:/android_apks/apk.patch&quot;;&#125; 1234567891011package com.haocai.bsdiff;/** * Created by Administrator on 2017/11/14. */public class BsDiffTest &#123; public static void main(String[] args)&#123; //得到差分包 BsDiff.diff(ConstantsWin.OLD_APK_PATH,ConstantsWin.NEW_APK_PATH,ConstantsWin.PATCH_PATH); &#125;&#125; 注意: test_new.apk、test_old.apk 要先放在目标目录 bsdiff.cpp中生成差分包的程序方法是异步的，所以生成完整的apk.patch可能要等一下。apk.patch体积大小停止增长，表示生成结束。1.2.3简单搭建后台JavaWeb供Android前端下载apk.patch差分包 1.3Android客户端行为1.3.1编译合并要用的第三方库（bsdiff、bzip2）对应的Java代码如下： 1234567891011121314151617181920package com.haocai.app.update;/** * Created by Xionghu on 2017/11/14. * Desc: */public class BsPatch &#123; /** * 合并 * @param oldfile * @param newfile * @param patchfile */ public native static void patch(String oldfile,String newfile,String patchfile); static &#123; System.loadLibrary(&quot;bspatch&quot;); &#125;&#125; 在Android端，我们需要把bzip2以及bsdiff的文件拷贝到jni目录里面，同样的，我们只需要编译一个bspatch.c源文件即可。 12345678910111213141516171819202122//合并JNIEXPORT void JNICALL Java_com_haocai_app_update_BsPatch_patch (JNIEnv *env, jclass jcls, jstring oldfile_jstr, jstring newfile_jstr, jstring patchfile_jstr)&#123; int argc = 4; char* oldfile = (char*)(*env)-&gt;GetStringUTFChars(env,oldfile_jstr, NULL); char* newfile = (char*)(*env)-&gt;GetStringUTFChars(env,newfile_jstr, NULL); char* patchfile = (char*)(*env)-&gt;GetStringUTFChars(env,patchfile_jstr, NULL); //参数（第一个参数无效） char *argv[4]; argv[0] = &quot;bspatch&quot;; argv[1] = oldfile; argv[2] = newfile; argv[3] = patchfile; bspatch_main(argc,argv); (*env)-&gt;ReleaseStringUTFChars(env,oldfile_jstr, oldfile); (*env)-&gt;ReleaseStringUTFChars(env,newfile_jstr, newfile); (*env)-&gt;ReleaseStringUTFChars(env,patchfile_jstr, patchfile); &#125; 代码v1.0差分包合并核心代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144package com.haocai.app.update;import android.Manifest;import android.content.pm.PackageManager;import android.os.Handler;import android.os.Message;import android.support.annotation.NonNull;import android.support.annotation.Nullable;import android.support.v4.app.ActivityCompat;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;import android.text.format.Formatter;import android.widget.Toast;import com.lzy.okgo.OkGo;import com.lzy.okgo.callback.FileCallback;import com.lzy.okgo.model.Progress;import com.lzy.okgo.model.Response;import com.lzy.okgo.request.base.Request;import java.io.File;import java.text.NumberFormat;public class MainActivity extends AppCompatActivity &#123; private static final int REQUEST_PERMISSION_STORAGE = 0x01; private Handler mHandler = new Handler() &#123; @Override public void handleMessage(Message msg) &#123; super.handleMessage(msg); switch (msg.what) &#123; case 0: Toast.makeText(MainActivity.this, &quot;您正在进行省流量更新&quot;, Toast.LENGTH_SHORT).show(); ApkUtils.installApk(MainActivity.this, Constants.NEW_APK_PATH); break; &#125; &#125; &#125;; private NumberFormat numberFormat; @Override protected void onCreate(@Nullable Bundle savedInstanceState) &#123; super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); setTitle(&quot;简单文件下载&quot;); numberFormat = NumberFormat.getPercentInstance(); numberFormat.setMinimumFractionDigits(2); checkSDCardPermission(); /** * 因为后台没有写版本判断语句 * 在高版本下暂时先注释fileDownload(); 否则一直下载安装 * * 低版本下运行fileDownload(); */ fileDownload(); &#125; /** * 检查SD卡权限 */ protected void checkSDCardPermission() &#123; if (ActivityCompat.checkSelfPermission(this, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) &#123; ActivityCompat.requestPermissions(this, new String[]&#123;Manifest.permission.WRITE_EXTERNAL_STORAGE&#125;, REQUEST_PERMISSION_STORAGE); &#125; &#125; @Override public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) &#123; super.onRequestPermissionsResult(requestCode, permissions, grantResults); if (requestCode == REQUEST_PERMISSION_STORAGE) &#123; if (grantResults.length &gt; 0 &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) &#123; //获取权限 fileDownload(); &#125; else &#123; Toast.makeText(getApplicationContext(), &quot;权限被禁止，无法下载文件！&quot;, Toast.LENGTH_SHORT).show(); &#125; &#125; &#125; @Override protected void onDestroy() &#123; super.onDestroy(); //Activity销毁时，取消网络请求 OkGo.getInstance().cancelTag(this); &#125; public void fileDownload() &#123; OkGo.&lt;File&gt;get(Constants.URL_PATCH_DOWNLOAD)// .tag(this)// .execute(new FileCallback(Constants.SD_CARD, Constants.PATCH_FILE) &#123; @Override public void onStart(Request&lt;File, ? extends Request&gt; request) &#123; &#125; @Override public void onSuccess(Response&lt;File&gt; response) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // File patchFile = new File(Constants.SD_CARD, Constants.PATCH_FILE); String oldfile = ApkUtils.getSourceApkPath(MainActivity.this, getPackageName()); String newfile = Constants.NEW_APK_PATH; String patchfile = Constants.SD_CARD + File.separator + Constants.PATCH_FILE; BsPatch.patch(oldfile, newfile, patchfile); mHandler.sendEmptyMessage(0); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; @Override public void onError(Response&lt;File&gt; response) &#123; &#125; @Override public void downloadProgress(Progress progress) &#123; System.out.println(progress); String downloadLength = Formatter.formatFileSize(getApplicationContext(), progress.currentSize); String totalLength = Formatter.formatFileSize(getApplicationContext(), progress.totalSize); String speed = Formatter.formatFileSize(getApplicationContext(), progress.speed); System.out.println(downloadLength); &#125; &#125;); &#125;&#125; 注意：这里7.0可能会有问题，把路径暴露给别的app，需要FileProvider去实现（不难，这个留给大家去做吧）。 源码下载 作者: (简书)香沙小熊 2.插件化插件化框架的一些对比，下面引用 https://github.com/wequick/Small/blob/master/Android/COMPARISION.md 特性 DynamicLoadApk DynamicAPK Small DroidPlugin VirtualAPK RePlugin 支持四大组件 只支持Activity 只支持Activity 只支持Activity 全支持 全支持 全支持 组件无需在宿主manifest中预注册 √ × √ √ √ √ 插件可以依赖宿主 √ √ √ × √ √ 支持PendingIntent × × × √ √ √ Android特性支持 大部分 大部分 大部分 几乎全部 几乎全部 几乎全部 兼容性适配 一般 一般 中等 高 高 高 插件构建 无 部署aapt Gradle插件 无 Gradle插件 Gradle插件 源码 https://github.com/singwhatiwanna/dynamic-load-apk https://github.com/CtripMobile/DynamicAPK https://github.com/wequick/Small https://github.com/DroidPluginTeam/DroidPlugin https://github.com/didi/VirtualAPK https://github.com/Qihoo360/RePlugin 开发者 singwhatiwanna CtripMobile Lody 滴滴 360 2.1DynamicLoadApk基于静态代理的实现 2.2VirtualAPK2.2.1特性 Feature Detail Supported components Activity, Service, Receiver and Provider Manually register components in AndroidManifest.xml No need Access host app classes and resources Supported PendingIntent Supported Supported Android features Almost all features Compatibility Almost all devices Building system Gradle plugin Supported Android versions API Level 15+ 2.2.2架构 2.2.3原理2.2.3.1基本原理 合并宿主和插件的ClassLoader 需要注意的是，插件中的类不可以和宿主重复 合并插件和宿主的资源 重设插件资源的packageId，将插件资源和宿主资源合并 去除插件包对宿主的引用 构建时通过Gradle插件去除插件对宿主的代码以及资源的引用2.2.3.2四大组件的实现原理 Activity 采用宿主manifest中占坑的方式来绕过系统校验，然后再加载真正的activity； Service 动态代理AMS，拦截service相关的请求，将其中转给Service Runtime去处理，Service Runtime会接管系统的所有操作； Receiver 将插件中静态注册的receiver重新注册一遍； ContentProvider 动态代理IContentProvider，拦截provider相关的请求，将其中转给Provider Runtime去处理，Provider Runtime会接管系统的所有操作。 2.3RePlugin2.3.1特性 特性 描述 组件 四大组件（含静态Receiver） 升级无需改主程序Manifest 完美支持 Android特性 支持近乎所有（包括SO库等） TaskAffinity &amp; 多进程 支持（坑位方案） 插件类型 支持自带插件（自识别）、外置插件 插件间耦合 支持Binder、Class Loader、资源等 进程间通讯 支持同步、异步、Binder、广播等 自定义Theme &amp; AppComat 支持 DataBinding 支持 安全校验 支持 资源方案 独立资源 + Context传递（相对稳定） Android 版本 API Level 9+ （2.3及以上） 2.3.2架构]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>Pluggable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(转)聊一聊机器学习的MLE和MAP:最大似然估计和最大后验估计]]></title>
    <url>%2F2018%2F01%2F08%2Ftips-ml-mle-map%2F</url>
    <content type="text"><![CDATA[TLDR (or the take away) 概率学派 - Frequentist - Maximum Likelihood Estimation(MLE,最大似然估计) 贝叶斯学派 - Baysesian - Maximum A Posteriori(MAP, 最大后验估计) 概述有时候和别人聊天，对方会说自己有很多机器学习经验，深入一聊发现，对方竟然对MLE和MAP一知半解，至少在我看来，这位同学的机器学习基础并不扎实。难道在这个深度学习盛行的年代，不少同学都只注重调参数？ 现代机器学习的终极问题都会转化为解目标函数的优化问题，MLE和MAP是生成这个函数的很基本的思想，因此我们对二者的认知是非常重要的。这次就和大家认真聊一聊MLE和MAP这两种estimator。 两大学派的争论抽象一点来讲，频率学派和贝叶斯学派对世界的认知有本质不同：频率学派认为世界是确定的，有一个本体，这个本体的真值是不变的，我们的目标就是要找到这个真值或真值所在的范围；而贝叶斯学派认为世界是不确定的，人们对世界先有一个预判，而后通过观测数据对这个预判做调整，我们的目标是要找到最优的描述这个世界的概率分布。 在对事物建模时，用 θ 表示模型的参数，请注意，解决问题的本质就是求θ 。那么： (1) 频率学派： 存在唯一真值 θ 。举一个简单直观的例子–抛硬币，我们用 P(head) 来表示硬币的bias。抛一枚硬币100次，有20次正面朝上，要估计抛硬币正面朝上的bias P(head)=θ。在频率学派来看，θ = 20 / 100 = 0.2，很直观。当数据量趋于无穷时，这种方法能给出精准的估计；然而缺乏数据时则可能产生严重的偏差。例如，对于一枚均匀硬币，即 θ = 0.5，抛掷5次，出现5次正面 (这种情况出现的概率是1/2^5=3.125%)，频率学派会直接估计这枚硬币 θ = 1，出现严重错误。 (2) 贝叶斯学派： θ 是一个随机变量，符合一定的概率分布。在贝叶斯学派里有两大输入和一大输出，输入是先验 (prior)和似然 (likelihood)，输出是后验 (posterior)。先验，即 P(θ) ，指的是在没有观测到任何数据时对 θ 的预先判断，例如给我一个硬币，一种可行的先验是认为这个硬币有很大的概率是均匀的，有较小的概率是是不均匀的；似然，即 P(X|θ) ，是假设 θ 已知后我们观察到的数据应该是什么样子的；后验，即 P(θ|X) ，是最终的参数分布。贝叶斯估计的基础是贝叶斯公式，如下： $P(\theta|X)=\frac{P(X|\theta) \times P(\theta)}{P(X)}$ 同样是抛硬币的例子，对一枚均匀硬币抛5次得到5次正面，那么 P(head) ，即 P(θ|X) ，是一个distribution，最大值会介于0.5~1之间，而不是武断的 θ = 1。 这里有两点值得注意的地方： 随着数据量的增加，参数分布会越来越向数据靠拢，先验的影响力会越来越小 如果先验是uniform distribution，则贝叶斯方法等价于频率方法。因为直观上来讲，先验是uniform distribution本质上表示对事物没有任何预判 MLE - 最大似然估计Maximum Likelihood Estimation, MLE是频率学派常用的估计方法！ 假设数据 x_1, x_2, …, x_n 是i.i.d.的一组抽样，X = (x_1, x_2, …, x_n) 。其中i.i.d.表示Independent and identical distribution，独立同分布。那么MLE对 $\theta$ 的估计方法可以如下推导： Maximum Likelihood Estimation, MLE是频率学派常用的估计方法！ 假设数据 x_1, x_2, …, x_n 是i.i.d.的一组抽样，X = (x_1, x_2, …, x_n) 。其中i.i.d.表示Independent and identical distribution，独立同分布。那么MLE对 $\theta$ 的估计方法可以如下推导： 最后这一行所优化的函数被称为Negative Log Likelihood (NLL)，这个概念和上面的推导是非常重要的！ 我们经常在不经意间使用MLE，例如 上文中关于频率学派求硬币概率的例子，其方法其实本质是由优化NLL得出。本文末尾附录中给出了具体的原因 :-) 给定一些数据，求对应的高斯分布时，我们经常会算这些数据点的均值和方差然后带入到高斯分布的公式，其理论依据是优化NLL 深度学习做分类任务时所用的cross entropy loss，其本质也是MLE MAP - 最大后验估计Maximum A Posteriori, MAP是贝叶斯学派常用的估计方法！ 同样的，假设数据 x_1, x_2, …, x_n 是i.i.d.的一组抽样，X = (x_1, x_2, …, x_n) 。那么MLE对 $\theta$ 的估计方法可以如下推导： 其中，第二行到第三行使用了贝叶斯定理，第三行到第四行P(X) 可以丢掉因为与 $\theta$ 无关。注意 $-\log P(X|\theta )$ 其实就是NLL，所以MLE和MAP在优化时的不同就是在于先验项 - $\log P(\theta) $。好的，那现在我们来研究一下这个先验项，假定先验是一个高斯分布，即 $P(\theta) = \text{constant} \times e^{-\frac{\theta^2}{2\sigma^2}}$ 那么， $-\log P(\theta) = \text{constant} + \frac{\theta^2}{2\sigma^2} $。至此，一件神奇的事情发生了 – 在MAP中使用一个高斯分布的先验等价于在MLE中采用L2的regularizaton！ 再稍微补充几点： 我们不少同学大学里学习概率论时，最主要的还是频率学派的思想，其实贝叶斯学派思想也非常流行，而且实战性很强 CMU的很多老师都喜欢用贝叶斯思想解决问题；我本科时的导师朱军老师也在做贝叶斯深度学习的工作，有兴趣可以关注一下。 后记有的同学说：“了解这些没用，现在大家都不用了。”这种想法是不对的，因为这是大家常年在用的知识，是推导优化函数的核心，而优化函数又是机器学习 (包含深度学习) 的核心之一。这位同学有这样的看法，说明对机器学习的本质并没有足够的认识，而让我吃惊的是，竟然有不少其他同学为这种看法点赞。内心感到有点儿悲凉，也引发了我写这篇文章的动力，希望能帮到一些朋友 :-) 参考资料 [1] Bayesian Method Lecture, UT Dallas. [2] MLE, MAP, Bayes classification Lecture, CMU. 附录为什么说频率学派求硬币概率的算法本质是在优化NLL？ 因为抛硬币可以表示为参数为 $\theta$ 的Bernoulli分布，即 $P(x_i; \theta) =\left{ \begin{array}{ll} \theta &amp; x_i = 1 \ 1 - \theta &amp; x_i = 0 \ \end{array} \right. \ = \theta^{x_i} (1- \theta)^{1-x_i}$ 其中 x_i = 1 表示第 i 次抛出正面。那么， $\text{NLL} = -\sum_{i=1}^n \log P(xi; \theta) = -\sum{i=1}^n \log \theta^{x_i} (1- \theta)^{1-x_i}$ 求导数并使其等于零，得到 $\text{NLL}’ = -\sum_{i=1}^n\Big(\frac{x_i}{\theta} + (1-x_i)\frac{-1}{1-\theta}\Big) = 0$ 即 $\hat{\theta} = \frac{\sum_{i=1}^n x_i}{n}$ ，也就是出现正面的次数除以总共的抛掷次数。 转自聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tips</tag>
        <tag>ml</tag>
        <tag>reprint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习资源]]></title>
    <url>%2F2017%2F12%2F29%2Ftips-ml-res%2F</url>
    <content type="text"><![CDATA[deep-voice-conversion:Deep neural networks for voice conversion (voice style transfer) in Tensorflow Prisma Prisma shifts focus to b2b with an API for AI-powered mobile effects Prisma 团队推出基于人工智能的贴纸制作应用 Sticky Prisma launches a social feed to see if style can transfer into a platform]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>tips</tag>
        <tag>ml</tag>
        <tag>res</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FLV格式解析]]></title>
    <url>%2F2017%2F12%2F20%2Fm-f-flv%2F</url>
    <content type="text"><![CDATA[简介FLV（Flash Video）是现在非常流行的流媒体格式，由于其视频文件体积轻巧、封装播放简单等特点，使其很适合在网络上进行应用，目前主流的视频网站无一例外地使用了FLV格式。另外由于当前浏览器与Flash Player紧密的结合，使得网页播放FLV视频轻而易举，也是FLV流行的原因之一。 FLV是流媒体封装格式，我们可以将其数据看为二进制字节流。总体上看，FLV包括文件头（File Header）和文件体（File Body）两部分，其中文件体由一系列的Tag及Tag Size对组成。 FLV格式解析先来一张图，这是《科比退役演讲》下载）的一个FLV视频。我使用的是UltraEdit的二进制查看工具。 header头部分由一下几部分组成 Signature(3 Byte)+Version(1 Byte)+Flags(1 Bypte)+DataOffset(4 Byte) signature 占3个字节 固定FLV三个字符作为标示。一般发现前三个字符为FLV时就认为他是flv文件。图中0x46 0x4C 0x56,代表FLV Version 占1个字节 标示FLV的版本号。这里我们看到是1 Flags 占1个字节 内容标示。第0位和第2位,分别表示 video 与 audio 存在的情况.(1表示存在,0表示不存在)。截图看到是0x05，也就是00000101，代表既有视频，也有音频。 DataOffset 4个字节 表示FLV的header长度。这里可以看到固定是9 BodyFLV的body部分是一系列的back-pointers+tag构成的 back-pointers固定4个字节,表示前一个tag的size tag分三种类型:video,audio,scripts. tag组成1tag type+tag data size+Timestamp+TimestampExtended+stream id+ tag data type 1个字节。8为Audio,9为Video,18为scripts tag data size 3个字节。表示tag data的长度。从streamd id 后算起。 Timestreamp 3个字节。时间戳 TimestampExtended 1个字节。时间戳扩展字段 stream id 3个字节。总是0 tag data 数据部分 图上第一个tag: type=0x12=18,表示是一个scripts,FLV中,header后的第一个tag是script tag,script tag内容是amf格式数据,包含两个amf. size=0x00 0x01 0x74 = 372 timpestreamp = 0x00 0x00 0x00 TimestampExtended=0x00 streamid=0x00 0x00 0x00 tag data部分: tag的划分图中红色部分是我标出”(“与”)”前后的的两个back-pointers，都是4个字节。而括号中间就是第一个TAG。那是怎么计算的呢？我们就以这个做个示例。 首先第一个back-pointers是0x00000000，那是因为后面是第一个TAG。所以他为0。 然后根据我们我们前面格式获取到size是0x00 0x01 0x74 = 372。也就是说从stream id后面再加上372个字节就到了第一个TAG的末尾，我们数一下。tag header有11个字节。那么到第一个TAG，总共有372+11=383=0x17f。 接下来我们找到0x17f的地址，从工具上很容易找到，正好就是后括号”)”的前面。红0x00 0x00 0x01 0x7F=372，这代表的是上一个TAG的大小。 最后我们计算一下，上一个TAG数据部分是372个字节，前面type、stream id等字段占了11个字节。正好是匹配的。 上面我们已经知道了怎么取划分每个TAG。接下来我们就看TAG的具体内容: tag的内容前面已经提到tag分3种。我们一个个看 script脚本Tag一般只有一个，是flv的第一个Tag，用于存放flv的信息，比如duration、audiodatarate、creator、width等。 首先介绍下脚本的数据类型。所有数据都是以数据类型+（数据长度）+数据的格式出现的，数据类型占1byte，数据长度看数据类型是否存在，后面才是数据。 一般来说，该Tag Data结构包含两个AMF包。AMF（Action Message Format）是Adobe设计的一种通用数据封装格式，在Adobe的很多产品中应用，简单来说，AMF将不同类型的数据用统一的格式来描述。第一个AMF包封装字符串类型数据，用来装入一个“onMetaData”标志，这个标志与Adobe的一些API调用有，在此不细述。第二个AMF包封装一个数组类型(srs返回为object类型)，这个数组中包含了音视频信息项的名称和值。具体说明如下 值 类型 说明 0 Number type 8 Bypte Double 1 Boolean type 1 Bypte bool 2 String type 后面2个字节为长度 3 Object type 4 MovieClip type 5 Null type 6 Undefined type 7 Reference type 8 ECMA array type 数组,类似Map 10 Strict array type 11 Date type 12 Long string type 后面4个字节为长度 上图为第一个AMF包 type=0x02对应String size=0A=10 value=onMetaData 正好是10个字节。 上图为第二个AMF type=0x08 对应ECMA array type。 表示数组，类似Map。后面4个字节为数组的个数。然后是键值对，第一个为键，2个字节为长度。后面跟具体的内容。接着3个字节表示值的类型，然后根据类型判断长度。 上图我们可以判断，总共有13个键值对。 第一个长度为8个字节是duration。值类型是0x004073，第一个字节是00，所以是double，8个字节。 第二个长度5个字节是width。值也是double类型，8个字节。 依次解析下去… Audio 视频中第二个tag为音频tag stream-id之后: 前4位为音频格式 值 类型 0 Linear PCM, platform endian 1 ADPCM 2 MP3 3 Linear PCM, little endian 4 Nellymoser 16-kHz mono 5 Nellymoser 8-kHz mono 6 Nellymoser 7 G.711 A-law logarithmic PCM 8 G.711 mu-law logarithmic PCM 9 reserved 10 AAC 11 Speex 14 MP3 8-Khz 15 Device-specific sound 接着2位为采样率(对于AAC总是3) 值 类型 0 5.5-kHz 1 11-kHz 2 22-kHz 3 44-kHz 接着1位为采样的长度(压缩过的音视频都是16bit) 值 类型 0 snd8Bit 1 snd16Bit 接着1位为音频类型(对于AAC总是1) 值 类型 0 sndMono 1 sndStereo video由于kobe视频音频编码是pcm,查找视频tag太难,使用&lt;&lt;东风破&gt;&gt; mv视频 type=0x09=9。这里应该是一个video。 size=0x000030=48。长度为48。 timestreamp=0x000000。 TimestampExtended =0x00。 stream id =0x000000 我们看到数据部分： 视频信息+数据 视频信息，1个字节。 StreamId之后的数据就表示是VideoTagHeader,如果是avc,VideoTagHeader会多出4个字节的信息就是AVCPacketType和CompositionTime 前4位为帧类型Frame Type 值 类型 1 keyframe (for AVC, a seekable frame) 关键帧 2 inter frame (for AVC, a non-seekable frame) 3 disposable inter frame (H.263 only) 4 generated keyframe (reserved for server use only) 5 video info/command frame 后4位为编码ID (CodecID) 值 类型 1 JPEG (currently unused) 2 Sorenson H.263 3 Screen video 4 On2 VP6 5 On2 VP6 with alpha channel 6 Screen video version 2 7 AVC 特殊情况 视频的格式(CodecID)是AVC（H.264）的话，VideoTagHeader会多出4个字节的信息，AVCPacketType 和CompositionTime。 AVCPacketType 占1个字节 值 类型 0 AVCDecoderConfigurationRecord(AVC sequence header) 1 AVC NALU 2 AVC end of sequence (lower level NALU sequence ender is not required or supported) AVCDecoderConfigurationRecord.包含着是H.264解码相关比较重要的sps和pps信息，再给AVC解码器送数据流之前一定要把sps和pps信息送出，否则的话解码器不能正常解码。而且在解码器stop之后再次start之前，如seek、快进快退状态切换等，都需要重新送一遍sps和pps的信息.AVCDecoderConfigurationRecord在FLV文件中一般情况也是出现1次，也就是第一个video tag. CompositionTime 占3个字节 条件 值 AVCPacketType ==1 Composition time offset AVCPacketType !=1 0 再看到第二个video tag 我们看到 AVCPacketType =1，而后面三个字节为000043。这是一个视频帧数据。 解析到的数据完全符合上面的理论。 sps pps 前面我们提到第一个video 一般存放的是sps和pps。这里我们具体解析下sps和pps内容。先看下存储的格）： 10x01+sps[1]+sps[2]+sps[3]+0xFF+0xE1+sps size+sps+01+pps size+pps sps[1]=0x64 sps[2]=00 sps[3]=0D sps size=0x001B=27(占两个字节) 跳过27个字节后，是0x01 pps size=0x0005=118(占两个字节) 跳过5个字节，就到了back-pointers。 视频帧数据 解析出sps和pps tag后，后面的video tag就是真正的视频数据内容了 这是第二个video tag其实和之前图一样，只是我圈出来关键信息。先看下格式 frametype=0x17=00010111 AVCPacketType =1 Composition Time=0x000043 后面就是NALU DATA 引用: flv格式详解+实例剖析 FLV视频封装格式详解 【总结】FLV（AAC/AVC）学习笔记 将h.264视频流封装成flv格式文件（一.flv格式） 将h.264视频流封装成flv格式文件（二.开始动手） RTMP协议中的AMF数据 rtmp协议简单解析以及用其发送h264的flv文件 FLV 文件格式解析 (原)从mp4,flv文件中解析出h264和aac,送解码器解码失败:,avc1与H264区别在这里其实有人遇到了和我一样的问题：http://stackoverflow.com/questions/11330764/ffmpeg-cant-decode-h264-stream-frame-data simplest_mediadata_test rtmp_relay RtmpMindmap]]></content>
      <categories>
        <category>音视频封装</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>format</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(转)总结Android开发中必备的代码Review清单]]></title>
    <url>%2F2017%2F12%2F05%2Ftips-android-review%2F</url>
    <content type="text"><![CDATA[前言本文收集了我自己工作以来提交代码前的所有检查点。事实证明，这样能有效提高自己的代码质量和功能的稳定性。所以推荐大家以后每次提交代码前，都可以看下这份Review清单哈。 此外，可能还有些检查点我并没有发现，欢迎大家踊跃在评论区补充哈～ 清理操作 页面退出时，是否完成必要的清理操作 是否调用Handler的removeCallbacksAndMessages(null)来清空Handler里的消息； 是否取消了还没完成的请求； 在页面里注册的监听，是否反注册； 假如自己用到观察者模式，是否反注册； 假如用了RxJava的话，是否解除订阅； 数据库的游标是否已经关闭 这个点一般人都知道，出问题一般在于，没有考虑到多线程并发时的情况下，Cursor没有被释放。 所以数据库的操作需要加上同步代码块 详细可参考：http://www.2cto.com/kf/201408/329574.html 打开过的文件流是否关闭 Android 3.0以下的版本，使用完的Bitmap是否调用recycle()，否则会一直占用内存 而Android 3.0及以上的版本不需要调用recycle()，因为这些版本的Bitmap全部放到虚拟机的堆内存中，让GC自动回收。 WebView使用完是否调用了其destory()函数 是否能进一步优化自己的代码 保存在内存中的图片，是否做过压缩处理再保存在内存里 否则可能由于图片质量太高，导致OOM Intent传递的数据太大，会导致页面跳转过慢。太大的数据可以通过持久化的形式传递，例如读写文件 频繁地操作同一个文件或者执行同一个数据库操作，是否考虑把它用静态变量或者局部变量的形式缓存在内存里。用空间换时间 放在主页面的控件，是否可以考虑用ViewStub来优化启动速度 要小心第三方包 build.gradle远程依赖第三方包时，版本号建议写死，不要使用+号 避免由于新版本的第三方包引入了新的问题 导入第三方工程时，记得把编码转换成自己工程当前是用的编码 调用第三方的包或者JDK的方法时，要跳进他们的源码，看要不要加 try-catch 否则可能会导致自己应用的崩溃 使用第三方包时，是否加上其混淆规则 若漏掉加上第三方包的混淆规则，会导致第三方包不该混淆的代码被混淆。在Debug版本没有发现问题，但是Release版本就会出现问题 系统应用添加so时，是否在固件对应的Android.mk文件上加入新增的so，否则系统可能编译不过 12@lib/armeabi/libcommon.so \@lib/armeabi/libabcdefg.so \ 注意要成对出现的地方 系统的、自己写的，注册和反注册的方法，是否成对出现 在生命周期的回调里，创建和销毁的代码是否对应起来 比如：onCreate()里面创建了Adapter，那么对应Adapter的退出处理操作(比如清空Image缓存)，一般就要写在onDestory()，而不能写在onDestoryView()。 类似的生命周期对应的代码有： onStart()、onStop(); onCreate()、onDestory(); onResume()、onPause(); onCreateView()、onDestoryView() 若ListView的item复用了，对Item里View的操作是否成对出现 比如：12345678910111213141516switch (type) &#123; case ArticleListItem.TYPE_AD: ...... mTitleView.setText(tencentAdBean.title); mGreenLabelView.setVisibility(VISIBLE); mRedLabelView.setText(&quot;&quot;); mRedLabelView.setVisibility(GONE); break; case ArticleListItem.TYPE_ARTICLE: ...... mTitleView.setText(mzAdBean.adData.getTitle()); mGreenLabelView.setVisibility(GONE); mRedLabelView.setText(&quot;ABC&quot;); mRedLabelView.setVisibility(VISIBLE); break;&#125; 比如以上对mTitleView、mGreenLabelView和mRedLabelView的操作，都是成对出现。否则ListView可能会由于Item复用，导致Item显示错乱问题 防内存泄漏 内部类，比如Handler、Listener、Callback是否是成static class 因为非静态内部类会持有外部类的引用。 假如子线程持有了Activity，要用弱引用来持有 比如Request的Activity就应该用弱引用的形式，防止内存泄漏。 要求传入Activity作为参数的函数，是否可以改用getApplicationContext()来作为参数 Handler相关 使用View.post()是否会有问题 因为在View处于detached状态期间，post()里面的Runnable是不会被执行的。只有在此View处于attached状态时才会被执行。 如果想改Runnable每次肯定会被执行，那么应该是用Handler.post来替代 假如程序可能多次在同一个Handler里post同一个Runnable，每次post之前都应该先清空这个Handler中还没执行的该Runnable 如：12345678910111213if (mCloudRun != null) &#123; mHandler.removeCallbacks(mCloudRun); mCloudRun = null;&#125;mCloudRun = new Runnable() &#123; @Override public void run() &#123; CloudAccelerateSwitchRequest request = new CloudAccelerateSwitchRequest(); request.setPriority(RequestTask.PRIORITY_LOW); RequestQueue.getInstance().addRequest(request); &#125;&#125;;mHandler.post(mCloudRun); 其他 多思考某些情况下，某变量是否会为空 而且在函数体内，处理参数前，必须加上判空语句 回调函数是否处理好 回调函数很容易出问题。比如网络请求的回调，需要判断此时的Aciivity等是否还存在，再进行调用。因为异步操作回来，Activity可能就消失不存在了。 而且还要对一些可能被回收的变量进行判空。 修改数据库后，是否把数据库的版本号+1 启动第三方的Activity时，是否判断了该Intent能否被解析 12345Intent sendIntent = new Intent(mContext, Demo.class);// 这种方式判断是否存在if (sendIntent.resolveActivity(getPackageManager()) != null) &#123; startActivity(sendIntent);&#125; 若Activity不存在，会出现ActivityNotFoundException的异常 新注册的Activity、Service或Provider，若AndroidManifest.xml中exported属性为true，要考虑是否会引发安全性问题12&lt;activity android:name=&quot;com.inkenka.DemoActivity&quot; android:exported=&quot;true&quot;/&gt; 因为exported属性为true时，外部应用就可以直接调用起该Activity。 可能导致的问题： 若外部应用直接启动详情页，从而让某些验证页面直接被绕过 若外部应用给该Activity传递乱七八糟的Intent，可能让该应用崩溃。也就是Android中的拒绝服务漏洞 除数是否做了非0判断 不要在Activity的onCreate里调用PopupWindow的showAsLoaction方法，由于Activity还没被加载完，会报错 功能完成后，自测时的检查点 思考某些情况下，某个变量是否会造成空指针问题 把手机横屏，检查布局是否有Bug 在不同分辨率的机型上，检查布局是否有Bug 切换到英文等外文字体下，检查外文是否能完整显示 从低版本升级上来，会不会有问题,比如可能会出现数据库不兼容的问题 按下Home再返回是否正常 熄灭屏幕再打开是否正常 切换成其它应用再切换回来会怎样 利用手机的开发者选项中的 “调试GPU过度绘制” ，“GPU呈现模式分析” 和 “显示FPS和功耗” 功能，看自己的新功能是否会导致过度绘制、是否会掉帧 测试看是否影响启动速度adb shell am start -W 包名/Activity 对比看APK大小是否有增大 跑1小时Monkey，测试其稳定性 转自: 良心推荐：总结Android开发中必备的代码Review清单 补充:总结工作中的Android内存泄漏问题简单判断是否有内存泄漏判断内存泄漏的定位的大单位是Activity。 可以通过反复进入退出一个Activity，然后用adb shell dumpsys meminfo + 包名 查看虚拟机的堆是否有不断地增长 定位内存泄漏1.使用Leak Canary在代码上加入Leak Canary，然后不断跑Monkey或者手动反复进出不同页面。若出现内存泄漏问题，会自动导出来，生成以下页面。 2.使用DDMS导出hprof，并用MAT工具进行分析 强烈建议先跑30分钟Monkey测试 使用eclipse的ddms找到对应的进程，触发一次gc后，dump出里面的内存快照hprof文件以分析当前应用内存的堆有什么东西 使用Android SDK 里的platform-tools文件夹的 hprof-conv工具，对刚才 hprof 文件进行转换，以至于 后面MAT工具能正常打开 使用MAT打开hprof文件，进入Histogram。输入自己猜测可能泄漏的Activity（项目中Activity不多时，可每个Activity都重复以下3、4、5步骤） 键该其中一项，打开菜单选择list objects -&gt;with incoming refs将列出该类的实例 右健Path to GC Roots–&gt;exclue all phantom/weak/soft etc. reference，找出这个实例GC后，还会存在什么对象的引用关系。 常见导致内存泄漏的几个点生命周期的原因比如：Activity中关联了一个生命周期超过Activity的Thread，这个Thread 若持有该Activity的引用，就会导致内存泄漏。 内部类的原因因为内部类会隐式地持有外部类的引用，若内部类不被释放，外部类也是无法释放。常见的有内部的Listener、Callback、Handler等导致。 情景1：若外部类应该释放的时候，内部类还在执行里面的函数，会导致外部类无法释放。 情景2：若一个异步操作，会回调内部类的Listener、Callback、Handler。当外部类应该释放的时候，但是这个异步操作还存在，而这个异步操作类又持有了Listener、Callback、Handler，导致外部类无法被释放。PS：这个原因也属于生命周期的原因。 静态变量的原因单例类里包含Activity 静态变量的类里引用到Activity 注册与反注册、打开与关闭没成对出现的原因比如：注册广播接收器、注册观察者（典型的譬如数据库的监听）等。或者自己写的跟Activity引用有关的clear()函数没有成对出现 解决方法解决内部类的问题（以Handler作为例子） onDestroy时候remove所有msgActivity finish后未处理的msg是问题根源，所以清空所有未被执行的msg1mHandler.removeCallbacksAndMessages(null); PS：比如Listener、Callback等其他内部类的问题，页面退出的时候，应该完成必要的清理操作，比如Cancel 请求 使用静态内部类 + weakReference 静态内部类不会保留对外部类的引用，如果一定要引用外部类，使用weakReference1234567891011121314static class MyHandler extends Handler &#123; WeakReference&lt;Activity &gt; mActivityReference; MyHandler(Activity activity) &#123; mActivityReference= new WeakReference&lt;Activity&gt;(activity); &#125; @Override public void handleMessage(Message msg) &#123; final Activity activity = mActivityReference.get(); if (activity != null) &#123; mImageView.setImageBitmap(mBitmap); &#125; &#125; &#125; PS:比如Listener、Callback等其他内部类的问题，也可以通过这个方法来解决 单例类里面尽量不要传入Activity，最好穿入ApplicationContext。假如传入了Activity，持有的时长也不能大于Activity的生命周期对象的注册与反注册要成对出现不使用WebView对象时，应该调用它的destory()函数来销毁它，并释放其占用的内存因为View会持有Context，所以注意不要异步引用View，不要让静态对象持有View，不要在集合框架中存储View]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android架构]]></title>
    <url>%2F2017%2F12%2F05%2Ftips-android-arch%2F</url>
    <content type="text"><![CDATA[Android官方架构组件介绍之LifeCycle,Android架构组件一共包括以下几个： LifeCycle ： 与Activity和Fragment的生命周期有关 LiveData ：异步可订阅数据，也是生命周期感知 ViewModel ：视图数据持有模型，也是生命周期感知 Room ：SQLite抽象层，用于简化SQLite数据存储 官网]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux批量操作文件]]></title>
    <url>%2F2017%2F11%2F30%2Ftips-linux-rename%2F</url>
    <content type="text"><![CDATA[一个批量将mp4文件转成gif文件的命令 1find . -name &quot;*.mp4&quot; |sed &apos;s/.mp4$//g&apos;|xargs -i ffmpeg -i &#123;&#125;.mp4 &#123;&#125;.gif sed &#39;s/.mp4$//g&#39;使用sed命令将mp4文件名的.mp4全部替换成空./g是全局替换.s是sed的替换命令,替换格式&#39;s/原文/要替换成的/&#39; 或者: 1for file in $(find . -name &quot;*.mp4&quot; -type f);do ffmpeg -i &quot;$file&quot; &quot;$&#123;file%.*&#125;.gif&quot;;done 找到所有.mp4文件进行循环,file是mp4文件全名,${file%.*}是剔除从右边最小匹配,即将.mp4去掉]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下Core Dump文件的行程与分析]]></title>
    <url>%2F2017%2F11%2F17%2Fenv-mac-debug-c%2F</url>
    <content type="text"><![CDATA[mac下生成core dump 使用ulimit -c查看ulimit设置,显示unlimited表示开启,显示0表示关闭,通过ulimit -c unlimited打开设置; 但是这个只在当前窗口有效果。如果需要变成系统全局设置。 就需要去改/etc/profile文件，打开，然后加上ulimit -c unlimited就可以了，这样当产生Crash的时候就会自动产生dump文件。 之后需要配置一下dump产生的规则和路径:sudo sysctl kern.corefile=/cores/core.%N.%P,其中%N表示进程名字，%P表示进程id。Linux还有%S,%T分别表示最后一个信号和时间，在MAC上没找到对应的。(mac默认生成的core dump在/cores/下). 最后如何用lldb来查看一个core dump文件lldb -c core.xxx. 在lldb命令下输入bt查看报错代码. 生成太多core文件会占用电脑磁盘,可以关闭全局的core dump生成配置: 永久关闭，则在/etc/sysctl.conf中加入一行（如果存在，则将其值修改为0），重启后生效：kern.coredump=0 零时关闭，当前生效，重启后失效：sudo sysctl -w kern.coredump=0]]></content>
      <categories>
        <category>env</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>language</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android兼容性]]></title>
    <url>%2F2017%2F11%2F14%2Ftips-android-compatibility%2F</url>
    <content type="text"><![CDATA[oppo r9s无法浮层无法显示问题oppo r9s,系统版本6.0.1,wmParams.type = WindowManager.LayoutParams.TYPE_TOAST;时无法正常弹出,改成wmParams.type = WindowManager.LayoutParams.TYPE_PHONE;可显示. 在activity中弹出浮层后马上将activity movetoback导致oppo r9s 浮层无法显示,moveTaskToBack后延迟一秒显示浮层可解决问题. 12345//moveTaskToBackval intent = Intent(Intent.ACTION_MAIN) intent.flags = Intent.FLAG_ACTIVITY_NEW_TASK// 注意 intent.addCategory(Intent.CATEGORY_HOME) aty.startActivity(intent)]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL查询案例]]></title>
    <url>%2F2017%2F11%2F08%2Fdb-sql-query%2F</url>
    <content type="text"><![CDATA[如下数据库表: 12345678910111213141516Student(S#,Sname,Sage,Ssex)学生表S#：学号Sname：学生姓名Sage：学生年龄Ssex：学生性别Course(C#,Cname,T#)课程表C#：课程编号Cname：课程名称T#：教师编号SC(S#,C#,score)成绩表S#：学号C#：课程编号score：成绩Teacher(T#,Tname)教师表T#：教师编号：Tname：教师名字 查询“001”课程比“002”课程成绩高的所有学生的学号 1select a.S# from (select S#,score from SC where C#=&apos;001&apos;)a, (select s#,score from SC where c#=&apos;002&apos;)b Where a.score&gt;b.score 查询平均成绩大于60分的同学的学号和平均成绩 1查询平均成绩大于60分的同学的学号和平均成绩 查询所有同学的学号、姓名、选课数、总成绩 1select student.S#, student.Sname, count(sc.C#), sum(score) from student left outer join SC on student.S# = SC.S# group by S 查询姓‘李’的老师的个数 123select count(distinct(Tname))from teacherwhere tname like &apos;李%&apos;; 查询没有学过“叶平”老师可的同学的学号、姓名： 1234select student.S#, student.Snamefrom Studentwhere S# not in (select distinct(SC.S#) from SC,Course,Teacherwhere sc.c#=course.c# AND teacher.T#=course.T# AND Teahcer.Tname =&apos;叶平&apos;); 查询学过“叶平”老师所教的所有课的同学的学号、姓名： 123456select S#,Sname from Student where S# in (select S# from SC ,Course ,Teacherwhere SC.C#=Course.C# and Teacher.T#=Course.T#and Teacher.Tname=&apos;叶平&apos; group by S#having count(SC.C#)=(select count(C#) from Course,Teacher where Teacher.T#=Course.T# and Tname=&apos;叶平&apos;)); 查询学过“011”并且也学过编号“002”课程的同学的学号、姓名： 1234select Student.S#,Student.Snamefrom Student,SC where Student.S#=SC.S#and SC.C#=&apos;001&apos;andexists( Select * from SC as SC_2 where SC_2.S#=SC.S# and SC_2.C#=&apos;002&apos;); 查询课程编号“002”的成绩比课程编号“001”课程低的所有同学的学号、姓名： 123456Select S#,Snamefrom (select Student.S#,Student.Sname,score ,(select score from SC SC_2 where SC_2.S#=Student.S# and SC_2.C#=&apos;002&apos;) score2 from Student,SCwhere Student.S#=SC.S# and C#=&apos;001&apos;) S_2where score2 &lt; score; 查询所有课程成绩小于60的同学的学号、姓名： 1234select S#, snamefrom studentwhere s# not in(select student.s# from student, sc where s.s# = sc.s# and score&gt;60); 查询没有学全所有课的同学的学号、姓名： 12345select student.s#, student.snamefrom student, scwhere student.s#=sc.s#group by student.s#, student.snamehaving count(c#)&lt;(select count(c#) from course); 查询至少有一门课与学号为“1001”同学所学相同的同学的学号和姓名： 1234select s#, Snamefrom Student, SCwhere student.s# = sc.s#and c# in (select c# from SC where s#=&apos;1001&apos;); 查询至少学过学号为“001”同学所有一门课的其他同学学号和姓名； 1234select distinct sc.s# , snamefrom student, scwhere student.s#=sc.s#and c# in (select C# from sc where s#=&apos;001&apos;); 把“SC”表中“叶平”老师教的课的成绩都更改为此课程的平均成绩： 123Update Sc Set Score=(Select Avg(s2_Score) From sc s2 Where s2.c#=sc.c#) Where c# IN(Select c# From sc cs INNER JOIN Teacher tc ON cs.t#=tc.t# WHERE tname =&apos;叶平&apos;) 查询和“1002”号的同学学习的课程完全相同的其他同学学号和姓名： 1234select s# from sc where c# in(select c# from sc where s#=&apos;1002&apos;)group by s# having count(*)=(select count(*) from sc where s#=&apos;1002&apos;); 删除学习“叶平”老师课的SC表记录： 12345delect scfrom course, Teacherwhere course.c#=sc.c#and course.t#=teacher.t#and tname=&apos;叶平&apos;; 向SC表中插入一些记录，这些记录要求符合以下条件：没有上过编号“003”课程的同学学号、002号课的平均成绩： 123Insert SC select S#,&apos;002&apos;,(Select avg(score) from SC where C#=&apos;002&apos;)from Student where S# not in (Select S# from SC where C#=&apos;002&apos;); 按平均成绩从高到低显示所有学生的“数据库”、“企业管理”、“英语”三门的课程成绩，按如下形式显示：学生ID，数据库，企业管理，英语，有效课程数，有效平均分： 12345678select s# as 学生ID,(select score from sc where sc.s#=t.s# and c#=&apos;004&apos;) as 数据库,(select score from sc where sc.s#=t.s# and c#=&apos;001&apos;) as 企业管理,(select score from sc where sc.s#=t.s# and c#=&apos;006&apos;) as 英语,count(*) as 有效课程数, avg(t.score) as 平局成绩from sc as tgroup by s#order by avg(t.score) 查询各科成绩最高和最低的分： 以如下的形式显示：课程ID，最高分，最低分 123456789101112select L.c# as 课程ID, L.score as 最高分,R.score as 最低分from sc L, sc Rwhere L.c# = R.c#and L.score = (select max(IL.score) from sc IL, student as IM where L.c#=IL.c# and IM.s#=IL.s# group by IL.c#)and R.score = (select min(IR.score) from sc as IR where R.c#=IR.c# group by IR.c#); 按各科平均成绩从低到高和及格率的百分数从高到低顺序： 12345678SELECT t.C# AS 课程号,max(course.Cname)AS 课程名,isnull(AVG(score),0) AS 平均成绩,100 * SUM(CASE WHEN isnull(score,0)&gt;=60 THEN 1 ELSE 0 END)/COUNT(*) AS 及格百分数 FROM SC T,Course where t.C#=course.C# GROUP BY t.C# ORDER BY 100 * SUM(CASE WHEN isnull(score,0)&gt;=60 THEN 1 ELSE 0 END)/COUNT(*) DESC 查询如下课程平均成绩和及格率的百分数(用”1行”显示): 企业管理（001），马克思（002），OO&amp;UML （003），数据库（004）： 查询不同老师所教不同课程平均分从高到低显示： 12345678SELECT max(Z.T#) AS 教师ID,MAX(Z.Tname) AS 教师姓名,C.C# AS 课程ID,AVG(Score) AS 平均成绩 FROM SC AS T,Course AS C ,Teacher AS Z where T.C#=C.C# and C.T#=Z.T# GROUP BY C.C# ORDER BY AVG(Score) DESC 查询如下课程成绩第3名到第6名的学生成绩单：企业管理(001)，马克思(002)，UML(003)，数据库(004)： 统计下列各科成绩，各分数段人数：课程ID，课程名称，[100-85],[85-70],[70-60],[ 小于60] ： 12345678SELECT SC.C# as 课程ID, Cname as 课程名称,SUM(CASE WHEN score BETWEEN 85 AND 100 THEN 1 ELSE 0 END) AS [100 - 85] ,SUM(CASE WHEN score BETWEEN 70 AND 85 THEN 1 ELSE 0 END) AS [85 - 70],SUM(CASE WHEN score BETWEEN 60 AND 70 THEN 1 ELSE 0 END) AS [70 - 60],SUM(CASE WHEN score &lt; 60 THEN 1 ELSE 0 END) AS [60 -] FROM SC,Course where SC.C#=Course.C# GROUP BY SC.C#,Cname; 查询学生平均成绩及其名次： 123456789SELECT 1+(SELECT COUNT( distinct 平均成绩) FROM (SELECT S#,AVG(score) AS 平均成绩 FROM SC GROUP BY S# ) AS T1 WHERE 平均成绩 &gt; T2.平均成绩) as 名次, S# as 学生学号,平均成绩 FROM (SELECT S#,AVG(score) 平均成绩 FROM SC GROUP BY S# ) AS T2 ORDER BY 平均成绩 desc; 查询各科成绩前三名的记录（不考虑成绩并列情况）： 123456789SELECT t1.S# as 学生ID,t1.C# as 课程ID,Score as 分数 FROM SC t1 WHERE score IN(SELECT TOP 3 score FROM SC WHERE t1.C#= C# ORDER BY score DESC)``` 26. 查询每门课程被选修的学生数： select c#, count(s#) from sc group by c#; 127. 查询出只选修一门课程的全部学生的学号和姓名： select sc.s#, student.sname, count(c#) as 选课数 from sc,student where sc.s# =student.s# group by sc.s#,Student.sname having count(c#)=1; 128. 查询男生、女生人数： select count(Ssex) as 男生人数 from student group by Ssex having Ssex=’男’； select count(Ssex) as 女生人数 from student group by Ssex having Ssex=’女’; 129. 查询姓“张”的学生名单： select sname from student where sname like ‘张%’; 130. 查询同名同姓的学生名单，并统计同名人数： select sanme,count() from student group by sname havang count()&gt;1; 131. 1981年出生的学生名单（注：student表中sage列的类型是datetime）: select sname, convert(char(11),DATEPART(year,sage)) as age from student where convert(char(11),DATEPART(year,Sage))=’1981’; 132. 查询平均成绩大于85的所有学生的学号、姓名和平均成绩： select Sname,SC.S# ,avg(score)from Student,SCwhere Student.S#=SC.S# group by SC.S#,Sname having avg(score)&gt;85; 133. 查询每门课程的平均成绩，结果按平均成绩升序排序，平均成绩相同时，按课程号降序排列： select C#, avg(score) from sc group by c# order by avg(score), c# desc; 134. 查询课程名称为“数据库”，且分数低于60的学生名字和分数： select sname, isnull(score,0) from student, sc ,course where sc.s#=student.s# and sc.c#=course.c# and course.cname=’数据库’ and score]]></content>
      <categories>
        <category>db</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android-phone-compatibility]]></title>
    <url>%2F2017%2F11%2F02%2Fandroid-phone-compatibility%2F</url>
    <content type="text"><![CDATA[系统摄像视频文件格式一般手机使用摄像头录制视频格式为yuv420p,而小米5录制出的为yuvj420p.格式转换是yuvj420p当成yuv420p处理即可.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>compatibility</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ndk编译常见问题]]></title>
    <url>%2F2017%2F11%2F01%2Fissue-ndk-compile%2F</url>
    <content type="text"><![CDATA[depends on undefined modules问题: 12Users/shenjunwei/program/android-ndk-r14b/build/core/build-binary.mk:687: Android NDK: Module magicsdk_fmod depends on undefined modules: cutils/Users/shenjunwei/program/android-ndk-r14b/build/core/build-binary.mk:700: *** Android NDK: Aborting (set APP_ALLOW_MISSING_DEPS=true to allow missing dependencies) . Stop. 解决方案: Android.mk中增加APP_ALLOW_MISSING_DEPS=true shared library text segment is not shareable问题: 1234/Users/shenjunwei/program/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: warning: shared library text segment is not shareable/Users/shenjunwei/program/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: treating warnings as errorsclang++: error: linker command failed with exit code 1 (use -v to see invocation)make: *** [/Users/shenjunwei/Documents/repository/wonxing/normandy_android_app/modules-int/magicsdk_core/src/main/obj/local/armeabi-v7a/libmagicsdk_ex.so] Error 1 解决: 123456from Android NDK r11 you can useLOCAL_LDLIBS += -Wl,--no-warn-shared-textrelYou can also useLOCAL_DISABLE_FATAL_LINKER_WARNINGS := true shared library text segment is not shareable has text relocations问题: 12345678910/data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so: has text relocationsE/FileUtil: access inferno failed! /data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so java.lang.UnsatisfiedLinkError: dlopen failed: /data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so: has text relocations at java.lang.Runtime.load0(Runtime.java:897) at java.lang.System.load(System.java:1505) at com.wonxing.magicsdk.core.util.FileUtil$EXLibUtil.load(FileUtil.java:465) at com.wonxing.magicsdk.core.MagicRecorder.loadEXLibrary(MagicRecorder.java:280) at com.wonxing.magicsdk.core.MagicRecorder.prepare(MagicRecorder.java:471) at com.wonxing.magicsdk.core.MagicRecorder.prepare(MagicRecorder.java:352) at com.wonxing.touchfa.ui.activity.VideoImportActivity.preparePlaySDK(VideoImportActivity.java:144) 解决: 方案一 This issue could be solved by checking the targetSDKVersion in the manifest file. Using “22” and not “23” as targetSDKVersion solved it. (See below) 123&lt;uses-sdk android:minSdkVersion=&quot;15&quot; android:targetSdkVersion=&quot;22&quot; /&gt; I also checked the build.gradle files for compile version and targetSDKversion: 1234567compileSdkVersion 22 buildToolsVersion &apos;22.0.1&apos; defaultConfig &#123; minSdkVersion 15 targetSdkVersion 22 &#125; 方案二 It was caused by the ffmpeg, and it could also be solved by patching the latest ffmpeg code12345libavcodec\arm\fft_fixed_neon.Slibavcodec\arm\fft_neon.Slibavcodec\arm\fft_vfp.Slibavcodec\arm\mlpdsp_armv5te.Slibutil\arm\asm.S I took the latest from https://github.com/FFmpeg/FFmpeg You will also need HAVE_SECTION_DATA_REL_RO declared somewhere in your build for the macro in asm.S to use the dynamic relocations option. 方案三(Further informations:) Previous versions of Android would warn if asked to load a shared library with text relocations: “libfoo.so has text relocations. This is wasting memory and prevents security hardening. Please fix.”. Despite this, the OS will load the library anyway. Marshmallow rejects library if your app’s target SDK version is &gt;= 23. System no longer logs this because it assumes that your app will log the dlopen(3) failure itself, and include the text from dlerror(3) which does explain the problem. Unfortunately, lots of apps seem to catch and hide the UnsatisfiedLinkError throw by System.loadLibrary in this case, often leaving no clue that the library failed to load until you try to invoke one of your native methods and the VM complains that it’s not present. You can use the command-line scanelf tool to check for text relocations. You can find advice on the subject on the internet; for example https://wiki.gentoo.org/wiki/Hardened/Textrels_Guide is a useful guide. And you can check if your shared lbirary has text relocations by doing this: 1readelf -a path/to/yourlib.so | grep TEXTREL If it has text relocations, it will show you something like this: 10x00000016 (TEXTREL) 0x0 If this is the case, you may recompile your shared library with the latest NDK version available: 1ndk-build -B -j 8 And if you check it again, the grep command will return nothing. Android Developers Blog Hardened/Textrels Guide]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>NDK</tag>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最近应用杀掉进程application不销毁问题探讨]]></title>
    <url>%2F2017%2F10%2F31%2Ftips-android-application-recent%2F</url>
    <content type="text"><![CDATA[建雨在芝士圈应用的application中使用了全局静态变量标志是否正在录制中,开启直播后将该变量设置为录制中,录制中一些操作将被屏蔽.但是对某些手机(如htc d816)当从”最近应用”杀掉进程后有时候application不被回收,该状态变量无法通过application的onCreate中重新初始化,同时通知栏也未消失.在Android 应用被杀后Notification不取消问题及应用深杀和浅杀时Service生命周期情况探讨中找到service的onTaskRemoved方法可以监听到应用被从最近应用中移除. 关于&lt;&gt;摘要: 目中有如下需求：后台service进行导入操作，要更新Notification。当运行系统清理使应用被杀时，Notification无法取消，仍然在通知栏显示。为解决这个问题进行了如下探索： 首先想到利用service的startForeground()来更新通知栏，这样当应用被杀掉时候Notification可以一起被去掉。但针对项目的需求：service可以同时导入多个文件，并且会对应显示多个通知。这种情况下用service.startForeground()更新通知栏时候，当应用被杀时候之后cancel掉最后一次调用startForeground对应id的Notification，而其他通知仍然不能被取消。 继续探索用其他方式取消通知栏：在进程被杀掉的时候，会调用service的哪些生命周期函数呢？service的onDestroy()方法只有在调用Context的stopService()或Service的stopSelf()后才会被调用，在应用被杀时候Service的onDestroy()不会被执行。 我们发现service的 onTaskRemoved()方法，该方法何时被调用呢？方法的注释说明是这么写的： 12345678910111213/*** This is called if the service is currently running and the user has* removed a task that comes from the service&apos;s application. If you have* set &#123;@linkandroid.content.pm.ServiceInfo#FLAG_STOP_WITH_TASK ServiceInfo.FLAG_STOP_WITH_TASK&#125;* then you will not receive this callback; instead, the service will simply* be stopped.**@paramrootIntentThe original root Intent that was used to launch* the task that is being removed.*/public void onTaskRemoved(Intent rootIntent) &#123;&#125; 注释表明onTaskRemoved()方法在当用户移除应用的一个Task栈时被调用。也就是当用户在最近任务界面把该应用的一个task划掉时，或者在最近任务界面进行清理时。这两种情况下onTaskRemoved()都会被调用，但在大多Android机型上，这两种情况有所不同：第一种情况即应用被浅杀(用户只划掉这一个Task)，该Task栈会被清理，但如果有后台service在运行，该应用的进程不会被杀掉，后台service仍然在运行。第二种即应用被深杀(用户在最近任务界面直接按清理按钮)，该应用的进程会被直接杀掉，后台的service当然也停止了。对于不同的手机品牌和机型在最近任务进行各种清理时过程可能不太一样，但应用浅杀和深杀对于所有Android手机都是有普遍意义的。 下面我们分析在应用被浅杀和被深杀以及先浅杀再深杀后的生命周期： 浅杀： 104-21 17:55:13.733 8264-8264/com.qintong.test D/qintong: vCardService onTaskRemoved. 深杀： 会出现两种情况： (a). 12304-26 16:20:00.349 32674-32674/? D/qintong: Service onTaskRemoved.04-26 16:21:01.621 2936-2936/? D/qintong: Service is being created.04-26 16:21:01.628 2936-2936/? D/qintong: Service onStartCommand. (b). 1204-21 17:59:58.397 8264-8264/com.qintong.test D/qintong: Service onCreate.04-21 17:59:58.404 8264-8264/com.qintong.test D/qintong: Service onTaskRemoved. 浅杀＋深杀 （service 的 onStartCommand 返回 STICKY）： 12304-21 18:05:12.717 8264-8264/com.qintong.test D/qintong: Service onTaskRemoved.04-21 18:05:29.214 9207-9207/com.qintong.test D/qintong: Service onCreate.04-21 18:05:29.223 9207-9207/com.qintong.test D/qintong: Service onStartCommand. 我们来分析这几种情况： (1).浅杀时:应用进程没被杀掉，service仍然在执行，service的onTaskRemoved()立即被调用。 (2).深杀时：有两种情况：第一种情况是深杀后直接调用onTaskRemoved()且service停止，过段时间后service重启调用其onCreate()和onStartCommand()。第二种是应用的进程被杀掉，过一会后service的onCreate()方法被调用，紧接着onTaskRemoved()被调用。由于被深杀后应用的进程立刻停止了，所以service的onTaskRemoved()无法被立即调用。而过若干秒后，service重启，onCreate()被调用，紧接着onTaskRemoved()被调用。而这里service的其他方法并没有被调用，即使onStartCommand()返回STICKY，service重启后onStartCommand()方法也没有被调用。 (3).浅杀+深杀时(service 的 onStartCommand 返回 STICKY)：onTaskRemoved()立刻被调用(浅杀后)，深杀后过段时间onCreate()和onStartCommand()相继被调用。执行浅杀Task被清理，应用的进程还在，onTaskRemoved()被调用，过程与(1)一样。再执行深杀：由于该应用的Task栈已经没有了，所有再深杀onTaskRemoved()不会再被调用，深杀后service停止。而由于实验时候onStartCommand()返回STICKY，所有service过段时间会被再次启动，执行了onCreate()方法和onStartCommand()方法。 所以综上所述，service的onTaskRemoved()在应用浅杀后会被立即调用而在service被深杀后，会直接调用onTaskRemoved或service会被重启并调用onTaskRemoved()。 回到我们的问题：应用被杀后，如何取消Notification： 我们先看最后的解决方案，在来分析为何能work。 service的代码如下： 12345678910111213141516171819202122@Overridepublic void onCreate() &#123; super.onCreate(); mBinder=newMyBinder(); if(DEBUG) Log.d(LOG_TAG,&quot;vCardService is being created.&quot;); mNotificationManager= ((NotificationManager)getSystemService(NOTIFICATION_SERVICE)); initExporterParams();&#125;@Overridepublic int onStartCommand(Intent intent, intflags, intid) &#123; if(DEBUG) Log.d(LOG_TAG,&quot;vCardService onStartCommand.&quot;); mNotificationManager.cancelAll(); return START_STICKY;&#125;@Overridepublic void onTaskRemoved(Intent rootIntent) &#123; if(DEBUG) Log.d(LOG_TAG,&quot;vCardService onTaskRemoved.&quot;); mNotificationManager.cancelAll(); super.onTaskRemoved(rootIntent);&#125; 如上代码，在浅杀时候：只执行onTaskRemoved()，通知被取消，但service仍然在运行，所以还会继续发通知，正常运行。 深杀时：第一种情况直接调用onTaskRemoved()且service停止，通知被取消。第二种情况，进程被杀掉，几秒后service重启，onCreate() -&gt; onTaskRemoved()，运行结果就是深杀后过几秒后Notification被取消。 浅杀+深杀时：浅杀后onTaskRemoved()被调用，service仍在运行，通知仍然在更新。深杀时，onCreate() -&gt; onStartCommand()，在onStartCommand()时候取消通知。 另外，mNotificationManager.cancelAll()会清除应用的所有通知，如果应用想保留和该service无关其他通知，可以调用mNotificationManager.cancel(String tag, int id)或cancel(int id)清除指定通知。 当然，还可以有另一种方式：浅杀时后就把service后台执行的任务停止，并清理notification，我们可以根据需求来选择。 补充： 疑问：1.为啥有时候深杀不立即调用onTaskRemoved()，而是在重启之后调用的呢？ stackoverflow上的答复:https://stackoverflow.com/questions/32224233/ontaskremoved-called-after-oncreate-in-started-service-on-swipe-out-from-recent/41506752 大意是service执行较重UI操作时候service不会立即停止，而新的service会启动。不太确定这个解释的正确性…… Calling onTaskRemoved of the running service(when app gets swiped out from recent apps) will be generally delayed if we are performing any heavy UI related stuff or broadcasting messages to receivers in service. E.g , Assume you are downloading the file of size 50MB from web server, so from web server everytime you are reading 1024bytes of stream data as buffer and that data you are writing to a file in device. Meanwhile you are updating the progress to the UI thread which means every KB you are updating to the UI thread, this will cause the application to freeze. So in between if you swipe-out from recent app list , then the system will try to stop the service but since the service is in-contact with the UI thread, the system will be unable to stop that service, but it will create new service eventhough the old service is not yet stopped. Once old service finishes the communication with the UI thread then onTaskRemoved() gets called and the old service will be stopped. The new service will be running in the background. 2.为何servive.startForeground()添加的Notification可以在service被杀死后去掉呢？我们分析源码：ActiveServices中killServicesLocked()-&gt;scheduleServiceRestartLocked()中调用了r.cancelNotification()，清除了notification: 1234567891011121314151617181920212223public void cancelNotification() &#123; if (foregroundId != 0) &#123; // Do asynchronous communication with notification manager to // avoid deadlocks. final String localPackageName = packageName; final int localForegroundId = foregroundId; ams.mHandler.post(new Runnable() &#123; public void run() &#123; INotificationManager inm = NotificationManager.getService(); if (inm == null) &#123; return; &#125; try &#123; inm.cancelNotificationWithTag(localPackageName, null, localForegroundId, userId); &#125; catch (RuntimeException e) &#123; Slog.w(TAG, &quot;Error canceling notification for service&quot;, e); &#125; catch (RemoteException e) &#123; &#125; &#125; &#125;); &#125; &#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(转)转使用C语言实现"泛型"链表]]></title>
    <url>%2F2017%2F10%2F31%2Fl-c-dllist%2F</url>
    <content type="text"><![CDATA[看到这个标题，你可能非常惊讶，C语言也能实现泛型链表？我们知道链表是我们非常常用的数据结构，但是在C中却没有像C++中的STL那样有一个list的模板类，那么我们是否可以用C语言实现一个像STL中的list那样的泛型链表呢？答案是肯定的。下面就以本人的一个用C语言设计的链表为例子，来分析说明一下本人的设计和实现要点，希望能给你一点有用的帮助。 一、所用的链表类型的选择我们知道，链表也有非常多的类型，包括单链表、单循环链表、双链表、双向循环链表等。在我的设计中，我的链表使用的类型是双向循环链表，并带一个不保存真实数据的头结点。其原因如下： 1）单链表由于不能从后继定位到前驱，在操作时较为不方便 2）双链表虽然能方便找到前驱，但是如果总是在其尾部插入或删除结点，为了定位的方便和操作的统一（所有的删除和插入操作，都跟在中间插入删除结点的操作一样），还要为其增加一个尾结点，并且程序还要保存一个指向这个尾结点的指针，并管理这个指针，从而增加程序的复杂性。而使用带头结点的循环双向链表，就能方便的定位（其上一个元素为链表的最后一个元素，其下一个元素为链表的第0个元素），并使所有的插入和删除的操作统一，因为头结点也是尾结点。注：结点的下标从0开始，头结点不算入下标值。 3）接口的使用与C++中stl中list和泛型算法的使用大致相同。 二、list类型的定义为了让大家一睹为快，下面就给出这个用C语言实现的“泛型”的定义，再来说明，我这样设计的原因及要点，其定义如下： 其定义在文件list_v2.c中 1234567891011121314typedef struct node &#123; //循环双链表的结点结构 void* data;//数据域指针 struct node *next;//指向当前结点的下一结点 struct node *last;//指向当前结点的上一结点 &#125;Node; struct list &#123; struct node *head;//头指针，指向头结点 int data_size;//链表对应的数据所占内存的大小 int length;//链表list的长度 &#125;; 其声明在文件list_v2.h中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108//泛型循环双链表，带头结点，结点下标从0开始，头结点不计入下标值 //定义结点指针Node*为List类型的迭代器 typedef struct node* Iterator; //List类型的定义 typedef struct list* List; //初始化链表,数据域所占内存的大小由data_size给出 int InitList(List *list, int data_size); //把data的内容插入到链表list的末尾 //assign指定数据data间的赋值方法 Iterator Append(List list, void *data, void (*assign)(void*, const void*)); //把data的内容插入到链表的迭代器it_before的前面 //assign指定数据data间的赋值方法 Iterator Insert(List list, void *data, Iterator it_before, void (*assign)(void*, const void*)); //把链表A中迭代器it_a指向的结点移动到链表B中迭代器it_b_befroe的前面 Iterator MoveFromAtoB(List A, Iterator it_a, List B, Iterator it_b_before); //删除链表list中迭代器it指向的结点 int Remove(List list, Iterator it); //删除链表list的第0个结点，下标从0开始 int RemoveFirst(List list); //删除链表list的最后一个结点 int RemoveLast(List list); //返回list中第index个数据的指针 void* At(List list, int index); //在begin和end之间查找符合condition的第一个元素， //比较函数由condition指向,比较的值由data指向 //当第一个参数的值小于第二个参数的值时，返回1，否则返回0 //根据condition函数的不同，可以查找第一个相等、大于或小于data的值 Iterator FindFirst(Iterator begin, Iterator end, void *data, int (*condition)(const void*, const void*)); //查找list中第一个与data相等的元素的下标， //equal函数，当第一个参数与第二个参数的值相等时，返回1，否则返回0 int IndexOf(List list, void *data, int (*equal)(const void*,const void*)); //查找在begin和end之间的最小值，比较函数由less指向 //当第一个参数的值小于第二个参数的值时，返回1，否则返回0 Iterator GetMin(Iterator begin, Iterator end, int (*less)(const void*, const void*)); //查找在begin和end之间的最大值，比较函数由large指向 //当第一个参数的值大于第二个参数的值时，返回1，否则返回0 Iterator GetMax(Iterator begin, Iterator end, int (*large)(const void*, const void*)); //获取list的长度 int GetLength(List list); //若list为空链表，则返回1，否则返回0 int IsEmpty(List list); //销毁list void DestroyList(List *list); //获得list的首迭代器 Iterator Begin(List list); //获得list的尾迭代器，指向最后一个元素的下一个位置 Iterator End(List list); //使it指向下一个位置，并返回指向下一个位置后的迭代器 Iterator Next(Iterator *it); //使it指向上一个位置，并返回指向上一个位置后的迭代器 Iterator Last(Iterator *it); //通过迭代器it获得数据，相当于*p void* GetData(Iterator it); //获取当前迭代器的下一个迭代器，注意，并不改变当前迭代器 Iterator GetNext(Iterator it); //获取当前迭代器的上一个迭代器，注意，并不改变当前迭代器 Iterator GetLast(Iterator it); 三、如何实现隐藏链表的成员变量（即封装）首先，我们为什么需要封装呢？我觉得封装主要有三大好处。 隔离变化，在程序中需要封装的通常是程序中最容易发生变化的地方，例如成员变量等，我们可以把它们封装起来，从而让它们的变化不会影响到系统的其他部分，也就是说，封装的是变化。 降低复杂度，因为我们把一个对象是如何实现的等细节封装起来，只留给用户一个最小依赖的接口，从而让系统变量简单明了，在一定程度降低了系统的复杂性，方便了用户的使用。 让用户只能按照我们设计好的接口来操作一个对象或类型，而不能自己直接对一个对象进行操作，从而减少了用户的误操作，提高了系统的稳定性。 在面向对象的设计中，如果我们想要隐藏一个类的成员变量，我们可以把这些成员变量声明为私有的，而在C语言中，我们可以怎么实现呢？其实其实现是很简单的，我们在C语言中，当我们要使用一个自己定义的类型或函数时，我们会把声明它的头文件包含（include）过来，只要我们在文件中只声明其类型是一个结构体，而把它的实现写在.c文件中即可。 在本例子中，我把struct list和struct node定义在.c文件中，而在头文件中，只声明其指针类型，即typedef struct node* Iterator和typedef struct list* List;当我们要使用该类型时，只需要在所在的文件中，include该头文件即可。因为在编译时，编译器只要知道List和Iterator是一个指针类型就能知道其所占的内存大小，也就能为其分配内存，所以能够编译成功。而又因为该头文件中并没有该类型（struct list和struct node）的定义，所以我们在使用该类型时，只能通过我们提供的接口来操作对象。例如，我们并不能使用List list; list-&gt;data等等的操作，而只能通过已定义的接口GetData来获得。 ###四、如何实现泛型 泛型，第一时间想起的可能是模板，但是在C语言中却没有这个东西。但是C语言中却有一个可以指向任何类型，在使用时，再根据具体的指针类型进行类型转换的指针类型，它就是void*。 为什么void可以指向任何类型的数据？这还得从C语言对于数据类型的处理方式来说明。在C语言中，我们使用malloc等函数来申请内存，而从内存的角度来看，数据是没有类型的，它们都是一串的0或1，而程序则根据不同的类型来解释这个内存单元中的数据的意义，例如对于内存中的数据，FFFFFFFF，如果它是一个有符号整型数据，它代表的是-1，而如果它是一个无符号整型数据，它代表的则是2^32-1。进一步说，如果你用一个int的指针变量p指向该内存，则p就是-1，如果你用unsigned int的指针p指向该内存，则*p = 2^32-1。 而我们使用malloc等函数时，也只需要说明申请的内存的大小即可，也不用说明申请的内存空间所存放的数据的类型，例如，我们申请一块内存空间来存放一个整型数据，则只需要malloc(sizeof(int))，即可，当然你完全可以把它当作一个具有4个单位的char数组来使用。所以我们可以使用void指针来指向我们申请的内存，申请内存的大小由链表中的成员data_size定义，它也是真正的data所占的内存大小。 五、为什么需要赋值函数指针assign这里来说明一下，该链表的数据的插入方式，我们的插入方式是，新建一个结点，把data指向的数据复制到结点中，并把该结点插入到链表中。插入的函数定义如下： 12Iterator Insert(List list, void *data, Iterator it_before, void (*assign)(void*, const void*)); 从上面的解说中，我们可以看到链表中的成员data_size指示了链表中的数据所占的内存大小，那我们们就可以使用函数memcpy把data指向的数据复制到新建的结点的data所指向的内存即可。为什么还需要一个函数指针assign，来指向一个定义数据之间如何赋值的函数呢？其实这和面向对象语言中常说到的深复制和浅复制有关。 注：memcpy函数的原型为：void * memcpy ( void * destination, const void * source, size_t num ); 试想一下，假如你的链表的数据类型不是int型等基本类型，也不是不含有指针的结构体，而是一个这样的结构体，例如： 123456struct student &#123; char *name; char *no; int age; &#125;; 学生的姓名和学号都是能过动态分配内存而来的，并由student结构体中的name和no指针指向，那么当我们使用memcpy时，只能复制其指针，而不能复制其指向的数据，这样在很多情况下都会带来一定的问题。这个跟在C++中什么时候需要自己定义复制构造函数的情况类似。因为这种情况下，默认的复制构造函数并不能满足我们的需要，只能自己定义复制构造函数。 所以在插入一个结点时，需要assign函数指针的原理与C++中自己定义复制构造函数的原理一样。它用于定义如何根据一个已有的对象生成一个该对象的拷贝对象。当然，可能在大多数的情况下，我们需要用到的数据类型都没有包含指针，所以在Insert函数的实现中，其实我也是有用到memcpy函数的，就是当assign为NULL时，就使用memcpy函数进行数据对象间的赋值，它其实就相当于C++中的默认复制构造函数或默认赋值操作函数。assign为NULL表示使用默认的逐位复制方式，即浅复制。 六、为什么不用typedef对于这个问题，其实很好回答。很多人实现一个通用链表是这样实现的，它们把node结构的实现如下： 1234567typedef struct node &#123; //循环双链表的结点结构 DataType data;//数据域指针 struct node *next;//指向当前结点的下一结点 struct node *last;//指向当前结点的上一结点 &#125;Node; 然后，当需要使用整型的链表时，就把DataType用typedef为int。其实这样做的一个最大的缺陷就是一个程序中只能存在着一个数据类型的链表，例如，如果我需要一个int型的链表和一个float型的链表，那么该把DataType定义为int呢还是float呢？所以这种看似可行的方式，其实只是虚有其表，在现象中是行不能的，虽然不少的数据结构的书都是这样实现的，但是它却没有什么实用价值。 而其本质的原因是把结点的数据域的数据类型与某一种特定的数据类型DataType绑定在一起，从而让链表不能独立地变化。 七、为什么只把结点的指针定义为Iterator在C++中iterator是一个类，为什么在这里，我只把结点的指针声明为一个Iterator呢？其实受STL的影响，我在一开始时，也是把Iterator实现为一个结构体，它只有一个数据成员，就是一个指向Node的指针。但在后来的实践中，发现其实并没有必要。在C++中为什么把iterator定义为一个类，是为了重载*，-&gt;等运行符，让iterator使用起来跟普通的指针一样。但是在C语言中，并没有重载运行符的做法，所以直接把Ierator声明为一个Node的指针最为方便、直接和好用，所有的比较运算都可以直接进行，而无需要借助函数。而把它声明为一个结构体反而麻烦、累赘。 八、为什么查找需要两个Iterator其实这是参考了STL中的泛型算法的思想。而且本人觉得这是一种比较好的实现。为什么FindFirst的函数原型不是 1Iterator FindFirst(List list, int (*condition)(const void*, const void*)); 而是 1Iterator FindFirst(Iterator begin, Iterator end, void *data,int (*condition)(const void*, const void*)); 们可以试想一下，这个链表的为char链表，链表的元素为ABCBCBC，我们要在链表中找出所有的B，如果查找算法是使用第一种定义的话，它只能找出第一个B，而后面的两个B就无能为力了，而第二种定义，则可以通过循环改变其始末迭代器来在不同的序列段间查找目标字符B的位置。 转自使用C语言实现“泛型”链表]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kotlin语法]]></title>
    <url>%2F2017%2F10%2F31%2Fl-kotlin%2F</url>
    <content type="text"><![CDATA[字符串比较123var str1 = &quot;chaychan&quot;var str2 = &quot;chaychan&quot;println(str1 == str2) 比较两个字符串，如果两个字符串的内容一致，在Java中使用 str1 == str2 时，是比较两个字符串的地址值，很清楚两个字符串的地址不一样，返回false，但是在kotlin中，则不是如此，比较的只是字符串的内容，而===相当于Java中的==，用来比较引用对象, 上述代码返回的是true。 equal函数 equals(str:String) 方法中的参数是与之对比的字符串，默认不忽略大小写，即大小写敏感，比如： 123var str1 = &quot;chaychan&quot;var str2 = &quot;ChayChan&quot;println(str1.equals(str2)) 打印结果为false，因为不忽略大小写的话，两个字符串内容对比是不一致的，所以返回false。 equals(str:String,ignoreCase:Boolean) 方法中有两个参数，第一个参数是与之对比的字符串，第二个参数是布尔类型的值，是否忽略大小写，如：123var str1 = &quot;chaychan&quot;var str2 = &quot;ChayChan&quot;println(str1.equals(str2,true)) 返回结果为true。 源码优化分析源码 1.Lateinit在View声明阶段，都会需要使用lateinit来延迟声明变量。 12345class TaskActivity : AppCompatActivity()&#123; private val CURRENT_FILTERING_KEY = &quot;CURRENT_FILTERING_KEY&quot;; private lateinit var drawerLayout : DrawerLayout private lateinit var tasksPresenter:TasksPresenter&#125; kotlin中延迟声明还包括lazy的方式 12val name:String by lazy &#123;&quot;cangwang&quot;&#125;lateinit var drawLayout:drawLayout 区别在于: .lazy{}只能用再val类型,lateinit只能用在var类型 .lateinit不能用在可空的属性上和java的基本类型上lateinit var name:String会报错 .lateinit可以在任何位置初始化并且可以初始化多次,因为其衔接var变量.而lazy在第一次被调用时就被初始化,其衔接的是val常量,想要被改变只能重新定义 2.findViewByIdApi26前: 1234@Overridepublic View findViewById(@IdRes int id)&#123; return getDelegate().findViewById(id);&#125; Api26之后 12345@SuppressWarnings(&quot;TypeParameterUnusedInFormals&quot;)@Overridepublic &lt;T extends View&gt; T indViewById(@IdRes int id)&#123; return getDelegate().findViewById(id);&#125; 五个kotlin Standard.kt里面的函数:apply,with,let,run,also apply作用12345setSupportActionBar(findViewById&lt;Toolbar&gt;(R.id.toolbar))supportActionBar?.apply&#123; setDisplayHomeAsUpEnabled(true) setDisplayShowHomeEnabled(true)&#125; 在函数内可以通过this指代该对象,返回值为该对象自己 with函数 将某对象作为函数的参数,在函数内可以通过this指代该对象.返回值为函数块的最后一行或指定return表达式1234567891011121314override fun getView(i:Int,view:View?,viewGroup:ViewGroup):View&#123; val rowView=Vview?:LayoutInflater.from(viewGroup.context).inflate(R.layout.task_item,viewGroup,false) val task = getItem(i) with(rowView.findViewById&lt;TextView&gt;(R.id.title))&#123; text = task.titleForList &#125; with(rowView.findViewById&lt;CheckBox&gt;(R.id.complete))&#123; isChecked=task.isCompleted rowView.setBackgroundDrawable(...) setOnClickListener&#123; &#125; &#125;&#125; 3.lat函数12345private fun showMessage(message:String)&#123; view?.let&#123; Snackbar.make(it,message,Snackbar.LENGTH_LONG).show() &#125;&#125; 将对象作为函数参数,在函数块内可以通过it指代该对象.返回值为函数块的最后一行或指定return表达式 4. run函数其有两种表达式: 第一种无参数输入 第二种会将对象本身this给函数调用 返回值为函数块最后一行,或者指定return表达式 Object单例对象是使用Object申明 Kotlin没有静态属性和方法,需要使用单例对象来实现类似的功能. data相当于java中定义的数据bean类,其可以直接在属性之后编写get和set方法 @JvmOverloads]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tool-as3]]></title>
    <url>%2F2017%2F10%2F31%2Ftool-as3%2F</url>
    <content type="text"><![CDATA[AndroidStudio3.0新特性支持Java8语言由于AS3.0默认支持Java8语言，所以我们就可以移除build.gradle里面的jackOptions了 jackOptions { true } 然后可以在build.gradle配置为Java8 1234567android &#123; ... compileOptions &#123; sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 &#125;&#125; 如果对Java8的一些特性存在问题,我们也可以在gradle.properties里面禁用Java8 1android.enableDesugar=false 配置产品渠道AS3.0以前我们常用productFlavors配置不同的渠道包，比如 123456789productFlavors &#123; dev&#123; applicationIdSuffix &quot;.dev&quot; ... &#125; prod &#123; ... &#125; &#125; AS3.0得新增flavorDimensions的配置，主要有以下 12 个构建变体： 构建变体： 1[minApi24, minApi23, minApi21][Demo, Full][Debug, Release] 对应 APK： 1app-[minApi24, minApi23, minApi21]-[demo, full]-[debug, release].apk 比如这里创建一个构建方式 首先得在defaultConfig通过flavorDimensions配置构建变体，如下 1234defaultConfig &#123; ... flavorDimensions &quot;debug&quot;,&quot;release&quot; &#125; 然后productFlavors的配置就可以如下: 1234567891011productFlavors &#123; demo &#123; dimension &quot;debug&quot; applicationIdSuffix &quot;.demo&quot; ... &#125; prod &#123; dimension &quot;release&quot; ... &#125; &#125; 改进的Android插件 优化了多 module 的项目并行编译运行更详细Task的展示 构建变体的从属管理，比如上文的Flavors Dimensions配置新 api ，implementation依赖（替代compile ），compileOnly（替代provided）和runtimeOnly（替代 apk） 通过增量编译 优化多dex的app构建速度 优化了AAPT2增量资源化处理。如果要启用AAPT2,在gradle.properties文件添加代码：android.enableAapt2=true 支持java8语言 增加测试工具，可通过dependencies依赖使用1234dependencies&#123; androidTestUtil“com.linkedin.testbutler：测试管家应用：1.3.0@apk” ...&#125; 常见出错总结1Error:Cause: getMainOutputFile is no longer supported. Use getOutputFileName if you need to determine the file name of the output. 或 1Error:Not valid. 主要是AndResGuard1.2.3版本还没有兼容AS3.0 1Error:All flavors must now belong to a named flavor dimension. The flavor &apos;prod&apos; is not assigned to a flavor dimension. Learn more at https://d.android.com/r/tools/flavorDimensions-missing-error-message.html AS3.0需要通过flavorDimensions来配置产品渠道，详细看上文。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>AndroidStudio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/CPP中的编程技巧及其概念]]></title>
    <url>%2F2017%2F10%2F17%2Ftips-candcpp%2F</url>
    <content type="text"><![CDATA[C Languagesize_tsize_t的全称应该是size type，就是说“一种用来记录大小的数据类型”。属于C99标准，它所定义的变量可以进行加减乘除运算。因此函数中表示数据大小的变量，推荐使用这个类型！例如： 1int xxx(voidvoid *p, size_t len); 指针的指针（双重指针）的作用： 用来传递需要修改的指针参数到函数中； 用来动态生成多维数组； 多用于指针交换，可以避免数据复制，提升系统的性能，同时还可以让函数修改指针，例如扩充其大小，指向等一般指针的指针用作参数，大多用在需要函数改变指针(重新引用变量)而又不能通过返回值传递(例如返回值用于传递其他结果)时。 内联函数以空间换时间。 backtrace函数追踪函数调用堆栈以及定位段错误一般察看函数运行时堆栈的方法是使用GDB（bt命令）之类的外部调试器,但是,有些时候为了分析程序的BUG,(主要针对长时间运行程序的分析),在程序出错时打印出函数的调用堆栈是非常有用的 CPP显示限定数组实参的原始个数数组在作为函数参数传递时会退化为指针： A declaration of a parameter as “array of type” shall be adjusted to “qualified pointer to type”. 以及前面已经提到的： int x[3][5];Here x is a 3 × 5 array of integers. When x appears in an expression, it is converted to a pointer to (the first of three) five-membered arrays of integers. 这意味着数组作为参数传递时会丢失边界(C/C++的原生数组本来也就没有边界检查…)。 123void funcA(int x[10])&#123;&#125;// Equivalent tovoid funcB(int *x)&#123;&#125; 其对应的中间代码为： 123456789101112; Function Attrs: nounwind uwtabledefine void @_Z5funcAPi(i32*) #4 &#123; %2 = alloca i32*, align 8 store i32* %0, i32** %2, align 8 ret void&#125;; Function Attrs: nounwind uwtabledefine void @_Z5funcBPi(i32*) #4 &#123; %2 = alloca i32*, align 8 store i32* %0, i32** %2, align 8 ret void&#125; 如果数组边界的精确数值非常重要，并且希望函数只接收含有特定数量的元素的数组，可以使用引用形参： 1void funcC(int (&amp;x)[10])&#123;&#125; 其中间代码为： 123456; Function Attrs: nounwind uwtabledefine void @_Z5funcCRA10_i([10 x i32]* dereferenceable(40)) #4 &#123; %2 = alloca [10 x i32]*, align 8 store [10 x i32]* %0, [10 x i32]** %2, align 8 ret void&#125; 如果我们使用数组元素个数不等于10的数组传递给funcC,会导致编译错误： 123456789// note: candidate function not viable: no known conversion from &apos;int [11]&apos; to &apos;int (&amp;)[10]&apos; for 1st argument.void funcC(int (&amp;x)[10])&#123;&#125;int main(int argc,char* argv[])&#123; int x[11]=&#123;0,1,2,3,4,5,6,7,8,9,10&#125;; // error: no matching function for call to &apos;funcC&apos;. funcC(x); return 0;&#125; 也可以使用函数模板参数来指定函数接收参数的数组大小： 12template&lt;int arrSize&gt;void funcA(int x[arrSize])&#123;&#125; 使用时： 123int x[12]funcA&lt;12&gt;(x); // OKfuncA&lt;13&gt;(x); //ERROR 启用编译器的改变符号的隐式类型转换警告12345if((unsigned int)4&lt;(unsigned int)(int)-1)&#123; cout&lt;&lt;&quot;yes&quot;&lt;&lt;endl;&#125;else&#123; cout&lt;&lt;&quot;no&quot;&lt;&lt;endl;&#125; if中的那段表达式是为true的(输出yes)，而且编译时也不会发出警告。 虽然我们指定了(int)-1，但是当将unsigned int和int比较时会发生隐式转换。即： The usual arithmetic conversions are performed on operands of arithmetic or enumeration type. 1((unsigned int)4&lt;(unsigned)(int)-1)==true Warnings about conversions between signed and unsigned integers are disabled by default in C++ unless -Wsign-conversion is explicitly enabled. 通过启用-Wsign-conversion就可以看到警告了(建议开启)。 该参数的作用为： Warn for implicit conversions that may change the sign of an integer value, like assigning a signed integer expression to an unsigned integer variable. An explicit cast silences the warning. In C, this option is enabled also by -Wconversion. 断言(assert)assert Defined in header(c++)/(C) If NDEBUG is defined as a macro name at the point in the source code where is included, then assert does nothing. If NDEBUG is not defined, then assert checks if its argument (which must have scalar type) compares equal to zero. 12345#ifdef NDEBUG#define assert(condition) ((void)0)#else#define assert(condition) /*implementation defined*/#endif assert只在Debug模式中有效，使用release模assert什么都不做了。 因为在VC++里面，release会在全局定义NDEBUG 下面的代码在VS中使用debug和release模式分别编译并输入&gt;100的数，会有不一样的结果(release不会) 123456789101112131415#include &lt;iostream&gt;using namespace std;bool func(int x) &#123; if (x &gt; 100) &#123; return true; &#125; else &#123; return false; &#125;&#125;int main(void) &#123; int i; cin &gt;&gt; i; assert(func(i));&#125; 无效的引用通常情况下我们创建的引用就是有效的，但是也可以人为因素使坏… 123456char* ident(char *p) &#123; return p; &#125;int main(int argc,char* argv[])&#123; char&amp; r &#123;*ident(nullptr)&#125;; return 0;&#125; 这是UB的行为。 in particular, a null reference cannot exist in a well-defined program, because the only way to create such a reference would be to bind it to the “object” obtained by indirection through a null pointer,which causes undefined behavior. 数组的引用123456789void f(int(&amp;r)[4])&#123; cout&lt;&lt;sizeof(r)&lt;&lt;endl;&#125;void g(void)&#123; int a[]=&#123;1,2,3,4&#125;; f(a); // OK int b[]=&#123;1,2,3&#125;; f(b); // 错误，元素个数有误&#125; 对于数组引用类型的从参数来说，元素个数也是其类型的一部分。通常只有在模板中才会使用数组引用，此时数组的引用可以通过推断得到。 12345678910template&lt;class T,int N&gt;void f(T(&amp;r)[N])&#123; // ...&#125;int a1[10];double a2[100];void g()&#123; f(a1); // T是int，N是10 f(a2); // T是double，N是100&#125; 这么做的后果是调用f()所用的不同类型的数组有多少个，对应定义的函数有多少个。 忽略函数参数的顶层const为了与C语言兼容，在C++中会自动忽略参数类型的顶层const。 例如下面的函数在C++会报重定义错误，而不是重载： 12345// 类型是int(int)int f(int x)&#123;&#125;// error: redefinition of &apos;f&apos;// 类型是int(int)int f(const int x)&#123;&#125; 不论对于哪种情况，允许修改实参也好，不允许修改实参也好，它都只是函数调用者提供的实参的一个副本。因此调用过程不会破坏调用上下文的数据安全性。 char作为数组下标时当心unsigned/signed当char类型用作数组下标时，一定要先转unsigned char（因为char通常是有符号的(依赖实现定义)）。不能直接转int或unsigned int，会数组下标越界。 12345678#include &lt;stdio.h&gt;int main(void) &#123; char ch=-1; printf(&quot;%d %u %d&quot;, (int)ch, (unsigned)ch, (unsigned char)ch); return 0;&#125;// output// -1 4294967295 255 struct tag (*[5])(float)The type designated as struct tag (*[5])(float) has type ‘‘array of pointer to function returning struct tag’’. The array has length five and the function has a single parameter of type float. Its type category is array. new一个指针数组123int TEN=10;auto A=new (void(*[TEN])(void));delete[] A; 底层(Low-Level)const和顶层(Top-Level)const 底层const(Low-Level const):表示指针所指的对象是一个常量。 顶层const(Top-Level const):表示指针本身是个常量。顶层const可以表示任意的对象是常量，这对于任何数据类型都适用。123456int ival=0;int *const ivalp_1=&amp;ival; // 不能改变ivalp_1的值，这是一个顶层constconst int ci=42; // 不能改变ci的值，这是一个顶层constconst int *ivalp_2=&amp;ci;; // 允许改变ivalp_2的值，这是一个底层constconst int *const ivalp_3=ivalp_2; //靠右的是顶层const，靠左的是底层constconst int &amp;ref=ci; // 用于声明引用的const都是底层const 其实我有一个简单的区分的方法：看const修饰的右边是什么。 对于int const *x=std::nullput;，const修饰的是x，因为x是指针，我们就暂且把此处的x当做解引用来看，他就代表x所指向的对象，则它就是底层const。 反之亦然，int * const x=std::nullptr;，因为const修饰的是指针x，所以它就是顶层const。 在构造函数中传递this指针的危害如果我们在构造函数中将this指针传递给其它的函数，有可能会引发这样的问题： 123456struct C;void no_opt(C*);struct C &#123; int c; C() : c(0) &#123; no_opt(this); &#125;&#125;; 看起来上面的代码似乎没什么问题，但是我们构造一个const C的时候，有可能会出现这样的问题： 1234567const C cobj;void no_opt(C* cptr) &#123; int i = cobj.c * 100; // value of cobj.c is unspecified cout&lt;&lt;i&lt;&lt;endl; cout &lt;&lt; cobj.c * 100 // value of cobj.c is unspecified &lt;&lt; &apos;\n&apos;;&#125; 上面的代码会编译通过并可以在no_opt中修改常量对象cobj的成员i的值。 在一个常量对象构造的时候将其this指针传递给其他函数，这意味着我们可以修改该常量中的对象的值，这是不合乎标准的。 During the construction of a const object, if the value of the object or any of its subobjects is accessed through a glvalue that is not obtained, directly or indirectly, from the constructor’s this pointer, the value of the object or subobject thus obtained is unspecified. 所以还是不要在构造函数中写将this指针传递出类外的东西(最好还是只初始化数据成员吧)… 获取当前执行程序的绝对路径有两种方法： 1234#include &lt;direct.h&gt;char buffer[MAXPATH];getcwd(buffer, MAXPATH);cout&lt;&lt;buffer&lt;&lt;endl; 这种方法有一个弊端：如果将可执行程序添加至系统的PATH路径，则获取到的是在某个目录执行时该目录的路径。 另一种方法是通过Windows API来获取： 123456const string getTheProgramAbsPath(void)&#123; TCHAR exeFullPath[MAX_PATH]; // MAX_PATH在WINDEF.h中定义了，等于260 memset(exeFullPath,0,MAX_PATH); GetModuleFileName(NULL,exeFullPath,MAX_PATH); return &#123;exeFullPath&#125;;&#125; 在此种方式下不论是否将该程序添加至系统的PATH路径以及在何处执行，都会获取该可执行程序在系统中存放的绝对路径。 一个奇葩的using用法12345using foofunc=void(int);foofunc foo;int main()&#123; foo(1);&#125; 上面的代码里： 1foofunc foo; 是声明一个函数foo，可以看一下目标文件中的符号信息(省去无关细节)： 123456$ clang++ -c testusing.cc -o testusing.o -std=c++11$ llvm-nm testusing.o-------- U _Z3fooi-------- U __main-------- U atexit00000050 T main 通过gcc工具链中的c++filt可以还原目标文件中的符号： 12$ c++filt _Z3fooifoo(int) 但是并没有定义，直接链接会产生未定义错误。 右值引用12int x=123;int &amp;&amp;y=x+1; 其IR代码为： 1234567891011121314# 使用值123初始化x%2 = alloca i32, align 4store i32 123, i32* %2, align 4# y%3 = alloca i32*, align 8# 存放x+1产生的临时对象%4 = alloca i32, align 4# 计算x+1%5 = load i32, i32* %2, align 4%6 = add nsw i32 %5, 1# x+1 产生一个临时值，该临时值为%4store i32 %6, i32* %4, align 4# 将该临时值的地址绑定到%3(y)store i32* %4, i32** %3, align 8 从而实现非拷贝行为，其行为类似于将一个对象的地址赋值给一个指针。 其实右值引用的作用就是给临时对象续命——将引用绑定到一个临时对象，不会带来额外的拷贝操作。 实现同样续命行为的还有const T&amp;： 12int x=123;const int &amp;y=x+1; 和上面的示例在LLVM下会产生一模一样的IR代码。 一个数组名字例子1234int a[]=&#123;1,2,3,4,5&#125;;int *p=(int*)(&amp;a+1);printf(&quot;%d,%d\n&quot;,*(a+1),*(p-1));// output: 2,5 到底有几种传参方式大多数人都觉得在C++函数中有以下三种传参方式： 传值(by value)：形参的值是实参的拷； 传引用(by reference)：形参是实参的别名； 传指针(by pointer)：传递指向对象的指针给形参； 实际上，C++中只有两种传参方式：传值、传引用。 因为传指针(by pointer)也是传值的一种，形参的值也只是实参的一份拷贝，只是形参和实参都是指针而已。 在C++之父的著作：《The C++ Programming Language 4th》中写道： Unless a formal argument(parameter) is a reference, a copy of the actual argument is passed to the function. 传指针(by value)只是一种利用指针的性质来实现防止拷贝带来开销的一种技巧，而不是一种传参方式。 定义拷贝/赋值与析构函数的三大法则 如果一个类需要自定义的拷贝构造函数、拷贝赋值操作符、析构函数中的任何一个，那么他往往同时需要三者。 因为编译器生成的隐式定义的copy constructor和operator=语义是逐成员拷贝(memberwise)的，所以如果编译器生成的操作不能够满足类的拷贝需求(比如类成员是具有管理某种资源的句柄)，使用编译器的隐式定义会具有浅拷贝，导致两个对象进入某种共享状态。 12345678910111213141516struct A&#123; A():memory(nullptr)&#123;&#125; void getMemory(std::size_t memSize)&#123; memory=(char*)malloc(memSize); &#125; ~A()&#123; free(memory); &#125;private: char* memory;&#125;;int main()&#123; A x; x.getMemory(12); A y; y=x;&#125; 如果使用编译器生成的语义会使对象x和y内部共享一块内存，所以需要用户自己定义拷贝构造和拷贝赋值操作符，同样的原因，因为类成员持有某种资源，也需要用户自定义一个析构函数。 引用的实现C++标准中是这么解释引用的: [ISO/IEC 14882:2014 §8.3.2]A reference can be thought of as a name of an object. 但是标准中并没有要求应该如何实现引用这一行为(这一点标准中比比皆是)，不过多数编译器底层都是使用指针来实现的。 看下列代码： 123int a=123;int &amp;ra=a;int *pc=&amp;a; 然后将其编译为LLVM-IR来看编译器的实际行为： 123456%2 = alloca i32, align 4%3 = alloca i32*, align 8%4 = alloca i32*, align 8store i32 123, i32* %2, align 4store i32* %2, i32** %3, align 8store i32* %2, i32** %4, align 8 可以看到，指针和引用在经过编译器之后具有了完全相同的行为。 适当使用编译器生成操作在特殊成员函数的隐式声明及其标准行为中提到了编译器会隐式生成和定义六种特殊的成员函数的行为。 因为编译器生成的copy constructor和copy assigment operator均是具有memberwise行为的。所以当我们撰写的类使用浅拷贝可以满足的时候(值语义)，没必要自己费劲再写相关的操作了，因为编译器生成的和你手写的一样好，而且不容易出错。 1234567struct A&#123; A(int a=0,double b=0.0):x(a),y(b)&#123;&#125; A(const A&amp;)=default; A&amp; operator=(const A&amp;)=default; int x; double y;&#125;; 虽然当你没有显式定义一个copy constructor和copy assignment operator的时候编译器就会隐式定义，但是最好还是自己手动使用=delete指定。 编译器生成的和下面这样手写的一样： 1234567891011121314struct A&#123; A(int a=0,double b=0.0):x(a),y(b)&#123;&#125; A(const A&amp; r)&#123; x=r.x; y=r.y; &#125; A&amp; operator=(const A&amp; r)&#123; x=r.x; y=r.y; return *this; &#125; int x; double y;&#125;; 显然自己手写容易出错，这样的行为可以放心地交给编译器来做。 STL容器中压缩容量和真正地删除元素摘取自《C++编程规范：101条规则/准则与最佳实践》第82条。 压缩容器容量：swap魔术1234vector&lt;int&gt; x&#123;1,2,3,4,5,6,7&#125;;// ...vector&lt;int&gt;(x).swap(x); // 压缩到合适容量vector&lt;int&gt;().swap(x); // 删除所有元素 真正地删除元素：std::remove并不执行删除操作STL中的std::remove算法并不真正地从容器中删除元素。因为std::remove属于algorithm，只操作迭代器范围，不掉用容器的成员函数，所以是不可能从容器中真正删除元素的。 来看一下SGISTL中的实现(SGISTL的实现太老，没有用到std::move)： 12345678910111213141516171819202122template &lt;class _InputIter, class _Tp&gt;inline _InputIter find(_InputIter __first, _InputIter __last, const _Tp&amp; __val)&#123; while (__first != __last &amp;&amp; !(*__first == __val)) ++__first; return __first;&#125;template &lt;class _InputIter, class _OutputIter, class _Tp&gt;_OutputIter remove_copy(_InputIter __first, _InputIter __last, _OutputIter __result, const _Tp&amp; __value) &#123; for ( ; __first != __last; ++__first) if (!(*__first == __value)) &#123; *__result = *__first; ++__result; &#125; return __result;&#125;template &lt;class _ForwardIter, class _Tp&gt;_ForwardIter remove(_ForwardIter __first, _ForwardIter __last, const _Tp&amp; __value) &#123; __first = find(__first, __last, __value); _ForwardIter __i = __first; return __first == __last ? __first : remove_copy(++__i, __last, __first, __value);&#125; 可以看到它们只是移动元素的位置，并非真正地把元素删除，只是将不该删除的元素移动到容器的首部，然后返回新的结束位置迭代器。 等于是把删除的部分移动到了元素的尾部，所以要真正地删除容器中所有匹配的元素，需要用erase-remove惯用法： 1c.erase(std::remove(c.begin(),c.end(),value),c.end()); // 删除std::remove之后容器尾部的元素 谨防隐藏基类中的重载函数如果基类中具有一个虚函数func但是其又重载了几个非虚函数： 12345678910111213141516struct A&#123; virtual void func()&#123; cout&lt;&lt;&quot;A::func()&quot;&lt;&lt;endl; &#125; void func(int)&#123; cout&lt;&lt;&quot;A::func(int)&quot;&lt;&lt;endl; &#125; void func(double)&#123; cout&lt;&lt;&quot;A::func(double)&quot;&lt;&lt;endl; &#125;&#125;;struct B:public A&#123; virtual void func()&#123; cout&lt;&lt;&quot;B::func()&quot;&lt;&lt;endl; &#125;&#125;; 如果我们想要在B对象中使用非虚版本的func函数： 123B x;// error: too many arguments to function call, expected 0, have 1x.func(123); 这是由于派生类在覆盖基类虚函数的时候会隐藏其他的重载函数，需要在B中显式引入： 1234567struct B:public A&#123; virtual void func()&#123; cout&lt;&lt;&quot;B::func()&quot;&lt;&lt;endl; &#125; // 将A::func的重载函数引入作用域 using A::func;&#125;; 宏的替代宏在预处理阶段被替换，此时C++的语法和语义规则还没有生效，宏能做的只是简单的文本替换，是极其生硬的工具。 C++中几乎从不需要宏。可以用const和enum定义易于理解的常量。用inline来避免函数调用的开销，用template指定函数系列和类型系列，用namespace避免名字冲突。 除非在条件编译时使用，其他任何时候都没有在C++中使用宏的正当理由。 类内内存分配函数C++中类内的内存分配函数都是static成员函数: Any allocation function for a class T is a static member (even if not explicitly declared static). 这意味着operator new/operator delete以及operator new[]/operator delete[]都被隐式声明为static成员函数。 异常安全 析构函数、operator new、operator delete不能抛出异常 swap操作不要抛出异常 首先做任何可能抛出异常的事情(但不会改变对象重要的状态)，然后以不会抛出异常的操作结束。 当一个被抛出的异常从throw表达式奔向catch子句时，所经之路任何一个部分执行的函数比从执行堆栈上移除其激活记录之前，都必须清理他所控制的任何资源。 不要在代码中插入可能会提前返回的代码、调用可能会抛出异常的函数、或者插入其他一些东西从而使得函数末尾的资源释放得不到执行。 指向类成员函数指针的cv版本如果我们具有一个类A，其中具有重载的成员函数func，而他们的区别只是该成员函数是否为const，那么在定义一个指向成员函数的指针时如何分别？ 12345678struct A&#123; void func()const&#123; std::cout&lt;&lt;&quot;void func()const&quot;&lt;&lt;std::endl; &#125; void func()&#123; std::cout&lt;&lt;&quot;void func()&quot;&lt;&lt;std::endl; &#125;&#125;; 如果我们只是创建一个A::func的指针，指向的只是non-const版本。 1void(A::*funcP)()=&amp;A::func; 想要指定const的版本，就需要在声明时指定const: 1void(A::*funcConstP)()const=&amp;A::func; 对于const的A对象要使用const的版本，对于non-const的A对象要使用non-const的版本，不能混用。 123456const A x;(x.*funcP)(); // ERROR!(x.*funcConstP)(); // OKA y;(y.*funcConstP)(); // ERROR!(y.*funcP)(); // OK STL中的compare操作实现不同于C语言中的宏，使用C++中的模板(template)和谓词(Predicates)可以很轻易的写出泛型的比较操作。 在宏定义中还要注意参数的副作用，因为宏只是简单的替换，比如： 1234#define MAX(a,b) a&gt;=b?a:b;MAX(--a,++b);// 被替换为--a&gt;=++b?--a:++b; 但是这个宏的实际操作这并不是我们所期待的行为。 幸运的是，在C++中我们可以使用模板来避免这种丑陋的宏定义，而且也可以传递一个自定义的谓词来实现我们的判断行为： 1234567891011struct Compare&#123; template&lt;typename T&gt; bool operator()(const T&amp; a,const T&amp; b)&#123; return a&lt;b?false:true; &#125;&#125;;template&lt;class T, class Compare&gt;const T&amp; max(const T&amp; a, const T&amp; b, Compare comp)&#123; return (comp(a, b)) ? b : a;&#125; 计算性构造函数在某些情况下，可以通过创建构造函数的方式来提高成员函数的执行效率。 123456789101112struct String&#123; String(const char* init); const String operator+(const String&amp; l,const String&amp; r)&#123; return String(l.s_,r.s_); &#125;private: String(const char* a,const char* b)&#123; s_=new char[strlen(a)+strlen(b)+1]; strcat(strcpy(s_,a),b); &#125; char *s_;&#125;; 自身类型的using成员怎么定义一个类的成员中能够获取到当前类类型的成员呢？ 可以用下面这种写法： 123456template&lt;typename T&gt;struct base&#123; using selfType=T;&#125;;template&lt;typename T&gt;struct foo:public base&lt;foo&lt;T&gt;&gt;&#123;&#125;; 虽然有种强行搞事的意思… std::vector的随机访问std::vector可以随机访问，因为其重载了[]操作符，以及有at成员函数，则通常有下面两种方式： 12345template&lt;typename T&gt;void f(std::vector&lt;T&gt;&amp; x)&#123; x[0]; x.at(0);&#125; 以上两种随机访问方式有什么区别？ 顺序容器的at(size_type)要求有范围检查。 [ISO/IEC 14882:2014]The member function at() provides bounds-checked access to container elements. at() throws out_of_range if n &gt;= a.size(). 而operator[]标准中则没有任何要求。 可以来看一下一些STL实现(SGISTL)的源码对std::vector的operator[size_type]和at(size_type)的实现： 首先是at(size_type)的实现 123456789101112// at(size_type)的实现#ifdef __STL_THROW_RANGE_ERRORSvoid _M_range_check(size_type __n) const &#123; if (__n &gt;= this-&gt;size()) __stl_throw_range_error(&quot;vector&quot;);&#125;reference at(size_type __n) &#123; _M_range_check(__n); return (*this)[__n]; &#125;const_reference at(size_type __n) const &#123; _M_range_check(__n); return (*this)[__n]; &#125;#endif /* __STL_THROW_RANGE_ERRORS */​` 再看一下operator[] (size_type)的实现： 123// operator[](size_type)的实现reference operator[](size_type __n) &#123; return *(begin() + __n); &#125;const_reference operator[](size_type __n) const &#123; return *(begin() + __n); &#125; 可以看到，operator[]的随机访问并没有范围检查。 即上面的问题： 12x[0];x.at(0); 这两个的区别在于，若x不为空，则行为相同，若x为空，x.at(0)则抛出一个std::out_of_range异常(C++标准规定)，而x[0]是未定义行为。 注意typedef和#define的区别12345678typedef int* INTPTR;#define INTPTR2 int*int main(int argc,char* argv[])&#123; INTPTR i1,i2; INTPTR2 i3,i4; return 0;&#125; 还是直接从IR代码来看吧： 1234%6 = alloca i32*, align 8%7 = alloca i32*, align 8%8 = alloca i32*, align 8%9 = alloca i32, align 4 注意%9不是i32*,它是一个i32的对象。 因为#define只是编译期的简单替换，所以在编译期展开的时候会变成这样： 1234#define INTPTR2 int*INTPTR2 i3,i4;// 编译期展开int* i3,i4; 即只有i3为int*，而i4则为int 为什么const object不是编译时常量？12const int x=10;int y[x]=&#123;0&#125;; 这里是可以的，在编译器优化下x会直接被替换为10 其中间代码如下: 12345%6 = alloca i32, align 4%7 = alloca [10 x i32], align 16store i32 10, i32* %6, align 4%8 = bitcast [10 x i32]* %7 to i8*call void @llvm.memset.p0i8.i64(i8* %8, i8 0, i64 40, i32 16, i1 false) 可以看到%7的分配时并没有使用%6，所以也并不依赖x这个对象，这个对象是编译期已知的。 但是，当我们这么写时，又如何编译期可知： 12345int x;cin&gt;&gt;x;const int y=x;// error: variable-sized object may not be initializedint z[y]=&#123;0&#125;; 这里是由于编译器扩展，所以C++也支持VLA。但是可以看到const是没办法为编译期常量的。 继承层次中的类查询在类的继承层次中，可能具有同一基类的几个不同的派生类，他们之间可能又互相继承派生出了几个继承层次，在这样的情况下如何判断某一个派生类的层次中是否继承自某一个类呢？ 可以使用dynamic_cast来实现我们的要求，关于C++类型转换的部分可以看我之前的一篇文章：详细分析下C++中的类型转换。下面先来看一下dynamic_cast在C++标准中的描述(ISO/IEC 14882:2014)： The result of the expression dynamic_cast(v) is the result of converting the expression v to type T. T shall be a pointer or reference to a complete class type, or “pointer to cv void.” The dynamic_cast operator shall not cast away constness (5.2.11). If C is the class type to which T points or refers, the run-time check logically executes as follows: If, in the most derived object pointed (referred) to by v, v points (refers) to a public base class subobject of a C object, and if only one object of type C is derived from the subobject pointed (referred) to by v the result points (refers) to that C object. Otherwise, if v points (refers) to a public base class subobject of the most derived object, and the type of the most derived object has a base class, of type C, that is unambiguous and public, the result points (refers) to the C subobject of the most derived object. Otherwise, the run-time check fails. The value of a failed cast to pointer type is the null pointer value of the required result type. A failed cast to reference type throws an exception (15.1) of a type that would match a handler (15.3) of type std::bad_cast (18.7.2). 所以我们可以对继承层次中的类指针执行dynamic_cast转换，检查是否转换成功，从而判断继承层次中是否具有某个类。 一个代码的例子如下： 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;using namespace std;struct Shape&#123; virtual void draw()=0; virtual ~Shape()&#123;&#125;&#125;;struct Roll&#123; virtual void roll()&#123;cout&lt;&lt;&quot;Roll:roll()&quot;&lt;&lt;endl;&#125; virtual ~Roll()&#123;&#125;&#125;;struct Circle:public Shape,public Roll&#123; void draw()&#123; cout&lt;&lt;&quot;Circle::draw&quot;&lt;&lt;endl; &#125; void roll()&#123; cout&lt;&lt;&quot;Circle::roll()&quot;&lt;&lt;endl; &#125; ~Circle()=default;&#125;;struct Square:public Shape&#123; void draw()&#123; cout&lt;&lt;&quot;Square::draw()&quot;&lt;&lt;endl; &#125; ~Square()=default;&#125;;int main(int argc,char* argv[])&#123; Shape *a=new Square; Roll *b=dynamic_cast&lt;Roll*&gt;(a); if(b!=NULL)&#123; cout&lt;&lt;&quot;yes&quot;&lt;&lt;endl; &#125;else&#123; cout&lt;&lt;&quot;no&quot;&lt;&lt;endl; &#125; delete a; return 0;&#125;// output: no 面的继承层次比较简单，但是当假设我们不知道Cricle和Square的具体继承层次时，那么如何判断Square中是否存在某一基类(如Roll)？ 解决的办法就是上面提到的dynamic_cast！通过dynamic_cast转换到转换到要检测的类类型的指针，如果转换成功，dynamic_cast会返回从源类型转换到目标类型的指针，如果失败会返回一个空指针(之所以不使用引用是因为要处理可能会抛出异常的潜在威胁)，这种转换并非是向上或者向下转型，而是横向转型。所以我们需要对dynamic_cast返回的对象(指针)作一个判断就可以得出检测目标的继承层次中是否存在要检测的类型。 但是，我觉得这种行为的适用场景十分狭窄，在良好的类设计下几乎不必要，如果你对自己所实现的类层次感到失控，那一定是糟糕的设计。 参考文献C/C++中的编程技巧及其概念]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[l-c-skill]]></title>
    <url>%2F2017%2F10%2F12%2Fl-c-skill%2F</url>
    <content type="text"><![CDATA[Segmentation fault段错误调试总结Segmetation fault也叫做段错误，引发的原因有好多，这里我们只说一下段错误发生时的调试方法。 方法1：加打印printf。这是最基本的往往也很有效的方法，在哪里Core掉就会在哪里停止打印–一目了然。同时这种方法也存在一个致命缺陷：如果恰巧Core掉的地方没加打印而程序代码又非常庞大又可能是多线程的，那查找问题等同于大海捞针。 方法2：gdb调试。加gdb调试往往能在Core dump时抓到，甚至能抓到哪一个文件哪个类哪个函数哪一行，甚是精确。要确保GDB能抓到可用信息要做一些准备： 加-g 参数，这样才会有调试信息。 我想是个程序员就应该知道吧。 在Makefile 中加上 -fstack-protector 和-fstack-protector-all 信息，确保函数调用栈不丢失，当然只能是一定程度的不丢失，要完成保留住是不太可能的，但起码可以得到栈顶函数。 有了上面两点对大多数的Segmentation fault都能抓住，但是函数调用栈彻底乱掉或者在动态库so中Core而这个库编译时没有加-g参数，这些情况就gdb就无能为力了。 方法3：手动获取函数调用栈。这种方法其实是借住两个系统函数backtrace和backtrace_symbol来获取函数调用栈的，把这两个函数放在信号处理函数中：当收到 SIGSEG时在信号处理函数中调用这两个函数打印函数调用栈，在没用GDB调试的时候这种方法可以代替gdb的一部分功能，这听起来是不是非常酷啊，来看一看实现吧： 12345678910111213141516171819202122232425262728293031323334#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;execinfo.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;static void SignalHandle(int sig)&#123; void *array[20]; size_t size; char **strings; int i; size = backtrace(array, 10); strings = backtrace_symbols(array, size); printf(&quot;SIGNAL ocurre %d, stack tarce:\n&quot;, sig); printf(&quot;obtained %d stack frames.\n&quot;, size); for (i = 0; i &lt; size; i++) printf(&quot;%s\n&quot;, strings); free(strings); printf(&quot;stack trace over!\n&quot;); exit(0);&#125;int main(int argc, char **argv)&#123; signal(SIGSEGV, SignalHandle); //...程序主体&#125; 当然这种方法在没有GDB时候会大显身手，经过实验就是有gdb的时候这种方法有时比gdb抓到调用栈要多一层；当然这种方法和用gdb调试一样要加-g和栈保护参数-fstack-protector 和 -fstack-protector-all。其缺点就是抓到的调用栈无效，这是什么意思呢？有时发生core dump,能定位到甚至哪一行，但是那一行根本没有明显的错误；或者追到没有调试信息的动态库里如glibc。当然这些情况大多数调试方法都无能为力，只能依靠程序员的经验了。 方法4：经验之谈。如果我们的程序是多线程的，发生core dump用以上方法均无效，除了仔细排查代码外，还有这么一方法让我们缩小范围。 c语言全局变量那些事 “C++的数组不支持多态”？ 代码执行的效率 深入理解C语言 对象的消息模型 读书笔记：对线程模型的批评 C语言的谜题 C语言函数实现的另类方法 谁说C语言很简单？ C语言下的错误处理的问题 C语言结构体里的成员数组和指针 C技巧：结构体参数转成不定参数]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arithmetic-kmp]]></title>
    <url>%2F2017%2F10%2F12%2Farithmetic-kmp%2F</url>
    <content type="text"><![CDATA[https://baike.baidu.com/item/kmp%E7%AE%97%E6%B3%95/10951804?fr=aladdin http://blog.csdn.net/yutianzuijin/article/details/11954939/]]></content>
  </entry>
  <entry>
    <title><![CDATA[(转)从头开始写项目makefile]]></title>
    <url>%2F2017%2F10%2F10%2Fcourse-makefile-project-practice%2F</url>
    <content type="text"><![CDATA[1. 基本规则一般一个稍大的linux项目会有很多个源文件组成，最终的可执行程序也是由这许多个源文件编译链接而成的。编译是把一个.c或.cpp文件编译成中间代码.o文件，链接是就使用这些中间代码文件生成可执行文件。比如在当前项目目录下有如下源文件： 123# ls common.h debug.c debug.h ipc.c ipc.h main.c tags timer.c timer.h tools.c tools.h # 以上源代码可以这样编译： 1# gcc -o target_bin main.c debug.c ipc.c timer.c tools.c 如果之后修改了其中某一个文件（如tools.c），再执行一下上一行代码即可，但如果有成千上万个源文件这样编译肯定是不够合理的。此时我们可以按下面步骤来编译： 123456# gcc -c debug.c # gcc -c ipc.c # gcc -c main.c # gcc -c timer.c # gcc -c tools.c # gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 如果其中tools.c修改了，只需要编译该文件，再执行最后生成可执行文件的操作，也就是做如下两步操作即可： 12# gcc -c tools.c # gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 这样做看上去应该很合理了。但是如果修改了多个文件，就很可能忘了编译某一文件，那么运行时就很有可能出错。如果是common.h文件修改了，那么包含该头文件的所有.c文件都需要重新编译，这样一来的话就更复杂更容易出错了。看来这种方法也不够好，手动处理很容易出错。那有没有一种自动化的处理方式呢？有的，那就是写一个Makefile来处理编译过程。 下面给一个简单的Makefile，在源代码目录下建一个名为Makefile的文件： 1234567891011121314151617target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o main.o: main.c common.h &gt;---gcc -c main.c debug.o: debug.c debug.h common.h &gt;---gcc -c debug.c ipc.o: ipc.c ipc.h common.h &gt;---gcc -c ipc.c timer.o: timer.c timer.h common.h &gt;---gcc -c timer.c tools.o: tools.c tools.h common.h &gt;---gcc -c tools.c 然后在命令行上执行命令： 1234567891011# make gcc -c main.c gcc -c debug.c gcc -c ipc.c gcc -c timer.c gcc -c tools.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # # ls common.h common.h~ debug.c debug.h debug.o ipc.c ipc.h ipc.o main.c main.o Makefile Makefile~ tags target_bin timer.c timer.h timer.o tools.c tools.h tools.o # 可见在该目录下生成了.o文件以及target_bin可执行文件。现在我们只需要执行一个make命令就可以完成所有编译工作，无需像之前一样手动执行所有动作，make命令会读取当前目录下的Makefile文件然后完成编译步骤。从编译过程输出到屏幕的内容看得到执行make命令之后所做的工作，其实就是我们之前手动执行的那些命令。现在来说一下什么是Makefile？ 所谓Makefile我的理解其实就是由一组组编译规则组成的文件，每条规则格式大致为： 123target ... : prerequisites ... &gt;---command ... 其中target是目标文件，可以为可执行文件、*.o文件或标签。Prerequisites是产生target所需要的源文件或*.o文件，可以是另一条规则的目标。commond是要产生该目标需要执行的操作系统命令，该命令必须以tab（文中以&gt;—标示tab字符）开头，不可用空格代替。 说白了就是要产生target，需要依赖后面的prerequisites文件，然后执行commond来产生来得到target。这和我们之前手动执行每条编译命令是一样的，其实就是定义好一个依赖关系，我们把产生每个文件的依赖文件写好，最终自动执行编译命令。 比如在我们给出的Makefile例子中target_bin main.o等就是target，main.o debug.o ipc.o timer.o tools.o是target_bin的prerequisites，gcc -o target_bin main.o debug.o ipc.o timer.o tools.o就是commond，把所有的目标文件编译为最终的可执行文件target，而main.c common.h是main.o的prerequisites，其gcc -c main.c命令生成target所需要的main.o文件。 在该例子中，Makefile工作过程如下： 首先查找第一条规则目标，第一条规则的目标称为缺省目标，只要缺省目标更新了就算完成任务了，其它工作都是为这个目的而做的。 该Makefile中第一条规则的目标target_bin，由于我们是第一次编译，target_bin文件还没生成，显然需要更新，但此时依赖文件main.o debug.o ipc.o timer.o tools.o都没有生成，所以需要先更新这些文件，然后才能更新target_bin。 所以make会进一步查找以这些依赖文件main.o debug.o ipc.o timer.o tools.o为目标的规则。首先找main.o，该目标也没有生成，该目标依赖文件为main.c common.h，文件存在，所以执行规则命令gcc -c main.c，生成main.o。其他target_bin所需要的依赖文件也同样操作。 最后执行gcc -o target_bin main.o debug.o ipc.o timer.o tools.o，更新target_bin。 在没有更改源代码的情况下，再次运行make： 123# make make: `target_bin&apos; is up to date. # 得到提示目标target_bin已经是最新的了。 如果修改文件main.c之后，再运行make： 12345# vim main.c # make gcc -c main.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # 此时make会自动选择受影响的目标重新编译： 首先更新缺省目标，先检查target_bin是否需要更新，这需要检查其依赖文件main.o debug.o ipc.o timer.o tools.o是否需要更新。 其次发现main.o需要更新，因为main.o目标的依赖文件main.c最后修改时间比main.o晚，所以需要执行生成目标main.o的命令：gcc -c main.c更新main.o。 最后发现目标target_bin的依赖文件main.o有更新过，所以执行相应命令gcc -o target_bin main.o debug.o ipc.o timer.o tools.o更新target_bin。 总结下，执行一条规则步骤如下： 先检查它的依赖文件，如果依赖文件需要更新，则执行以该文件为目标的的规则。如果没有该规则但找到文件，那么该依赖文件不需要更新。如果没有该规则也没有该文件，则报错退出。 再检查该文件的目标，如果目标不存在或者目标存在但依赖文件修改时间比他要晚或某依赖文件已更新，那么执行该规则的命令。 由此可见，Makefile可以自动发现更新过的文件，自动重新生成目标，使用Makefile比自己手动编译比起来，不仅效率高，还减少了出错的可能性。 Makefile中有很多目标，我们可以编译其中一个指定目标，只需要在make命令后面带上目标名称即可。如果不指定编译目标的话make会编译缺省的目标，也就是第一个目标，在本文给出的Makefile第一个目标为target_bin。如果只修改了tools.c文件的话，我们可能只想看看我们的更改的源代码是否有语法错误而又不想重新编译这个工程的话可以执行如下命令： 123# make tools.o gcc -c tools.c # 编译成功，这里又引出一个问题，如果继续执行同样的命令： 123# make tools.o make: `tools.o&apos; is up to date. # 我们先手动删掉tools.o文件再执行就可以了，怎么又是手动呢？我们要自动，要自动！！好吧，我们加一个目标来删除这些编译过程中产生的临时文件，该目标为clean。 我们在上面Makefile最后加上如下内容： 12clean: &gt;---rm *.o target_bin 当我们直接make命令时不会执行到该目标，因为没有被默认目标target_bin目标或以target_bin依赖文件为目标的目标包含在内。我们要执行该目标需要在make时指定目标即可。如下： 123# make clean rm *.o target_bin # 可见clean目标被执行到了，再执行make时make就会重新生成所有目标对应的文件，因为执行make clean时，那些文件被清除了。 clean目标应该存在与你的Makefile当中，它既可以方便你的二次编译，又可以保持的源文件的干净。该目标一般放在最后，不可放在最开头，否则会被当做缺省目标被执行，这很可能不是你的意愿。 最后总结一下，Makefile只是告诉了make命令如何来编译和链接程序，告诉make命令生成目标文件需要的文件，具体的编译链接工作是你的目标对应的命令在做。 给一个今天完整的makefile： 1234567891011121314151617181920target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o main.o: main.c common.h &gt;---gcc -c main.c debug.o: debug.c debug.h common.h &gt;---gcc -c debug.c ipc.o: ipc.c ipc.h common.h &gt;---gcc -c ipc.c timer.o: timer.c timer.h common.h &gt;---gcc -c timer.c tools.o: tools.c tools.h common.h &gt;---gcc -c tools.c clean: &gt;---rm *.o target_bin 2. 隐含规则自动推导上一节的Makefile勉强可用，但还写的比较繁琐，不够简洁。对每一个.c源文件，都需要写一个生成其对应的.o目标文件的规则，如果有几百个或上千个源文件，都手动来写，还不是很麻烦，这也不够自动化啊。 这样，我们把生成.o目标文件的规则全部删除掉，就是这样一个Makefile文件： 12345target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o clean: &gt;---rm *.o target_bin 这下简洁了不少，这样也能用吗？试试看吧先，make一下： 12345678# make cc -c -o main.o main.c cc -c -o debug.o debug.c cc -c -o ipc.o ipc.c cc -c -o timer.o timer.c cc -c -o tools.o tools.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # 原来酱紫都可以啊！！target_bin后面那一群依赖文件怎么生成呢？不是没有生成*.o目标文件的规则了吗？再看屏幕编译输出内容： 12345cc -c -o main.o main.c cc -c -o debug.o debug.c cc -c -o ipc.o ipc.c cc -c -o timer.o timer.c cc -c -o tools.o tools.c 怎么长的和之前不太一样呢，尤其是前面那个cc是何物？ 其实make可以自动推导文件以及文件依赖关系后面的命令，于是我们就没必要去在每一个*.o文件后都写上类似的命令，因为，我们的 make 会自动推导依赖文件，并根据隐含规则自己推导命令。所以上面.o文件是由于make自动推导出的依赖文件以及命令来生成的。 下面来看看make是如何推导的。 命令make –p可以打印出很多默认变量和隐含规则。Makefile变量可以理解为C语言的宏，直接展开即可（后面会讲到）。取出我们关心的部分： 12345678910# default OUTPUT_OPTION = -o $@ # default CC = cc # default COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH) –c # Implicit Rules %.o: %.c # commands to execute (built-in): &gt;---$(COMPILE.c) $(OUTPUT_OPTION) $&lt; 其中cc是一个符号链接，指向gcc，这就可以解释为什么我们看到的编译输出为cc，其实还是使用gcc在编译。 123# ll /usr/bin/cc lrwxrwxrwx. 1 root root 3 Dec 3 2013 /usr/bin/cc -&gt; gcc # 变量$(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH)都为空。所以%.o: %.c规则命令展开为： 1cc -c -o $@ $&lt; 再看屏幕输出编译内容，摘取一条： 1cc -c -o main.o main.c 不是看出点什么？$@和main.o对应，$&lt;和main.c对应。其实$@和$&lt;是两个变量。$@为规则中的目标，$&lt;为规则中的第一个依赖文件。%.o:%.c是一种称为模式规则的特殊规则。因为main.o符合该模模式，再推导出依赖文件main.c，最终推导出整个规则为： 12main.o : main.c： &gt;--- cc -c -o main.o main.c 其余几个目标也同样推导。make自动推导的功能为我们减少了不少的Makefile代码，尤其是对源文件比较多的大型工程，我们的Makefile可以不用写得那么繁琐了。 最后，今天的Makefile相对于上一节进化成这个样子了： 12345target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o clean: &gt;---rm *.o target_bin 3. 变量的使用仔细研究我们的之前Makefile发现，我们还有改进的地方，就是此处： 12target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 如果增加一个源文件xx.c的话，需要在两处或多处增加xx.o文件。我们可以使用变量来解决这个问题。之前说过，Makefile的变量就像C语言的宏一样，使用时在其位置上直接展开。变量在声明时赋予初值，在引用变量时需要给在变量名前加上“$”符号，但最好用小括号“（）”或是大括号“{}”把变量给包括起来。 默认目标target_bin也在多处出现了，该文件也可以使用变量代替。 修改我们的Makefile如下： 1234567SRC_OBJ = main.o debug.o ipc.o timer.o tools.o SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---gcc -o $(SRC_BIN) $(SRC_OBJ) clean: &gt;---rm $(SRC_OBJ) $(SRC_BIN) 这样每次有新增的文件是只需要在SRC_OBJ变量里面增加一个文件即可。要修改最终目标的名字是可以只修改变量SRC_BIN。 其实在之前还说过特殊变量： $@，表示规则中的目标。 $&lt;，表示规则中的第一个依赖文件。 $?，表示规则中所有比目标新的条件，组成一个列表，以空格分隔。 $^:，表示规则中的所有条件，组成一个列表，以空格分隔。 上一节我们看到make -p有很多自定义的变量，比如CC。其中很多变量我们可以直接使用或修改其变量值或增加值。我们的Makefile中可以使用CC（默认值为cc）、RM（默认值为rm -f）。 由此可见我们的Makefile还可以进一步修改： 123456SRC_OBJ = main.o debug.o ipc.o timer.o tools.o SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) 这样的Makefile编译也是可用的。 但是这样的Makefile还是需要我们手动添加文件，还是不够自动化，最好增删文件都要修改Makefile。伟大的人类真是太懒了！！于是乎，他们发明了一个函数wilcard（函数后面会讲到），它可以用来获取指定目录下的所有的.c文件列表。这样的话我们可以自动获取当前目录下所有.c源文件，然后通过其他方法再得到.o文件列表，这样的话就不需要在每次增删文件时去修改Makefile了。所谓其他方法这里给出两种： 使用patsubst函数。在$(patsubst %.c,%.o,$(dir) )中，patsubst把$(dir)中的变量符合后缀是.c的全部替换成.o。 变量值的替换。 我们可以替换变量中的共有的部分，其格式是“$(var:a=b)”或“${var:a=b}”，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。 修改后的Makefile如下： 1234567891011# SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC = $(wildcard *.c) SRC_OBJ = $(SRC:.c=.o) SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) 其中# 后面的内容为注释。 这样终于满足了那些懒人的想法了。可见在使用变量时，的确可以是编译变得更自动化。 其实变量的定义有三种运算符=、:=、?=、+=。 =运算符可以读取到后面定义的变量。比如：12345VAR = $(VAR2) VAR2 = hello_make all: &gt;---@echo =====$(VAR)===== 运行结果为： 123# =====hello_make===== # 但是这种定义可能会导致并非我们意愿的事发生，并不是很符合C语言的编程习惯。 :=运算符在遇到变量定义时立即展开。12345VAR := $(VAR2) VAR2 = hello_make all: &gt;---@echo =====$(VAR)===== 运行结果为： 123# ========== # ?=运算符在复制之前先做判断变量是否已经存在。例如var1 ?= $(var2)的意思是：如果var1没有定义过，那么?=相当于=，如果var1先前已经定义了，则什么也不做，不会给var重新赋值。 +=运算符是给变了追加值。如果变量还没有定义过就直接用+=赋值，那么+=相当于= 如何使用这几个运算符要看实际情况，有时一个大的工程可能有许多Makefile组成，变量可能在多个Makefile中都在使用，这时可能使用+=比较好。使用:=有时可能比要好。 有时在编译程序时，我们需要编译器给出警告，或加入调试信息，或告知编译器优化可执行文件。编译时C编译器的选项CFLAGS使用的较多，默认没有提供值，我们可以给该变量赋值。有时我们还需要使用链接器选项LFLAGS告诉链接器链接时需要的库文件。可能我们还需要给出包含头文件的路径，因为头文件很可能和源文件不再同一目录。所以，我们今天的Makefile加上部分注释又更新了： 1234567891011121314151617# A commonMakefile for c programs, version 1.0 # Copyright (C)2014 shallnew \at 163 \dot com CFLAGS += -g -Wall-Werror -O2 CPPFLAGS += -I.-I./inc LDFLAGS +=-lpthread # SRC_OBJ =$(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES =$(wildcard *.c) SRC_OBJ =$(SRC_FILES:.c=.o) SRC_BIN =target_bin $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_BIN) 编译： 12345678# make cc -g -Wall-Werror -O2 -I. -I./inc -c -o debug.odebug.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o ipc.oipc.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o main.omain.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o timer.otimer.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o tools.otools.c cc -o target_bindebug.o ipc.o main.o timer.o tools.o -lpthread # 可见我们的预编译选项，编译选项都用到了，之前我们说过make的使用隐含规则自动推导： 1COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH) –c 其中变量CFLAGS 和 CPPFLAGS均是我们给出的，变量$(TARGET_ARCH)未给，所以在编译输出可以看到-c前面有2个空，最早未给变量是有四个空。 目前给出的Makefile基本上可以适用于那些源代码全部在同一目录下的简单项目，并且基本上在增删文件时不需要再去手动修改Makefile代码。在新的一个项目只需要把该Makefile拷贝到源代码目录下，再修改一下你需要编译的可执行文件名称以及你需要的编译连接选项即可。 后面章节将会讲到如何写多目录源代码工程下的Makefile。 最后，今天的最终Makefile是这样的： 1234567891011121314151617# A commonMakefile for c programs, version 1.0 # Copyright (C)2014 shallnew \at 163 \dot com CFLAGS += -g -Wall-Werror -O2 CPPFLAGS += -I.-I./inc LDFLAGS +=-lpthread # SRC_OBJ =$(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES =$(wildcard *.c) SRC_OBJ =$(SRC_FILES:.c=.o) SRC_BIN =target_bin $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_BIN) 3. 伪目标一般情况下，Makefile都会有一个clean目标，用于清除编译过程中产生的二进制文件。我们在第一节的Makefile就用到了这个 clean目标，该目标没有任何依赖文件，并且该目标对应的命令执行后不会生产clean文件。 像这种特点目标，它的规则所定义的命令不是去创建文件，而仅仅通过make指定目标来执行一些特定系统命令或其依赖为目标的规则（如all），称为伪目标。 一个Makefile一般都不会只有一个伪目标，如果按Makefile的“潜规则”以及其约定俗成的名字来说的话，在较大的项目的Makefile中比较常用的为目标有这些： all：执行主要的编译工作，通常用作缺省目标，放在最前面。 Install：执行编译后的安装工作，把可执行文件、配置文件、文档等分别拷到不同的安装目录。 clean：删除编译生成的二进制文件。 distclean：删除除源文件之外的所有中间生成文件，如配置文件，文档等。 tags：为vim等编辑器生成tags文件。 help：打印当前Makefile的帮助信息，比如有哪些目标可以有make指定去执行。 等。 make处理Makefile时，首先读取所有规则，建立关系依赖图。然后从缺省目标（第一个目标）或指定的目标开始执行。像clean，tags这样的目标一般不会作为缺省目标，也不会跟缺省目标有任何依赖关系，所以 make 无法生成它的依赖关系和决定它是否要执行。所以要执行这样的目标时，必须要显示的指定make该目标。就像前面我们清楚便已产生的中间二进制文件一样，需要显示执行命令：make clean。 伪目标也可以作为默认目标（如all），并且可以为其指定依赖文件。 我们先将version 1.0的Makefile完善下，我们可以加入帮助信息，tags等功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344# A common Makefile for c programs, version 1.1 # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc LDFLAGS += -lpthread # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard *.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefile for cprograms==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163 \dotcom&quot; &gt;---@echo &quot;The following targets are support:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, without link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vim editor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make [target]&apos;&quot; &gt;---@echo &quot;========================= Version 1.1=======================&quot; # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags *~ make会把执行的命令打印在屏幕上，如果我们不想把命令打印在屏幕上，只显示命令结果时，直接在命令前面加上符号“@”就可以实现。如上面help目标一样，只显示命令结果。一般我们会在make时都会输出“Compiling xxx.c…”,不输出编译时的命令。我们在后面写Makefile时可以模仿。 如果当前目录下存在一个和伪目标同名的文件时（如clean），此时如果执行命令make clean后出现如下结果： 1234# touch clean # make clean make: `clean&apos; is up to date. # 这是因为clean文件没有依赖文件，make认为目标clean是最新的不会去执行规则对应的命令。为了解决这个问题，我们可以明确地将该目标声明为伪目标。将一个目标声明为伪目标需要将它作为特殊目标.PHONY”的依赖。如下： 1.PHONY : clean 这条规则写在clean:规则的后面也行，也能起到声明clean是伪目标的作用 这样修改一下之前Makefile，将所有伪目标都作为.PHONY的依赖： 1.PHONY : all obj tag help clean disclean 这样在当前目录下存在文件clean时执行: 123# make clean rm -f debug.o ipc.o main.o timer.o tools.o target_bin target_bin.exe # 发现问题解决。 最后，给出今天最终的Makefile： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# A common Makefile for c programs, version 1.1 # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc LDFLAGS += -lpthread # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard *.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) tag: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefile for cprograms==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163 \dotcom&quot; &gt;---@echo &quot;The following targets are support:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, without link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and other information&quot; &gt;---@echo &quot; tags - create ctags for vim editor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make [target]&apos;&quot; &gt;---@echo &quot;========================= Version 1.1=======================&quot; # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags *~ .PHONY : all obj tag help clean disclean 5. 嵌套执行在大一些的项目里面，所有源代码不会只放在同一个目录，一般各个功能模块的源代码都是分开的，各自放在各自目录下，并且头文件和.c源文件也会有各自的目录，这样便于项目代码的维护。这样我们可以在每个功能模块目录下都写一个Makefile，各自Makefile处理各自功能的编译链接工作，这样我们就不必把所有功能的编译链接都放在同一个Makefile里面，这可使得我们的Makefile变得更加简洁，并且编译的时候可选择编译哪一个模块，这对分块编译有很大的好处。 现在我所处于工程目录树如下： 123456789101112131415161718192021222324252627282930313233. ├── include │ ├── common.h │ ├── ipc │ │ └── ipc.h │ └── tools │ ├── base64.h │ ├── md5.h │ └── tools.h ├── Makefile ├── src │ ├── ipc │ │ ├── inc │ │ ├── Makefile │ │ └── src │ │ └── ipc.c │ ├── main │ │ ├── inc │ │ ├── Makefile │ │ └── src │ │ ├── main.c │ │ └── main.c~ │ └── tools │ ├── inc │ ├── Makefile │ └── src │ ├── base64.c │ ├── md5.c │ └── tools.c └── tags 13 directories, 16 files 这样组织项目源码要比之前合理一些，那这样怎么来写Makefile呢？我们可以在每个目录下写一个Makefile，通过最顶层的Makefile一层一层的向下嵌套执行各层Makefile。那么我们最顶层的Makefile简单点的话可以这样写： 123456789101112# top Makefile for xxx all : &gt;---$(MAKE) -C src tags: &gt;---ctags -R clean : &gt;---$(MAKE) -C src clean .PHONY : all clean tags 命令： 1&gt;---$(MAKE) -C src 就是进入src目录继续执行该目录下的Makefile。然后src目录下的Makefile在使用同样的方法进入下一级目录tools、main、ipc，再执行该目录下的Makefile。其实这样有些麻烦，我们可以直接从顶层目录进入最后的目录执行make。再加入一些伪目标完善下，我们的顶层Makefile就出来了： 12345678910111213141516171819202122232425262728293031323334353637383940414243# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com all : &gt;---$(MAKE) -C src/ipc &gt;---$(MAKE) -C src/tools &gt;---$(MAKE) -C src/main tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, withoutlink&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.0 =======================&quot; obj: &gt;---$(MAKE) -C src/ipc obj &gt;---$(MAKE) -C src/tools obj &gt;---$(MAKE) -C src/main obj clean : &gt;---$(MAKE) -C src/ipc clean &gt;---$(MAKE) -C src/tools clean &gt;---$(MAKE) -C src/main clean distclean: &gt;---$(MAKE) -C src/ipc distclean &gt;---$(MAKE) -C src/tools distclean &gt;---$(MAKE) -C src/main distclean .PHONY : all clean distclean tags help 当我们这样组织源代码时，最下面层次的Makefile怎么写呢？肯定不可以将我们上一节的Makefile（version 1.1）直接拷贝到功能模块目录下，需要稍作修改。不能所有的模块都最终生成各自的可执行文件吧，我们目前是一个工程，所以最后只会生成一个可执行程序。我们这样做，让主模块目录生成可执行文件，其他模块目录生成静态库文件，主模块链接时要用其他模块编译产生的库文件来生成最终的程序。将上一节Makefile稍作修改得出编译库文件Makefile和编译可执行文件Makefile分别如下： 12345678910111213141516171819202122232425262728# A Makefile to generate archive file # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc -I../../include # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_LIB = libtools.a all : $(SRC_LIB) $(SRC_LIB) : $(SRC_OBJ) &gt;---$(AR) rcs $@ $^ &gt;---cp $@ ../../libs obj : $(SRC_OBJ) # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) tags *~ .PHONY : all obj clean disclean ==================== 12345678910111213141516171819202122232425262728# A Makefile to generate executive file # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc -I../../include LDFLAGS += -lpthread -L../../libs -ltools -lipc # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags*~ .PHONY : all obj clean disclean 最后在顶层执行： 1234567891011121314151617181920212223242526272829303132333435# make clean make -C src/ipc clean make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; rm -f src/ipc.o libipc.a make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; make -C src/tools clean make[1]: Entering directory `/home/Myprojects/example_make/version-3.0/src/tools&apos; rm -f src/base64.o src/md5.o src/tools.o libtools.a make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; make -C src/main clean make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/main&apos; rm -f src/main.o target_bin target_bin.exe make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/main&apos; # make make -C src/ipc make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/ipc.osrc/ipc.c ar rcs libipc.a src/ipc.o cp libipc.a ../../libs make[1]: Leaving directory `/home/Myprojects/example_make/version-3.0/src/ipc&apos; make -C src/tools make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/base64.osrc/base64.c cc -g -Wall -Werror -O2 -I. -I./inc -I../../include -c -o src/md5.o src/md5.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/tools.osrc/tools.c ar rcs libtools.a src/base64.o src/md5.o src/tools.o cp libtools.a ../../libs make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; make -C src/main make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/main&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/main.osrc/main.c cc -o target_bin src/main.o -lpthread -L../../libs -ltools-lipc make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/main&apos; # 最后生成了可执行程序文件。这样的话一个工程的各个模块就变得独立出来了，不但源码分开了，而且各自有各自的Makefile，并且各个功能模块是可独立编译的。 我们发现顶层Makefile还有可以改进的地方，就是在进入下一层目录是要重复写多次，如下： 123&gt;---$(MAKE) -C src/ipc &gt;---$(MAKE) -C src/tools &gt;---$(MAKE) -C src/main 每增加一个目录都要在多个伪目标里面加入一行，这样不够自动化啊，于是我们想到shell的循环语 句，我们可以在每条规则的命令处使用for循环。如下： 1234567DIR = src SUBDIRS = $(shell ls $(DIR)) all : &gt;---@for subdir in $(SUBDIRS); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir; \ &gt;---done 这样懒人有可以高兴很久了。不过还有问题： 上面for循环会依次进入系统命令ls列出的目录，但我们对每个目录的make顺序可能有要求，在该项目当中，main目录下的Makefile必须最后执行，因为最终的链接需要其他目录编译生成的库文件，否则会执行失败。并且在当前的Makefile中，当子目录执行make出现错误时，make不会退出。在最终执行失败的情况下，我们很难根据错误的提示定位出具体是是那个目录下的Makefile出现错误。这给问题定位造成了很大的困难。为了避免这样的问题，在命令执行错误后make退出。 所以将刚才的Makefile修改为如下 1234567DIR = src SUBDIRS = $(shell ls $(DIR)) all : &gt;---@for subdir in $(SUBDIRS); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir || exit 1; \ &gt;---done 这样在执行出错时立马退出，但这样还是没有解决问题，编译错误还是会出现。那怎么解决呢？ 我们可以通过增加规则来限制make执行顺序，这样就要用到伪目标，对每一个模块我们都为他写一条规则，每个模块名称是目标，最后需要执行的模块目标又是其他模块的目标，这样就限制了make顺序。在执行到最后需要执行的目标时，发现存在依赖，于是先更新依赖的目标，这样就不会出错了。并且这样的话，我们还可以对指定模块进行编译，比如我只修改了tools模块，我只想看看我修改的这个模块代码是否可以编译通过，我可以在编译时这样： 12345678910# make tools make -C src/tools make[1]: Entering directory`/home/Myprojects/example_make/version-2.1/src/tools&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/base64.o src/base64.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/md5.osrc/md5.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/tools.osrc/tools.c ar rcs libtools.a src/base64.o src/md5.o src/tools.o cp libtools.a ../../libs make[1]: Leaving directory`/home/Myprojects/example_make/version-2.1/src/tools&apos; # 还有另外一种方法也可以解决此问题，就是手动列出需要进入执行的模块名称（这里就是目录了），把最后需要执行的模块放在最后，这样for循环执行时最后需要编译链接的模块就放在最后了，不会像我们之前那样make是按照使用系统命令ls列出模块目录的顺序来执行。ls列出目录是按照每个目录的名称来排序的，我们总不能要求写代码的时候最后执行的模块的名称必须是以z开头的吧，总之不现实。 我们的顶层Makefile又进化了，也是这一节最终Makefile： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com DIR = src MODULES = $(shell ls $(DIR)) # MODULES = ipc main tools all : $(MODULES) $(MODULES): &gt;---$(MAKE) -C $(DIR)/$@ main:tools ipc obj: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done clean : &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done distclean: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, withoutlink&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.0 =======================&quot; .PHONY : all clean distclean tags help 6.参数传递、条件判断、include 在多个Makefile嵌套调用时，有时我们需要传递一些参数给下一层Makefile。比如我们在顶层Makefile里面定义的打开调试信息变量DEBUG_SYMBOLS，我们希望在进入子目录执行子Makefile时该变量仍然有效，这是需要将该变量传递给子Makefile，那怎么传递呢？这里有两种方法： 在上层Makefile中使用”export”关键字对需要传递的变量进行声明。比如： 12DEBUG_SYMBOLS = TRUE export DEBUG_SYMBOLS 当不希望将一个变量传递给子 make 时，可以使用指示符 “unexport”来声明这个变量。 export一般用法是在定义变量的同时对它进行声明。如下： 1export DEBUG_SYMBOLS = TRUE 在命令行上指定变量。比如：1$(MAKE) -C xxx DEBUG_SYMBOLS = TRUE 这样在进入子目录xxx执行make时该变量也有效。 像编程语言一样，Makefile也有自己的条件语句。条件语句可以根据一个变量值来控制make的执行逻辑。比较常用的条件语句是ifeq –else-endif、ifneq-else-endif、ifdef-else-endif。 ifeq关键字用来判断参数是否相等。 比如判断是否生成调试信息可以这么用： 12345ifeq ($(DEBUG_SYMBOLS), TRUE) &gt;---CFLAGS += -g -Wall -Werror -O0 else &gt;---CFLAGS += -Wall -Werror -O2 endif Ifneq和ifeq作用相反，此关键字是用来判断参数是否不相等。 ifdef关键字用来判断一个变量是否已经定义。 后两个关键字用法和ifeq类似。 现在我们继续改进我们上一节的Makefile，上一节的Makefile完成Makefile的嵌套调用，每一个模块都有自己的Makefile。其实每个模块的Makefile都大同小异，只需要改改最后编译成生成的目标名称或者编译链接选项，规则都差不多，那么我们是否可以考虑将规则部分提取出来，每个模块只需修改各自变量即可。这样是可行的，我们将规则单独提取出来，写一个Makefile.rule，将他放在顶层Makefile同目录下，其他模块内部的Makefile只需要include该Makefile就可以了。如下： 1include $(SRC_BASE)/Makefile.rule include类似于C语言的头文件包含，你把它理解为为本替换就什么都明白了。 这样以后规则有修改的话我们直接修改该Makefile就可以了，就不用进入每一个模块去修改，这样也便于维护。 这样我们今天顶层Makefile稍作修改： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com export DEBUG_SYMBOLS = TRUE DIR = src MODULES = $(shell ls $(DIR)) # MODULES = ipc main tools all : $(MODULES) $(MODULES): &gt;---$(MAKE) -C $(DIR)/$@ main:tools ipc clean : &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done distclean: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.2 =======================&quot; .PHONY : all clean distclean tags help 目前我们顶层目录下的目录树为： 123456789101112131415161718192021222324252627282930313233. ├── include │ ├── common.h │ ├── ipc │ │ └── ipc.h │ └── tools │ ├── base64.h │ ├── md5.h │ └── tools.h ├── libs ├── Makefile ├── Makefile.rule └── src ├── ipc │ ├──inc │ ├──Makefile │ └──src │ └── ipc.c ├── main │ ├──inc │ ├──Makefile │ └──src │ ├── main.c │ └── main.c~ └── tools ├── inc ├── Makefile └── src ├── base64.c ├── md5.c └── tools.c 14 directories, 16 files 每个子模块下的Makefile删除规则后修改为如下： 1234567891011SRC_BASE = ../.. CFLAGS += CPPFLAGS += -I. -I./inc -I$(SRC_BASE)/include # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_LIB = libtools.a include $(SRC_BASE)/Makefile.rule 而处于顶层目录下的Makefile.rule专门处理各模块编译链接时需要的规则。内容如下： 123456789101112131415161718192021222324252627282930# Copyright (C) 2014 shallnew \at 163 \dot com ifeq ($(DEBUG_SYMBOLS), TRUE) &gt;---CFLAGS += -g -Wall -Werror -O0 else &gt;---CFLAGS += -Wall -Werror -O2 endif all : $(SRC_BIN) $(SRC_LIB) ifneq ($(SRC_BIN),) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) endif ifneq ($(SRC_LIB),) $(SRC_LIB) : $(SRC_OBJ) &gt;---$(AR) rcs $@ $^ &gt;---cp $@ $(SRC_BASE)/libs endif # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) $(SRC_BIN)$(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) $(SRC_BIN)$(SRC_BIN).exe $(SRC_BASE)/libs/* $(SRC_BASE)/tags *~ .PHONY : all clean disclean ~ 我们将Makefile.rule放在顶层有可能会一不小心在命令行上面执行了该Makefile，如下： 123# make -f Makefile.rule make: Nothing tobe done for `all&apos;. # 由于我们没有定义变量$(SRC_BIN)和$(SRC_LIB)，伪目标all没有任何依赖，所以编译是无法成功的。这里我们我们应该禁止直接执行该Makefile。 在make里面有这样一个变量：MAKELEVEL，它在多级调用的 make 执行过程中。变量代表了调用的深度。在 make 一级级的执行过程中变量MAKELEVEL的值不断的发生变化，通过它的值我们可以了解当前make 递归调用的深度。顶层的MAKELEVEL的值为“0” 、下一级时为“1” 、再下一级为“2”…….，所以我们希望一个子目录的Makefile必须被上层 make 调用才可以执行，而不允许直接执行，我们可以判断变量MAKELEVEL来控制。所以我们这一节最终的Makefile.rule为： 123456789101112131415161718192021222324252627282930313233343536# Copyright (C)2014 shallnew \at 163 \dot com ifeq ($(DEBUG_SYMBOLS),TRUE) &gt;---CFLAGS +=-g -Wall -Werror -O0 else &gt;---CFLAGS +=-Wall -Werror -O2 endif ifeq($(MAKELEVEL), 0) all : msg else all : $(SRC_BIN)$(SRC_LIB) endif ifneq ($(SRC_BIN),) $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) endif ifneq($(SRC_LIB),) $(SRC_LIB) :$(SRC_OBJ) &gt;---$(AR) rcs$@ $^ &gt;---cp $@$(SRC_BASE)/libs endif msg: &gt;---@echo&quot;You cannot directily execute this Makefile! This Makefile should calledby toplevel Makefile.&quot; # clean target clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_LIB) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM)$(SRC_OBJ) $(SRC_LIB) $(SRC_BIN) $(SRC_BIN).exe $(SRC_BASE)/libs/*$(SRC_BASE)/tags *~ .PHONY : all cleandisclean 此时再直接执行该Makefile： 123# make -f Makefile.rule You cannot directily execute this Makefile! This Makefile should called by toplevel Makefile. # 7. 统一目标输出目录上一节我们把规则单独提取出来，方便了Makefile的维护，每个模块只需要给出关于自己的一些变量，然后再使用统一的规则Makefile。这一节我们继续改进我们的Makefile，到目前为止我们的Makefile编译链接输出的目标都在源文件同目录下或模块Makefile同一目录下，当一个项目大了之后，这样会显得很乱，寻找编译输出的文件也比较困难。既然Makefile本身就是按照我们的的规则来编译链接程序，那么我们就可以指定其编译链接目标的目录，这样，我们可以清楚输出文件的地方，并且在清除已编译的目标时直接删除指定目录即可，不需要一层一层的进入源代码目录进行删除，这样又提高了效率。 既然要统一目标输出目录，那么该目录就需要存在，所以我们可以增加一条规则来创建这些目录，包括创建可执行文件的目录、链接库文件的目录以及.o文件的目录。并且目录还可以通过条件判断根据是否产生调试信息来区分开相应的目标文件。一般一个工程的顶层目录下都会有一个build目录来存放编译的目标文件结果，目前我的工程目录下通过Makefile创建的目录build的目录树如下： 1234567891011121314151617181920build/ //build根目录 ├── unix //unix平台项目下不带调试信息输出目录 │ ├── bin //存放可执行文件目录 │ ├── lib //存放可文件目录 │ └── obj //存放.o文件目录，该目录下将每个模块生成的.o文件各自的目录下面 │ ├── ipc │ ├── main │ └── tools └── unix_dbg ////unix平台项目下带调试信息输出目录 ├── bin ├── lib └── obj ├── ipc ├── main └── tools 14 directories, 0 files``` 以上目录中bin和lib目录在顶层Makefile中创建，obj及其下面模块子目录在各模块的Makefile里面创建。顶层Makefile创建目录如下： ifeq ($(DEBUG_SYMBOLS), TRUE) —BUILDDIR = ./build/$(PLATFORM)_dbgelse—BUILDDIR = ./build/$(PLATFORM)endif all : $(BUILDDIR) $(MODULES) $(BUILDDIR): —@echo “ Create directory $@ …”—mkdir -p $(BUILDDIR)/bin $(BUILDDIR)/lib123我们在all目标里面增加了其依赖目标BUILDDIR，该目标对应的规则为创建bin目录和lib目录。这样每次编译之前都会创建目录。各模块内部Makefile创建生成.O文件的目录，如上目录树所示。类似于顶层Makefile，各模块内部Makefile需要根据平台、编译调试信息、以及模块名称来生成需要的目录名称，然后再增加创建该目录的规则。因为每个模块都会做这些处理，所以我们将这部分写在规则Makefile(Makefile.rule)里面，如下： …… define a root build directory base on the platformif without a SRC_BASE defined, just use local src directoryifeq ($(SRC_BASE),) —BUILDDIR = $(MOD_SRC_DIR)—OBJDIR = $(MOD_SRC_DIR)—LIBDIR = $(MOD_SRC_DIR)—BINDIR = $(MOD_SRC_DIR)else—ifeq ($(DEBUG_SYMBOLS), TRUE)—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)_dbg—else—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)—endif—OBJDIR = $(BUILDDIR)/obj/$(MODULE)—LIBDIR = $(BUILDDIR)/lib—BINDIR = $(BUILDDIR)/binendif……ifeq ($(MAKELEVEL), 0)all : msgelseall : lib binendif lib : $(OBJDIR) $(SRC_LIB) bin : $(OBJDIR) $(SRC_BIN) $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@……1此时我们编译一下后查看build目录： build/└── unix_dbg ├── bin ├── lib └── obj ├── ipc ├── main └── tools 7 directories, 0 files123456由于我们是开启了调试信息，所以创建了unix_dbg目录，并且该目录下创建了bin、lib、obj目录及其模块目录，但我们没有发现有文件存放在里面。到目前为止，这一节仅仅讲述如何创建统一的目标文件存放目录，但是要想将编译生成的目标文件自动生成到这些目录还没有完成。其实我们只需要给目标加上路径即可，但还是有一些详细的地方需要处理，具体的我们会在下一节中讲到，这一节暂不给出最后的Makefile。### 8. 模式规则上一节讲到目录创建成功，目标文件没有生产到对应目录下，这里我们先给目标文件加上对应目录，这样的话产生对应的目标文件会直接生成到对应目录。我们先给库文件目标和可执行文件目标加上路径，如下： lib : $(OBJDIR) $(LIBDIR)/$(SRC_LIB) bin : $(OBJDIR) $(BINDIR)/$(SRC_BIN) $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —$(AR) rcs $@ $^—cp $@ $(SRC_BASE)/libsendif1此时再执行make，完成后查看build目录树： build/└── unix_dbg ├── bin │ └── target_bin ├── lib │ ├── libipc.a │ └── libtools.a └── obj ├── ipc ├── main └── tools1可以看到，生成的目标是在对应目录下。我们乘胜追击，把.o文件也将其修改了。我们之前的每个模块Makefile大致是这样写的： SRC_BASE = ../.. CFLAGS +=CPPFLAGS += -I. -I./inc -I$(SRC_BASE)/include SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c))SRC_FILES = $(wildcard src/*.c)SRC_OBJ = $(SRC_FILES:.c=.o)SRC_LIB = xx.a include $(SRC_BASE)/Makefile.rule1其中SRC_OBJ在此处给出，然后再在Makefile.rule中使用，此处的.o文件会在.c文件相同目录下生成，所以我们现在需要将.o文件加上路径，由于取得路径是在Makefile.rule里面，所以我们可以统一在Makefile.rule里面给变量SRC_OBJ赋值，大致如下： SRC_OBJ = $(patsubst %.c, $(OBJDIR)/%.o, $(notdir $(SRC_FILES)))12这里用到函数patsubst、notdir，关于函数会在后面讲到。这样.o文件作为目标生成之后就会生成到相应目录里面了。此时再编译： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make target../../build/unix_dbg/obj/ipc/ipc.o’, needed by ../../build/unix_dbg/lib/libipc.a&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2 12发现出错了，并且是在生成目标文件ipc.o时没有成功，查看build目录树也没有生成.o文件。为什么会生成失败呢？我们没有给出生成.o目标的规则，之前可以生成是因为make有通过隐含规则来自动推导的能力（这个之前有讲到，链接过去）。在我们没有修改之前，生成.o通过隐含规则来完成： %.o: %.c commands to execute (built-in): —$(COMPILE.c) $(OUTPUT_OPTION) $&lt;1该模式规则中目标文件是$(OBJDIR)/%.o，那么现在有了符合生成我们需要的.o文件的规则了，编译一下： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make target../../build/unix_dbg/obj/ipc/ipc.o’, needed by ../../build/unix_dbg/lib/libipc.a&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2# 123456发现还是不对，不是已经增加了模式规则了吗，为何还是没有生成.o文件。我们这里先说说静态模式规则：一个规则中可以有多个目标，规则所定义的命令对所有的目标有效。一个具有多目标的规则相当于多个规则。 规则的命令对不同的目标的执行效果不同， 因为在规则的命令中可能使用了自动化变量 `“$@”` 。 多目标规则意味着所有的目标具有相同的依赖文件。多目标通常用在以下两种情况：虽然在多目标的规则中， 可以根据不同的目标使用不同的命令 （在命令行中使用自动化变量 `“$@”` ）。但是， 多目标的规则并不能做到根据目标文件自动改变依赖文件 （像上边例子中使用自动化变量“$@”改变规则的命令一样） 。需要实现这个目的是，要用到make的静态模式。静态模式规则是这样一个规则：规则存在多个目标， 并且不同的目标可以根据目标文件的名字来自动构造出依赖文件。静态模式规则比多目标规则更通用， 它不需要多个目标具有相同的依赖。但是静态模式规则中的依赖文件必须是相类似的而不是完全相同的。静态模式规则语法如下： : : ….1比如下面是一个静态模式规则： objects = foo.o bar.o all: $(objects) $(objects): %.o: %.c$(CC) -c $(CFLAGS) $&lt; -o $@ 1该规则描述了所有的.o文件的依赖文件为对应的.c文件，对于目标“foo.o” ，取其茎“foo”替代对应的依赖模式“%.c”中的模式字符“%”之后可得到目标的依赖文件“foo.c”。这就是目标“foo.o”的依赖关系“foo.o: foo.c”，规则的命令行描述了如何完成由“foo.c”编译生成目标“foo.o” 。命令行中“$&lt;”和“$@”是自动化变量，“$&lt;” 表示规则中的第一个依赖文件， “$@” 表示规则中的目标文件。上边的这个规则描述了以下两个具体的规则： foo.o : foo.c —$(CC) -c $(CFLAGS) foo.c -o foo.obar.o : bar.c—$(CC) -c $(CFLAGS) bar.c -o bar.o123456789注：该示例与其相关描述摘抄于互联网，描述很不错，估计比我讲的详细）那静态模式规则和普通的模式规则（非静态模式规则）有什么去区别呢？两者都是用目标模式和依赖模式来构建目标的规则中的文件依赖关系，两者不同的地方是 make 在执行时使用它们的时机。静态模式规则只能用在规则中明确指出的那些文件的重建过程中。不能用在除此之外的任何文件的重建过程中，并且它对指定的每一个目标来说是唯一的。如果一个目标存在于两个规则，并且这两个规则都定义了命令， make 执行时就会提示错误。非静态模式规则可被用在任何和它相匹配的目标上，当一个目标文件同时符合多个目标模式时，make将会把第一个目标匹配的模式规则作为重建它的规则。那有没有想过如果我们指定了模式规则后，那还有隐含规则呢，那怎么选择执行哪一个模式规则呢？Makefile中明确指定的模式规则会覆盖隐含模式规则。就是说如果在Makefile中出现了一个对目标文件合适可用的模式规则，那么make就不会再为这个目标文件寻找其它隐含规则，而直接使用在Makefile中出现的这个规则。在使用时，明确规则永远优先于隐含规则。我们继续说之前的那个问题，我们定义了模式规则后还是没有生成.o文件，我们现在将其改为静态规则再试试就看，如下： $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@1执行后： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make targetipc.c’, needed by ../../build/unix_dbg/obj/ipc/ipc.o&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2# 123456789发现提示没有文件ipc.c，这说明没有生成.o的原因是没有.c文件，我很好奇的是为何使用非静态模式为何不提示呢？（还没搞懂，再研究研究，知道的可以给个提示哈~~）缺少依赖文件，为何没有*.c文件，仔细想想我们的.o文件没有和.c文件在同一目录。在我们工程中，将源代码和二进制文件（.o 文件和可执行文件）安排在不同的目录来进行区分管理。这种情况下，我们可以使用 make 提供的目录搜索依赖文件功能。该功能在下一节讲述，这一节说的够多了，有点累了。可惜最终还是没有给出一个可用的Makefile，在下一节将会给出。### 9. 目标搜索在一个较大的工程中，一般会将源代码和二进制文件（.o 文件和可执行文件）安排在不同的目录来进行区分管理。这种情况下，我们可以使用 make 提供的目录搜索依赖文件功能（在指定的若干个目录下自动搜索依赖文件）。在Makefile中，使用依赖文件的目录搜索功能。当工程的目录结构发生变化后，就可以做到不更改 Makefile的规则，只更改依赖文件的搜索目录。在我们上一节出现的问题当中，我们将.c文件统一放在src目录下，没有和Makefile目录在同一目录下，因此没有办法寻找到.o文件的依赖文件。make程序有一个特殊的变量VPATH，该变量可以指定依赖文件的搜索路径，当规则的依赖文件在当前目录不存在时，make 会在此变量所指定的目录下去寻找这些依赖文件。通常我们都是用此变量来指定规则的依赖文件的搜索路径。定义变量 “VPATH”时，使用空格或者冒号（:）将多个需要搜索的目录分开。make搜索目录的顺序是按照变量“VPATH”定义中的目录顺序进行的，当前目录永远是第一搜索目录。例如如下定义 VPATH += ./src123指定了依赖搜索目录为当前目录下的src目录，我们可以在Makefile.rules里面添加给VPATH变量赋值，而在包含该Makefile.rules之前给出当前模块.c文件所在目录。其实我们也可以直接指定依赖文件的路径，这样也是可以的，如下： $(SRC_OBJ) : $(OBJDIR)/%.o : $(MOD_SRC_DIR)/%.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@123456789101112但是这样在我们更改了工程目录结构之后，对应的依赖文件没有在同一目录下，又变得麻烦了，所以还不如直接给VPATH变量赋值，我们只需要指定源码所在的目录即可。其实我们还有另外一种搜索文件路径方法：使用vpath关键字（注意不是VPATH变量）， 它和VPATH类似，但是它可以为不同类型的文件（由文件名区分）指定不同的搜索目录。使用方法有三种：1. vpath PATTERN DIRECTORIES为所有符合模式“PATTERN”的文件指定搜索目录“DIRECTORIES” 。多个目录使用空格或者冒号（：）分开。2. vpath PATTERN清除之前为符合模式“PATTERN”的文件设置的搜索路径。3. vpath清除所有已被设置的文件搜索路径。vapth 使用方法中的“PATTERN”需要包含模式字符“%”；例如上面的定义： VPATH += ./src1可以写为： vpath %.c ./src1现在给一个我们的Makefile.rules： Copyright (C) 2014 shallnew \at 163 \dot comif without a platform defined, give value “unknow” to PLATFORMifndef PLATFORM —PLATFORM = unknowendif define a root build directory base on the platformif without a SRC_BASE defined, just use local src directoryifeq ($(SRC_BASE),) —BUILDDIR = $(MOD_SRC_DIR)—OBJDIR = $(MOD_SRC_DIR)—LIBDIR = $(MOD_SRC_DIR)—BINDIR = $(MOD_SRC_DIR)else—ifeq ($(DEBUG_SYMBOLS), TRUE)—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)_dbg—else—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)—endif—OBJDIR = $(BUILDDIR)/obj/$(MODULE)—LIBDIR = $(BUILDDIR)/lib—BINDIR = $(BUILDDIR)/binendif update compilation flags base on “DEBUG_SYMBOLS”ifeq ($(DEBUG_SYMBOLS), TRUE) —CFLAGS += -g -Wall -Werror -O0else—CFLAGS += -Wall -Werror -O2endif VPATH += $(MOD_SRC_DIR) SRC_OBJ = $(patsubst %.c, $(OBJDIR)/%.o, $(notdir $(SRC_FILES))) ifeq ($(MAKELEVEL), 0)all : msgelseall : lib binendif lib : $(OBJDIR) $(LIBDIR)/$(SRC_LIB) bin : $(OBJDIR) $(BINDIR)/$(SRC_BIN) $(OBJDIR) : —mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —$(AR) rcs $@ $^—cp $@ $(SRC_BASE)/libsendif $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@ msg: —@echo “You cannot directily execute this Makefile! This Makefile should called by toplevel Makefile.” clean targetclean:ifneq ($(SRC_LIB),) —&gt;—$(RM) $(SRC_OBJ) $(LIBDIR)/$(SRC_LIB)endififneq ($(SRC_BIN),)—&gt;—$(RM) $(SRC_OBJ) $(BINDIR)/$(SRC_BIN)endif .PHONY : all clean12345678910111213### 10. make内嵌函数及make命令显示这一节我们讲一下make的函数，在之前的章节已经讲到了几个函数：wildcard、patsubst、notdir、shell等。一般函数的调用格式如下：`$(funcname arguments)`或`$(funcname arguments)`其中funcname是需要调用函数的函数名称，应该是make内嵌函数；arguments是函数参数，参数和函数名之间使用空格分割，如果存在多个参数时，参数之间使用逗号“,”分开。函数调用以“$”开头，使用成对的圆括号或花括号把函数名和参数括起，一般使用圆括号。下面来看一下常用的一些函数：1. 获取匹配模式文件名函数—wildcard 。用法：`$(wildcard PATTERN)`该函数会列出当前目录下所有符合模式“PATTERN”格式的文件名。返回空格分割的、存在当前目录下的所有符合模式“PATTERN”的文件名。例如： SRC_FILES = $(wildcard src/*.c)12345678返回src目录下所有.c文件列表。2. 字符串替换函数—subst。用法：`$(subst FROM,TO,TEXT)`该函数把字串“TEXT”中的“FROM”字符替换为“TO”，返回替换后的新字符串。3. 模式替换函数—patsubst。用法：`$(patsubst PATTERN,REPLACEMENT,TEXT)`该函数搜索“TEXT”中以空格分开的单词，将符合模式“TATTERN”替换为“REPLACEMENT” 。参数“PATTERN”中可以使用模式通配符“%”，来代表一个单词中的若干字符。如果参数“REPLACEMENT”中也包含一个“%” ，那么“REPLACEMENT”中的“%”将是“TATTERN”中的那个“%”所代表的字符串。例如： SRC_OBJ = $(patsubst %.c, %.o, $(SRC_FILES)) 12345将SRC_FILES中所有.c文件替换为.o返回给变量SRC_OBJ。此函数功能类似之前讲过的变量替换，http://blog.csdn.net/shallnet/article/details/37529935变量替换格式是“$(var:a=b)”或“$&#123;var:a=b&#125;”，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。例如我们存在一个代表所有.c 文件的变量。定义为“src_files = a.c b.c c.c” 。为了得到这些.c文件所对应的.o源文件。如下两种使用可以得到同一种结果： $(objects:.c=.o)$(patsubst %.c,%.o,$( src_files)) 123456789101112131415161718192021224. 过滤函数—filter。用法：$(filter PATTERN…,TEXT)该函数过滤掉字串“TEXT”中所有不符合模式“PATTERN”的单词，保留所有符合此模式的单词。可以使用多个模式。模式中一般需要包含模式字符“%” 。存在多个模式时，模式表达式之间使用空格分割。返回空格分割的“TEXT”字串中所有符合模式“PATTERN”的字串。5. 反过滤函数—filter-out。用法：`$(filter-out PATTERN...,TEXT)`和“filter”函数实现的功能相反。过滤掉字串“TEXT”中所有符合模式“PATTERN” 的单词， 保留所有不符合此模式的单词。 可以有多个模式。存在多个模式时，模式表达式之间使用空格分割。6. 取目录函数—dir。用法：`$(dir NAMES…)`从文件名序列“NAMES…”中取出各个文件名的目录部分。文件名的目录部分就是包含在文件名中的最后一个斜线`（ “/” ）` （包括斜线）之前的部分。返回空格分割的文件名序列“NAMES…”中每一个文件的目录部分。如果文件名中没有斜线，认为此文件为当前目录`（ “./” ）`下的文件。7. 取文件名函数——notdir。用法：`$(notdir NAMES…)`从文件名序列“NAMES…”中取出非目录部分。目录部分是指最后一个斜线`（ “/” ）` （包括斜线）之前的部分。删除所有文件名中的目录部分，只保留非目录部分。文件名序列“NAMES…”中每一个文件的非目录部分。8. 取后缀函数—suffix。用法：`$(suffix NAMES…) `函数从文件名序列“NAMES…”中取出各个文件名的后缀。后缀是文件名中最后一个以点“.”开始的（包含点号）部分，如果文件名中不包含一个点号，则为空。 返回以空格分割的文件名序列“NAMES…”中每一个文件的后缀序列。9. 取前缀函数—basename。用法：`$(basename NAMES…)`从文件名序列“NAMES…”中取出各个文件名的前缀部分（点号之后的部分） 。前缀部分指的是文件名中最后一个点号之前的部分。 返回空格分割的文件名序列“NAMES…”中各个文件的前缀序列。如果文件没有前缀，则返回空字串。这里仅仅讲到一些常用的函数，还有一些函数没有讲到，用到的时候可以去翻翻makefile手册。通常情况下make在编译时会打印出当前正在执行的命令，当编译链接选项很长时，会输出很多东西在屏幕上，如果我 不想再屏幕上看到很多东西，我们可以在命令前面加上@，这样命令就不会输出到屏幕了。我们这样尝试修改下： makemake[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/ipc&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/ipc’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/tools&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/tools’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/main&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/main’ 123发现只有进入目录和退出目录的显示，这样很难知道目前编译过程。其实我们可以在规则命令处加入一行类似打印：`@echo &quot;do something......&quot;`这样可以输出目前正在做的事，又不会输出正在执行命令。现在将规则修改下如下： $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —@echo “ LINK $(notdir $@)…”—@$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —@echo “ ARCHIVE $(notdir $@)…”—@$(AR) rcs $@ $^—@echo “ COPY $@ to $(SRC_BASE)/libs”—@cp $@ $(SRC_BASE)/libsendif $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —@echo “ COMPILE $(notdir $&lt;)…”—@$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@1编译输出如下： makemake[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/ipc&#39; COMPILE ipc.c... ARCHIVE libipc.a... COPY ../../build/unix_dbg/lib/libipc.a to ../../libs make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/ipc’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/tools&#39; COMPILE base64.c... COMPILE md5.c... COMPILE tools.c... ARCHIVE libtools.a... COPY ../../build/unix_dbg/lib/libtools.a to ../../libs make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/tools’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/main&#39; COMPILE main.c... LINK target_bin... make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/main’ 12其中目录切换的输出仍然很多，我们可以将其关闭，这需要使用到make的参数，在make -C是指定--no-print-directory参数。我们将顶层目录下Makefile规则修改如下： $(BUILDDIR): —@echo “ Create directory $@ …”—mkdir -p $(BUILDDIR)/bin $(BUILDDIR)/lib $(MODULES): —@$(MAKE) -C $(DIR)/$@ MODULE=$@ –no-print-directory main:tools ipc clean : —@for subdir in $(MODULES); \—do $(MAKE) -C $(DIR)/$$subdir MODULE=$$subdir $@ –no-print-directory; \—done编译输出： makeCOMPILE ipc.c... ARCHIVE libipc.a... COPY ../../build/unix_dbg/lib/libipc.a to ../../libs COMPILE base64.c... COMPILE md5.c... COMPILE tools.c... ARCHIVE libtools.a... COPY ../../build/unix_dbg/lib/libtools.a to ../../libs COMPILE main.c... LINK target_bin… make cleanrm -f ../../build/unix_dbg/obj/ipc/ipc.o ../../build/unix_dbg/lib/libipc.arm -f ../../build/unix_dbg/obj/main/main.o ../../build/unix_dbg/bin/target_binrm -f ../../build/unix_dbg/obj/tools/base64.o ../../build/unix_dbg/obj/tools/md5.o../../build/unix_dbg/obj/tools/tools.o ../../build/unix_dbg/lib/libtools.a # ``` 这样看上去输出清爽多了。其实我们也可以使用make -s 来全面禁止命令的显示。 【版权声明：转载请保留出处：http://blog.csdn.net/shallnet/article/details/37358655】]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Makefile经典教程]]></title>
    <url>%2F2017%2F09%2F30%2Fcourse-makefile%2F</url>
    <content type="text"><![CDATA[什么是makefile？或许很多Winodws的程序员都不知道这个东西，因为那些Windows的IDE都为你做了这个工作，但我觉得要作一个好的和professional的程序员，makefile还是要懂。这就好像现在有这么多的HTML的编辑器，但如果你想成为一个专业人士，你还是要了解HTML的标识的含义。特别在Unix下的软件编译，你就不能不自己写makefile了，会不会写makefile，从一个侧面说明了一个人是否具备完成大型工程的能力。因为，makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。 现在讲述如何写makefile的文章比较少，这是我想写这篇文章的原因。当然，不同产商的make各不相同，也有不同的语法，但其本质都是在“文件依赖性”上做文章，这里，我仅对GNU的make进行讲述，我的环境是RedHat Linux 8.0，make的版本是3.80。必竟，这个make是应用最为广泛的，也是用得最多的。而且其还是最遵循于IEEE 1003.2-1992 标准的（POSIX.2）。 在这篇文档中，将以C/C++的源码作为我们基础，所以必然涉及一些关于C/C++的编译的知识，相关于这方面的内容，还请各位查看相关的编译器的文档。这里所默认的编译器是UNIX下的GCC和CC。 关于程序的编译和链接 在此，我想多说关于程序编译的一些规范和方法，一般来说，无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）。 编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（O文件或是OBJ文件）。 链接时，主要是链接函数和全局变量，所以，我们可以使用这些中间目标文件（O文件或是OBJ文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。 总结一下，源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法，和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker Error），在VC下，这种错误一般是：Link 2001错误，意思说是说，链接器未能找到函数的实现。你需要指定函数的ObjectFile. 1 Makefile 介绍make命令执行时，需要一个 Makefile 文件，以告诉make命令需要怎么样的去编译和链接程序。 首先，我们用一个示例来说明Makefile的书写规则。以便给大家一个感兴认识。这个示例来源于GNU的make使用手册，在这个示例中，我们的工程有8个C文件，和3个头文件，我们要写一个Makefile来告诉make命令如何编译和链接这几个文件。我们的规则是： 如果这个工程没有编译过，那么我们的所有C文件都要编译并被链接。 如果这个工程的某几个C文件被修改，那么我们只编译被修改的C文件，并链接目标程序。 如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的C文件，并链接目标程序。 只要我们的Makefile写得够好，所有的这一切，我们只用一个make命令就可以完成，make命令会自动智能地根据当前的文件修改的情况来确定哪些文件需要重编译，从而自己编译所需要的文件和链接目标程序。 1.1 Makefile的规则在讲述这个Makefile之前，还是让我们先来粗略地看一看Makefile的规则。 12345target... : prerequisites ... command ... ... ------------------------------------------------------------------------------- target也就是一个目标文件，可以是Object File，也可以是执行文件。还可以是一个标签（Label），对于标签这种特性，在后续的“伪目标”章节中会有叙述。 prerequisites就是，要生成那个target所需要的文件或是目标。 command也就是make需要执行的命令。（任意的Shell命令） 这是一个文件的依赖关系，也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。说白一点就是说，prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。这就是Makefile的规则。也就是Makefile中最核心的内容。 说到底，Makefile的东西就是这样一点，好像我的这篇文档也该结束了。还不尽然，这是Makefile的主线和核心，但要写好一个Makefile还不够，我会以后面一点一点地结合我的工作经验给你慢慢到来。内容还多着呢。：） 1.2 一个示例正如前面所说的，如果一个工程有3个头文件，和8个C文件，我们为了完成前面所述的那三个规则，我们的Makefile应该是下面的这个样子的。 1234567891011121314151617181920212223edit : main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.omain.o : main.c defs.h cc -c main.ckbd.o : kbd.c defs.h command.h cc -c kbd.ccommand.o : command.c defs.h command.h cc -c command.cdisplay.o : display.c defs.h buffer.h cc -c display.cinsert.o : insert.c defs.h buffer.h cc -c insert.csearch.o : search.c defs.h buffer.h cc -c search.cfiles.o : files.c defs.h buffer.h command.h cc -c files.cutils.o : utils.c defs.h cc -c utils.cclean : rm edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 反斜杠（\）是换行符的意思。这样比较便于Makefile的易读。我们可以把这个内容保存在文件为“Makefile”或“makefile”的文件中，然后在该目录下直接输入命令“make”就可以生成执行文件edit。如果要删除执行文件和所有的中间目标文件，那么，只要简单地执行一下make clean就可以了。 在这个makefile中，目标文件（target）包含：执行文件edit和中间目标文件（*.o），依赖文件（prerequisites）就是冒号后面的那些 .c 文件和 .h文件。每一个 .o 文件都有一组依赖文件，而这些 .o 文件又是执行文件 edit 的依赖文件。依赖关系的实质上就是说明了目标文件是由哪些文件生成的，换言之，目标文件是哪些文件更新的。 在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统命令，一定要以一个Tab键作为开头。记住，make并不管命令是怎么工作的，他只管执行所定义的命令。make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，那么，make就会执行后续定义的命令。 这里要说明一点的是，clean不是一个文件，它只不过是一个动作名字，有点像C语言中的lable一样，其冒号后什么也没有，那么，make就不会自动去找文件的依赖性，也就不会自动执行其后所定义的命令。要执行其后的命令，就要在make命令后明显得指出这个lable的名字。这样的方法非常有用，我们可以在一个makefile中定义不用的编译或是和编译无关的命令，比如程序的打包，程序的备份，等等。 1.3 make是如何工作的在默认的方式下，也就是我们只输入make命令。那么， make会在当前目录下找名字叫“Makefile”或“makefile”的文件。 如果找到，它会找文件中的第一个目标文件（target），在上面的例子中，他会找到“edit”这个文件，并把这个文件作为最终的目标文件。 如果edit文件不存在，或是edit所依赖的后面的 .o 文件的文件修改时间要比edit这个文件新，那么，他就会执行后面所定义的命令来生成edit这个文件。 如果edit所依赖的.o文件也存在，那么make会在当前文件中找目标为.o文件的依赖性，如果找到则再根据那一个规则生成.o文件。（这有点像一个堆栈的过程） 当然，你的C文件和H文件是存在的啦，于是make会生成 .o 文件，然后再用 .o 文件声明make的终极任务，也就是执行文件edit了。 这就是整个make的依赖性，make会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件。在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么make就会直接退出，并报错，而对于所定义的命令的错误，或是编译不成功，make根本不理。make只管文件的依赖性，即，如果在我找了依赖关系之后，冒号后面的文件还是不在，那么对不起，我就不工作啦。 通过上述分析，我们知道，像clean这种，没有被第一个目标文件直接或间接关联，那么它后面所定义的命令将不会被自动执行，不过，我们可以显示要make执行。即命令——make clean，以此来清除所有的目标文件，以便重编译。 于是在我们编程中，如果这个工程已被编译过了，当我们修改了其中一个源文件，比如file.c，那么根据我们的依赖性，我们的目标file.o会被重编译（也就是在这个依性关系后面所定义的命令），于是file.o的文件也是最新的啦，于是file.o的文件修改时间要比edit要新，所以edit也会被重新链接了（详见edit目标文件后定义的命令）。而如果我们改变了“command.h”，那么，kdb.o、command.o和files.o都会被重编译，并且，edit会被重链接。 1.4 makefile中使用变量在上面的例子中，先让我们看看edit的规则： 1234edit : main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 我们可以看到[.o]文件的字符串被重复了两次，如果我们的工程需要加入一个新的[.o]文件，那么我们需要在两个地方加（应该是三个地方，还有一个地方在clean中）。当然，我们的makefile并不复杂，所以在两个地方加也不累，但如果makefile变得复杂，那么我们就有可能会忘掉一个需要加入的地方，而导致编译失败。所以，为了makefile的易维护，在makefile中我们可以使用变量。makefile的变量也就是一个字符串，理解成C语言中的宏可能会更好。 比如，我们声明一个变量，叫objects, OBJECTS, objs, OBJS, obj, 或是 OBJ，反正不管什么啦，只要能够表示obj文件就行了。我们在makefile一开始就这样定义： 12objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 于是，我们就可以很方便地在我们的makefile中以“$(objects)”的方式来使用这个变量了，于是我们的改良版makefile就变成下面这个样子： 12345678910111213141516171819202122objects = main.o kbd.o command.o display.o \ insert.osearch.o files.o utils.oedit : $(objects) cc -o edit $(objects)main.o : main.c defs.h cc -c main.ckbd.o : kbd.c defs.h command.h cc -c kbd.ccommand.o : command.c defs.h command.h cc -c command.cdisplay.o : display.c defs.h buffer.h cc -c display.cinsert.o : insert.c defs.h buffer.h cc -c insert.csearch.o : search.c defs.h buffer.h cc -c search.cfiles.o : files.c defs.h buffer.h command.h cc -c files.cutils.o : utils.c defs.h cc -c utils.cclean : rm edit $(objects) 于是如果有新的 .o 文件加入，我们只需简单地修改一下 objects 变量就可以了。 关于变量更多的话题，我会在后续给你一一道来。 1.5 让make自动推导GNU的make很强大，它可以自动推导文件以及文件依赖关系后面的命令，于是我们就没必要去在每一个[.o]文件后都写上类似的命令，因为，我们的make会自动识别，并自己推导命令。 只要make看到一个[.o]文件，它就会自动的把[.c]文件加在依赖关系中，如果make找到一个whatever.o，那么whatever.c，就会是whatever.o的依赖文件。并且 cc -c whatever.c 也会被推导出来，于是，我们的makefile再也不用写得这么复杂。我们的是新的makefile又出炉了。 123456789101112131415161718objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.oedit : $(objects) cc -o edit $(objects)main.o : defs.hkbd.o : defs.h command.hcommand.o : defs.h command.hdisplay.o : defs.h buffer.hinsert.o : defs.h buffer.hsearch.o : defs.h buffer.hfiles.o : defs.h buffer.h command.hutils.o : defs.h.PHONY : cleanclean : rm edit $(objects) 这种方法，也就是make的“隐晦规则”。上面文件内容中，“.PHONY”表示，clean是个伪目标文件。 关于更为详细的“隐晦规则”和“伪目标文件”，我会在后续给你一一道来。 1.6 另类风格的makefile即然我们的make可以自动推导命令，那么我看到那堆[.o]和[.h]的依赖就有点不爽，那么多的重复的[.h]，能不能把其收拢起来，好吧，没有问题，这个对于make来说很容易，谁叫它提供了自动推导命令和文件的功能呢？来看看最新风格的makefile吧。 12345678910111213objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.oedit : $(objects) cc -o edit $(objects)$(objects) : defs.hkbd.o command.o files.o : command.hdisplay.o insert.o search.o files.o : buffer.h.PHONY : cleanclean : rm edit $(objects) 这种风格，让我们的makefile变得很简单，但我们的文件依赖关系就显得有点凌乱了。鱼和熊掌不可兼得。还看你的喜好了。我是不喜欢这种风格的，一是文件的依赖关系看不清楚，二是如果文件一多，要加入几个新的.o文件，那就理不清楚了。 1.7 清空目标文件的规则每个Makefile中都应该写一个清空目标文件（.o和执行文件）的规则，这不仅便于重编译，也很利于保持文件的清洁。这是一个“修养”（呵呵，还记得我的《编程修养》吗）。一般的风格都是： 12clean: rm edit $(objects) 更为稳健的做法是： 123.PHONY : cleanclean : -rm edit $(objects) 前面说过，.PHONY意思表示clean是一个“伪目标”，。而在rm命令前面加了一个小减号的意思就是，也许某些文件出现问题，但不要管，继续做后面的事。当然，clean的规则不要放在文件的开头，不然，这就会变成make的默认目标，相信谁也不愿意这样。不成文的规矩是——“clean从来都是放在文件的最后”。 上面就是一个makefile的概貌，也是makefile的基础，下面还有很多makefile的相关细节，准备好了吗？准备好了就来。 2 Makefile 总述2.1 Makefile里有什么？Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。 显式规则。显式规则说明了，如何生成一个或多的的目标文件。这是由Makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。 隐晦规则。由于我们的make有自动推导的功能，所以隐晦的规则可以让我们比较粗糙地简略地书写Makefile，这是由make所支持的。 变量的定义。在Makefile中我们要定义一系列的变量，变量一般都是字符串，这个有点你C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。 文件指示。其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样；另一个是指根据某些情况指定Makefile中的有效部分，就像C语言中的预编译#if一样；还有就是定义一个多行的命令。有关这一部分的内容，我会在后续的部分中讲述。 注释。Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用“#”字符，这个就像C/C++中的“//”一样。如果你要在你的Makefile中使用“#”字符，可以用反斜框进行转义，如：\#。 最后，还值得一提的是，在Makefile中的命令，必须要以[Tab]键开始。 2.2Makefile的文件名默认的情况下，make命令会在当前目录下按顺序找寻文件名为“GNUmakefile”、“makefile”、“Makefile”的文件，找到了解释这个文件。在这三个文件名中，最好使用“Makefile”这个文件名，因为，这个文件名第一个字符为大写，这样有一种显目的感觉。最好不要用“GNUmakefile”，这个文件是GNU的make识别的。有另外一些make只对全小写的“makefile”文件名敏感，但是基本上来说，大多数的make都支持“makefile”和“Makefile”这两种默认文件名。 当然，你可以使用别的文件名来书写Makefile，比如：“Make.Linux”，“Make.Solaris”，“Make.AIX”等，如果要指定特定的Makefile，你可以使用make的“-f”和“–file”参数，如：make -f Make.Linux或make --file Make.AIX。 2.3 引用其它的Makefile在Makefile使用include关键字可以把别的Makefile包含进来，这很像C语言的#include，被包含的文件会原模原样的放在当前文件的包含位置。include的语法是： 1include&lt;filename&gt;filename可以是当前操作系统Shell的文件模式（可以保含路径和通配符） 在include前面可以有一些空字符，但是绝不能是[Tab]键开始。include和可以用一个或多个空格隔开。举个例子，你有这样几个Makefile：a.mk、b.mk、c.mk，还有一个文件叫foo.make，以及一个变量$(bar)，其包含了e.mk和f.mk，那么，下面的语句： 1include foo.make *.mk $(bar) 等价于： 1include foo.make a.mk b.mk c.mk e.mk f.mk make命令开始时，会把找寻include所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的#include指令一样。如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找： 如果make执行时，有“-I”或“–include-dir”参数，那么make就会在这个参数所指定的目录下去寻找。 如果目录/include（一般是：/usr/local/bin或/usr/include）存在的话，make也会去找。 如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如： -include 其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。 2.4 环境变量 MAKEFILES如果你的当前环境中定义了环境变量MAKEFILES，那么，make会把这个变量中的值做一个类似于include的动作。这个变量中的值是其它的Makefile，用空格分隔。只是，它和include不同的是，从这个环境变中引入的Makefile的“目标”不会起作用，如果环境变量中定义的文件发现错误，make也会不理。 但是在这里我还是建议不要使用这个环境变量，因为只要这个变量一被定义，那么当你使用make时，所有的Makefile都会受到它的影响，这绝不是你想看到的。在这里提这个事，只是为了告诉大家，也许有时候你的Makefile出现了怪事，那么你可以看看当前环境中有没有定义这个变量。 2.5 make的工作方式GNU的make工作时的执行步骤入下：（想来其它的make也是类似） 读入所有的Makefile。 读入被include的其它Makefile。 初始化文件中的变量。 推导隐晦规则，并分析所有规则。 为所有的目标文件创建依赖关系链。 根据依赖关系，决定哪些目标要重新生成。 执行生成命令。 1-5步为第一个阶段，6-7为第二个阶段。第一个阶段中，如果定义的变量被使用了，那么，make会把其展开在使用的位置。但make并不会完全马上展开，make使用的是拖延战术，如果变量出现在依赖关系的规则中，那么仅当这条依赖被决定要使用了，变量才会在其内部展开。 当然，这个工作方式你不一定要清楚，但是知道这个方式你也会对make更为熟悉。有了这个基础，后续部分也就容易看懂了。 3 Makefile书写规则规则包含两个部分，一个是依赖关系，一个是生成目标的方法。 在Makefile中，规则的顺序是很重要的，因为，Makefile中只应该有一个最终目标，其它的目标都是被这个目标所连带出来的，所以一定要让make知道你的最终目标是什么。一般来说，定义在Makefile中的目标可能会有很多，但是第一条规则中的目标将被确立为最终的目标。如果第一条规则中的目标有很多个，那么，第一个目标会成为最终的目标。make所完成的也就是这个目标。 好了，还是让我们来看一看如何书写规则。 3.1 规则举例12foo.o: foo.c defs.h # foo模块 cc -c -g foo.c 看到这个例子，各位应该不是很陌生了，前面也已说过，foo.o是我们的目标，foo.c和defs.h是目标所依赖的源文件，而只有一个命令“cc -c -g foo.c”（以Tab键开头）。这个规则告诉我们两件事： 文件的依赖关系，foo.o依赖于foo.c和defs.h的文件，如果foo.c和defs.h的文件日期要比foo.o文件日期要新，或是foo.o不存在，那么依赖关系发生。 如果生成（或更新）foo.o文件。也就是那个cc命令，其说明了，如何生成foo.o这个文件。（当然foo.c文件include了defs.h文件） 3.2 规则的语法123targets : prerequisites command ... 或是这样： 123targets : prerequisites ; command command ... targets是文件名，以空格分开，可以使用通配符。一般来说，我们的目标基本上是一个文件，但也有可能是多个文件。 command是命令行，如果其不与“target:prerequisites”在一行，那么，必须以[Tab键]开头，如果和prerequisites在一行，那么可以用分号做为分隔。（见上） prerequisites也就是目标所依赖的文件（或依赖目标）。如果其中的某个文件要比目标文件要新，那么，目标就被认为是“过时的”，被认为是需要重生成的。这个在前面已经讲过了。 如果命令太长，你可以使用反斜框\作为换行符。make对一行上有多少个字符没有限制。规则告诉make两件事，文件的依赖关系和如何成成目标文件。 一般来说，make会以UNIX的标准Shell，也就是/bin/sh来执行命令。 3.3 在规则中使用通配符如果我们想定义一系列比较类似的文件，我们很自然地就想起使用通配符。make支持三各通配符：*，?和[...]。这是和Unix的B-Shell是相同的。 ~ :波浪号（~）字符在文件名中也有比较特殊的用途。如果是“~/test”，这就表示当前用户的$HOME目录下的test目录。而“~hchen/test”则表示用户hchen的宿主目录下的test目录。（这些都是Unix下的小知识了，make也支持）而在Windows或是MS-DOS下，用户没有宿主目录，那么波浪号所指的目录则根据环境变量“HOME”而定。 *:通配符代替了你一系列的文件，如*.c表示所以后缀为c的文件。一个需要我们注意的是，如果我们的文件名中有通配符，如：*，那么可以用转义字符\，如\*来表示真实的*字符，而不是任意长度的字符串。 好吧，还是先来看几个例子吧：12clean: rm -f *.o 上面这个例子我不不多说了，这是操作系统Shell所支持的通配符。这是在命令中的通配符。 123print: *.c lpr -p $? touch print 上面这个例子说明了通配符也可以在我们的规则中，目标print依赖于所有的[.c]文件。其中的“$?”是一个自动化变量，我会在后面给你讲述。 1objects = *.o 上面这个例子，表示了，通符同样可以用在变量中。并不是说[*.o]会展开，不！objects的值就是*.o。Makefile中的变量其实就是C/C++中的宏。如果你要让通配符在变量中展开，也就是让objects的值是所有[.o]的文件名的集合，那么，你可以这样： 1objects := $(wildcard *.o) 这种用法由关键字“wildcard”指出，关于Makefile的关键字，我们将在后面讨论。 3.4 文件搜寻在一些大的工程中，有大量的源文件，我们通常的做法是把这许多的源文件分类，并存放在不同的目录中。所以，当make需要去找寻文件的依赖关系时，你可以在文件前加上路径，但最好的方法是把一个路径告诉make，让make在自动去找。 Makefile文件中的特殊变量VPATH就是完成这个功能的，如果没有指明这个变量，make只会在当前的目录中去找寻依赖文件和目标文件。如果定义了这个变量，那么，make就会在当当前目录找不到的情况下，到所指定的目录中去找寻文件了。 1VPATH = src:../headers 上面的的定义指定两个目录，src和../headers，make会按照这个顺序进行搜索。目录由“冒号”分隔。（当然，当前目录永远是最高优先搜索的地方） 另一个设置文件搜索路径的方法是使用make的vpath关键字（注意，它是全小写的），这不是变量，这是一个make的关键字，这和上面提到的那个VPATH变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。这是一个很灵活的功能。它的使用方法有三种： vpath &lt; pattern&gt; &lt; directories&gt; 为符合模式&lt; pattern&gt;的文件指定搜索目录。 vpath &lt; pattern&gt; 清除符合模式&lt; pattern&gt;的文件的搜索目录。 vpath 清除所有已被设置好了的文件搜索目录。 vapth使用方法中的&lt; pattern&gt;需要包含“%”字符。“%”的意思是匹配零或若干字符，例如，“%.h”表示所有以“.h”结尾的文件。&lt; pattern&gt;指定了要搜索的文件集，而&lt; directories&gt;则指定了的文件集的搜索的目录。例如：1vpath %.h ../headers 该语句表示，要求make在“../headers”目录下搜索所有以“.h”结尾的文件。（如果某文件在当前目录没有找到的话） 我们可以连续地使用vpath语句，以指定不同搜索策略。如果连续的vpath语句中出现了相同的&lt; pattern&gt;，或是被重复了的&lt; pattern&gt;，那么，make会按照vpath语句的先后顺序来执行搜索。如： 123vpath %.c foovpath % blishvpath %.c bar 其表示“.c”结尾的文件，先在“foo”目录，然后是“blish”，最后是“bar”目录。 12vpath %.c foo:barvpath % blish 而上面的语句则表示“.c”结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录。 3.5 伪目标最早先的一个例子中，我们提到过一个“clean”的目标，这是一个“伪目标”， 12clean: rm *.o temp 正像我们前面例子中的“clean”一样，即然我们生成了许多文件编译文件，我们也应该提供一个清除它们的“目标”以备完整地重编译而用。 （以“make clean”来使用该目标） 因为，我们并不生成“clean”这个文件。“伪目标”并不是一个文件，只是一个标签，由于“伪目标”不是文件，所以make无法生成它的依赖关系和决定它是否要执行。我们只有通过显示地指明这个“目标”才能让其生效。当然，“伪目标”的取名不能和文件名重名，不然其就失去了“伪目标”的意义了。 当然，为了避免和文件重名的这种情况，我们可以使用一个特殊的标记.PHONY来显示地指明一个目标是“伪目标”，向make说明，不管是否有这个文件，这个目标就是“伪目标”。 1.PHONY : clean 只要有这个声明，不管是否有“clean”文件，要运行“clean”这个目标，只有“make clean”这样。于是整个过程可以这样写： 123.PHONY: cleanclean: rm *.o temp 伪目标一般没有依赖的文件。但是，我们也可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个。一个示例就是，如果你的Makefile需要一口气生成若干个可执行文件，但你只想简单地敲一个make完事，并且，所有的目标文件都写在一个Makefile中，那么你可以使用“伪目标”这个特性： 1234567891011all : prog1 prog2 prog3.PHONY : allprog1 : prog1.o utils.o cc -o prog1 prog1.o utils.oprog2 : prog2.o cc -o prog2 prog2.oprog3 : prog3.o sort.o utils.o cc -o prog3 prog3.o sort.o utils.o 我们知道，Makefile中的第一个目标会被作为其默认目标。我们声明了一个“all”的伪目标，其依赖于其它三个目标。由于伪目标的特性是，总是被执行的，所以其依赖的那三个目标就总是不如“all”这个目标新。所以，其它三个目标的规则总是会被决议。也就达到了我们一口气生成多个目标的目的。“.PHONY : all”声明了“all”这个目标为“伪目标”。 随便提一句，从上面的例子我们可以看出，目标也可以成为依赖。所以，伪目标同样也可成为依赖。看下面的例子： 12345678910.PHONY: cleanall cleanobj cleandiffcleanall : cleanobj cleandiff rm programcleanobj : rm *.ocleandiff : rm *.diff “makeclean”将清除所有要被清除的文件。“cleanobj”和“cleandiff”这两个伪目标有点像“子程序”的意思。我们可以输入“makecleanall”和“make cleanobj”和“makecleandiff”命令来达到清除不同种类文件的目的 3.6 多目标Makefile的规则中的目标可以不止一个，其支持多目标，有可能我们的多个目标同时依赖于一个文件，并且其生成的命令大体类似。于是我们就能把其合并起来。当然，多个目标的生成规则的执行命令是同一个，这可能会可我们带来麻烦，不过好在我们的可以使用一个自动化变量“$@”（关于自动化变量，将在后面讲述），这个变量表示着目前规则中所有的目标的集合，这样说可能很抽象，还是看一个例子吧。 12bigoutput littleoutput : text.g generate text.g -$(subst output,,$@) &gt; $@ 上述规则等价于： 1234bigoutput : text.g generate text.g -big &gt; bigoutputlittleoutput : text.g generate text.g -little &gt; littleoutput 其中，-$(subst output,,$@)中的“$”表示执行一个Makefile的函数，函数名为subst，后面的为参数。关于函数，将在后面讲述。这里的这个函数是截取字符串的意思，“$@”表示目标的集合，就像一个数组，“$@”依次取出目标，并执于命令。 3.7 静态模式静态模式可以更加容易地定义多目标的规则，可以让我们的规则变得更加的有弹性和灵活。我们还是先来看一下语法： 123&lt;targets...&gt;: &lt;target-pattern&gt;: &lt;prereq-patterns ...&gt; &lt;commands&gt;... targets定义了一系列的目标文件，可以有通配符。是目标的一个集合。 target-parrtern是指明了targets的模式，也就是的目标集模式。 prereq-parrterns是目标的依赖模式，它对target-parrtern形成的模式再进行一次依赖目标的定义。 这样描述这三个东西，可能还是没有说清楚，还是举个例子来说明一下吧。如果我们的定义成“%.o”，意思是我们的集合中都是以“.o”结尾的，而如果我们的定义成“%.c”，意思是对所形成的目标集进行二次定义，其计算方法是，取模式中的“%”（也就是去掉了[.o]这个结尾），并为其加上[.c]这个结尾，形成的新集合。 所以，我们的“目标模式”或是“依赖模式”中都应该有“%”这个字符，如果你的文件名中有“%”那么你可以使用反斜杠\进行转义，来标明真实的“%”字符。 看一个例子： 123456objects = foo.o bar.oall: $(objects)$(objects): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@ 上面的例子中，指明了我们的目标从$object中获取，“%.o”表明要所有以“.o”结尾的目标，也就是“foo.o bar.o”，也就是变量$object集合的模式，而依赖模式“%.c”则取模式“%.o”的“%”，也就是“foobar”，并为其加下“.c”的后缀，于是，我们的依赖目标就是“foo.cbar.c”。而命令中的“$&lt;”和“$@”则是自动化变量，“$&lt;”表示所有的依赖目标集（也就是“foo.c bar.c”），“$@”表示目标集（也就是oo.o bar.o”）。于是，上面的规则展开后等价于下面的规则： 1234foo.o : foo.c $(CC) -c $(CFLAGS) foo.c -o foo.obar.o : bar.c $(CC) -c $(CFLAGS) bar.c -o bar.o 试想，如果我们的“%.o”有几百个，那种我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会一个很强大的功能。再看一个例子： 123456files = foo.elc bar.o lose.o$(filter %.o,$(files)): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@$(filter %.elc,$(files)): %.elc: %.el emacs -f batch-byte-compile $&lt; $(filter%.o,$(files))表示调用Makefile的filter函数，过滤“$filter”集，只要其中模式为“%.o”的内容。其的它内容，我就不用多说了吧。这个例字展示了Makefile中更大的弹性。 3.8 自动生成依赖性在Makefile中，我们的依赖关系可能会需要包含一系列的头文件，比如，如果我们的main.c中有一句“#include “defs.h””，那么我们的依赖关系应该是： 1main.o : main.c defs.h 但是，如果是一个比较大型的工程，你必需清楚哪些C文件包含了哪些头文件，并且，你在加入或删除头文件时，也需要小心地修改Makefile，这是一个很没有维护性的工作。为了避免这种繁重而又容易出错的事情，我们可以使用C/C++编译的一个功能。大多数的C/C++编译器都支持一个“-M”的选项，即自动找寻源文件中包含的头文件，并生成一个依赖关系。例如，如果我们执行下面的命令： 1cc -M main.c 其输出是： 1main.o : main.c defs.h 于是由编译器自动生成的依赖关系，这样一来，你就不必再手动书写若干文件的依赖关系，而由编译器自动生成了。需要提醒一句的是，如果你使用GNU的C/C++编译器，你得用-MM参数，不然，-M参数会把一些标准库的头文件也包含进来。 gcc-M main.c的输出是： 123456789main.o: main.c defs.h /usr/include/stdio.h /usr/include/features.h \ /usr/include/sys/cdefs.h /usr/include/gnu/stubs.h \ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stddef.h \ /usr/include/bits/types.h /usr/include/bits/pthreadtypes.h \ /usr/include/bits/sched.h /usr/include/libio.h \ /usr/include/_G_config.h /usr/include/wchar.h \ /usr/include/bits/wchar.h /usr/include/gconv.h \ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stdarg.h \ /usr/include/bits/stdio_lim.h gcc-MM main.c的输出则是： 1main.o: main.c defs.h 那么，编译器的这个功能如何与我们的Makefile联系在一起呢。因为这样一来，我们的Makefile也要根据这些源文件重新生成，让Makefile自已依赖于源文件？这个功能并不现实，不过我们可以有其它手段来迂回地实现这一功能。GNU组织建议把编译器为每一个源文件的自动生成的依赖关系放到一个文件中，为每一个“name.c”的文件都生成一个“name.d”的Makefile文件，[.d]文件中就存放对应[.c]文件的依赖关系。 于是，我们可以写出[.c]文件和[.d]文件的依赖关系，并让make自动更新或自成[.d]文件，并把其包含在我们的主Makefile中，这样，我们就可以自动化地生成每个文件的依赖关系了。 这里，我们给出了一个模式规则来产生[.d]文件： 1234567%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.; \ sed &apos;s,$∗\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.&gt; $@; \ rm -f $@. 这个规则的意思是，所有的[.d]文件依赖于[.c]文件，rm-f $@的意思是删除所有的目标，也就是[.d]文件，第二行的意思是，为每个依赖文件“$&#8221;&#65292;&#x4e5f;&#23601;&#x662f;&#91;&#46;&#99;&#x5d;&#25991;&#x4ef6;&#x751f;&#x6210;&#20381;&#x8d56;&#x6587;&#x4ef6;&#xff0c;&#8220;&#x24;&#x40;&#x201d;&#34920;&#x793a;&#27169;&#24335;&#8220;&#37;&#46;&#100;&#8221;&#25991;&#x4ef6;&#xff0c;&#22914;&#x679c;&#26377;&#19968;&#20010;&#x43;&#25991;&#x4ef6;&#x662f;&#110;&#97;&#x6d;&#101;&#x2e;&#99;&#65292;&#37027;&#20040;&#8220;&#37;&#x201d;&#x5c31;&#x662f;&#x201c;&#110;&#x61;&#109;&#101;&#x201d;&#65292;&#x201c;&#xa;&#x201d;&#x610f;&#x4e3a;&#19968;&#x4e2a;&#38543;&#x673a;&#x7f16;&#21495;&#xff0c;&#31532;&#20108;&#x884c;&#x751f;&#25104;&#x7684;&#x6587;&#20214;&#26377;&#x53ef;&#x80fd;&#26159;&#x201c;&#110;&#97;&#x6d;&#101;&#x2e;&#x64;&#46;&#49;&#x32;&#51;&#52;&#x35;&#x201d;&#65292;&#x7b2c;&#x4e09;&#x884c;&#x4f7f;&#29992;&#x73;&#x65;&#x64;&#21629;&#20196;&#x505a;&#x4e86;&#x4e00;&#20010;&#x66ff;&#25442;&#xff0c;&#20851;&#x4e8e;&#x73;&#101;&#x64;&#x547d;&#x4ee4;&#30340;&#29992;&#27861;&#35831;&#x53c2;&#30475;&#30456;&#x5173;&#x7684;&#x4f7f;&#x7528;&#x6587;&#26723;&#x3002;&#31532;&#22235;&#x884c;&#x5c31;&#x662f;&#21024;&#38500;&#x4e34;&#x65f6;&#25991;&#20214;&#x3002;&#xa;&#x603b;&#x800c;&#x8a00;&#20043;&#xff0c;&#x8fd9;&#x4e2a;&#27169;&#x5f0f;&#x8981;&#20570;&#x7684;&#x4e8b;&#x5c31;&#x662f;&#22312;&#x7f16;&#x8bd1;&#22120;&#x751f;&#x6210;&#x7684;&#20381;&#x8d56;&#x5173;&#x7cfb;&#x4e2d;&#x52a0;&#20837;&#91;&#46;&#100;&#93;&#25991;&#20214;&#x7684;&#x4f9d;&#36182;&#xff0c;&#21363;&#25226;&#20381;&#36182;&#x5173;&#x7cfb;&#xff1a;&#10;&#x3c;&#33;&#x2d;&#45;&#65532;&#52;&#48;&#x2d;&#45; 转成： 1main.o main.d : main.c defs.h 于是，我们的[.d]文件也会自动更新了，并会自动生成了，当然，你还可以在这个[.d]文件中加入的不只是依赖关系，包括生成的命令也可一并加入，让每个[.d]文件都包含一个完赖的规则。一旦我们完成这个工作，接下来，我们就要把这些自动生成的规则放进我们的主Makefile中。我们可以使用Makefile的“include”命令，来引入别的Makefile文件（前面讲过），例如： 123sources = foo.c bar.cinclude $(sources:.c=.d) 上述语句中的“$(sources:.c=.d)”中的“.c=.d”的意思是做一个替换，把变量$(sources)所有[.c]的字串都替换成[.d]，关于这个“替换”的内容，在后面我会有更为详细的讲述。当然，你得注意次序，因为include是按次来载入文件，最先载入的[.d]文件中的目标会成为默认目标 4 Makefile 书写命令每条规则中的命令和操作系统Shell的命令行是一致的。make会一按顺序一条一条的执行命令，每条命令的开头必须以[Tab]键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。 我们在UNIX下可能会使用不同的Shell，但是make的命令默认是被“/bin/sh”——UNIX的标准Shell解释执行的。除非你特别指定一个其它的Shell。Makefile中，“#”是注释符，很像C/C++中的“//”，其后的本行字符都被注释。 4.1 显示命令通常，make会把其要执行的命令行在命令执行前输出到屏幕上。当我们用“@”字符在命令行前，那么，这个命令将不被make显示出来，最具代表性的例子是，我们用这个功能来像屏幕显示一些信息。如： 1@echo 正在编译XXX模块...... 当make执行时，会输出“正在编译XXX模块……”字串，但不会输出命令，如果没有“@”，那么，make将输出： 12echo 正在编译XXX模块......正在编译XXX模块...... 如果make执行时，带入make参数-n或--just-print，那么其只是显示命令，但不会执行命令，这个功能很有利于我们调试我们的Makefile，看看我们书写的命令是执行起来是什么样子的或是什么顺序的。 而make参数-s或--slient则是全面禁止命令的显示。 4.2 命令执行当依赖目标新于目标时，也就是当规则的目标需要被更新时，make会一条一条的执行其后的命令。需要注意的是，如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如： 示例一： 123exec: cd /home/hchen pwd 示例二： 12exec: cd /home/hchen; pwd 当我们执行“make exec”时，第一个例子中的cd没有作用，pwd会打印出当前的Makefile目录，而第二个例子中，cd就起作用了，pwd会打印出“/home/hchen”。 make一般是使用环境变量SHELL中所定义的系统Shell来执行命令，默认情况下使用UNIX的标准Shell——/bin/sh来执行命令。但在MS-DOS下有点特殊，因为MS-DOS下没有SHELL环境变量，当然你也可以指定。如果你指定了UNIX风格的目录形式，首先，make会在SHELL所指定的路径中找寻命令解释器，如果找不到，其会在当前盘符中的当前目录中寻找，如果再找不到，其会在PATH环境变量中所定义的所有路径中寻找。MS-DOS中，如果你定义的命令解释器没有找到，其会给你的命令解释器加上诸如“.exe”、“.com”、“.bat”、“.sh”等后缀。 4.3 命令出错每当命令运行完后，make会检测每个命令的返回码，如果命令返回成功，那么make会执行下一条命令，当规则中所有的命令成功返回后，这个规则就算是成功完成了。如果一个规则中的某个命令出错了（命令退出码非零），那么make就会终止执行当前规则，这将有可能终止所有规则的执行。 有些时候，命令的出错并不表示就是错误的。例如mkdir命令，我们一定需要建立一个目录，如果目录不存在，那么mkdir就成功执行，万事大吉，如果目录存在，那么就出错了。我们之所以使用mkdir的意思就是一定要有这样的一个目录，于是我们就不希望mkdir出错而终止规则的运行。 为了做到这一点，忽略命令的出错，我们可以在Makefile的命令行前加一个减号“-”（在Tab键之后），标记为不管命令出不出错都认为是成功的。如： 12clean: -rm -f *.o 还有一个全局的办法是，给make加上-i或是--ignore-errors参数，那么，Makefile中所有命令都会忽略错误。而如果一个规则是以“.IGNORE”作为目标的，那么这个规则中的所有命令将会忽略错误。这些是不同级别的防止命令出错的方法，你可以根据你的不同喜欢设置。 还有一个要提一下的make的参数的是-k或是--keep-going，这个参数的意思是，如果某规则中的命令出错了，那么就终目该规则的执行，但继续执行其它规则。 4.4 嵌套执行make在一些大的工程中，我们会把我们不同模块或是不同功能的源文件放在不同的目录中，我们可以在每个目录中都书写一个该目录的Makefile，这有利于让我们的Makefile变得更加地简洁，而不至于把所有的东西全部写在一个Makefile中，这样会很难维护我们的Makefile，这个技术对于我们模块编译和分段编译有着非常大的好处。 例如，我们有一个子目录叫subdir，这个目录下有个Makefile文件，来指明了这个目录下文件的编译规则。那么我们总控的Makefile可以这样书写： 12subsystem: cd subdir &amp;&amp; $(MAKE) 其等价于： 12subsystem: $(MAKE) -C subdir 定义$(MAKE)宏变量的意思是，也许我们的make需要一些参数，所以定义成一个变量比较利于维护。这两个例子的意思都是先进入“subdir”目录，然后执行make命令。 我们把这个Makefile叫做 总控Makefile，总控Makefile的变量可以传递到下级的Makefile中（如果你显示的声明），但是不会覆盖下层的Makefile中所定义的变量，除非指定了“-e”参数。 如果你要传递变量到下级Makefile中，那么你可以使用这样的声明： 1export&lt;variable ...&gt; 如果你不想让某些变量传递到下级Makefile中，那么你可以这样声明： 1unexport&lt;variable ...&gt; 如： 示例一： 1export variable = value 其等价于： 12variable = valueexport variable 其等价于： 1export variable := value 其等价于： 12variable := valueexport variable 示例二： 1export variable += value 其等价于： 12variable += valueexport variable 如果你要传递所有的变量，那么，只要一个export就行了。后面什么也不用跟，表示传递所有的变量。 需要注意的是，有两个变量，一个是SHELL，一个是MAKEFLAGS，这两个变量不管你是否export，其总是要传递到下层Makefile中，特别是MAKEFILES变量，其中包含了make的参数信息，如果我们执行“总控Makefile”时有make参数或是在上层Makefile中定义了这个变量，那么MAKEFILES变量将会是这些参数，并会传递到下层Makefile中，这是一个系统级的环境变量。 但是make命令中的有几个参数并不往下传递，它们是“-C”,“-f”,“-h”“-o”和“-W”（有关Makefile参数的细节将在后面说明），如果你不想往下层传递参数，那么，你可以这样来： 12subsystem: cd subdir &amp;&amp; $(MAKE) MAKEFLAGS= 如果你定义了环境变量MAKEFLAGS，那么你得确信其中的选项是大家都会用到的，如果其中有“-t”,“-n”,和“-q”参数，那么将会有让你意想不到的结果，或许会让你异常地恐慌。 还有一个在“嵌套执行”中比较有用的参数，“-w”或是“–print-directory”会在make的过程中输出一些信息，让你看到目前的工作目录。比如，如果我们的下级make目录是“/home/hchen/gnu/make”，如果我们使用“make -w”来执行，那么当进入该目录时，我们会看到： 1make: Entering directory `/home/hchen/gnu/make&apos;. 而在完成下层make后离开目录时，我们会看到：1make: Leaving directory `/home/hchen/gnu/make&apos; 当你使用“-C”参数来指定make下层Makefile时，“-w”会被自动打开的。如果参数中有“-s”（“–slient”）或是“–no-print-directory”，那么，“-w”总是失效的。 4.5 定义命令包如果Makefile中出现一些相同命令序列，那么我们可以为这些相同的命令序列定义一个变量。定义这种命令序列的语法以“define”开始，以“endef”结束，如： 1234define run-yaccyacc $(firstword $^)mv y.tab.c $@endef 这里，“run-yacc”是这个命令包的名字，其不要和Makefile中的变量重名。在“define”和“endef”中的两行就是命令序列。这个命令包中的第一个命令是运行Yacc程序，因为Yacc程序总是生成“y.tab.c”的文件，所以第二行的命令就是把这个文件改改名字。还是把这个命令包放到一个示例中来看看吧。 12foo.c : foo.y $(run-yacc) 我们可以看见，要使用这个命令包，我们就好像使用变量一样。在这个命令包的使用中，命令包“run-yacc”中的“$^”就是“foo.y”，“$@”就是“foo.c”（有关这种以“$”开头的特殊变量，我们会在后面介绍），make在执行命令包时，命令包中的每个命令会被依次独立执行。 5.使用变量在 Makefile中的定义的变量，就像是C/C++语言中的宏一样，他代表了一个文本字串，在Makefile中执行的时候其会自动原模原样地展开在所使用的地方。其与C/C++所不同的是，你可以在Makefile中改变其值。在Makefile中，变量可以使用在“目标”，“依赖目标”，“命令”或是 Makefile的其它部分中。变量的命名字可以包含字符、数字，下划线（可以是数字开头），但不应该含有“:”、“#”、“=”或是空字符（空格、回车等）。变量是大小写敏感的，“foo”、“Foo”和“FOO”是三个不同的变量名。传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。有一些变量是很奇怪字串，如“$&lt;”、“$@”等，这些是自动化变量，我会在后面介绍。 5.1变量的基础变量在声明时需要给予初值，而在使用时，需要给在变量名前加上“$”符号，但最好用小括号“（）”或是大括号“{}”把变量给包括起来。如果你要使用真实的“$”字符，那么你需要用$$来表示。变量可以使用在许多地方，如规则中的“目标”、“依赖”、“命令”以及新的变量中。 先看一个例子： 12345objects = program.o foo.o utils.oprogram : $(objects)cc -o program $(objects)$(objects) : defs.h 变量会在使用它的地方精确地展开，就像C/C++中的宏一样，例如： 123foo = cprog.o : prog.$(foo)$(foo)$(foo) -$(foo) prog.$(foo) 展开后得到： 12prog.o : prog.ccc -c prog.c 当然，千万不要在你的Makefile中这样干，这里只是举个例子来表明Makefile中的变量在使用处展开的真实样子。可见其就是一个“替代”的原理。另外，给变量加上括号完全是为了更加安全地使用这个变量，在上面的例子中，如果你不想给变量加上括号，那也可以，但我还是强烈建议你给变量加上括号。 5.2变量中的变量在定义变量的值时，我们可以使用其它变量来构造变量的值，在Makefile中有两种方式来在用变量定义变量的值。 先看第一种方式，也就是简单的使用“=”号，在“=”左侧是变量，右侧是变量的值，右侧变量的值可以定义在文件的任何一处，也就是说，右侧中的变量不一定非要是已定义好 的值，其也可以使用后面定义的值。如： 1234567foo = $(bar)bar = $(ugh)ugh = Huh?all:echo $(foo) 我们执行“make all”将会打出变量$(foo)的值是“Huh?”（ $(foo)的值是$(bar)，$(bar)的值是$(ugh)，$(ugh)的值是“Huh?”）可见，变量是可以使用后面的变量来定义的。 这个功能有好的地方，也有不好的地方，好的地方是，我们可以把变量的真实值推到后面来定义，如： 12CFLAGS = $(include_dirs) -Oinclude_dirs = -Ifoo -Ibar 当“CFLAGS”在命令中被展开时，会是“-Ifoo -Ibar -O”。但这种形式也有不好的地方 ，那就是递归定义，如： 1CFLAGS = $(CFLAGS) -O 或： 12A = $(B)B = $(A) 这会让make陷入无限的变量展开过程中去，当然，我们的make是有能力检测这样的定义，并会报错。还有就是如果在变量中使用函数，那么，这种方式会让我们的make运行时非常慢，更糟糕的是，他会使用得两个make的函数“wildcard”和“shell”发生不可预知的错误。因为你不会知道这两个函数会被调用多少次。 为了避免上面的这种方法，我们可以使用make中的另一种用变量来定义变量的方法。这种方法使用的是“:=”操作符，如： 123x := fooy := $(x) barx := later 其等价于： 12y := foo barx := later 值得一提的是，这种方法，前面的变量不能使用后面的变量，只能使用前面已定义好了的变量。如果是这样： 12y := $(x) barx := foo 那么，y的值是“bar”，而不是“foo bar”。 上面都是一些比较简单的变量使用了，让我们来看一个复杂的例子，其中包括了make的函数、条件表达式和一个系统变量“MAKELEVEL”的使用： 123456ifeq (0,$&#123;MAKELEVEL&#125;)cur-dir := $(shell pwd)whoami := $(shell whoami)host-type := $(shell arch)MAKE := $&#123;MAKE&#125; host-type=$&#123;host-type&#125; whoami=$&#123;whoami&#125;endif 关于条件表达式和函数，我们在后面再说，对于系统变量“MAKELEVEL”，其意思是，如果我们的make有一个嵌套执行的动作（参见前面的“嵌套使用make”），那么，这个变量会记录了我们的当前Makefile的调用层数。 下面再介绍两个定义变量时我们需要知道的，请先看一个例子，如果我们要定义一个变量，其值是一个空格，那么我们可以这样来： 12nullstring :=space := $(nullstring) # end of the line nullstring 是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个 Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。请注意这里关于“#”的使用，注释符“#”的这种特性值得我们注意，如果我们这样定义一个变量： 1dir := /foo/bar # directory to put the frobs in dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这样变量来指定别的目录——“$(dir)/file”那么就完蛋了。 还有一个比较有用的操作符是“?=”，先看示例： 1FOO ?= bar 其含义是，如果FOO没有被定义过，那么变量FOO的值就是“bar”，如果FOO先前被定义过，那么这条语将什么也不做，其等价于： 123ifeq ($(origin FOO), undefined)FOO = barendif 5.3变量高级用法这里介绍两种变量的高级使用方法 第一种是变量值的替换。 我们可以替换变量中的共有的部分，其格式是$(var:a=b)或是${var:a=b}，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。这里的“结尾”意思是“空格”或是“结束符”。 还是看一个示例吧： 12foo := a.o b.o c.obar := $(foo:.o=.c) 这个示例中，我们先定义了一个“$(foo)”变量，而第二行的意思是把“$(foo)”中所有以“.o”字串“结尾”全部替换成“.c”，所以我们的“$(bar)”的值就是“a.c b.c c.c”。 另外一种变量替换的技术是以“静态模式”（参见前面章节）定义的，如： 12foo := a.o b.o c.obar := $(foo:%.o=%.c) 这依赖于被替换字串中的有相同的模式，模式中必须包含一个“%”字符，这个例子同样让$(bar)变量的值为“a.c b.c c.c”。 第二种高级用法是——“把变量的值再当成变量”。先看一个例子： 123x = yy = za := $($(x)) 在这个例子中，$(x)的值是“y”，所以$($(x))就是$(y)，于是$(a)的值就是“z”。（注意，是“x=y”，而不是“x=$(y)”） 我们还可以使用更多的层次： 1234x = yy = zz = ua := $($($(x))) 这里的$(a)的值是“u”，相关的推导留给读者自己去做吧。 让我们再复杂一点，使用上“在变量定义中使用变量”的第一个方式，来看一个例子： 1234x = $(y)y = zz = Helloa := $($(x)) 这里的$($(x))被替换成了$($(y))，因为$(y)值是“z”，所以，最终结果是：a:=$(z)，也就是“Hello”。 再复杂一点，我们再加上函数： 12345x = variable1variable2 := Helloy = $(subst 1,2,$(x))z = ya := $($($(z))) 这个例子中，“$($($(z)))”扩展为“$($(y))”，而其再次被扩展为“$($(subst 1,2,$(x)))”。$(x)的值是“variable1”，subst函数把“variable1”中的所有“1”字串替换成“2”字串，于是，“variable1”变成“variable2”，再取其值，所以，最终，$(a)的值就是$(variable2)的值—— “Hello”。（喔，好不容易） 在这种方式中，或要可以使用多个变量来组成一个变量的名字，然后再取其值： 1234first_second = Helloa = firstb = secondall = $($a_$b) 这里的“$a_$b”组成了“first_second”，于是，$(all)的值就是“Hello”。 再来看看结合第一种技术的例子： 1234a_objects := a.o b.o c.o1_objects := 1.o 2.o 3.osources := $($(a1)_objects:.o=.c) 这个例子中，如果$(a1)的值是“a”的话，那么，$(sources)的值就是“a.c b.c c.c”；如果$(a1)的值是“1”，那么$(sources)的值是“1.c 2.c 3.c”。 再来看一个这种技术和“函数”与“条件语句”一同使用的例子： 123456789ifdef do_sortfunc := sortelsefunc := stripendifbar := a d b g q cfoo := $($(func) $(bar)) 这个示例中，如果定义了“do_sort”，那么：foo := $(sort a d b g q c)，于是$(foo)的值就是“a b c d g q”，而如果没有定义“do_sort”，那么：foo := $(sort a d bg q c)，调用的就是strip函数。 当然，“把变量的值再当成变量”这种技术，同样可以用在操作符的左边： 12345dir = foo$(dir)_sources := $(wildcard $(dir)/*.c)define $(dir)_printlpr $($(dir)_sources)endef 这个例子中定义了三个变量：“dir”，“foo_sources”和“foo_print”。 5.4追加变量值我们可以使用“+=”操作符给变量追加值，如： 12objects = main.o foo.o bar.o utils.oobjects += another.o 于是，我们的$(objects)值变成：“main.o foo.o bar.o utils.o another.o”（another.o被追加进去了） 使用“+=”操作符，可以模拟为下面的这种例子： 12objects = main.o foo.o bar.o utils.oobjects := $(objects) another.o 所不同的是，用“+=”更为简洁。 如果变量之前没有定义过，那么，“+=”会自动变成“=”，如果前面有变量定义，那么“+=”会继承于前次操作的赋值符。如果前一次的是“:=”，那么“+=”会以“:=”作为其赋值符，如： 12variable := valuevariable += more 等价于： 12variable := valuevariable := $(variable) more 但如果是这种情况： 12variable = valuevariable += more 由于前次的赋值符是“=”，所以“+=”也会以“=”来做为赋值，那么岂不会发生变量的递补归定义，这是很不好的，所以make会自动为我们解决这个问题，我们不必担心这个问题。 5.5override 指示符如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略。如果你想在Makefile中设置这类参数的值，那么，你可以使用“override”指示符。其语法是： 12override &lt;variable&gt; = &lt;value&gt;override &lt;variable&gt; := &lt;value&gt; 当然，你还可以追加： 1override &lt;variable&gt; += &lt;more text&gt; 对于多行的变量定义，我们用define指示符，在define指示符前，也同样可以使用ovveride指示符，如： 123override define foobarendef 5.6多行变量还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令（前面我们讲过“命令包”的技术就是利用这个关键字）。 define 指示符后面跟的是变量的名字，而重起一行定义变量的值，定义是以endef关键字结束。其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以[Tab]键开头，那么make就不会把其认为是命令。 下面的这个示例展示了define的用法： 1234define two-linesecho fooecho $(bar)endef 5.7环境变量make 运行时的系统环境变量可以在make开始运行时被载入到Makefile文件中，但是如果Makefile中已定义了这个变量，或是这个变量由make命令行带入，那么系统的环境变量的值将被覆盖。（如果make指定了“-e”参数，那么，系统环境变量将覆盖Makefile中定义的变量） 因此，如果我们在环境变量中设置了“CFLAGS”环境变量，那么我们就可以在所有的Makefile中使用这个变量了。这对于我们使用统一的编译参数有比较大的好处。如果Makefile中定义了CFLAGS，那么则会使用Makefile中的这个变量，如果没有定义则使用系统环境变量的值，一个共性和个性的统一，很像“全局变量”和“局部变量”的特性。 当make嵌套调用时（参见前面的“嵌套调用”章节），上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile中。当然，默认情况下，只有通过命令行设置的变量会被传递。而定义在文件中的变量，如果要向下层 Makefile传递，则需要使用exprot关键字来声明。（参见前面章节） 当然，我并不推荐把许多的变量都定义在系统环境中，这样，在我们执行不用的Makefile时，拥有的是同一套系统变量，这可能会带来更多的麻烦。 5.8目标变量前面我们所讲的在Makefile中定义的变量都是“全局变量”，在整个文件，我们都可以访问这些变量。当然，“自动化变量”除外，如“$&lt;”等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义。 当然，我样同样可以为某个目标设置局部变量，这种变量被称为“Target-specific Variable”，它可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值。 其语法是： 12345&lt;target ...&gt; : &lt;variable-assignment&gt;&lt;target ...&gt; : overide &lt;variable-assignment&gt;` 可以是前面讲过的各种赋值表达式，如“=”、“:=”、“+=”或是“？=”。第二个语法是针对于make命令行带入的变量，或是系统环境变量。 这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如： 123456789101112131415prog : CFLAGS = -gprog : prog.o foo.o bar.o$(CC) $(CFLAGS) prog.o foo.o bar.oprog.o : prog.c$(CC) $(CFLAGS) prog.cfoo.o : foo.c$(CC) $(CFLAGS) foo.cbar.o : bar.c$(CC) $(CFLAGS) bar.c 在这个示例中，不管全局的$(CFLAGS)的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则），$(CFLAGS)的值都是“-g” 5.9模式变量在GNU的make中，还支持模式变量（Pattern-specific Variable），通过上面的目标变量中，我们知道，变量可以定义在某个目标上。模式变量的好处就是，我们可以给定一种“模式”，可以把变量定义在符合这种模式的所有目标上。 我们知道，make的“模式”一般是至少含有一个“%”的，所以，我们可以以如下方式给所有以[.o]结尾的目标定义目标变量： 1%.o : CFLAGS = -O 同样，模式变量的语法和“目标变量”一样： 1234&lt;pattern ...&gt; : &lt;variable-assignment&gt;&lt;pattern ...&gt; : override &lt;variable-assignment&gt; override同样是针对于系统环境传入的变量，或是make命令行指定的变量。 6. 使用条件判断使用条件判断，可以让make根据运行时的不同情况选择不同的执行分支。条件表达式可以是比较变量的值，或是比较变量和常量的值。 6.1 示例下面的例子，判断$(CC)变量是否“gcc”，如果是的话，则使用GNU函数编译目标。 12345678910libs_for_gcc = -lgnunormal_libs =foo: $(objects)ifeq ($(CC),gcc)$(CC) -o foo $(objects) $(libs_for_gcc)else$(CC) -o foo $(objects) $(normal_libs)endif 可见，在上面示例的这个规则中，目标“foo”可以根据变量“$(CC)”值来选取不同的函数库来编译程序。 我们可以从上面的示例中看到三个关键字：ifeq、else和endif。ifeq的意思表示条件语句的开始，并指定一个条件表达式，表达式包含两个参数，以逗号分隔，表达式以圆括号括起。else表示条件表达式为假的情况。endif表示一个条件语句的结束，任何一个条件表达式都应该以endif结束。 当我们的变量$(CC)值是“gcc”时，目标foo的规则是： 12foo: $(objects)$(CC) -o foo $(objects) $(libs_for_gcc) 而当我们的变量$(CC)值不是“gcc”时（比如“cc”），目标foo的规则是： 12foo: $(objects)$(CC) -o foo $(objects) $(normal_libs) 当然，我们还可以把上面的那个例子写得更简洁一些： 12345678910111213libs_for_gcc = -lgnunormal_libs =ifeq ($(CC),gcc)libs=$(libs_for_gcc)elselibs=$(normal_libs)endiffoo: $(objects)$(CC) -o foo $(objects) $(libs) 6.2 语法条件表达式的语法为： 123&lt;conditional-directive&gt;&lt;text-if-true&gt;endif 以及： 12345&lt;conditional-directive&gt;&lt;text-if-true&gt;else&lt;text-if-false&gt;endif 其中表示条件关键字，如“ifeq”。这个关键字有四个。 第一个是我们前面所见过的“ifeq” 12345ifeq (&lt;arg1&gt;, &lt;arg2&gt; )ifeq &apos;&lt;arg1&gt;&apos; &apos;&lt;arg2&gt;&apos;ifeq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;ifeq &quot;&lt;arg1&gt;&quot; &apos;&lt;arg2&gt;&apos;ifeq &apos;&lt;arg1&gt;&apos; &quot;&lt;arg2&gt;&quot; 比较参数“arg1”和“arg2”的值是否相同。当然，参数中我们还可以使用make的函数。如： 123ifeq ($(strip $(foo)),)&lt;text-if-empty&gt;endif 这个示例中使用了“strip”函数，如果这个函数的返回值是空（Empty），那么就生效。 第二个条件关键字是“ifneq”。语法是： 12345ifneq (&lt;arg1&gt;, &lt;arg2&gt; )ifneq &apos;&lt;arg1&gt;&apos; &apos;&lt;arg2&gt;&apos;ifneq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;ifneq &quot;&lt;arg1&gt;&quot; &apos;&lt;arg2&gt;&apos;ifneq &apos;&lt;arg1&gt;&apos; &quot;&lt;arg2&gt;&quot; 其比较参数“arg1”和“arg2”的值是否相同，如果不同，则为真。和“ifeq”类似。 第三个条件关键字是“ifdef”。语法是： 1ifdef &lt;variable-name&gt; 如果变量的值非空，那到表达式为真。否则，表达式为假。当然，同样可以是一个函数的返回值。注意，ifdef只是测试一个变量是否有值，其并不会把变量扩展到当前位置。还是来看两个例子： 示例一： 1234567bar =foo = $(bar)ifdef foofrobozz = yeselsefrobozz = noendif 示例二： 123456foo =ifdef foofrobozz = yeselsefrobozz = noendif 第一个例子中，“$(frobozz)”值是“yes”，第二个则是“no”。 第四个条件关键字是“ifndef”。其语法是： 1ifndef &lt;variable-name&gt; 这个我就不多说了，和“ifdef”是相反的意思。 在这一行上，多余的空格是被允许的，但是不能以[Tab]键做为开始（不然就被认为是命令）。而注释符“#”同样也是安全的。“else”和“endif”也 一样，只要不是以[Tab]键开始就行了。 特别注意的是，make是在读取Makefile时就计算条件表达式的值，并根据条件表达式的值来选择语句，所以，你最好不要把自动化变量（如“$@”等）放入条件表达式中，因为自动化变量是在运行时才有的。 而且，为了避免混乱，make不允许把整个条件语句分成两部分放在不同的文件中。 7. 使用函数在Makefile中可以使用函数来处理变量，从而让我们的命令或是规则更为的灵活和具有智能。make所支持的函数也不算很多，不过已经足够我们的操作了。函数调用后，函数的返回值可以当做变量来使用。 7.1函数的调用语法函数调用，很像变量的使用，也是以“$”来标识的，其语法如下： 1$(&lt;function&gt; &lt;arguments&gt; ) 或是 1$&#123;&lt;function&gt; &lt;arguments&gt;&#125; 这里，就是函数名，make支持的函数不多。是函数的参数，参数间以逗号“,”分隔，而函数名和参数之间以“空格”分隔。函数调用以“$”开头，以圆括号或花括号把函数名和参数括起。感觉很像一个变量，是不是？函数中的参数可以使用变量，为了风格的统一，函数和变量的括号最好一样，如使用“$(subst a,b,$(x))”这样的形式，而不是“$(subst a,b,${x})”的形式。因为统一会更清楚，也会减少一些不必要的麻烦。 还是来看一个示例： 12345comma:= ,empty:=space:= $(empty) $(empty)foo:= a b cbar:= $(subst $(space),$(comma),$(foo)) 在这个示例中，$(comma)的值是一个逗号。$(space)使用了$(empty)定义了一个空格，$(foo)的值是“a b c”，$(bar)的定义用，调用了函数“subst”，这是一个替换函数，这个函数有三个参数，第一个参数是被替换字串，第二个参数是替换字串，第三个参数是替换操作作用的字串。这个函数也就是把$(foo)中的空格替换成逗号，所以$(bar)的值是“ a,b,c”。 7.2 字符串处理函数1$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt; ) 名称：字符串替换函数——subst。 功能：把字串中的字符串替换成。 返回：函数返回被替换过后的字符串。 示例： 1$(subst ee,EE,feet on the street)， 把“feet on the street”中的“ee”替换成“EE”，返回结果是“fEEt on the strEEt ”。 12$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt; ) 名称：模式字符串替换函数——patsubst。 功能：查找中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式，如果匹配的话，则以替换。这里，可以包括通配符“%”，表示任意长度的字串。如果中也包含“%”，那么，中的这个“%”将是中的那个“%”所代表的字串。（可以用“\”来转义，以“\%”来表示真实含义的“%”字符）返回：函数返回被替换过后的字符串。 示例： 1$(patsubst %.c,%.o,x.c.c bar.c) 把字串“x.c.c bar.c”符合模式[%.c]的单词替换成[%.o]，返回结果是“x.c.o bar.o” 备注： 这和我们前面“变量章节”说过的相关知识有点相似。如： 1“$(var:&lt;pattern&gt;=&lt;replacement&gt; )” 相当于 1“$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,$(var))”， 而“$(var: = )” 则相当于 “$(patsubst %,%,$(var))”。 例如有：objects = foo.o bar.o baz.o， 那么，“$(objects:.o=.c)”和“$(patsubst %.o,%.c,$(objects))”是一样的。 1$(strip &lt;string&gt; ) 名称：去空格函数——strip。 功能：去掉字串中开头和结尾的空字符。 返回：返回被去掉空格的字符串值。 示例： 1$(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。 1$(findstring &lt;find&gt;,&lt;in&gt; ) 名称：查找字符串函数——findstring。 功能：在字串中查找字串。 返回：如果找到，那么返回，否则返回空字符串。 示例： 12$(findstring a,a b c)$(findstring a,b c) 第一个函数返回“a”字符串，第二个返回“”字符串（空字符串） 1$(filter &lt;pattern...&gt;,&lt;text&gt; ) 名称：过滤函数——filter。 功能：以模式过滤字符串中的单词，保留符合模式的单词。可 以有多个模式。 返回：返回符合模式的字串。 示例： 123sources := foo.c bar.c baz.s ugh.hfoo: $(sources)cc $(filter %.c %.s,$(sources)) -o foo $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。 1$(filter-out &lt;pattern...&gt;,&lt;text&gt; ) 名称：反过滤函数——filter-out。 功能：以模式过滤字符串中的单词，去除符合模式的单词。可 以有多个模式。 返回：返回不符合模式的字串。 示例： 12objects=main1.o foo.o main2.o bar.omains=main1.o main2.o $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”。 1$(sort &lt;list&gt; ) 名称：排序函数——sort。 功能：给字符串中的单词排序（升序）。 返回：返回排序后的字符串。 示例：$(sort foo bar lose)返回“bar foo lose” 。 备注：sort函数会去掉中相同的单词。 1$(word &lt;n&gt;,&lt;text&gt; ) 名称：取单词函数——word。 功能：取字符串中第个单词。（从一开始） 返回：返回字符串中第个单词。如果比中的单词数要大，那么返回空 字符串。 示例：$(word 2, foo bar baz)返回值是“bar”。 1$(wordlist &lt;s&gt;,&lt;e&gt;,&lt;text&gt; ) 名称：取单词串函数——wordlist。 功能：从字符串中取从开始到的单词串。和是一个数字。 返回：返回字符串中从到的单词字串。如果比中的单词数要大，那 么返回空字符串。如果大于的单词数，那么返回从开始，到结束的单 词串。 示例： $(wordlist 2, 3, foo bar baz)返回值是“bar baz”。 1$(words &lt;text&gt; ) 名称：单词个数统计函数——words。 功能：统计中字符串中的单词个数。 返回：返回中的单词数。 示例：$(words, foo bar baz)返回值是“3”。 备注：如果我们要取中最后的一个单词，我们可以这样：$(word $(words ), )。 1$(firstword &lt;text&gt; ) 名称：首单词函数——firstword。 功能：取字符串中的第一个单词。 返回：返回字符串的第一个单词。 示例：$(firstword foo bar)返回值是“foo”。 备注：这个函数可以用word函数来实现：$(word 1, )。 以上，是所有的字符串操作函数，如果搭配混合使用，可以完成比较复杂的功能。这里， 举一个现实中应用的例子。我们知道，make使用“VPATH”变量来指定“依赖文件”的搜索 路径。于是，我们可以利用这个搜索路径来指定编译器对头文件的搜索路径参数CFLAGS， 如： override CFLAGS += $(patsubst %,-I%,$(subst :, ,$(VPATH))) 如果我们的“$(VPATH)”值是“src:../headers”，那么“$(patsubst %,-I%,$(subst : , ,$(VPATH)))”将返回“-Isrc -I../headers”，这正是cc或gcc搜索头文件路径的参数 7.3文件名操作函数下面我们要介绍的函数主要是处理文件名的。每个函数的参数字符串都会被当做一个或是 一系列的文件名来对待。 1$(dir &lt;names...&gt; ) 名称：取目录函数——dir。 功能：从文件名序列中取出目录部分。目录部分是指最后一个反斜杠（“/”）之 前的部分。如果没有反斜杠，那么返回“./”。 返回：返回文件名序列的目录部分。 示例： $(dir src/foo.c hacks)返回值是“src/ ./”。 1$(notdir &lt;names...&gt; ) 名称：取文件函数——notdir。 功能：从文件名序列中取出非目录部分。非目录部分是指最后一个反斜杠（“/” ）之后的部分。 返回：返回文件名序列的非目录部分。 示例： $(notdir src/foo.c hacks)返回值是“foo.c hacks”。 1$(suffix &lt;names...&gt; ) 名称：取后缀函数——suffix。 功能：从文件名序列中取出各个文件名的后缀。 返回：返回文件名序列的后缀序列，如果文件没有后缀，则返回空字串。 示例：$(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c”。 1$(basename &lt;names...&gt; ) 名称：取前缀函数——basename。 功能：从文件名序列中取出各个文件名的前缀部分。 返回：返回文件名序列的前缀序列，如果文件没有前缀，则返回空字串。 示例：$(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar h acks”。 1$(addsuffix &lt;suffix&gt;,&lt;names...&gt; ) 名称：加后缀函数——addsuffix。 功能：把后缀加到中的每个单词后面。 返回：返回加过后缀的文件名序列。 示例：$(addsuffix .c,foo bar)返回值是“foo.c bar.c”。 1$(addprefix &lt;prefix&gt;,&lt;names...&gt; ) 名称：加前缀函数——addprefix。 功能：把前缀加到中的每个单词后面。 返回：返回加过前缀的文件名序列。 示例：$(addprefix src/,foo bar)返回值是“src/foo src/bar”。 1$(join &lt;list1&gt;,&lt;list2&gt; ) 名称：连接函数——join。 功能：把中的单词对应地加到的单词后面。如果的单词个数要比&lt; list2&gt;的多，那么，中的多出来的单词将保持原样。如果的单词个数要比 多，那么，多出来的单词将被复制到中。 返回：返回连接过后的字符串。 示例：$(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”。 7.4 foreach 函数foreach 函数和别的函数非常的不一样。因为这个函数是用来做循环用的，Makefile中的 foreach函数几乎是仿照于Unix标准Shell（/bin /sh）中的for语句，或是C-Shell（/bin /csh）中的foreach语句而构建的。它的语法是： 1$(foreach &lt;var&gt;,&lt;list&gt;,&lt;text&gt; ) 这个函数的意思是，把参数中的单词逐一取出放到参数所指定的变量中，然后再执行所包含的表达式。每一次会返回一个字符串，循环过程中，的所返回的每个字符串会以空格分隔，最后当整个循环结束时，所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。 所以，最好是一个变量名，可以是一个表达式，而中一般会使用 这个参数来依次枚举中的单词。举个例子： 1234names := a b c dfiles := $(foreach n,$(names),$(n).o) 上面的例子中，$(name)中的单词会被挨个取出，并存到变量“n”中，“$(n).o”每次根据“$(n)”计算出一个值，这些值以空格分隔，最后作为foreach函数的返回，所以，$(f iles)的值是“a.o b.o c.o d.o”。 注意，foreach中的参数是一个临时的局部变量，foreach函数执行完后，参数的变量将不在作用，其作用域只在foreach函数当中。 7.5 if 函数if函数很像GNU的make所支持的条件语句——ifeq（参见前面所述的章节），if函数的语法是： 1$(if &lt;condition&gt;,&lt;then-part&gt; ) 或是 1$(if &lt;condition&gt;,&lt;then-part&gt;,&lt;else-part&gt; ) 可见，if函数可以包含“else”部分，或是不含。即if函数的参数可以是两个，也可以是三个。参数是if的表达式，如果其返回的为非空字符串，那么这个表达式就相当于返回真，于是，会被计算，否则 会被计算。 而if函数的返回值是，如果为真（非空字符串），那个会是整个函数的返回值，如果为假（空字符串），那么会是整个函数的返回值，此时如果没有被定义，那么，整个函数返回空字串。 所以，和只会有一个被计算。 7.6 call函数call函数是唯一一个可以用来创建新的参数化的函数。你可以写一个非常复杂的表达式，这个表达式中，你可以定义许多参数，然后你可以用call函数来向这个表达式传递参数。其语法是： 1$(call &lt;expression&gt;,&lt;parm1&gt;,&lt;parm2&gt;,&lt;parm3&gt;...) 当 make执行这个函数时，参数中的变量，如$(1)，$(2)，$(3)等，会被参数，，依次取代。而的返回值就是 call函数的返回值。例如： 123reverse = $(1) $(2)foo = $(call reverse,a,b) 那么，foo的值就是“a b”。当然，参数的次序是可以自定义的，不一定是顺序的，如： 12reverse = $(2) $(1)foo = $(call reverse,a,b) 此时的foo的值就是“b a”。 7.7origin函数origin函数不像其它的函数，他并不操作变量的值，他只是告诉你你的这个变量是哪里来的？其语法是： 1$(origin &lt;variable&gt; ) 注意，是变量的名字，不应该是引用。所以你最好不要在中使用“$”字符。Origin函数会以其返回值来告诉你这个变量的“出生情况”，下面，是origin函 数的返回值: “undefined” 如果从来没有定义过，origin函数返回这个值“undefined”。 “default” 如果是一个默认的定义，比如“CC”这个变量，这种变量我们将在后面讲述。 “environment” 如果是一个环境变量，并且当Makefile被执行时，“-e”参数没有被打开。 “file” 如果这个变量被定义在Makefile中。 “command line” 如果这个变量是被命令行定义的。 “override” 如果是被override指示符重新定义的。 “automatic” 如果是一个命令运行中的自动化变量。关于自动化变量将在后面讲述。 这些信息对于我们编写Makefile是非常有用的，例如，假设我们有一个Makefile其包了一个定义文件Make.def，在Make.def中定义了一个变量“bletch”，而我们的环境中也有一 个环境变量“bletch”，此时，我们想判断一下，如果变量来源于环境，那么我们就把之重定义了，如果来源于Make.def或是命令行等非环境的，那么我们就不重新定义它。于是 ，在我们的Makefile中，我们可以这样写： 1234567891011ifdef bletchifeq &quot;$(origin bletch)&quot; &quot;environment&quot;bletch = barf, gag, etc.endifendif 当然，你也许会说，使用override关键字不就可以重新定义环境中的变量了吗？为什么需要使用这样的步骤？是的，我们用override是可以达到这样的效果，可是override过于粗 暴，它同时会把从命令行定义的变量也覆盖了，而我们只想重新定义环境传来的，而不想重新定义命令行传来的。 7.8 shell函数shell 函数也不像其它的函数。顾名思义，它的参数应该就是操作系统Shell的命令。它和反引号 是相同的功能。这就是说，shell函数把执行操作系统命令后的输出作为函数 返回。于是，我们可以用操作系统命令以及字符串处理命令awk，sed等等命令来生成一个变量，如： 12contents := $(shell cat foo)files := $(shell echo *.c) 注意，这个函数会新生成一个Shell程序来执行命令，所以你要注意其运行性能，如果你的Makefile中有一些比较复杂的规则，并大量使用了这个函数，那么对于你的系统性能是有害的。特别是Makefile的隐晦的规则可能会让你的shell函数执行的次数比你想像的多得多。 7.9 控制make的函数make提供了一些函数来控制make的运行。通常，你需要检测一些运行Makefile时的运行时信息，并且根据这些信息来决定，你是让make继续执行，还是停止。 1$(error &lt;text ...&gt; ) 产生一个致命的错误，是错误信息。注意，error函数不会在一被使用就会产生错误信息，所以如果你把其定义在某个变量中，并在后续的脚本中使用这个变量，那么也 是可以的。例如： 示例一： 123ifdef ERROR_001$(error error is $(ERROR_001))endif 示例二： 123ERR = $(error found an error!).PHONY: errerr: ; $(ERR) 示例一会在变量ERROR_001定义了后执行时产生error调用，而示例二则在目录err被执行时才发生error调用。 1$(warning &lt;text ...&gt; ) 这个函数很像error函数，只是它并不会让make退出，只是输出一段警告信息，而make继续执行。 8. make 的运行一般来说，最简单的就是直接在命令行下输入make命令，make命令会找当前目录的makefile来执行，一切都是自动的。但也有时你也许只想让 make重编译某些文件，而不是整个工程，而又有的时候你有几套编译规则，你想在不同的时候使用不同的编译规则，等等。本章节就是讲述如何使用make命令的。 8.1 make的退出码make命令执行后有三个退出码： 0 —— 表示成功执行。 1 —— 如果make运行时出现任何错误，其返回1。 2 —— 如果你使用了make的“-q”选项，并且make使得一些目标不需要更新，那么返回2。 Make的相关参数我们会在后续章节中讲述。 8.2 指定Makefile前面我们说过，GNU make找寻默认的Makefile的规则是在当前目录下依次找三个文件——“GNUmakefile”、“makefile”和“Makefile”。其按顺序找这三个文件，一旦找到，就 开始读取这个文件并执行。 当前，我们也可以给make命令指定一个特殊名字的Makefile。要达到这个功能，我们要使用make的“-f”或是“–file”参数（“– makefile”参数也行）。例如，我们有个mak efile的名字是“hchen.mk”，那么，我们可以这样来让make来执行这个文件： 1make –f hchen.mk 如果在make的命令行是，你不只一次地使用了“-f”参数，那么，所有指定的makefile将会被连在一起传递给make执行。 8.3 指定目标一般来说，make的最终目标是makefile中的第一个目标，而其它目标一般是由这个目标连带出来的。这是make的默认行为。当然，一般来说，你的 makefile中的第一个目标是由许多个目标组成，你可以指示make，让其完成你所指定的目标。要达到这一目的很简单，需在make命令后直接跟目标的名字就可以完成（如前面提到的“make clean”形式）任何在makefile中的目标都可以被指定成终极目标，但是除了以“- ”打头，或是包含了“=”的目标，因为有这些字符的目标，会被解析成命令行参数或是变量。甚至没有被我们明确写出来的目标也可以成为make的终极目标，也就是说，只要make可以找到其隐含规则推导规则，那么这个隐含目标同样可以被指定成终极目标。 有一个make的环境变量叫“MAKECMDGOALS”，这个变量中会存放你所指定的终极目标的列表，如果在命令行上，你没有指定目标，那么，这个变量是空值。这个变量可以让你使用在一些比较特殊的情形下。比如下面的例子： 1234sources = foo.c bar.cifneq ( $(MAKECMDGOALS),clean)include $(sources:.c=.d)endif 基于上面的这个例子，只要我们输入的命令不是“make clean”，那么makefile会自动包含“foo.d”和“bar.d”这两个makefile。 使用指定终极目标的方法可以很方便地让我们编译我们的程序，例如下面这个例子： 12.PHONY: allall: prog1 prog2 prog3 prog4 从这个例子中，我们可以看到，这个makefile中有四个需要编译的程序——“prog1”， “prog2”， “prog3”和 “prog4”，我们可以使用“make all”命令来编译所有的目标 （如果把all置成第一个目标，那么只需执行“make”），我们也可以使用“make prog2”来单独编译目标“prog2”。 即然make可以指定所有makefile中的目标，那么也包括“伪目标”，于是我们可以根据这种性质来让我们的makefile根据指定的不同的目标来完成不同的事。在Unix世界中，软件 发布时，特别是GNU这种开源软件的发布时，其 makefile都包含了编译、安装、打包等功能。我们可以参照这种规则来书写我们的makefile中的目标。 “all” 这个伪目标是所有目标的目标，其功能一般是编译所有的目标。 “clean” 这个伪目标功能是删除所有被make创建的文件。 “install” 这个伪目标功能是安装已编译好的程序，其实就是把目标执行文件拷贝到指定的目标中去。 “print” 这个伪目标的功能是例出改变过的源文件。 “tar” 这个伪目标功能是把源程序打包备份。也就是一个tar文件。 “dist” 这个伪目标功能是创建一个压缩文件，一般是把tar文件压成Z文件。或是gz文件。 “TAGS” 这个伪目标功能是更新所有的目标，以备完整地重编译使用。 “check”和“test” 这两个伪目标一般用来测试makefile的流程。 当然一个项目的makefile中也不一定要书写这样的目标，这些东西都是GNU的东西，但是我想，GNU搞出这些东西一定有其可取之处（等你的UNIX下的程序文件一多时你就会发现这些功能很有用了），这里只不过是说明了，如果你要书写这种功能，最好使用这种名字命名你的目标，这样规范一些，规范的好处就是——不用解释，大家都明白。而且如果你的makefile中有这些功能，一是很实用，二是可以显得你的makefile很专业（不是那种初学者的作品）。 8.4 检查规则有时候，我们不想让我们的makefile中的规则执行起来，我们只想检查一下我们的命令，或是执行的序列。于是我们可以使用make命令的下述参数： “-n” “–just-print” “–dry-run” “–recon” 不执行参数，这些参数只是打印命令，不管目标是否更新，把规则和连带规则下的命令打印出来，但不执行，这些参数对于我们调试makefile很有用处。 “-t” “–touch” 这个参数的意思就是把目标文件的时间更新，但不更改目标文件。也就是说，make假装编译目标，但不是真正的编译目标，只是把目标变成已编译过的状态。 “-q” “–question” 这个参数的行为是找目标的意思，也就是说，如果目标存在，那么其什么也不会输出，当然也不会执行编译，如果目标不存在，其会打印出一条出错信息。 “-W ” “–what-if=” “–assume-new=” “–new-file=” 这个参数需要指定一个文件。一般是是源文件（或依赖文件），Make会根据规则推导来运行依赖于这个文件的命令，一般来说，可以和“-n”参数一同使用，来查看这个依赖文件 所发生的规则命令。 另外一个很有意思的用法是结合“-p”和“-v”来输出makefile被执行时的信息（这个将在后面讲述）。 8.5 make的参数下面列举了所有GNU make 3.80版的参数定义。其它版本和产商的make大同小异，不过其它产商的make的具体参数还是请参考各自的产品文档。 “-b” “-m” 这两个参数的作用是忽略和其它版本make的兼容性。 “-B” “–always-make” 认为所有的目标都需要更新（重编译）。 “-C ” “–directory=” 指定读取makefile的目录。如果有多个“-C”参数，make的解释是后面的路径以前面的作为相对路径，并以最后的目录作为被指定目录。如：“make –C ~hchen/test –C prog” 等价于“make –C ~hchen/test/prog”。 “—debug[=]” 输出make的调试信息。它有几种不同的级别可供选择，如果没有参数，那就是输出最简单的调试信息。下面是的取值： a —— 也就是all，输出所有的调试信息。（会非常的多） b —— 也就是basic，只输出简单的调试信息。即输出不需要重编译的目标。 v —— 也就是verbose，在b选项的级别之上。输出的信息包括哪个makefile被解析，不需要被重编译的依赖文件（或是依赖目标）等。 i —— 也就是implicit，输出所以的隐含规则。 j —— 也就是jobs，输出执行规则中命令的详细信息，如命令的PID、返回码等。 m —— 也就是makefile，输出make读取makefile，更新makefile，执行makefile的信息。 “-d” 相当于“–debug=a”。 “-e” “–environment-overrides” 指明环境变量的值覆盖makefile中定义的变量的值。 “-f=” “–file=” “–makefile=” 指定需要执行的makefile。 “-h” “–help” 显示帮助信息。 “-i” “–ignore-errors” 在执行时忽略所有的错误。 “-I ” “–include-dir=” 指定一个被包含makefile的搜索目标。可以使用多个“-I”参数来指定多个目录。 “-j []” “–jobs[=]” 指同时运行命令的个数。如果没有这个参数，make运行命令时能运行多少就运行多少。如果有一个以上的“-j”参数，那么仅最后一个“-j”才是有效的。（注意这个参数在MS-D OS中是无用的） “-k” “–keep-going” 出错也不停止运行。如果生成一个目标失败了，那么依赖于其上的目标就不会被执行了。 “-l ” “–load-average[=&lt;load]” “—max-load[=]” 指定make运行命令的负载。 “-n” “–just-print” “–dry-run” “–recon” 仅输出执行过程中的命令序列，但并不执行。 “-o ” “–old-file=” “–assume-old=” 不重新生成的指定的，即使这个目标的依赖文件新于它。 “-p” “–print-data-base” 输出makefile中的所有数据，包括所有的规则和变量。这个参数会让一个简单的makefile都会输出一堆信息。如果你只是想输出信息而不想执行 makefile，你可以使用“make -q p”命令。如果你想查看执行makefile前的预设变量和规则，你可以使用“make –p –f /dev/null”。这个参数输出的信息会包含着你的makefile文件的文件名和行号，所以，用 这个参数来调试你的makefile会是很有用的，特别是当你的环境变量很复杂的时候。 “-q” “–question” 不运行命令，也不输出。仅仅是检查所指定的目标是否需要更新。如果是0则说明要更新，如果是2则说明有错误发生。 “-r” “–no-builtin-rules” 禁止make使用任何隐含规则。 “-R” “–no-builtin-variabes” 禁止make使用任何作用于变量上的隐含规则。 “-s” “–silent” “–quiet” 在命令运行时不输出命令的输出。 “-S” “–no-keep-going” “–stop” 取消“-k”选项的作用。因为有些时候，make的选项是从环境变量“MAKEFLAGS”中继承下来的。所以你可以在命令行中使用这个参数来让环境变量中的“-k”选项失效。 “-t” “–touch” 相当于UNIX的touch命令，只是把目标的修改日期变成最新的，也就是阻止生成目标的命令运行。 “-v” “–version” 输出make程序的版本、版权等关于make的信息。 “-w” “–print-directory” 输出运行makefile之前和之后的信息。这个参数对于跟踪嵌套式调用make时很有用。 “–no-print-directory” 禁止“-w”选项。 “-W ” “–what-if=” “–new-file=” “–assume-file=” 假定目标需要更新，如果和“-n”选项使用，那么这个参数会输出该目标更新时的运行动作。如果没有“-n”那么就像运行UNIX的“touch”命令一样，使得的修改时 间为当前时间。 “–warn-undefined-variables” 只要make发现有未定义的变量，那么就输出警告信息。 9. 隐含规则在我们使用Makefile时，有一些我们会经常使用，而且使用频率非常高的东西，比如，我们编译C/C++的源程序为中间目标文件（Unix下是[.o] 文件，Windows下是[.obj]文件）。本章讲述的就是一些在Makefile中的“隐含的”，早先约定了的，不需要我们再写出来的规则。 “隐含规则”也就是一种惯例，make会按照这种“惯例”心照不喧地来运行，那怕我们的Makefile中没有书写这样的规则。例如，把[.c]文件编译成[.o]文件这一规则，你根本就 不用写出来，make会自动推导出这种规则，并生成我们需要的[.o]文件。 “隐含规则”会使用一些我们系统变量，我们可以改变这些系统变量的值来定制隐含规则的运行时的参数。如系统变量“CFLAGS”可以控制编译时的编译器参数。 我们还可以通过“模式规则”的方式写下自己的隐含规则。用“后缀规则”来定义隐含规则会有许多的限制。使用“模式规则”会更回得智能和清楚，但“后缀规则”可以用来保 证我们Makefile的兼容性。 我们了解了“隐含规则”，可以让其为我们更好的服务，也会让我们知道一些“约定俗成”了的东西，而不至于使得我们在运行Makefile时出现一些我们觉得莫名其妙的东西。当 然，任何事物都是矛盾的，水能载舟，亦可覆舟，所以，有时候“隐含规则”也会给我们造成不小的麻烦。只有了解了它，我们才能更好地使用它。 9.1 使用隐含规则如果要使用隐含规则生成你需要的目标，你所需要做的就是不要写出这个目标的规则。那么，make会试图去自动推导产生这个目标的规则和命令，如果make可以自动推导生成这个目标的规则和命令，那么这个行为就是隐含规则的自动推导。当然，隐含规则是make事先约定好的一些东西。例如，我们有下面的一个Makefile： 12foo : foo.o bar.occ –o foo foo.o bar.o $(CFLAGS) $(LDFLAGS) 我们可以注意到，这个Makefile中并没有写下如何生成foo.o和bar.o这两目标的规则和命令。因为make的“隐含规则”功能会自动为我们自动去推导这两个目标的依赖目标和生成 命令。 make 会在自己的“隐含规则”库中寻找可以用的规则，如果找到，那么就会使用。如果找不到，那么就会报错。在上面的那个例子中，make调用的隐含规则是，把 [.o]的目标的依赖文件置成[.c]，并使用C的编译命令“cc –c $(CFLAGS) [.c]”来生成[.o]的目标。也就是说，我们完全没有必要写下下面的两条规则： 1234foo.o : foo.ccc –c foo.c $(CFLAGS)bar.o : bar.ccc –c bar.c $(CFLAGS) 因为，这已经是“约定”好了的事了，make和我们约定好了用C编译器“cc”生成[.o]文件的规则，这就是隐含规则。 当然，如果我们为[.o]文件书写了自己的规则，那么make就不会自动推导并调用隐含规则，它会按照我们写好的规则忠实地执行。 还有，在make的“隐含规则库”中，每一条隐含规则都在库中有其顺序，越靠前的则是越被经常使用的，所以，这会导致我们有些时候即使我们显示地指定了目标依赖，make也不会管。如下面这条规则（没有命令）： 1foo.o : foo.p 依赖文件“foo.p”（Pascal程序的源文件）有可能变得没有意义。如果目录下存在了“foo.c”文件，那么我们的隐含规则一样会生效，并会通过 “foo.c”调用C的编译器生成f oo.o文件。因为，在隐含规则中，Pascal的规则出现在C的规则之后，所以，make找到可以生成foo.o的 C的规则就不再寻找下一条规则了。如果你确实不希望任何隐含规则推导，那么，你就不要只写出“依赖规则”，而不写命令。 9.2隐含规则一览这里我们将讲述所有预先设置（也就是make内建）的隐含规则，如果我们不明确地写下规则，那么，make就会在这些规则中寻找所需要规则和命令。当然，我们也可以使用make的参数“-r”或“–no-builtin-rules”选项来取消所有的预设置的隐含规则。 当然，即使是我们指定了“-r”参数，某些隐含规则还是会生效，因为有许多的隐含规则都是使用了“后缀规则”来定义的，所以，只要隐含规则中有“后缀列表 ”（也就一系统 定义在目标.SUFFIXES的依赖目标），那么隐含规则就会生效。默认的后缀列表是：.out,.a, .ln, .o, .c, .cc, .C, .p, .f, .F, .r, .y, .l, .s, .S, .mod, .sym, .def, . h, .info, .dvi, .tex, .texinfo, .texi, .txinfo, .w, .ch .web, .sh, .elc, .el。具体的细节，我们会在后面讲述。 还是先来看一看常用的隐含规则吧。 编译C程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.c”，并且其生成命令是“$(CC) –c $(CPPFLAGS) $(CFLAGS)” 编译C++程序的隐含规则。 “.o” 的目标的依赖目标会自动推导为“.cc”或是“.C”，并且其生成命令是“$(CXX) –c $(CPPFLAGS) $(CFLAGS)”。（建议使用“.cc”作为C++源文件的后缀，而 不是“.C”） 编译Pascal程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.p”，并且其生成命令是“$(PC) –c $(PFLAGS)”。 编译Fortran/Ratfor程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.r”或“.F”或“.f”，并且其生成命令是: 123“.f” “$(FC) –c $(FFLAGS)”“.F” “$(FC) –c $(FFLAGS) $(CPPFLAGS)”“.f” “$(FC) –c $(FFLAGS) $(RFLAGS)” 预处理Fortran/Ratfor程序的隐含规则。 “.f”的目标的依赖目标会自动推导为“.r”或“.F”。这个规则只是转换Ratfor或有预处理的Fortran程序到一个标准的Fortran程序。其使用的命令是： 12“.F” “$(FC) –F $(CPPFLAGS) $(FFLAGS)”“.r” “$(FC) –F $(FFLAGS) $(RFLAGS)” 编译Modula-2程序的隐含规则。 “.sym” 的目标的依赖目标会自动推导为“.def”，并且其生成命令是：“$(M2C) $(M2FLAGS) $(DEFFLAGS)”。“&lt;n.o&gt;”的目标的依赖目标会自动推导为“.mod”， 并且其生成命令是：“$(M2C) $(M2FLAGS) $(MODFLAGS)”。 汇编和汇编预处理的隐含规则。 “.o” 的目标的依赖目标会自动推导为“.s”，默认使用编译品“as”，并且其生成命令是：“$(AS) $(ASFLAGS)”。“.s” 的目标的依赖目标会自动推导为“.S” ，默认使用C预编译器“cpp”，并且其生成命令是：“$(AS) $(ASFLAGS)”。 链接Object文件的隐含规则。 “” 目标依赖于“.o”，通过运行C的编译器来运行链接程序生成（一般是“ld”），其生成命令是：“$(CC) $(LDFLAGS) .o $(LOADLIBES) $(LDLIBS)”。这个规则对 于只有一个源文件的工程有效，同时也对多个Object文件（由不同的源文件生成）的也有效。例如如下规则：1x : y.o z.o 并且“x.c”、“y.c”和“z.c”都存在时，隐含规则将执行如下命令： 1234567cc -c x.c -o x.occ -c y.c -o y.occ -c z.c -o z.occ x.o y.o z.o -o xrm -f x.orm -f y.orm -f z.o 如果没有一个源文件（如上例中的x.c）和你的目标名字（如上例中的x）相关联，那么，你最好写出自己的生成规则，不然，隐含规则会报错的。 Yacc C程序时的隐含规则。 “.c”的依赖文件被自动推导为“n.y”（Yacc生成的文件），其生成命令是：“$(YACC) $(YFALGS)”。（“Yacc”是一个语法分析器，关于其细节请查看相关资料） Lex C程序时的隐含规则。 “.c”的依赖文件被自动推导为“n.l”（Lex生成的文件），其生成命令是：“$(LEX) $(LFALGS)”。（关于“Lex”的细节请查看相关资料） Lex Ratfor程序时的隐含规则。 “.r”的依赖文件被自动推导为“n.l”（Lex生成的文件），其生成命令是：“$(LEX ) $(LFALGS)”。 从C程序、Yacc文件或Lex文件创建Lint库的隐含规则。 “.ln” （lint生成的文件）的依赖文件被自动推导为“n.c”，其生成命令是：“$(LINT) $(LINTFALGS) $(CPPFLAGS) -i”。对于“.y”和“.l”也是同样的规则。 9.3隐含规则使用的变量在隐含规则中的命令中，基本上都是使用了一些预先设置的变量。你可以在你的makefile中改变这些变量的值，或是在make的命令行中传入这些值，或是在你的环境变量中设置这些值，无论怎么样，只要设置了这些特定的变量，那么其就会对隐含规则起作用。当然，你也可以利用make的“-R”或“–no– builtin-variables”参数来取消你所定义的变量 对隐含规则的作用。 例如，第一条隐含规则——编译C程序的隐含规则的命令是“$(CC) –c $(CFLAGS) $(CPPFLAGS)”。Make默认的编译命令是“cc”，如果你把变量“$(CC)”重定义成“gcc”，把 变量“$(CFLAGS)”重定义成 “-g”，那么，隐含规则中的命令全部会以“gcc –c -g $(CPPFLAGS)”的样子来执行了。 我们可以把隐含规则中使用的变量分成两种：一种是命令相关的，如“CC”；一种是参数 相的关，如“CFLAGS”。下面是所有隐含规则中会用到的变量： 关于命令的变量。 AR 函数库打包程序。默认命令是“ar”。 AS 汇编语言编译程序。默认命令是“as”。 CC C语言编译程序。默认命令是“cc”。 CXX C++语言编译程序。默认命令是“g++”。 CO 从 RCS文件中扩展文件程序。默认命令是“co”。 CPP C程序的预处理器（输出是标准输出设备）。默认命令是“$(CC) –E”。 FC Fortran 和 Ratfor 的编译器和预处理程序。默认命令是“f77”。 GET 从SCCS文件中扩展文件的程序。默认命令是“get”。 LEX Lex方法分析器程序（针对于C或Ratfor）。默认命令是“lex”。 PC Pascal语言编译程序。默认命令是“pc”。 YACC Yacc文法分析器（针对于C程序）。默认命令是“yacc”。 YACCR Yacc文法分析器（针对于Ratfor程序）。默认命令是“yacc –r”。 MAKEINFO 转换Texinfo源文件（.texi）到Info文件程序。默认命令是“makeinfo”。 TEX 从TeX源文件创建TeX DVI文件的程序。默认命令是“tex”。 TEXI2DVI 从Texinfo源文件创建军TeX DVI 文件的程序。默认命令是“texi2dvi”。 WEAVE 转换Web到TeX的程序。默认命令是“weave”。 CWEAVE 转换C Web 到 TeX的程序。默认命令是“cweave”。 TANGLE 转换Web到Pascal语言的程序。默认命令是“tangle”。 CTANGLE 转换C Web 到 C。默认命令是“ctangle”。 RM 删除文件命令。默认命令是“rm –f”。 关于命令参数的变量 下面的这些变量都是相关上面的命令的参数。如果没有指明其默认值，那么其默认值都是 空。 ARFLAGS 函数库打包程序AR命令的参数。默认值是“rv”。 ASFLAGS 汇编语言编译器参数。（当明显地调用“.s”或“.S”文件时）。 CFLAGS C语言编译器参数。 CXXFLAGS C++语言编译器参数。 COFLAGS RCS命令参数。 CPPFLAGS C预处理器参数。（ C 和 Fortran 编译器也会用到）。 FFLAGS Fortran语言编译器参数。 GFLAGS SCCS “get”程序参数。 LDFLAGS 链接器参数。（如：“ld”） LFLAGS Lex文法分析器参数。 PFLAGS Pascal语言编译器参数。 RFLAGS Ratfor 程序的Fortran 编译器参数。 YFLAGS Yacc文法分析器参数。 9.4 隐含规则链有些时候，一个目标可能被一系列的隐含规则所作用。例如，一个[.o]的文件生成，可能会是先被Yacc的[.y]文件先成[.c]，然后再被C的编译器生成。我们把这一系列的隐含规则 叫做“隐含规则链”。 在上面的例子中，如果文件[.c]存在，那么就直接调用C的编译器的隐含规则，如果没有[.c]文件，但有一个[.y]文件，那么Yacc的隐含规则会被调用，生成[.c]文件，然后，再调 用C编译的隐含规则最终由[.c]生成[.o]文件，达到目标。 我们把这种[.c]的文件（或是目标），叫做中间目标。不管怎么样，make会努力自动推导生成目标的一切方法，不管中间目标有多少，其都会执着地把所有的隐含规则和你书写的规则全部合起来分析，努力达到目标，所以，有些时候，可能会让你觉得奇怪，怎么我的目标会这样生成？怎么我的makefile发疯了？ 在默认情况下，对于中间目标，它和一般的目标有两个地方所不同：第一个不同是除非中间的目标不存在，才会引发中间规则。第二个不同的是，只要目标成功产生，那么，产生最终目标过程中，所产生的中间目标文件会被以“rm -f”删除。 通常，一个被makefile指定成目标或是依赖目标的文件不能被当作中介。然而，你可以明显地说明一个文件或是目标是中介目标，你可以使用伪目标“.INTERMEDIATE”来强制声明。（如：.INTERMEDIATE ： mid ） 你也可以阻止make自动删除中间目标，要做到这一点，你可以使用伪目标“.SECONDARY”来强制声明（如：.SECONDARY : sec）。你还可以把你的目标，以模式的方式来指定（如：%.o）成伪目标“.PRECIOUS”的依赖目标，以保存被隐含规则所生成的中间文件。 在“隐含规则链”中，禁止同一个目标出现两次或两次以上，这样一来，就可防止在make自动推导时出现无限递归的情况。 Make 会优化一些特殊的隐含规则，而不生成中间文件。如，从文件“foo.c”生成目标程序“foo”，按道理，make会编译生成中间文件“foo.o”，然后链接成“foo”，但在实际情况下，这一动作可以被一条“cc”的命令完成（cc –o foo foo.c），于是优化过的规 则就不会生成中间文件。 9.5定义模式规则你可以使用模式规则来定义一个隐含规则。一个模式规则就好像一个一般的规则，只是在规则中，目标的定义需要有”%”字符。”%”的意思是表示一个或多个任意字符。在依赖目标中同样可以使用”%”，只是依赖目标中的”%”的取值，取决于其目标。 有一点需要注意的是，”%”的展开发生在变量和函数的展开之后，变量和函数的展开发生在make载入Makefile时，而模式规则中的”%”则发生在运行时。 9.5.1 模式规则介绍模式规则中，至少在规则的目标定义中要包含”%”，否则，就是一般的规则。目标中的”%”定义表示对文件名的匹配，”%”表示长度任意的非空字符串。例如：”%.c”表示以”.c”结尾的文件名（文件名的长度至少为3），而”s.%.c”则表示以”s.”开头，”.c”结尾的文件名（文件名的长度至少为 5）。 如果”%”定义在目标中，那么，目标中的”%”的值决定了依赖目标中的”%”的值，也就是说，目标中的模式的”%”决定了依赖目标中”%”的样子。例如有一个模式规则如下： 1%.o : %.c ; &lt;command ......&gt; 其含义是，指出了怎么从所有的[.c]文件生成相应的[.o]文件的规则。如果要生成的目标是”a.o b.o”，那么”%c”就是”a.c b.c”。 一旦依赖目标中的”%”模式被确定，那么，make会被要求去匹配当前目录下所有的文件名，一旦找到，make就会规则下的命令，所以，在模式规则中，目标可能会是多个的，如果有模式匹配出多个目标，make就会产生所有的模式目标，此时，make关心的是依赖的文件名和生成目标的命令这两件事。 9.5.2 模式规则示例下面这个例子表示了,把所有的[.c]文件都编译成[.o]文件. 12%.o : %.c$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@ 其中，&quot;$@&quot;表示所有的目标的挨个值，&quot;$&lt;&quot;表示了所有依赖目标的挨个值。这些奇怪的变 量我们叫”自动化变量”，后面会详细讲述。 下面的这个例子中有两个目标是模式的： 12%.tab.c %.tab.h: %.ybison -d $&lt; 这条规则告诉make把所有的[.y]文件都以”bison -d .y”执行，然后生成”.tab.c”和”.tab.h”文件。（其中，”“ 表示一个任意字符串）。如果我们的执行程序”foo”依 赖于文件”parse.tab.o”和”scan.o”，并且文件”scan.o”依赖于文件”parse.tab.h”，如果”parse.y”文件被更新了，那么根据上述的规则，”bison -d parse.y”就会被执行一次，于 是，”parse.tab.o”和”scan.o”的依赖文件就齐了。（假设，”parse.tab.o” 由”parse.tab.c”生成，和”scan.o”由”scan.c”生成，而”foo”由”parse.tab.o”和”scan.o”链接生成， 而且foo和其[.o]文件的依赖关系也写好，那么，所有的目标都会得到满足） 9.5.3 自动化变量在上述的模式规则中，目标和依赖文件都是一系例的文件，那么我们如何书写一个命令来完成从不同的依赖文件生成相应的目标？因为在每一次的对模式规则的解析时，都会是不同的目标和依赖文件。 自动化变量就是完成这个功能的。在前面，我们已经对自动化变量有所提涉，相信你看到这里已对它有一个感性认识了。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，直至所有的符合模式的文件都取完了。这种自动化变量只应出现在规则的命令中。 下面是所有的自动化变量及其说明： $@:表示规则中的目标文件集。在模式规则中，如果有多个目标，那么，”$@”就是匹配于目标中模式定义的集合。 $%:仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是”foo.a(bar.o)”，那么，&quot;$%&quot;就是”bar.o”，”$@”就是”foo.a”。如果目标不是函数库文件（Unix下是[.a]，Windows下是[.lib]），那么，其值为空。 $&lt;:依赖目标中的第一个目标名字。如果依赖目标是以模式（即”%”）定义的，那么”$&lt;”将是符合模式的一系列的文件集。注意，其是一个一个取出来的。 $?: 所有比目标新的依赖目标的集合。以空格分隔。 $^: 所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那个这个变量会去除重复的依赖目标，只保留一份。 $+:这个变量很像”$^”，也是所有依赖目标的集合。只是它不去除重复的依赖目标。 $*:这个变量表示目标模式中”%”及其之前的部分。如果目标是”dir/a.foo.b”，并且目标的模式是”a.%.b”，那么，&quot;$*&quot;的值就是&quot;dir /a.foo“。这个变量对于构造有关联的文件名是比较有较。如果目标中没有模式的定义，那么&quot;$*“也就不能被推导出，但是，如果目标文件的后缀是 make所识别的，那么&quot;$*&quot;就是除了后缀的那一部分。例如：如果目标是”foo.c”，因为”.c”是make所能识别的后缀名，所以，&quot;$*&quot;的值就是”foo”。这个特性是GNU make的，很有可能不兼容于其它版本的make，所以，你应该尽量避免使用&quot;$*&quot;，除非是在隐含规则或是静态模式中。如果目标中的后缀是make所不能识别的，那么&quot;$*&quot;就是空值。当你希望只对更新过的依赖文件进行操作时，&quot;$?&quot;在显式规则中很有用，例如，假设有一个函数库文件叫”lib”，其由其它几个object文件更新。那么把object文件打包的比较有效率的Makefile规则是：lib : foo.o bar.o lose.o win.o ar r lib $? 在上述所列出来的自动量变量中。四个变量（$@、$&lt;、$%、$*）在扩展时只会有一个文件，而另三个的值是一个文件列表。这七个自动化变量还可以取得文件的目录名或是在当前目录下的符合模式的文件名，只需要搭配上”D”或”F”字样。这是GNU make中老版本的特性，在新版本中，我们使用函数”dir”或”notdir”就可以做到了。”D”的含义就是Directory，就是目录，”F”的含义就是File，就是文件。 下面是对于上面的七个变量分别加上”D”或是”F”的含义： $(@D):表示”$@”的目录部分（不以斜杠作为结尾），如果”$@”值是”dir/foo.o”，那么&quot;$(@D)&quot;就是”dir”，而如果”$@”中没有包含斜杠的话，其值就是”.”（当前目录）。 $(@F):表示”$@”的文件部分，如果”$@”值是”dir/foo.o”，那么&quot;$(@F)&quot;就是”foo.o”，&quot;$(@F)&quot;相当于函数”$(notdir $@)”。 &quot;$(*D)&quot; &quot;$(*F)&quot;:和上面所述的同理，也是取文件的目录部分和文件部分。对于上面的那个例子，&quot;$(*D)&quot;返回”dir”，而&quot;$(*F)&quot;返回”foo” &quot;$(%D)&quot; &quot;$(%F)&quot;:分别表示了函数包文件成员的目录部分和文件部分。这对于形同”archive(member)”形式的目标中的”member”中包含了不同的目录很有用。 &quot;$(&lt;D)&quot; &quot;$(&lt;F)&quot;:分别表示依赖文件的目录部分和文件部分。 &quot;$(^D)&quot; &quot;$(^F)&quot;:分别表示所有依赖文件的目录部分和文件部分。（无相同的） &quot;$(+D)&quot; &quot;$(+F)&quot;:分别表示所有依赖文件的目录部分和文件部分。（可以有相同的） &quot;$(?D)&quot; &quot;$(?F)&quot;:分别表示被更新的依赖文件的目录部分和文件部分。 最后想提醒一下的是，对于&quot;$&lt;&quot;，为了避免产生不必要的麻烦，我们最好给$后面的那个特定字符都加上圆括号，比如，&quot;$(&lt; )&quot;就要比&quot;$&lt;&quot;要好一些。 还得要注意的是，这些变量只使用在规则的命令中，而且一般都是”显式规则”和”静态模式规则”（参见前面”书写规则”一章）。其在隐含规则中并没有意义。 9.5.4 模式的匹配一般来说，一个目标的模式有一个有前缀或是后缀的”%”，或是没有前后缀，直接就是一个”%”。因为”%”代表一个或多个字符，所以在定义好了的模式中，我们把”%”所匹配的内容叫做”茎”，例如”%.c”所匹配的文件”test.c”中”test”就是”茎”。因为在目标和依赖目标中同时有”%”时，依赖目标的”茎”会传给目标，当做目标中的”茎”。 当一个模式匹配包含有斜杠（实际也不经常包含）的文件时，那么在进行模式匹配时，目录部分会首先被移开，然后进行匹配，成功后，再把目录加回去。在进行”茎”的传递时，我们需要知道这个步骤。例如有一个模式”e%t”，文件”src/eat” 匹配于该模式，于是”src/a”就是其”茎”，如果这个模式定义在依赖目标中，而被依赖于这个模式的目标中又有个模式”c%r”，那么，目标就是”src/car”。（”茎”被传递） 9.5.5 重载内建隐含规则你可以重载内建的隐含规则（或是定义一个全新的），例如你可以重新构造和内建隐含规则不同的命令，如： 12%.o : %.c$(CC) -c $(CPPFLAGS) $(CFLAGS) -D$(date) 你可以取消内建的隐含规则，只要不在后面写命令就行。如： 1%.o : %.s 同样，你也可以重新定义一个全新的隐含规则，其在隐含规则中的位置取决于你在哪里写下这个规则。朝前的位置就靠前。 9.6 老式风格的”后缀规则”后缀规则是一个比较老式的定义隐含规则的方法。后缀规则 会被 模式规则 逐步地取代。因为模式规则更强更清晰。为了和老版本的Makefile兼容，GNU make同样兼容于这些东西。后缀规则有两种方式：”双后缀”和”单后缀”。 双后缀规则定义了一对后缀：目标文件的后缀和依赖目标（源文件）的后缀。如”.c.o”相当于”%o : %c”。单后缀规则只定义一个后缀，也就是源文件的后缀。如”.c”相当于”% : %.c”。 后缀规则中所定义的后缀应该是make所认识的，如果一个后缀是make所认识的，那么这个规则就是单后缀规则，而如果两个连在一起的后缀都被make所认识，那就是双后缀规则。例如：”.c”和”.o”都是make所知道。因而，如果你定义了一个规则是”.c.o”那么其就是双后缀规则，意义就是”.c” 是源文件的后缀，”.o”是目标文件的后缀。如下示例： 12.c.o:$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 后缀规则不允许任何的依赖文件，如果有依赖文件的话，那就不是后缀规则，那些后缀统统被认为是文件名，如： 12.c.o: foo.h$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 这个例子，就是说，文件”.c.o”依赖于文件”foo.h”，而不是我们想要的这样： 12%.o: %.c foo.h$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 后缀规则中，如果没有命令，那是毫无意义的。因为他也不会移去内建的隐含规则。 而要让make知道一些特定的后缀，我们可以使用伪目标&quot;.SUFFIXES&quot;来定义或是删除，如： 1.SUFFIXES: .hack .win 把后缀.hack和.win加入后缀列表中的末尾。 12.SUFFIXES: # 删除默认的后缀.SUFFIXES: .c .o .h # 定义自己的后缀 先清楚默认后缀，后定义自己的后缀列表。 make的参数”-r”或”-no-builtin-rules”也会使用得默认的后缀列表为空。而变量”SUFFIXE”被用来定义默认的后缀列表，你可以用”.SUFFIXES”来改变后缀列表，但请不要改变变量”SUFFIXE”的值。 9.7 隐含规则搜索算法比如我们有一个目标叫 T。下面是搜索目标T的规则的算法。请注意，在下面，我们没有提到后缀规则，原因是，所有的后缀规则在Makefile被载入内存时，会被转换成模式规则。如果目标是”archive(member)”的函数库文件模式，那么这个算法会被运行两次，第一次是找目标T，如果没有找到的话，那么进入第二次，第二次会把”member”当作T来搜索。 把T的目录部分分离出来。叫D，而剩余部分叫N。（如：如果T是”src/foo.o”，那么，D就是”src/“，N就是”foo.o”） 创建所有匹配于T或是N的模式规则列表。 如果在模式规则列表中有匹配所有文件的模式，如”%”，那么从列表中移除其它的模式。 移除列表中没有命令的规则。 对于第一个在列表中的模式规则： 推导其”茎”S，S应该是T或是N匹配于模式中”%”非空的部分。 计算依赖文件。把依赖文件中的”%”都替换成”茎”S。如果目标模式中没有包含斜框字符，而把D加在第一个依赖文件的开头。 测试是否所有的依赖文件都存在或是理当存在。（如果有一个文件被定义成另外一个规则的目标文件，或者是一个显式规则的依赖文件，那么这个文件就叫”理当存在”） 如果所有的依赖文件存在或是理当存在，或是就没有依赖文件。那么这条规则将被采用，退出该算法。 如果经过第5步，没有模式规则被找到，那么就做更进一步的搜索。对于存在于列表中的第一个模式规则： 如果规则是终止规则，那就忽略它，继续下一条模式规则。 计算依赖文件。（同第5步） 测试所有的依赖文件是否存在或是理当存在。 对于不存在的依赖文件，递归调用这个算法查找他是否可以被隐含规则找到。 如果所有的依赖文件存在或是理当存在，或是就根本没有依赖文件。那么这条规则被采用，退出该算法。 如果没有隐含规则可以使用，查看”.DEFAULT”规则，如果有，采用，把”.DEFAULT”的命令给T使用。 一旦规则被找到，就会执行其相当的命令，而此时，我们的自动化变量的值才会生成。 10. 使用make更新函数库文件函数库文件也就是对Object文件（程序编译的中间文件）的打包文件。在Unix下，一般是由命令”ar”来完成打包工作。 10.1 函数库文件的成员一个函数库文件由多个文件组成。你可以以如下格式指定函数库文件及其组成： 1archive(member) 这个不是一个命令，而一个目标和依赖的定义。一般来说，这种用法基本上就是为了”ar”命令来服务的。如： 12foolib(hack.o) : hack.oar cr foolib hack.o 如果要指定多个member，那就以空格分开，如： 1foolib(hack.o kludge.o) 其等价于： 1foolib(hack.o) foolib(kludge.o) 你还可以使用Shell的文件通配符来定义，如： 1foolib(*.o) 10.2 函数库成员的隐含规则当 make搜索一个目标的隐含规则时，一个特殊的特性是，如果这个目标是”a(m)”形式的，其会把目标变成”(m)”。于是，如果我们的成员是”%.o” 的模式定义，并且如果我们使用”make foo.a(bar.o)”的形式调用Makefile时，隐含规则会去找”bar.o”的规则，如果没有定义bar.o的规则，那么内建隐含规则生效，make会去找bar.c文件来生成bar.o，如果找得到的话，make执行的命令大致如下： 123cc -c bar.c -o bar.oar r foo.a bar.orm -f bar.o 还有一个变量要注意的是”$%”，这是专属函数库文件的自动化变量，有关其说明请参见”自动化变量”一节。 10.3 函数库文件的后缀规则你可以使用”后缀规则”和”隐含规则”来生成函数库打包文件，如： 1234.c.a:$(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o$(AR) r $@ $*.o$(RM) $*.o 其等效于： 1234(%.o) : %.c$(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o$(AR) r $@ $*.o$(RM) $*.o 10.4 注意事项在进行函数库打包文件生成时，请小心使用make的并行机制（”-j”参数）。如果多个ar命令在同一时间运行在同一个函数库打包文件上，就很有可以损坏这个函数库文件。所以，在make未来的版本中，应该提供一种机制来避免并行操作发生在函数打包文件上。 但就目前而言，你还是应该不要尽量不要使用”-j”参数。 该篇文章为转载，是对原作者系列文章的总汇加上标注。 支持原创，请移步陈浩大神博客： http://blog.csdn.net/haoel/article/details/2886]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile语法]]></title>
    <url>%2F2017%2F09%2F30%2Ftips-makefile%2F</url>
    <content type="text"><![CDATA[一个自定义模式规则示例1234567891011121314151617181920212223242526272829303132CC=gccSRCPATH=srcOUTPATH=objsSRCS_TEST_SORT=$(SRCPATH)/Common.c \ $(SRCPATH)/XSort.c\ $(SRCPATH)/Test_Sort.c#OBJS_TEST_SORT=$(SRCS_TEST_SORT:.c=.o)OBJS_TEST_SORT=$(patsubst src/%.c,$(OUTPATH)/%.o,$(SRCS_TEST_SORT))EXERC_TEST_SORT=TestSortSRCS_TEST_LIST=$(SRCPATH)/Common.c \ $(SRCPATH)/alist.c\ $(SRCPATH)/llist.c\ $(SRCPATH)/sllist.c\ $(SRCPATH)/linkedlist.c\ $(SRCPATH)/Test_List.c\ $(SRCPATH)/polynomial.c#OBJS_TEST_LIST=$(SRCS_TEST_LIST:.c=.o)OBJS_TEST_LIST=$(patsubst src/%.c,$(OUTPATH)/%.o,$(SRCS_TEST_LIST))EXERC_TEST_LIST=TestListstart:$(OBJS_TEST_SORT) $(OBJS_TEST_LIST) $(CC) -o $(EXERC_TEST_SORT) $(OBJS_TEST_SORT) $(CC) -o $(EXERC_TEST_LIST) $(OBJS_TEST_LIST) @echo ---------------SUCCESS----------------$(OUTPATH)/%.o:src/%.c $(CC) -g -fstack-protector -fstack-protector-all -o $@ -c $&lt;clean: rm -rf $(OBJS_TEST_SORT) $(EXERC_TEST_SORT) rm -rf $(OBJS_TEST_LIST) $(EXEC_TEST_LIST) 使用VPATH设置搜索路径VPATH = path1:path2:...,make 会自动找到指定文件的目录并添加到文件上 可以指定文件输入/输出路径,OBJS_TEST_SORT=$(SRCS_TEST_SORT:.c=.o)使用源文件集合推到编译输出文件名,当源文件增加路径后,如src/Common.c后,输出路径也变为src/Common.o,不是需要的bin/Common.o,使用函数patsubst替换输出文件集合中文件路径. 使用模式匹配%.o:%.c替换后缀规则.c.o: patsubst ( patten substitude,匹配替换的缩写)函数。它需要3个参数——第一个是一个需要匹配的式样，第二个表示用什么来替换它，第三个是一个需要处理由空格分隔的序列。我们将两个函数合起来用：objects := $(patsubst %.c,%.o,$(wildcard *.c))会被处理为: objects := a.o b.o同理： executables := $(patsubst %.c,%,$(wildcard *.c))会被处理为： executables := a b.%o：所有以“.o”结尾的目标，也就是如Common.o alist.o等,依赖模式“%.c”：取模式“%.o”的%Common alist，并为其加上.c后缀，即Common.c，alist.c $&lt;：表示所有依赖目标集，也就是Common.c alist.c,$@：表示目标集，也就是Common.o alist.o.命令前加@，表示在终端中不打印，如@mkdir -p ./bin makefile之隐含规则和模式规则Makefile有很多灵活的写法，可以写得更简洁，同时减少出错的可能。本节我们来看看这样一个例子还有哪些改进的余地。 一个目标依赖的所有条件不一定非得写在一条规则中，也可以拆开写，例如： 1234main.o: main.h stack.h maze.h main.o: main.c gcc-c main.c 就相当于： 12main.o: main.c main.h stack.h maze.h gcc-c main.c 如果一个目标拆开写多条规则，其中只有一条规则允许有命令列表，其它规则应该没有命令列表，否则make会报警告并且采用最后一条规则的命令列表。 这样我们的例子可以改写成： 1234567891011121314151617181920main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o: main.h stack.h maze.h stack.o: stack.h main.h maze.o: maze.h main.h main.o: main.c gcc-c main.c stack.o: stack.c gcc-c stack.c maze.o: maze.c gcc-c maze.c clean: -rmmain *.o .PHONY: clean 这不是比原来更繁琐了吗？现在可以把提出来的三条规则删去，写成： 1234567891011main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o: main.h stack.h maze.h stack.o: stack.h main.h maze.o: maze.h main.h clean: -rmmain *.o .PHONY: clean 这就比原来简单多了。可是现在main.o、stack.o和maze.o这三个目标连编译命令都没有了，怎么编译的呢？试试看： 12345$ make cc -c -o main.o main.c cc -c -o stack.o stack.c cc -c -o maze.o maze.c gcc main.o stack.o maze.o -o main 现在解释一下前三条编译命令是怎么来。如果一个目标在Makefile中的所有规则都没有命令列表，make会尝试在内建的隐含规则（Implicit Rule）数据库中查找适用的规则。make的隐含规则数据库可以用make -p命令打印，打印出来的格式也是Makefile的格式，包括很多变量和规则，其中和我们这个例子有关的隐含规则有： 123456789101112# default OUTPUT_OPTION = -o $@ # default CC = cc # default COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS)$(TARGET_ARCH) -c %.o: %.c # commands to execute (built-in): $(COMPILE.c) $(OUTPUT_OPTION) $&lt; #号在Makefile中表示单行注释，就像C语言的//注释一样。CC是一个Makefile变量，用CC = cc定义和赋值，用$(CC)取它的值，其值应该是cc。Makefile变量像C的宏定义一样，代表一串字符，在取值的地方展开。cc是一个符号链接，通常指向gcc，在有些UNIX系统上可能指向另外一种C编译器。 CFLAGS这个变量没有定义，$(CFLAGS)展开是空，CPPFLAGS和TARGET_ARCH也是如此。这样$(COMPILE.c)展开应该是cc 空 空 空 -c，去掉“空”得到cc -c，注意中间留下4个空格，所以%.o:%.c规则的命令$(COMPILE.c) $(OUTPUT_OPTION) $&lt;展开之后是cc -c -o $@$&lt;，和上面的编译命令已经很接近了。 $@和$&lt;是两个特殊的变量，$@的取值为规则中的目标，$&lt;的取值为规则中的第一个条件。%.o: %.c是一种特殊的规则，称为模式规则（Pattern Rule）。现在回顾一下整个过程，在我们的Makefile中以main.o为目标的规则都没有命令列表，所以make会查找隐含规则，发现隐含规则中有这样一条模式规则适用，main.o符合%.o的模式，现在%就代表main（称为main.o这个名字的Stem），再替换到%.c中就是main.c。所以这条模式规则相当于： 12main.o: main.c cc -c -o main.o main.c 随后，在处理stack.o目标时又用到这条模式规则，这时又相当于： 12stack.o: stack.c cc -c -o stack.o stack.c maze.o也同样处理。这三条规则可以由make的隐含规则推导出来，所以不必写在Makefile中。 先前我们写Makefile都是以目标为中心，一个目标依赖于若干条件，现在换个角度，以条件为中心，Makefile还可以这么写： 1234567891011main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o stack.o maze.o: main.h main.o maze.o: maze.h main.o stack.o: stack.h clean: -rmmain *.o .PHONY: clean 我们知道，写规则的目的是让make建立依赖关系图，不管怎么写，只要把所有的依赖关系都描述清楚了就行。对于多目标的规则，make会拆成几条单目标的规则来处理，例如 12target1 target2: prerequisite1prerequisite2 command$&lt; -o $@ 这样一条规则相当于： 123456target1: prerequisite1 prerequisite2 commandprerequisite1 -o target1 target2: prerequisite1 prerequisite2 commandprerequisite1 -o target2 注意两条规则的命令列表是一样的，但$@的取值不同。 Linux Makefile与shell脚本区别在Makefile可以调用shell脚本，但是Makefile和shell脚本是不同的。本文试着归纳一下Makefile和shell脚本的不同。 1. shell中所有引用以$打头的变量其后要加{},而在Makefile中的变量是以$打头的后加()。实例如下： 123456Makefile:PATH=&quot;/data/&quot;SUBPATH=$(PATH)Shell:PATH=&quot;/data/&quot;SUBPATH=$&#123;PATH&#125; 2. Makefile中所有以$打头的单词都会被解释成Makefile中的变量。如果你需要调用shell中的变量（或者正则表达式中锚定句位$），都需要加两个$符号（$$）。 Makfile实例如下： 1234PATH=&quot;/data/&quot;all: echo $&#123;PATH&#125; echo $$PATH 例子中的第一个${PATH}引用的是Makefile中的变量，而不是shell中的PATH环境变量，后者引用的是Shell中的PATH环境变量。 ####3. 通配符区别 shell 中通配符*表示所有的字符 Makefile 中通配符%表示所有的字符 ####4. 在Makefile中只能在target中调用Shell脚本，其他地方是不能输出的。比如如下代码就是没有任何输出： 1234VAR=&quot;Hello&quot;echo &quot;$VAR&quot; all: ..... 以上代码任何时候都不会输出，而且还会报错，如下：Makefile:*** command commence before first target.Stop,因为没有在target内。如果上述代码改为如下： 1234VAR=&quot;Hello&quot;all: echo &quot;$VAR&quot; ..... 以上代码，在make all的时候将会执行echo命令，同时必须注意echo &quot;$VAR&quot;之前必须有一个table，这样Makefile才会认为其为一条command，如果没有table会报错如下：Makefile:*** missing separator.Stop. ####5. 在Makefile中执行shell命令，一行创建一个进程来执行。 这也是为什么很多Makefile中有很多行的末尾都是“; \”，以此来保证代码是一行而不是多行，这样Makefile可以在一个进程中执行，例如： 123456SUBDIR=src exampleall: @for subdir in $(SUBDIR); \ do\ echo &quot;building &quot;; \ done 上述可以看出for循环中每行都是以”; \”结尾的。 ####6. 获取当前目录 1PATH=`pwd` 注意是``,不是&apos;&apos; ####7. shell总=两边不允许有空格，Makfile中=两边允许有空格。]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell开发使用小技巧]]></title>
    <url>%2F2017%2F09%2F30%2Ftips-shell-language%2F</url>
    <content type="text"><![CDATA[写脚本修改数据库中表的某一字段值12345678910111213141516171819202122###########################################################修改表TBL_BAT_TASK_CTL的USE_FLAG字段，启动或停止贷记卡销卡的批处理#useage：执行脚本时加-n参数就是关闭批处理# 执行脚本时加-y参数就是打开批处理###########################################################!/bin/bashif test &quot;$1&quot; = &quot;-n&quot;then db2 connect to $DBLINK db2 &quot;update TBL_BAT_TASK_CTL set USE_FLAG=&apos;N&apos; where BAT_ID=&apos;0024&apos; or BAT_ID=&apos;0025&apos;&quot; db2 terminate# exit 0fiif test &quot;$1&quot; = &quot;-y&quot;then db2 connect to $DBLINK db2 &quot;update TBL_BAT_TASK_CTL set USE_FLAG=&apos;Y&apos; where BAT_ID=&apos;0024&apos; or BAT_ID=&apos;0025&apos;&quot; db2 terminatefi]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>tips</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv核心类型]]></title>
    <url>%2F2017%2F09%2F29%2Fopencv-core%2F</url>
    <content type="text"><![CDATA[matMat替代lplImage 创建和清理mat空间 Mat mat(3000, 4000, CV_8UC3);//3000行,4000列数组,数组里存放3个unsigned char类型的数据 mat.create(rows, cols, CV_8UC1);//行数,列数,如果mat已经有空间,create时会自动清理已有空间 release或者析构:引用计数为1时释放 处理类型一定要用unsigned char而不是char 3*3RGB图像存放方式(连续) isContinuous 判断存储空间是否连续 通过step记录 直接地址访问连续空间1234567int size = mat.rows*mat.cols*mat.elemSize();for(int i = 0; i&lt; size; i+3)//3是因为RGB&#123; mat.data[i] = 0; //B mat.data[i+1] = 0; //G mat.data[i+2] = 0; //R&#125; //优化编码后效率高13ms (4000*3000) 直接地址访问不连续空间123456789for(int i = 0; i &lt; mat.row; i++)&#123; for(int j = 0; j &lt; mat.cols; j++) &#123; (&amp;mat.data[i*mat.step])[j*3] = 255;//B (&amp;mat.data[i*mat.step])[j*3 + 1] = 255;//G (&amp;mat.data[i*mat.step])[j*3 + 2] = 1;//R &#125;&#125; 通过ptr接口遍历Mat(模板函数) 性能基本等同与地址访问 mat.ptr(row);//返回的指针 mat.ptr(row, col); 通过at接口遍历Mat(模板函数) 接口最简单的遍历方法123mat.at&lt;Vec3b&gt;(row, col)[0] = 255;mat.at&lt;Vec3b&gt;(row, col)[1] = 0;mat.at&lt;Vec3b&gt;(row, col)[2] = 0; at可以使用try{} catch(…/cv::Exception &amp;ex){}捕获异常 通过迭代器遍历Mat 可以不用管mat的行列 auto it = mr.begin(); auto it_end = mr.end(); ROI感兴趣区域cv::Rect rect(100, 100, 300, 300); 像素格式和灰度图RGB, YUV, GRAY cvtColor(src, img, COLOR_BGR2GRAY);//源图像,目标凸显,转换方式,利用多线程等方式提高效率 自己实现转换: Gray = (R30 + G59 + B*11 + 50)/100 二值化和阈值 THRESH_BINARY 二进制阈值化 THRESH_BINARY_INV 反二进制阈值化 改变图片的对比度和亮度g(i,j) = a*f(i,j) + b a 1.0~3.0(对比) b 0~100(亮度) saturate_cast防止移除函数 图像尺寸调整 INTER_NEAREST 近邻算法(最快) 1234567891011int sx, sy = 0;//原图对应的坐标float fy = float(src.rows)/out.rows;float fx = float(src.cols)/out.cols;for(int y = 0; y&lt; out.rows;y++)&#123; sy = fy*y + 0.5;//+0.5四舍五入 for(int x = 0; x &lt; out.cols;x++)&#123; sx = fx*x + 0.5; out.at&lt;Vec3b&gt;(y,x) = src.at&lt;Vec3b&gt;(sy, sx); &#125;&#125; CV_INTER_LINEAR 双线程差值(缺省使用) 滤波: 输入图像中像素的小领域来产生输出图像的方法,在信号处理中,这种方法称为滤波(filtering).其中,最常用的是线性滤波:输出像素是输入领域像素的加权和. 双线性内插值: 是由源图像位置在它附近的2*2区域4个邻近像素的值通过加权平均计算得出的. 低通滤波性质,使高频分量受损,图像轮廓可能会有一点模糊. 图像金字塔高斯金字塔(Gaussian pyramid):用来向下采样 获取G(i+1)将G(i)与高斯内核卷积 将所有偶数行和列去除 - 拉普拉斯金字塔(Laplacian pyramid):用来从金字塔底层图像重建上层未采样图像 用来从金字塔底层图像重建上层未采样图像 首先,将图像扩大两杯,新增以0填充 高斯内核(乘以4)与放大后的图像卷积 两幅图像混合(blending) dst = src1*a + src2*(1-a) + gamma//gamma增益 a=[0~1] 画面叠化(cross-dissolve)效果 addWeighted(src1, a, src2, 1-a, 0.0, dst);//两幅图像大小需一致 图像旋转和镜像 cv::rotate(src, dst, type); ROTATE_180 ROTATE_90_CLOCKWISE ROTATE_90_COUNTERCLOCKWISE cv::flip(src,dst, type);//镜像type 0(x), 1(y), -1 ###通过ROI图像合并 打开摄像头接口说明和源码分析 VideoCapture bool open(int index) VideoCapture cap(index) open(int cameraNum, int apiPrefrence) 打开视频流文件 bool open(const String &amp;filename) VideoCapture cap(const String &amp;file) bool open(const String &amp;filename, int apiPrefrence) 关闭和空间释放 ~VideoCapture release 读取一帧视频read(OutputArray image); bool grab() 读取并解码 virtual bool retrieve(OUtputArray , intflag= 0):图像色彩转换 vc&gt;&gt;mat 获取视频,相机属性 CAP_PROP_FPS帧率 CAP_PROP_FRAME_COUNT 总帧数 CAP_PROP_POS_FRAMES 播放帧的位置 CAP_PROP_FRAME_WIDTH HEIGHT VideoWriter open(const String &amp;filename, int fourcc, //VideoWrite::fourcc(‘H’, ‘2’, ‘6’, ‘4’) double fps, Size frameSize,bool isColor=true) release void write(const Mat&amp;) cvVideoWriter_FFMPEG::writeFrame]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv开发环境搭建]]></title>
    <url>%2F2017%2F09%2F29%2Fopencv-env%2F</url>
    <content type="text"><![CDATA[从github下载opencv最新源码https://github.com/opencv/opencv,目前最新是`5e93c8202363a13fc72df30f8c14069c5ab66e42`. Ubuntu环境下编译安装依赖库: 123456789sudo apt-get install build-essentialsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-devgit clone https://github.com/opencv/opencv.gitsudo apt-get install cmake-gui Mac环境下编译进入源码路径,新建一个release的文件夹,并进入,执行: 123cmake -G &quot;Unix Makefiles&quot; ..makesudo make install 编译完成后会在release生成lib目录,lib下存放所有编译成的动态库,可能与ubuntu下编译结果不同,ubuntu下编译只生成libopencv_world.so一个动态库,而mac下会生成opencv_core opencv_highgui opencv_imgproc opencv_ml opencv_objdetect opencv_photo opencv_video opencv_dnn opencv_imgcodecs opencv_shape等多个动态库.执行make install后会将头文件拷贝到/usr/local/include/下,将动态库拷贝到/usr/local/lib/下,将jar包等其他文件拷贝到/usr/local/share/OpenCV/下,makefile脚本加入动态链接库: 12testopencv:main.cpp g++ $+ -o $@ -lopencv_core -lopencv_highgui -lopencv_imgproc -lopencv_ml -lopencv_objdetect -lopencv_photo -lopencv_video -lopencv_dnn -lopencv_imgcodecs -lopencv_shape main.cpp下输入下面测试代码: 123456789101112#include &lt;opencv2/core.hpp&gt;#include &lt;opencv2/imgcodecs.hpp&gt;#include &lt;opencv2/highgui.hpp&gt;using namespace cv;int main(int argc, char *argv[])&#123; Mat image = imread(&quot;1.png&quot;); namedWindow(&quot;img&quot;); imshow(&quot;img&quot;, image); waitKey(0); return 0;&#125; 在生成的执行文件同目录下放入名字为1.png的图片. 配置QT环境在新建的QT工程中的.pro文件中添加如下配置代码: 1234567INCLUDEPATH += /usr/local/includeINCLUDEPATH += /usr/local/include/opencvINCLUDEPATH += /usr/local/include/opencv2LIBS += -L/usr/local/lib \ -lopencv_core \ -lopencv_highgui \ -lopencv_imgproc \ 完成以上步骤后按理应该是能成功的，但是运行时发现会出现如下的错误。 1234dyld: Symbol not found: __cg_jpeg_resync_to_restartReferenced from: /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIOExpected in: /usr/local/lib/libjpeg.8.dylibin /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO 针对以上问题,在项目-运行配置中,增加变量DYLD_LIBRARY_PATH值为/Application/QT5.7.0/5.7/clang_64/lib:/usr/local/lib qt+opencv常见问题在Mac上运行以上代码时，提示以下错误： 1234dyld: Symbol not found: __cg_jpeg_resync_to_restart Referenced from: /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO Expected in: /usr/local/lib/libJPEG.dylib in /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO 解决办法是将“”目录下的对应动态链接库文件创建软连接到“/usr/local/lib”目录下： 12345$ pwd/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources$ sudo ln -sf libJPEG.dylib /usr/local/lib/libJPEG.dylib$ sudo ln -sf libPng.dylib /usr/local/lib/libPng.dylib$ sudo ln -sf libTIFF.dylib /usr/local/lib/libTIFF.dylib]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tips-android]]></title>
    <url>%2F2017%2F09%2F27%2Ftips-android%2F</url>
    <content type="text"><![CDATA[1.使用Glide库提取视频帧图片加载框架Glide就可以做到获取本地视频的缩略图(不能获取网络视频文件): 12345String filePath = &quot;/storage/emulated/0/Pictures/example_video.mp4&quot;;Glide .with( context ) .load( Uri.fromFile( new File( filePath ) ) ) .into( imageViewGifAsBitmap );]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于QT QAudioOutput push模式问题]]></title>
    <url>%2F2017%2F09%2F13%2Ftips-qt-audiooutput%2F</url>
    <content type="text"><![CDATA[在MAC上基于QT和ffmpeg实现最简单播放器,在完成声音播放模块后导致无法正常播放,QAudioOutput start后state仍是idel,将QAudioOutput buffer写满后就不能继续写数据了,导致播放被卡死. QAudioOutput创建代码: 12345678910111213141516171819QAudioFormat fmt;fmt.setSampleRate(this-&gt;sampleRate);fmt.setSampleSize(this-&gt;sampleSize);fmt.setChannelCount(this-&gt;channel);fmt.setCodec(&quot;audio/pcm&quot;);fmt.setByteOrder(QAudioFormat::LittleEndian);fmt.setSampleType(QAudioFormat::UnSignedInt);QAudioDeviceInfo info = QAudioDeviceInfo::defaultOutputDevice();printf(&quot;deviceName:%s\n&quot;,qPrintable(info.deviceName()));if (!info.isFormatSupported(fmt)) &#123; printf(&quot;default format not supported try to use nearest\n&quot;); fmt = info.nearestFormat(fmt);&#125;output = new QAudioOutput(fmt);//connect(output, SIGNAL(stateChanged(QAudio::State)), this, SLOT(handleStateChanged(QAudio::State)));io = output-&gt;start();printf(&quot;io:%p\n&quot;, io);//printf(&quot;state:%s&quot;,output-&gt;state());QAudio::State stat = output-&gt;state(); 在stackoverflow Qt QAudioOutput push mode看到别人的问题和解释,发现是setSampleType引起的,代码在window上可以正常跑,只是在mac上失败. 问题I’ve got a question about using QAudioOutput to directly write samples at a specific sample rate to the sound output device. I’m writing an emulator that emualates sound chips on a per-frame basis, and then gets a buffer containing a frame’s worth of audio samples, which I would like to write to the audio output. Currently, to test my audio output routine, I allocate a huge (5 minute) buffer to put random numbers into, like so: Header: 1234uint16_t *audio_outputBuffer;uint32_t audio_bytesRemainingToRead;QAudioOutput *audio_outputStream;QIODevice *audio_outputDevice; Implementation: 12345678910audio_outputBuffer = (uint16_t *) malloc((96000 * 4) * 300);int i = 0;uint16_t *tempAudioBuffer = audio_outputBuffer;for(i = 0; i &lt; ((96000 * 4) * 150); i++) &#123; *tempAudioBuffer = (uint16_t) rand() &amp; 0xFFFF; tempAudioBuffer++;&#125;audio_bytesRemainingToRead = (96000 * 4) * 300; Next, I set up my audio device with some basic parameters: 1234567891011121314151617// Set up the formatQAudioFormat format;format.setFrequency(96000); // Usually this is specified through an UI optionformat.setChannels(2);format.setSampleSize(16);format.setCodec(&quot;audio/pcm&quot;);format.setByteOrder(QAudioFormat::LittleEndian);format.setSampleType(QAudioFormat::UnSignedInt);// There&apos;s code here to notify the user of inability to match the format and choose an action, which is omitted for clarity// Create audio output stream, set up signalsaudio_outputStream = new QAudioOutput(format, this);connect(audio_outputStream, SIGNAL(stateChanged(QAudio::State)), this, SLOT(audio_stateChanged(QAudio::State)));audio_outputDevice = audio_outputStream-&gt;start(); Then, in my timer tick routine, which is called by a QTimer at 60 FPS, I do the following code to write a ‘chunk’ of audio data to the QAudioOutput’s buffer: 123456if(audio_outputDevice-&gt;isOpen() &amp;&amp; audio_outputStream-&gt;state() != QAudio::StoppedState) &#123; qint64 bytesOfAudioWrittenToDevice = audio_outputDevice-&gt;write((char *) audio_outputBuffer, audio_outputStream-&gt;periodSize()); audio_bytesRemainingToRead -= bytesOfAudioWrittenToDevice; qDebug() &lt;&lt; &quot;Wrote&quot; &lt;&lt; bytesOfAudioWrittenToDevice &lt;&lt; &quot;bytes of audio to output device. Remaining bytes to read:&quot; &lt;&lt; audio_bytesRemainingToRead; qDebug() &lt;&lt; &quot;Free bytes in audio output:&quot; &lt;&lt; audio_outputStream-&gt;bytesFree();&#125; Once I start the audio output process, I get the following output on the console: 12345678910Current audio state: 3 Error: 0Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115197952Free bytes in audio output: 6144Current audio state: 0 Error: 0Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115195904Free bytes in audio output: 4096Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115193856Free bytes in audio output: 2048Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115191808Free bytes in audio output: 0 (This and the above line is repeated forever) To me, it looks like QAudioOutput isn’t flushing it’s internal buffer to the sound card, which goes along with the entire “no sound coming out of my computer” thing. What would cause this issue, and how could I fix it? (By the way, I’m compiling my code against Qt 4.8.1, on Mac OS X 10.7.4.) Thanks for any answers. 解释Upfront just wanna point out: This is not a Qt bug. Why? The answer is that in the WAV spec’, 8-bit samples are always unsigned, whereas 16-bit samples are always signed. Any other combination does not work. This is device related, the framework can not do anything about it. So this will not work because you have set 16 bit sample size and unsigned integer format. And yes, the solution is: you have to set the sample type to signed for 16-bit resolution: 1format.setSampleType(QAudioFormat::SignedInt); Inversely for 8-bit samples you would have to put: 1format.setSampleType(QAudioFormat:UnsignedInt); Also this very similar question (same problem but with 8-bit) shows you that it is not a particular problem of using signed or unsigned samples in Qt, but that it is the combination of samples size and type that matters (for the audio device, not for Qt ;) QAudioOutput in Qt5 is not producing any sound IMHO the fact that Qt does not take care of handling these cases by forcing the correct format is a flaw but not a lack in functionnality. You can learn more about this in the notes section of this page: https://ccrma.stanford.edu/courses/422/projects/WaveFormat/ I’ve figured this out — apparently Qt has issues with UNSIGNED samples. If you set the sample type to signed, everything works fine, regardless of platform.]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>QT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG api使用流程]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-arch%2F</url>
    <content type="text"><![CDATA[ffmpeg接口使用流程比较固定: av_register_all():注册所有模块 int ret = avformat_open_input(&amp;ic, ofn, 0, 0);:获取AVFormatContext ic(ofn为输入文件地址) for(i = 0; i &lt; ic-&gt;nb_streams; i++):遍历AVFormatContext中所有stream,分别找到Audio与Video对应的AVCodecContext; AVCodec *codec = avcodec_find_decoder(enc-&gt;codec_id);:根据AVCodecContext中codec_id获取到AVCodec; avcodec_open2(enc, codec,NULL):打开AVCodec; 接下来分配AVPacket与AVFrame]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG编解码]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-codec%2F</url>
    <content type="text"><![CDATA[解码ffmpeg3版本的解码接口做了调整,之前的视频解码接口avcodec_decode_video2和音频解码接口avcodec_decode_audio4被设置为deprecated,对这两个接口做了合并,使用同一的接口.并且将音视频解码步骤分成了两步,第一步avcodec_send_packet,第二步avcodec_receive_frame, 旧版本avcodec_decode_video2旧版本avcodec_decode_audio4123456789101112int got_picture; ret = avcodec_decode_audio4(enc, pcm,&amp;got_picture, pkt); if ( ret &lt; 0 ) &#123; char buf[1024] = &#123;0&#125;; av_strerror(err, buf, sizeof(buf)); printf(buf); printf(&quot;avcodec_decode_audio4 failed:%d&quot; ,got_picture); av_packet_unref(pkt); av_frame_free(&amp;pcm); if(ic) avformat_close_input(&amp;ic); return -1; &#125; 将AVPacket的pkt解码成AVFrame的pcm 新版本avcodec_send_packet接口源码:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Supply raw packet data as input to a decoder. * * Internally, this call will copy relevant AVCodecContext fields, which can * influence decoding per-packet, and apply them when the packet is actually * decoded. (For example AVCodecContext.skip_frame, which might direct the * decoder to drop the frame contained by the packet sent with this function.) * * @warning The input buffer, avpkt-&gt;data must be AV_INPUT_BUFFER_PADDING_SIZE * larger than the actual read bytes because some optimized bitstream * readers read 32 or 64 bits at once and could read over the end. * * @warning Do not mix this API with the legacy API (like avcodec_decode_video2()) * on the same AVCodecContext. It will return unexpected results now * or in future libavcodec versions. * * @note The AVCodecContext MUST have been opened with @ref avcodec_open2() * before packets may be fed to the decoder. * * @param avctx codec context * @param[in] avpkt The input AVPacket. Usually, this will be a single video * frame, or several complete audio frames. * Ownership of the packet remains with the caller, and the * decoder will not write to the packet. The decoder may create * a reference to the packet data (or copy it if the packet is * not reference-counted). * Unlike with older APIs, the packet is always fully consumed, * and if it contains multiple frames (e.g. some audio codecs), * will require you to call avcodec_receive_frame() multiple * times afterwards before you can send a new packet. * It can be NULL (or an AVPacket with data set to NULL and * size set to 0); in this case, it is considered a flush * packet, which signals the end of the stream. Sending the * first flush packet will return success. Subsequent ones are * unnecessary and will return AVERROR_EOF. If the decoder * still has frames buffered, it will return them after sending * a flush packet. * * @return 0 on success, otherwise negative error code: * AVERROR(EAGAIN): input is not accepted right now - the packet must be * resent after trying to read output * AVERROR_EOF: the decoder has been flushed, and no new packets can * be sent to it (also returned if more than 1 flush * packet is sent) * AVERROR(EINVAL): codec not opened, it is an encoder, or requires flush * AVERROR(ENOMEM): failed to add packet to internal queue, or similar * other errors: legitimate decoding errors */int avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt); 参数分析 AVCodecContext *avctx：第一个参数与旧的接口一致，是视频解码的上下文，包含解码器。 const AVPacket *avpkt： 编码的音视频帧数据 为什么要传递空的avpkt 这里有一个说明是可以传递NULL，什么情况下需要传递NULL，你平时看一些视频播放器，播放经常会少最后几帧，很多情况就是因为没有处理好缓冲帧的问题，ffmpeg内部会缓冲几帧，要想取出来就需要传递空的AVPacket进去。 新版本avcodec_receive_frame接口源码12345678910111213141516171819/** * Return decoded output data from a decoder. * * @param avctx codec context * @param frame This will be set to a reference-counted video or audio * frame (depending on the decoder type) allocated by the * decoder. Note that the function will always call * av_frame_unref(frame) before doing anything else. * * @return * 0: success, a frame was returned * AVERROR(EAGAIN): output is not available right now - user must try * to send new input * AVERROR_EOF: the decoder has been fully flushed, and there will be * no more output frames * AVERROR(EINVAL): codec not opened, or it is an encoder * other negative values: legitimate decoding errors */int avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame); 参数分析 AVCodecContext *avctx：第一个参数视频解码的上下文，与上面接口一致。 AVFrame *frame：解码后的视频帧数据。 空间申请和释放问题解码后图像空间由函数内部申请，你所做的只需要分配 AVFrame 对象空间，如果你每次调用avcodec_receive_frame传递同一个对象，接口内部会判断空间是否已经分配，如果没有分配会在函数内部分配。 avcodec_send_packet和avcodec_receive_frame调用关系并不一定是一对一的，比如一些音频数据一个AVPacket中包含了1秒钟的音频，调用一次avcodec_send_packet之后，可能需要调用25次 avcodec_receive_frame才能获取全部的解码音频数据，所以要做如下处理： 12345678910int re = avcodec_send_packet(codec, pkt);if (re != 0)&#123; return;&#125;while( avcodec_receive_frame(codec, frame) == 0)&#123; //读取到一帧音频或者视频 //处理解码后音视频 frame&#125; 参考 send/receive encoding and decoding API overview]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG工具方法]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-util%2F</url>
    <content type="text"><![CDATA[av_strerror1234int av_strerror ( int errnum,char * errbuf,size_t errbuf_size) ffmpeg获取与设置mp4文件旋转方向方法设置与获取都是对AVStream的dict操作. 设置 1234567891011121314151617181920212223242526272829for (i = 0; i &lt; ifmt_ctx_v-&gt;nb_streams; i++) &#123; //Create output AVStream according to input AVStream if(ifmt_ctx_v-&gt;streams[i]-&gt;codec-&gt;codec_type==AVMEDIA_TYPE_VIDEO)&#123; AVStream *in_stream = ifmt_ctx_v-&gt;streams[i]; AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream-&gt;codec-&gt;codec); videoindex_v=i; if (!out_stream) &#123; printf( &quot;Failed allocating output stream\n&quot;); ret = AVERROR_UNKNOWN; goto end; &#125; videoindex_out=out_stream-&gt;index; //Copy the settings of AVCodecContext ret = av_dict_set(&amp;out_stream-&gt;metadata,&quot;rotate&quot;,&quot;90&quot;,0); //设置旋转角度 if(ret&gt;=0) &#123; printf(&quot;=========yes=====set rotate success!===\n&quot;); &#125; if (avcodec_copy_context(out_stream-&gt;codec, in_stream-&gt;codec) &lt; 0) &#123; printf( &quot;Failed to copy context from input to output stream codec context\n&quot;); goto end; &#125; out_stream-&gt;codec-&gt;codec_tag = 0; if (ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER) out_stream-&gt;codec-&gt;flags |= CODEC_FLAG_GLOBAL_HEADER; break; &#125; &#125; 读取 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647for (i = 0; i &lt; ifmt_ctx_v-&gt;nb_streams; i++) &#123; //Create output AVStream according to input AVStream if(ifmt_ctx_v-&gt;streams[i]-&gt;codec-&gt;codec_type==AVMEDIA_TYPE_VIDEO)&#123; AVStream *in_stream = ifmt_ctx_v-&gt;streams[i]; AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream-&gt;codec-&gt;codec); videoindex_v=i; if (!out_stream) &#123; printf( &quot;Failed allocating output stream\n&quot;); ret = AVERROR_UNKNOWN; goto end; &#125; videoindex_out=out_stream-&gt;index; //Copy the settings of AVCodecContext ret = av_dict_set(&amp;out_stream-&gt;metadata,&quot;rotate&quot;,&quot;90&quot;,0); //设置旋转角度 if(ret&gt;=0) &#123; printf(&quot;=========yes=====set rotate success!===\n&quot;); &#125; if (avcodec_copy_context(out_stream-&gt;codec, in_stream-&gt;codec) &lt; 0) &#123; printf( &quot;Failed to copy context from input to output stream codec context\n&quot;); goto end; &#125; out_stream-&gt;codec-&gt;codec_tag = 0; if (ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER) out_stream-&gt;codec-&gt;flags |= CODEC_FLAG_GLOBAL_HEADER; break; &#125; &#125; double g_rotate_theta = get_rotation(decoder-&gt;is_video);//is_video是video的AVStream int rotate = 0; if (fabs(g_rotate_theta - 90) &lt; 1.0) &#123; rotate = 90; &#125; else if(fabs(g_rotate_theta - 180) &lt; 1.0||fabs(g_rotate_theta + 180) &lt; 1.0) &#123; rotate = 180; &#125; else if(fabs(g_rotate_theta - 270) &lt; 1.0||fabs(g_rotate_theta + 90) &lt; 1.0) &#123; rotate = 270; &#125; LOGI(&quot;get rotate is : %d&quot; , rotate); metadata-&gt;rotate = rotate;]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音视频参数之Profile]]></title>
    <url>%2F2017%2F09%2F12%2Ftips-media-profile%2F</url>
    <content type="text"><![CDATA[前两天发现公司产品 触发 有导入从微信等下载的外部小视频时失败的情况, 触发 导入视频时使用开源库media-for-mobile对视频进行重新编码.media-for-mobile使用android系统接口android.media.MediaExtractor对mp4文件解复用,使用android硬件编解码接口android.media.MediaCodec对视频解码-处理-编码操作,最后通过Android系统APIandroid.media.MediaMuxer将视频写成文件. 反馈的两个有问题视频,一个视频导入时报BufferOverFlowException错误,另一个视频不报错但是导入时进度一直为0%. 经分析出问题的两个视频的Video profile为High,普通视频为Baseline,报BufferOverFlowException错误的视频的Audio profile为HE-AAC,普通视频的Audio profile为LC. 详细了解了一下H264 与AAC profile: H264各种profile作为行业标准，H.264编码体系定义了4种不同的Profile(类)：Baseline(基线类),Main(主要类), Extended(扩展类)和High Profile(高端类)（它们各自下分成许多个层）： Baseline Profile: 提供I/P帧，仅支持progressive(逐行扫描)和CAVLC； Extended Profile: 提供I/P/B/SP/SI帧，仅支持progressive(逐行扫描)和CAVLC； Main Profile: 提供I/P/B帧，支持progressive(逐行扫描)和interlaced(隔行扫描)，提供CAVLC或CABAC； High Profile: （也就是FRExt）在Main Profile基础上新增：8x8 intra prediction(8x8 帧内预测), custom quant(自定义量化), lossless video coding(无损视频编码), 更多的yuv格式（4:4:4…）； H.264在高清中具有最小体积。在同等图像质量下，采用H.264技术压缩后的数据量只有MPEG2的1/8，MPEG4的1/3，相对Xvid、Divx等属于MPEG4编码而言，其体积优势明显，在互联网上，H.264资源处在爆发趋势。而High Profile是H.264解码中的高端类型，拥有最完善的支持程度、最优秀的特性，可以说是高清视频编码中的劳斯莱斯，只有征服了这个优秀的编码，MP4才能将H.264完全掌控，也才能充分享受到高清视频带来的视觉震撼，意义非凡。 针对当前高清是视频会议行业的主流发展趋势，而目前高清普及的主要阻力之一就是带宽的限制。而High Profile H.264技术在同等视频质量的情况下可节省50%的带宽，为客户节省大量的网络带宽成本。据业内专家介绍，此次H.264 High Profile的推出是视频技术的一个巨大进步，其意义不亚于2003年从H.263向H.264过渡的价值。它将为目前正在推广的高清视频通信应用扫清了令人头疼的网络带宽障碍，不仅如此，这些变化对于包括CIF、标清等品质的视频通信应用也同样适用。 鉴于High Profile H.264对于视频会议行业的非凡影响，目前已有国内外厂商尝鲜，宣布其旗下产品全面支持该项技术，包括宝利通、华平、华腾网讯。从这一趋势来看，未来视频会议产品全面支持High Profile H.264也经成为不可逆转的潮流，而高清普及也在技术层面更近了一步。 参考: H264 各种profile AAC各种profileAAC历史如果说目前H.264是视频CODEC的实际霸主，那么AAC就是音频CODEC的女王。主流的音视频格式都是H.264搭配AAC，无论是非实时的媒体文件还是实时的媒体流。 Advanced Audio Coding (AAC) 是一个有损压缩的音频编码集（其实新的编码工具也支持无损）。其设计目标是替代原有MP3编码标准，在与MP3在相似的码率下希望质量优于MP3。这一目标已达到并且由ISO和IEC标准组织标准化在MPEG-2和MPEG-4中。 AAC已被广泛支持并应用到各种设备和系统中 YouTube, iPhone, iPod, iPad, Nintendo DSi, Nintendo 3DS, iTunes,DivX Plus Web Player and PlayStation 3. It is supported on PlayStation Vita,Wii (with the Photo Channel 1.1 update installed), Sony Walkman MP3 series andlater, Android and BlackBerry等等。 1997年，AAC第一次出现在标准MPEG-2 Part 7,（ISO/IEC 13818-7:1997）。和视频CODEC标准类似，AAC在MPEG-2 Part 7就有三个profiles他们分别是。 Low-Complexity profile(AAC-LC / LC-AAC) Main profile (AAC Main) Scalable Sampling Rateprofile (AAC-SSR) 从此可知AAC-LC出现最早，所以AAC-LC的应用最广泛，兼容性最好。 1999年, AAC从原有标准升级并且合入标准MPEG-4Part 3（ISO/IEC14496-3:1999） 这次升级一个重要变化是引入 Audio Object Types(AOT) 并且把AOT概念合并到profiles中。这时profile也变成4个。 Main (which includes most of the MPEG-4 Audio Object Types) Scalable (AAC LC, AAC LTP, CELP, HVXC, TwinVQ, Wavetable Synthesis,TTSI), Speech (CELP, HVXC, TTSI) Low Rate Synthesis (Wavetable Synthesis, TTSI)合成语音。 2000年，版本更新到2，MPEG-4 AudioVersion 2 (ISO/IEC 14496-3:1999/Amd 1:2000)，标准定义了一种新的AOT, 低时延AAC，the low delay AAC(AAC-LD)。 2001年，标准化High-Efficiency Advanced Audio Coding (HE-AAC) ISO/IEC 14496-3:2001。 2003年，标准化HE-AAC v2 Profile (AAC LC with SBR and Parametric Stereo) ISO/IEC14496-3:2005 目前AAC的标准化的版本是 ISO/IEC 14496-3:2009。 从上面标准化历史可知，AAC不在一单纯的一个编码器了，而是一个庞大的音频编码工具集合。 AOT(Audio Object Types)AOT就是MPEG-4 Audio Object Types的缩写。能力集协商时用的是AOT ID。 也正是由于AAC的AOT繁多，导致识别使用AAC的用户很困扰。 AAC-LC 可认为是AOT为2的AAC。 下表是AOT的对应表。 object type ID Audio Object Type z description 0 Null 1 AAC Main 1999 contains AACLC 2 AAC LC (Low Complexity) 1999 used in the “AAC Profile”.MPEG-4 AAC LC Audio Object Type is based on the MPEG-2 Part7 Low Complexity profile(LC)combined with Perceptual Noise Subsitution(PNS)(define in MPEG-4 part 3 Subpart 4) 3 AAC SSR (Scalable Sample Rate) 1999 Mpeg4 AAC SSR Audio Object Type is based on the MPEG-2 Parg 7 Scalable Sampling Rate profile(SSR)combined with Perceptual Noise Subsitution(PNS)(defined in MPEG-4 Parg 3 Subpart 4) 4 AAC LTP (Long Term Prediction) 1999 contains AAC LC 5 SBR (Spectral Band Replication) 2003 used with AAC LC in the “High Efficiency AAC Profile”(HE-AAC v1) 6 AAC Scalable 1999 7 TwinVQ 1999 audio coding at very low bitrates 8 CELP (Code Excited Linear Prediction) 1999 speech coding 9 HXVC (Harmonic Vector eXcitation Coding) speech coding 10 Reserved 11 Reserved 12 TTSI (Text-To-Speech Interface) 13 Main Synthesis 14 Wavetable Synthesis 15 General MIDI 16 Algorithmic Synthesis and Audio Effects 17 ER (Error Resilient) AAC LC 18 Reserved 19 ER AAC LTP 20 ER AAC Scalable 21 ER TwinVQ 22 ER BSAC (Bit-Sliced Arithmetic Coding) 23 ER AAC LD (Low Delay) 24 ER CELP 25 ER HVXC 26 ER HILN (Harmonic and Individual Lines plus Noise) 27 ER Parametric 28 SSC (SinuSoidal Coding) 29 PS (Parametric Stereo) 30 MPEG Surround 31 (Escape value) 32 Layer-1 33 Layer-2 34 Layer-3 35 DST (Direct Stream Transfer) 36 ALS (Audio Lossless) 37 SLS (Scalable LosslesS) 38 SLS non-core 39 ER AAC ELD (Enhanced Low Delay) 40 SMR (Symbolic Music Representation) Simple 41 SMR Main 42 USAC (Unified Speech and Audio Coding) (no SBR) 43 SAOC (Spatial Audio Object Coding) 44 LD MPEG Surround 45 USAC MPEG-4 Audio Profile MPEG-4在音频编码方向对音频能力集合的描述称为Audio Profiles，音频能力描述基于AOT MPEG-2 AAC LC: Advanced Audio Coding Low-Complexity，(AAC-LC / LC-AAC)格式是MPEG-2格式，设计用于数字电视。AAC-LC用于存储空间和计算能力有限的情况。这种类型没有使用预测和增益控制这两种工具，瞬时噪声整形的阶数也比较低。 AAC-LC是充分利用心理声学原理，对人类对音频信号的感知存在不相干性和统计冗余的特性，最大程度的减少用于表达信号的比特数据 ，实现音频信号快速有效地压缩，而不再追求输出信号和原始信号相似度。 AAC-LC的重要技术点有如下一些。 Temporal Noise Shaping：瞬时噪声整形是用来控制量化噪声的瞬时形态，解决掩蔽阈值和量化噪声的错误匹配的问题。TNS利用时频对偶性，即时域平稳的信号会在频域上变比剧烈，而频域平稳的信号会在时域上变化剧烈。对时域的瞬态信号可以对频谱系数进行预测编码。对频谱系数进行预测，可以及时调节量化器以适应输入信号的时域状态，可以有效的控制量化噪声， Intensity Stereo：利用心理声学原理提高编码效率的一种方法。由于人耳对高频信号的相位不敏感，只要信号的能量和频谱相似，在感知上没有什么区别，所以当一对声道的信号相关性较高时，可以对高频部分进行一定的处理，只在一个声道中编码传输数据，而不会影响解码后的重建音质。 AAC-LC把6kHz作为声强立体声处理的起始频率，在这个频率上的都进行声强立体声处理。计算出左右声道各个子带的能量和总能量，然后计算左声道能量和总能量的比值并换算成一个强度因子，按照这个强度因子对了带内的所有频谱进行左右声道求和并归一化，右声道的数据则全部置零，这样只需要对左声道数据进行量化编码。 Perceptual Noise Substitution：感知噪声替代用于频谱成分分类似噪声（功率谱密度是均匀的）时，用人造噪声代替。当判断某个频带需要进行感知噪声替代后，只用把该频带的能量作为参数编码传输，而不需要对子带内的频谱值进行编码，解码时解出子带能量和随机矢量生成函数产生的类似噪声。 Middle/Side：立体声编码，是利用一对声道的信号之间的相关性去冗余，降低编码比特率的方法。AAC-LD编码器中对左右声道的数据相关性较大时，可以用Middle=（L+R）/ 2，Side = (L-R)/2来代替左右声道的数据进行编码。这样能量集中在一个声道数据中，而另外一个声道只要少量比特数据，这样实现了数据压缩。 MPEG-2 AAC Main: 主规格 MPEG-2 AAC SSR: 可变采样率规格（Scaleable Sample Rate） MPEG-4 AAC LC: 低复杂度规格（Low Complexity）——现在的手机比较常见的MP4文件中的音频部份就包括了该规格音频文件 MPEG-4 AAC Main: 主规格 ——包含了除增益控制之外的全部功能，其音质最好 MPEG-4 AAC SSR: 可变采样率规格（Scaleable Sample Rate） MPEG-4 AAC LTP: 长时期预测规格（Long Term Predicition） MPEG-4 AAC LD: AAC是感知型音频编解码器，可以在较低的比特率下提供很高质量的主观音质。但是这样的编解码器在低比特率下的算法延时往往超过100ms，所以并不适合实时的双向通信。而基于G.722的语音编解码方案因为其较小的算法延时而适合于双向通信。但是这种基于语音的编解码方案只能针对语音信号提供较好的主观质量，并不适合更为复杂的音频信号，而且即使在很高的比特率下，该编解码方案给出的结果也很难达到良好的音质。 常用的感知音频编码器的延时包括： Framing delay：进行块变换需要的块长； Filterbank delay：分析-综合滤波器所需要的延时； Look-ahead delay for block switching：块切换为检测瞬态而需要的延时； Use of bit reservoir：比特池大小相对于平均比特率所需要的延时。 总延时计算公式： 如下面的AAC-LC为例： 在AAC-LD中，为了减少延时，将原来的1024的帧长改为512；没有了窗切换功能，减少了为进行窗切换所需要的前瞻延时；同时为了增强对瞬态信号的编码质量，引入了窗型切换机制，窗型包括一般的SINE窗和一个少重叠的窗，该窗与后面的窗有很少的重叠，这样通过对TNS工具的优化来消除瞬态信号产生的预回声效应。 MPEG-4 Low Delay Audio Coder (AAC-LD)是直接源于MPEG-2 AAC，并且结合了感知音频编码和双向通信必须的低延时要求。它可以保证最大的20ms的算法延时和包括语音和音乐的信号的很好的音质。现在的MPEG-4 AAC LD支持最大采样率48kHz，最大声道数目是2（可以扩展为多声道）。 MPEG-4 AAC HE: 高效率规格（High Efficiency）—–这种规格适合用于低码率编码，有Nero ACC 编码器支持 14496-3标准，里面定义的profile除了上述的一些规格，还有如Scalable 、 TwinVQ、 CELP、 HVXC等更多其他的profile。 目前听到用的比较多的应该是LC和HE(适合低码率)。流行的Nero AAC的命令行编码程序就支持LC，HE，HEv2这三种，试用后，用MediaInfo分析了编码后的AAC音频，发现规格显示都是LC，当时就感到奇怪，不是说支持三种规格吗？然后才又查资料发现，原来HE其实就是AAC（LC）+SBR技术，HEv2就是AAC（LC）+SBR+PS技术，难怪用MediaInfo分析后，HE规格的文件即显示: 123格式简介:LC格式设置,SBR:是格式设置,PS:否 关于HE与HEv2 HE：“high efficiency”（高效性）。HE-AAC v1（又称AACPlusV1，SBR)用容器的方法加了原AAC（LC）+SBR技术。SBR其实代表的是Spectral Band Replication(频段复制)。简单概括一下，音乐的主要频谱集中在低频段，高频段幅度很小（但很重要，决定了音质），如果对整个频段编码，要么为了保护高频造成低频段编码过细以致文件巨大，要么为了保存了低频的主要成分而失去高频成分以致丧失音质。SBR把频谱切割开来，低频单独编码保存主要成分，高频单独放大编码保存音质，“统筹兼顾”了，在减少文件大小的情况下还保存了音质，完美的化解了一对矛盾 HEv2 它用容器的方法包含了HE-AAC v1和PS技术。PS指“parametric stereo”（参数立体声）。这个其实好理解，原来的立体声文件，文件大小是一个声道的两倍。但是两个声道的声音存在某种相似性，根据香农信息熵编码定理，相关性应该被去掉才能减小文件大小。所以PS技术存储了一个声道的全部信息，然后，花很少的字节用参数描述另一个声道和它不同的地方 这样，HEv1和HEv2用个图简单表示下就是：(图中的AAC即指的是原来的AAC-LC) 由于NERO AAC编码后产生的是经过MP4容器封装后的，而我们的decoder需要处理的是未经封装的AAC流，因此还需要处理从MP4封装格式中extract出AAC流的步骤；哦，这里提到了MP4容器封装，就再把我看到的一些关于MP4容器的心得插入在此也说下： 其实.mp4格式规范是MPEG4 Part 1标准定义的。但是这个格式本身相当通用，并不是只能用来存贮MPEG4视频格式。举个例子，一个.mp4文件中包含的可能是H.263的视频轨及AMR的音频轨。这样它和MPEG4视频压缩算法就半点边都沾不上。但它绝对是一个合法的.mp4文件。从这个意义上讲，.mp4是一个独立的封包格式。也许它的原始设计意图是仅用于MPEG4，但事实上大家觉得它很好用，已经把它扩展成可以包容其它格式了。现在市场上比如某产品号称“支持MP4播放”，到底是什么意思呢？如果它是指可以播放.mp4这种文件，那里面的音频和视频格式它能支持多少种组合呢？没说清楚吧。举个极端的例子，假设一台设备仅支持“视频为未压缩YUV以及不带音频轨的.mp4文件，但它的文件名确实可以是.mp4，是不是也可以在盒子上印上“支持MP4”呢？那么，买回去，复制一个网上下载的.mp4文件（MPEG4视频和AAC音频应该是个比较流行的组合），结果却发现根本不能播放。就算不举这么极端的例子，一般.mp4文件中常见的视频音频格式也有多种，一个产品要做到支持所有的格式是很难的。所以，如果要准确的描述，应该写清楚类似“支持视频格式为MPEG4或H.264/AVC，音频为AMR或AAC的*.mp4文件”。其实更严格一些，还应该写清楚MPEG4支持到哪种profile, AMR是NB还是WB，AAC是LC还是HE等更多细节。当然，这种误导型的说明应该在减少，不过如果有比较确切的格式需求，最好还是先搞清楚这些细节。看到网上还有人说到N73，其实只支持视频为MPEG4 Simple Profile / Advanced Simple Profile及H.263 Profile 0 &amp; 3，音频为AMR-NB/WB或者AAC-LC, HE-AAC的mp4文件。如果你放一个视频格式为H.264/AVC的mp4上去，是无法播放出画面来的。 在网上找了一些工具，如MP4UI,MP4BOX,Yamb(mp4box的GUI程序),采用它们进行extract操作后发现，原来的SBR和PS等信息咋没有了，都变成LC规格的AAC文件啦。好容易准备的测试流，难道还是不能用？于是一番苦寻发现，可能是SBR和PS等信息在ADTS头中是无法体现的，所以分析ADTS格式头的AAC，就无法判别是否是HE和HEv2啦。但是我总觉得SBR和PS等技术信息在AAC流中应该还是存在的。因为我还在一个国外的论坛上看到这么几句话：There’s no requirement for MP4 with AAC to have SBR indicated in the headers. It’s still correct not to have it marked and have SBR or PS data in the stream anyway. Likewise, decoding a frame and not seeing any SBR or PS info doesn’t mean you can’t find it further up in the stream anyway（我理解就是说SBR OR PS信息不一定在Header中有，但是并不意味着你不能进一步在stream中发现它）。 HE-AAC的.mp4码流，经过extract出AAC(ADTS)后，44.1KHZ的变成了22.05KHZ。HEv2-AAC的.mp4码流，经过extract出AAC(ADTS)后，不但44.1KHZ的变成了22.05KHZ(一半)，连2channels也变成了1channels，这个问题更奇怪了，在论坛上找，发现也有人有此问题：“I get 22050Hz, 1 channel for audio that is in fact 44100Hz, 2channels and having both SBR and PS”。 后来看到MSDN中的AAC Decoder的描述中有这么一小段话： The media type gives the sample rate and number of channels prior to the application of spectral band replication (SBR) and parametric stereo (PS) tools, if present. The effect of the SBR tool is to double the decoded sample rate relative to the core AAC-LC sample rate. The effect of the PS tool is to decode stereo from a mono-channel core AAC-LC stream. 我的理解是AAC的decoder如果支持SBR和PS，会将AAC-HEV1(SBR)中的sample rate提高一倍，而会将AAC-HEV2(SBR+PS)中不仅sample rate提高一倍，单声道也提高至双声道了。结合前面提到的SBR(频段复制)和PS(参数立体声）技术的简单介绍，好像觉得这样是有点儿道理的哦~~ 用IPP example提供的解码工具simple_player简单试了下，对于44.1khz，stereo的HEv2-AAC的.mp4码流，经过extract出22.05KHZ，mono 的AAC(ADTS)后，再使用simple_player进行音频解码测试，解完后，果然发现又恢复了44.1khz和stereo。（但目前也测试了好几种extract出的HE和HEv2的aac码流，有的能将sample rate和channel 又double回来，有的又不能，这个具体原因是不是由于Ipp example提供的解码器的问题还不确定）。 另外，用simple_player如果直接decoder编码出的经过封装的.mp4格式的AAC音频的话，发现：其它都正常，只AAC-HEv2格式的.mp4音频解码后变成了单声道。难道是解码器中的PS tools没能发挥作用？初步估计应该是IPP 的那个小解码器的问题吧。 AAC封装格式 以常用的两个格式为例: ADIF：Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。 ADTS：Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。 简单说，ADTS可以在任意帧解码，也就是说它每一帧都有头信息。ADIF只有一个统一的头，所以必须得到所有的数据后解码。且这两种的header的格式也是不同的，具体的组织结构在这里就不详说了。 参考: AAC的各种规格 AAC格式和M4A格式AAC（Advanced Audio Coding），中文称为“高级音频编码”，出现于1997年，基于 MPEG-2的音频编码技术。由Fraunhofer IIS、杜比实验室、AT&amp;T、Sony（索尼）等公司共同开发，目的是取代MP3格式。2000年，MPEG-4标准出现后，AAC 重新集成了其特性，加入了SBR技术和PS技术，为了区别于传统的 MPEG-2 AAC 又称为 MPEG-4 AAC。AAC编码的主要扩展名有三种： .AAC - 使用MPEG-2 Audio Transport Stream( ADTS，参见MPEG-2 )容器，区别于使用MPEG-4容器的MP4/M4A格式，属于传统的AAC编码（FAAC默认的封装，但FAAC亦可输出 MPEG-4 封装的AAC） .MP4 - 使用了MPEG-4 Part 14（第14部分）的简化版即3GPP Media Release 6 Basic (3gp6，参见3GP ) 进行封装的AAC编码（Nero AAC 编码器仅能输出MPEG-4封装的AAC）； .M4A - 为了区别纯音频MP4文件和包含视频的MP4文件而由苹果(Apple)公司使用的扩展名，Apple iTunes 对纯音频MP4文件采用了”.M4A”命名。M4A的本质和音频MP4相同，故音频MP4文件亦可直接更改扩展名为M4A。是 MPEG-4 Audio 标准容器，而 AAC 作为一个容器是 MPEG-2 标准的。现在的 AAC-LC 就是以前制定的 MPEG-2 时代的 AAC 的更名延续，而 MPEG-4 时代的 AAC 叫 AAC-HE .AAC-LC 可以用 AAC (ADTS) 作容器也可以用 MP4 做容器，两者可以用 MP4Box 的一个命令直接转换，而 AAC-HE 只能用 MP4 做容器。 Sampling FrequenciesThere are 13 supported frequencies: 0: 96000 Hz 1: 88200 Hz 2: 64000 Hz 3: 48000 Hz 4: 44100 Hz 5: 32000 Hz 6: 24000 Hz 7: 22050 Hz 8: 16000 Hz 9: 12000 Hz 10: 11025 Hz 11: 8000 Hz 12: 7350 Hz 13: Reserved 14: Reserved 15: frequency is written explictly Channel ConfigurationsThese are the channel configurations: 0: Defined in AOT Specifc Config 1: 1 channel: front-center 2: 2 channels: front-left, front-right 3: 3 channels: front-center, front-left, front-right 4: 4 channels: front-center, front-left, front-right, back-center 5: 5 channels: front-center, front-left, front-right, back-left, back-right 6: 6 channels: front-center, front-left, front-right, back-left, back-right, LFE-channel 7: 8 channels: front-center, front-left, front-right, side-left, side-right, back-left, back-right, LFE-channel 8-15: Reserved 术语说明 AAC: Advanced Audio Coding 高级音频编码 AAC LC: AAC with Low Complexity AAC的低复杂度配置 AAC plus: 也叫HE-AAC, AAC+,MPEG4 AAC LC加入SBR模块后形成的一个AAC版本 MPEG：Motion Picture Expert Group IMDCT：反离散余弦变换 ADIF：Audio Data Interchange Format 音频数据交换格式 ADTS：Audio Data Transport Stream 音频数据传输流 SCE: Single Channel Element单通道元素 CPE: Channel Pair Element 双通道元素 CCE: Coupling Channel Element 藕合通道元素 DSE: Data Stream Element 数据流元素 PCE: Program Config Element 程序配置元素 FIL: Fill Element 填充元素 ICS: Individual Channel Stream 独立通道流 PNS: Perceptual Noise Substitution 知觉噪声替换 SBR: Spectral Band Replication 频段复制 TNS: Temporal Noise Shaping 瞬时噪声整形 ch：channel 通道 最后AAC-LC 是什么格式？和 AAC 有什么区别？ AAC是标准化在MPEG2和MPEG4的音频编码集合的总称。 AAC-LC是标准化AAC中AOT为2的一种音频编解码，它的特点是运算复杂度低，对内存占用小，标准化的时间早，对通性好，兼容性好，使用广。不足是算法时延高，不利于实时的音频通讯。 问题原因分析首先BufferOverFlowException问题,由于音频采用AAC-HE导致MediaExtractor解析出的音频采样率为本身采样率的一半,同时创建出的解码OutputBuffer的大小是编码InputBuffer的2倍,而media-for-mobile开源项目直接将从解码器OutputBuffer取出的数据塞入编码器InputBuffer中,2倍的数据放入一倍的Buffer导致溢出,暂时的解决办法手动指定编码器InputBuffer max-size为一个较大值(10*1024).同时,由于MediaExtractor不能获取正确的audio profile,也无法确认获取到的采样率是否不正确采样率的一半,所以采用ffmpeg接口获取profile,但是ffmpeg调用avcodec_open2获取到的profile为-99,而且采样率依然为正常采样率一半,只有在解码一帧音频后才能得到正确的profile与采样率. 其次,转码进度不增加的问题,主要是High的H264视频,media-for-mobile使用一个MediaExtractor一次抽取音视频帧,如果是音频则交音频解码器,如果为视频则交视频解码器,解码后将解码帧转交编码器,编码后将数据写入MediaMuxer,将数据写入MediaMuxer的前提是吊用过addTrack,将音视频track加入到Muxer中,而addTrack需要在音视频解码若干帧后产生INFO_OUTPUT_FORMAT_CHANGED,若没有addTrack会导致编码后数据如法写入Muxer,卡死编码器,Baseline视频只需要少量帧就可以产生INFO_OUTPUT_FORMAT_CHANGED,但High视频产生INFO_OUTPUT_FORMAT_CHANGED需要更多的帧,而media-for-mobile中,MediaExtractor首先一直获取到的是音频数据,音频一直解码编码,但是输出的muxer时,videotrack未被添加,所以无法将音频编码器的数据写入muxer,音频解码器被卡死,而mediasource一直被产生的audio数据无法被消费,无法获取到视频数据导致视频INFO_OUTPUT_FORMAT_CHANGED一直无法产生,最终产生死锁,导致audio等待video的INFO_OUTPUT_FORMAT_CHANGED,video等待audio被读完后读到video解码产生INFO_OUTPUT_FORMAT_CHANGED. 最后将audio和video使用两个MediaExtractor各读取各自内容.]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试(一):UiAutomator官方介绍]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-start%2F</url>
    <content type="text"><![CDATA[了解android测试需要查询android官方文档,android官方培训教程Getting Started with Testing介绍了android提供的测试类型,测试接口等,相较与网上总结的android自动化测试框架,官方文档显然分类更合理,定位更准确. 两种测试类型在使用Android Studio创建模块时会在src下生成androidTest和test两个用于测试的的目录,对应下面两种测试类型. 本地单元测试(Local unit tests)位于module-name/src/test/java/.下,运行在PC端本地的JVM虚拟机上,并且不能访问Android框架的接口. 参考Building Local Tests 设备化测试位于module-name/src/androidTest/java/.下,必须运行在Android物理设备和虚拟机上. 参考Building Instrumented Unit Tests Instrumented unit tests are tests that run on physical devices and emulators, and they can take advantage of the Android framework APIs and supporting APIs, such as the Android Testing Support Library. You should create instrumented unit tests if your tests need access to instrumentation information (such as the target app’s Context) or if they require the real implementation of an Android framework component (such as a Parcelable or SharedPreferences object). Using instrumented unit tests also helps to reduce the effort required to write and maintain mock code. You are still free to use a mocking framework, if you choose, to simulate any dependency relationships. 设备化单元测试分为: 设备化单元测试(Instrumented Unit Test):Building Instrumented Unit Tests: Build complex unit tests with Android dependencies that cannot be satisfied with mock objects. 组件集成测试:Automating User Interface Tests: Create tests to verify that the user interface behaves correctly for user interactions within a single app or for interactions across multiple apps. app集成测试:Testing App Component Integrations: Verify the behavior of components that users do not directly interact with, such as a Service or aContent Provider.]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试(N):UiAutomator官方介绍]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-uiautomator-official%2F</url>
    <content type="text"><![CDATA[Automating User Interface TestsUser interface (UI) testing lets you ensure that your app meets its functional requirements and achieves a high standard of quality such that it is more likely to be successfully adopted by users. One approach to UI testing is to simply have a human tester perform a set of user operations on the target app and verify that it is behaving correctly. However, this manual approach can be time-consuming, tedious, and error-prone. A more efficient approach is to write your UI tests such that user actions are performed in an automated way. The automated approach allows you to run your tests quickly and reliably in a repeatable manner. Note: It is strongly encouraged that you use Android Studio for building your test apps, because it provides project setup, library inclusion, and packaging conveniences. This class assumes you are using Android Studio. To automate UI tests with Android Studio, you implement your test code in a separate Android test folder (src/androidTest/java). The Android Plug-in for Gradle builds a test app based on your test code, then loads the test app on the same device as the target app. In your test code, you can use UI testing frameworks to simulate user interactions on the target app, in order to perform testing tasks that cover specific usage scenarios. For testing Android apps, you typically create these types of automated UI tests: UI tests that span a single app: This type of test verifies that the target app behaves as expected when a user performs a specific action or enters a specific input in its activities. It allows you to check that the target app returns the correct UI output in response to user interactions in the app’s activities. UI testing frameworks like Espresso allow you to programmatically simulate user actions and test complex intra-app user interactions. UI tests that span multiple apps: This type of test verifies the correct behavior of interactions between different user apps or between user apps and system apps. For example, you might want to test that your camera app shares images correctly with a 3rd-party social media app, or with the default Android Photos app. UI testing frameworks that support cross-app interactions, such as UI Automator, allow you to create tests for such scenarios. The lessons in this class teach you how to use the tools and APIs in the Android Testing Support Library to build these types of automated tests. Before you begin building tests using these APIs, you must install the Android Testing Support Library, as described in Downloading the Android Testing Support Library. UI TestingIn addition to unit testing the individual components that make up your Android application (such as activities, services, and content providers), it is also important that you test the behavior of your application’s user interface (UI) when it is running on a device. UI testing ensures that your application returns the correct UI output in response to a sequence of user actions on a device, such as entering keyboard input or pressing toolbars, menus, dialogs, images, and other UI controls. Functional or black-box UI testing does not require testers to know the internal implementation details of the app, only its expected output when a user performs a specific action or enters a specific input. This approach allows for better separation of development and testing roles in your organization. One common approach to UI testing is to run tests manually and verify that the app is behaving as expected. However, this approach can be time-consuming, tedious, and error-prone. A more efficient and reliable approach is to automate the UI testing with a software testing framework. Automated testing involves creating programs to perform testing tasks (test cases) to cover specific usage scenarios, and then using the testing framework to run the test cases automatically and in a repeatable manner. Overviewhe Android SDK provides the following tools to support automated, functional UI testing on your application: uiautomatorviewer - A GUI tool to scan and analyze the UI components of an Android application. uiautomator - A Java library containing APIs to create customized functional UI tests, and an execution engine to automate and run the tests. To use these tools, you must have the following versions of the Android development tools installed: Android SDK Tools, Revision 21 or higher Android SDK Platform, API 16 or higher Workflow for the the uiautomator testing framework Here’s a short overview of the steps required to automate UI testing: Prepare to test by installing the app on a test device, analyzing the app’s UI components, and ensuring that your application is accessible by the test automation framework. Create automated tests to simulate specific user interactions on your application. Compile your test cases into a JAR file and install it on your test device along with your app. Run the tests and view the test results. Correct any bugs or defects discovered in testing. Analyzing Your Application’s UIBefore you start writing your test cases, it’s helpful to familiarize yourself with the UI components (including the views and controls) of the targeted application. You can use the uiautomatorviewer tool to take a snapshot of the foreground UI screen on any Android device that is connected to your development machine. The uiautomatorviewer tool provides a convenient visual interface to inspect the layout hierarchy and view the properties of the individual UI components that are displayed on the test device. Using this information, you can later create uiautomator tests with selector objects that target specific UI components to test. To analyze the UI components of the application that you want to test: Connect your Android device to your development machine. Open a terminal window and navigate to /tools/. Run the tool with this command: 1$ uiautomatorviewer To capture a screen for analysis, click the Device Screenshot button in the GUI of the uiautomatorviewer tool. Note: If you have more than one device connected, specify the device for screen capture by setting the ANDROID_SERIAL environment variable: a. Find the serial numbers for your connected devices by running this command: 123$ adb devices``` b. Set the ANDROID_SERIAL environment variable to select the device to test: #In Windows: set ANDROID_SERIAL= #In UNIX: export ANDROID_SERIAL= 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657If you are connected to only a single device, you do not need to set the ANDROID_SERIAL environment variable.5. View the UI properties for your application:- Hover over the snapshot in the left-hand panel to see the UI components identified by the uiautomatorviewer tool. You can view the component’s properties listed in the lower right-hand panel, and the layout hierarchy in the upper right-hand panel.- Optionally, click on the Toggle NAF Nodes button to see UI components that are not accessible to the uiautomator testing framework. Only limited information may be available for these components.#### Preparing to TestBefore using the uiautomator testing framework, complete these pre-flight tasks:##### Load the application to a deviceIf you are reading this document, chances are that the Android application that you want to test has not been published yet. If you have a copy of the APK file, you can install the APK onto a test device by using the adb tool. To learn how to install an APK file using the adb tool, see the [adb](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/adb.html#move) documentation.##### Identify the application’s UI componentsBefore writing your `uiautomator` tests, first identify the UI components in the application that you want to test. Typically, good candidates for testing are UI components that are visible and that users can interact with. The UI components should also have visible text labels, `android:contentDescription` values, or both.You can inspect the visible screen objects in an application conveniently by using the `uiautomatorviewer` tool. For more information about how to analyze an application screen with this tool, see the section [Analyzing Your Application’s UI](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/testing/testing_ui.html#uianalaysis). For more information about the common types of UI components provided by Android, see [User Interface](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/index.html).##### Ensure that the application is accessibleThis step is required because the `uiautomator` tool depends on the accessibility features of the Android framework to execute your functional UI tests. You should include these minimum optimizations to support the `uiautomator` tool:- Use the `android:contentDescription` attribute to label the `ImageButton`, `ImageView`, `CheckBox` and other user interface controls.- Provide an `android:hint` attribute instead of a content description for `EditText` fields- Associate an `android:hint` attribute with any graphical icons used by controls that provide feedback to the user (for example, status or state information).- Make sure that all the user interface elements are accessible with a directional controller, such as a trackball or D-pad.- Use the `uiautomatorviewer` tool to ensure that the UI component is accessible to the testing framework. You can also test the application by turning on accessibility services like TalkBack and Explore by Touch, and try using your application using only directional controls.For more information about implementing and testing accessibility, see [Making Applications Accessible](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/accessibility/apps.html).&gt; Note: To identify the non-accessible components in the UI, click on the Toggle NAF Nodes option in the `uiautomatorviewer` tool.Generally, Android application developers get accessibility support for free, courtesy of the `View` and `ViewGroup` classes. However, some applications use custom view components to provide a richer user experience. Such custom components won&apos;t get the accessibility support that is provided by the standard Android UI components. If this applies to your application, ensure that the application developer exposes the custom drawn UI components to Android accessibility services, by implementing the `AccessibilityNodeProvider` class. For more information about making custom view components accessible, see [Making Applications Accessible](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/accessibility/apps.html#custom-views).##### Configure your development environmentIf you&apos;re developing in Eclipse, the Android SDK provides additional tools that help you write test cases using `uiautomator` and buiild your JAR file. In order to set up Eclipse to assist you, you need to create a project that includes the `uiautomator` client library, along with the Android SDK library. To configure Eclipse:1. Create a new Java project in Eclipse, and give your project a name that is relevant to the tests you’re about to create (for example, &quot;MyAppNameTests&quot;). In the project, you will create the test cases that are specific to the application that you want to test.2. From the Project Explorer, right-click on the new project that you created, then select Properties &gt; Java Build Path, and do the following: - Click Add Library &gt; JUnit then select JUnit3 to add JUnit support. - Click Add External JARs... and navigate to the SDK directory. Under the platforms directory, select the latest SDK version and add both the uiautomator.jar and android.jar files.If you did not configure Eclipse as your development environment, make sure that the `uiautomator.jar` and `android.jar` files from the `&lt;android-sdk&gt;/platforms/&lt;sdk&gt;` directory are in your Java class path.Once you have completed these prerequisite tasks, you&apos;re almost ready to start creating your `uiautomator` tests.#### Creating uiautomator TestsTo build a test that runs in the `uiautomator` framework, create a test case that extends the `UiAutomatorTestCase` class. In Eclipse, the test case file goes under the `src` directory in your project. Later, you will build the test case as a JAR file, then copy this file to the test device. The test JAR file is not an APK file and resides separately from the application that you want to test on the device.Because the `UiAutomatorTestCase` class extends `junit.framework.TestCase`, you can use the `JUnit` Assert class to test that UI components in the app return the expected results. To learn more about JUnit, you can read the documentation on the `junit.org` home page.The first thing your test case should do is access the device that contains the target app. It’s also good practice to start the test from the Home screen of the device. From the Home screen (or some other starting location you’ve chosen in the target app), you can use the classes provided by the `uiautomator` API to simulate user actions and to test specific UI components. For an example of how to put together a `uiautomator` test case, see the sample test case.##### uiautomator APIThe `uiautomator` API is bundled in the `uiautomator.jar` file under the `&lt;android-sdk&gt;/platforms/` directory. The API includes these key classes that allow you to capture and manipulate UI components on the target app:- [UiDevice](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiDevice.html)Represents the device state. In your tests, you can call methods on the UiDevice instance to check for the state of various properties, such as current orientation or display size. Your tests also can use the UiDevice instance to perform device level actions, such as forcing the device into a specific rotation, pressing the d-pad hardware button, or pressing the Home and Menu buttons.To get an instance of UiDevice and simulate a Home button press: getUiDevice().pressHome(); 12- [UiSelector](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiSelector.html)Represents a search criteria to query and get a handle on specific elements in the currently displayed UI. If more than one matching element is found, the first matching element in the layout hierarchy is returned as the target UiObject. When constructing a UiSelector, you can chain together multiple properties to refine your search. If no matching UI element is found, a `UiAutomatorObjectNotFoundException` is thrown. You can use the childSelector() method to nest multiple UiSelector instances. For example, the following code example shows how to specify a search to find the first ListView in the currently displayed UI, then search within that ListView to find a UI element with the text property Apps. UiObject appItem = new UiObject(new UiSelector() .className(“android.widget.ListView”).instance(1) .childSelector(new UiSelector().text(“Apps”))); 1234- [UiObject](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiObject.html)Represents a UI element. To create a UiObject instance, use a UiSelector that describes how to search for, or select, the UI element.The following code example shows how to construct UiObject instances that represent a Cancel button and a OK button in your application. UiObject cancelButton = new UiObject(new UiSelector().text(“Cancel”)); UiObject okButton = new UiObject(new UiSelector().text(“OK”)); 12You can reuse the UiObject instances that you have created in other parts of your app testing, as needed. Note that the `uiautomator` test framework searches the current display for a match every time your test uses a UiObject instance to click on a UI element or query a property.In the following code example, the `uiautomator` test framework searches for a UI element with the text property OK. If a match is found and if the element is enabled, the framework simulates a user click action on the element. if(okButton.exists() &amp;&amp; okButton.isEnabled()) { okButton.click(); } 1You can also restrict the search to find only elements of a specific class. For example, to find matches of the Button class: UiObject cancelButton = new UiObject(new UiSelector().text(“Cancel”) .className(“android.widget.Button”)); UiObject okButton = new UiObject(new UiSelector().text(“OK”) .className(“android.widget.Button”)); 12- [UiCollection](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiCollection.html)Represents a collection of items, for example songs in a music album or a list of emails in an inbox. Similar to a UiObject, you construct a UiCollection instance by specifying a UiSelector. The UiSelector for a UiCollection should search for a UI element that is a container or wrapper of other child UI elements (such as a layout view that contains child UI elements). For example, the following code snippet shows how to construct a UiCollection to represent a video album that is displayed within a FrameLayout: UiCollection videos = new UiCollection(new UiSelector() .className(“android.widget.FrameLayout”)); 1If the videos are listed within a LinearLayout view, and you want to to retrieve the number of videos in this collection: int count = videos.getChildCount(new UiSelector() .className(“android.widget.LinearLayout”)); 1If you want to find a specific video that is labeled with the text element Cute Baby Laughing from the collection and simulate a user-click on the video: UiObject video = videos.getChildByText(new UiSelector() .className(“android.widget.LinearLayout”), “Cute Baby Laughing”); video.click(); 12Similarly, you can simulate other user actions on the UI object. For example, if you want to simulate selecting a checkbox that is associated with the video: UiObject checkBox = video.getChild(new UiSelector() .className(“android.widget.Checkbox”)); if(!checkBox.isSelected()) checkbox.click(); 123- [UiScrollable](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiScrollable.html)Represents a scrollable collection of UI elements. You can use the UiScrollable class to simulate vertical or horizontal scrolling across a display. This technique is helpful when a UI element is positioned off-screen and you need to scroll to bring it into view.For example, the following code shows how to simulate scrolling down the Settings menu and clicking on an About tablet option: UiScrollable settingsItem = new UiScrollable(new UiSelector() .className(“android.widget.ListView”)); UiObject about = settingsItem.getChildByText(new UiSelector() .className(“android.widget.LinearLayout”), “About tablet”); about.click() 1234For more information about these APIs, see the uiautomator reference.##### A sample uiautomator test caseThe following code example shows a simple test case which simulates a user bringing up the Settings app in a stock Android device. The test case mimics all the steps that a user would typically take to perform this task, including opening the Home screen, launching the All Apps screen, scrolling to the Settings app icon, and clicking on the icon to enter the Settings app. package com.uia.example.my; // Import the uiautomator libraries import com.android.uiautomator.core.UiObject; import com.android.uiautomator.core.UiObjectNotFoundException; import com.android.uiautomator.core.UiScrollable; import com.android.uiautomator.core.UiSelector; import com.android.uiautomator.testrunner.UiAutomatorTestCase; public class LaunchSettings extends UiAutomatorTestCase { public void testDemo() throws UiObjectNotFoundException { // Simulate a short press on the HOME button. getUiDevice().pressHome(); // We’re now in the home screen. Next, we want to simulate // a user bringing up the All Apps screen. // If you use the uiautomatorviewer tool to capture a snapshot // of the Home screen, notice that the All Apps button’s // content-description property has the value “Apps”. We can // use this property to create a UiSelector to find the button. UiObject allAppsButton = new UiObject(new UiSelector() .description(&quot;Apps&quot;)); // Simulate a click to bring up the All Apps screen. allAppsButton.clickAndWaitForNewWindow(); // In the All Apps screen, the Settings app is located in // the Apps tab. To simulate the user bringing up the Apps tab, // we create a UiSelector to find a tab with the text // label “Apps”. UiObject appsTab = new UiObject(new UiSelector() .text(&quot;Apps&quot;)); // Simulate a click to enter the Apps tab. appsTab.click(); // Next, in the apps tabs, we can simulate a user swiping until // they come to the Settings app icon. Since the container view // is scrollable, we can use a UiScrollable object. UiScrollable appViews = new UiScrollable(new UiSelector() .scrollable(true)); // Set the swiping mode to horizontal (the default is vertical) appViews.setAsHorizontalList(); // Create a UiSelector to find the Settings app and simulate // a user click to launch the app. UiObject settingsApp = appViews.getChildByText(new UiSelector() .className(android.widget.TextView.class.getName()), &quot;Settings&quot;); settingsApp.clickAndWaitForNewWindow(); // Validate that the package name is the expected one UiObject settingsValidation = new UiObject(new UiSelector() .packageName(&quot;com.android.settings&quot;)); assertTrue(&quot;Unable to detect Settings&quot;, settingsValidation.exists()); }} 1234#### Building and Deploying Your uiautomator Tests1. Once you have coded your test, follow these steps to build and deploy your test JAR to your target Android test device:Create the required build configuration files to build the output JAR. To generate the build configuration files, open a terminal and run the following command: /tools/android create uitest-project -n -t 1 -p 12345The &lt;name&gt; is the name of the project that contains your uiautomator test source files, and the &lt;path&gt; is the path to the corresponding project directory.2. From the command line, set the ANDROID_HOME variable:- In Windows:`set ANDROID_HOME=&lt;path_to_your_sdk&gt;`- In UNIX:`export ANDROID_HOME=&lt;path_to_your_sdk&gt;`3. Go to the project directory where your build.xml file is located and build your test JAR. ant build 14. Deploy your generated test JAR file to the test device by using the adb push command: adb push /data/local/tmp/ 1Here’s an example: adb push ~/dev/workspace/LaunchSettings/bin/LaunchSettings.jar /data/local/tmp/ 123#### Running uiautomator TestsHere’s an example of how to run a test that is implemented in the `LaunchSettings.jar` file. The tests are bundled in the `com.uia.example.my` package: adb shell uiautomator runtest LaunchSettings.jar -c com.uia.example.my.LaunchSettings 123456789101112131415To learn more about the syntax, subcommands, and options for uiautomator, see the [uiautomator](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/index.html) reference.#### Best PracticesHere are some best practices for functional UI testing with the uiautomator framework:- Ensure that you validate the same UI functions on your application across the various types of devices that your application might run on (for example, devices with different screen densities).- You should also test your UI against common scenarios such as in-coming phone calls, network interruptions, and user-initiated switching to other applications on the device.### [uiautomator tools](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/index.html)The uiautomator testing framework lets you test your user interface (UI) efficiently by creating automated functional UI testcases that can be run against your app on one or more devices.For more information on testing with the uiautomator framework, see [UI Testing](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/testing/testing_ui.html).#### SyntaxTo run your testcases on the target device, you can use the `adb shell` command to invoke the `uiautomator` tool. The syntax is: adb shell uiautomator runtest -c [options] 1Here’s an example: adb shell uiautomator runtest LaunchSettings.jar -c com.uia.example.my.LaunchSettings ``` Command-line OptionsThe following table describes the subcommands and options for uiautomator. Table 1. Command-line options for uiautomator Subcommand Option Description runtest &lt;jar&gt; Required. The argument is the name of one or more JAR files that you deployed to the target device which contain your uiautomator testcases. You can list more than one JAR file by using a space as a separator. -c &lt;test_class_or_method&gt; Required. The argument is a list of one or more specific test classes or test methods from the JARs that you want uiautomator to run.Each class or method must be fully qualified with the package name, in one of these formats: package_name.class_name package_name.class_name#method_name You can list multiple classes or methods by using a space as a separator. –nohup Runs the test to completion on the device even if its parent process is terminated (for example, if the device is disconnected). -e Specify other name-value pairs to be passed to test classes. May be repeated.Note: The -e options cannot be combined; you must prefix each option with a separate -e flag. -e debug [true false] Wait for debugger to connect before starting. dump [file] Generate an XML file with a dump of the current UI hierarchy. If a filepath is not specified, by default, the generated dump file is stored on the device in this location /storage/sdcard0/window_dump.xml. events Prints out accessibility events to the console until the connection to the device is terminated UiAutomation apiClass for interacting with the device’s UI by simulation user actions and introspection of the screen content. It relies on the platform accessibility APIs to introspect the screen and to perform some actions on the remote view tree. It also allows injecting of arbitrary raw input events simulating user interaction with keyboards and touch devices. One can think of a UiAutomation as a special type of AccessibilityService which does not provide hooks for the service life cycle and exposes other APIs that are useful for UI test automation. 这是一个通过模拟用户操作来与设备用户界面交互以及获取屏幕内容的类。它依赖于平台的辅助功能APIs来在远程的控件树上获取屏幕内容以及执行一些操作。同时它也允许通过注入原生事件(译者注:指的就是InputEvent. KeyEvent也是继承于InputEvent的，所以说它是原生事件)来模拟用户的按键和触屏操作。我们可以认为UiAutomation就是一个特殊类型的AccessibilityService,其既不会为控制服务的生命周期而提供钩子函数，也不会暴露任何其他可以直接用于用户界面测试自动化的APIs. The APIs exposed by this class are low-level to maximize flexibility when developing UI test automation tools and libraries. Generally, a UiAutomation client should be using a higher-level library or implement high-level functions. For example, performing a tap on the screen requires construction and injecting of a touch down and up events which have to be delivered to the system by a call to injectInputEvent(InputEvent, boolean). 这个类暴露出来的APIs是很低层的，目的就是为了在开发用户界面测试自动化框架和库时提供最大的弹性。总的来说，一个UiAutomation客户端应该使用一些（基于UiAutomation的)更高层次的库或者实现更高层次的方法。比如，模拟一个用户在屏幕上的点击事件需要构造并注入一个按下和一个弹起事件，然后必须调用UiAutomation的一个injectInputEvent(InputEvent, boolean)的调用来发送给操作系统。 The APIs exposed by this class operate across applications enabling a client to write tests that cover use cases spanning over multiple applications. For example, going to the settings application to change a setting and then interacting with another application whose behavior depends on that setting. 这个类暴露出来的APIs可以跨应用，这样用户就可以编写可以跨越多个应用的测试用例脚本了。比如，打开系统的设置应用去修改一些设置然后再与另外一个依赖于该设置的应用进行交互（译者注：这个在instrumentation这个框架可以做不到的）]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试之(N):测试支持库]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-support-library%2F</url>
    <content type="text"><![CDATA[Android官方文档-测试支持库 Android 测试支持库提供了大量用于测试 Android 应用的框架。此库提供了一组 API，让您可以为应用快速构建何运行测试代码，包括 JUnit 4 和功能性用户界面 (UI) 测试。您可以从 Android Studio IDE 或命令行运行使用这些 API 创建的测试。 Android 测试支持库通过 Android SDK 管理器提供。如需了解详细信息，请参阅测试支持库设置 本页介绍了 Android 测试支持库提供了哪些工具、如何在测试环境中使用这些工具，以及库版本的相关信息。 测试支持库功能Android 测试支持库包括以下自动化测试工具： AndroidJUnitRunner：适用于 Android 且与 JUnit 4 兼容的测试运行器 Espresso：UI 测试框架；适合应用中的功能性 UI 测试 UI Automator：UI 测试框架；适合跨系统和已安装应用的跨应用功能性 UI 测试 AndroidJUnitRunnerAndroidJUnitRunner 类是一个 JUnit 测试运行器，可让您在 Android 设备上运行 JUnit 3 或 JUnit 4 样式测试类，包括使用 Espresso 和 UI Automator 测试框架的设备。测试运行器可以将测试软件包和要测试的应用加载到设备、运行测试并报告测试结果。此类将替换 InstrumentationTestRunner 类，后者仅支持 JUnit 3 测试。 此测试运行器的主要功能包括： JUnit 支持 访问仪器信息 测试筛选 测试分片 要求 Android 2.2（API 级别 8）或更高版本。 JUnit 支持测试运行器与 JUnit 3 和 JUnit 4（最高版本为 JUnit 4.10）测试兼容。不过，请勿在同一软件包中混用 JUnit 3 和 JUnit 4 测试代码，因为这可能会导致意外结果。如果要创建一个 JUnit 4 仪器测试类以在设备或模拟器上运行，则测试类必须以 @RunWith(AndroidJUnit4.class) 注解作为前缀。 以下代码段显示了如何编写 JUnit 4 仪器测试来验证 CalculatorActivity 类中的 add 操作是否正常工作。 1234567891011121314151617181920212223242526272829import android.support.test.runner.AndroidJUnit4;import android.support.test.runner.AndroidJUnitRunner;import android.test.ActivityInstrumentationTestCase2;@RunWith(AndroidJUnit4.class)public class CalculatorInstrumentationTest extends ActivityInstrumentationTestCase2&lt;CalculatorActivity&gt; &#123; @Before public void setUp() throws Exception &#123; super.setUp(); // Injecting the Instrumentation instance is required // for your test to run with AndroidJUnitRunner. injectInstrumentation(InstrumentationRegistry.getInstrumentation()); mActivity = getActivity(); &#125; @Test public void typeOperandsAndPerformAddOperation() &#123; // Call the CalculatorActivity add() method and pass in some operand values, then // check that the expected value is returned. &#125; @After public void tearDown() throws Exception &#123; super.tearDown(); &#125;&#125; 访问仪器信息您可以使用 InstrumentationRegistry 类访问与测试运行相关的信息。此类包括 Instrumentation 对象、目标应用 Context 对象、测试应用 Context 对象，以及传递到测试中的命令行参数。使用 UI Automator 框架编写测试或编写依赖于 Instrumentation 或 Context 对象的测试时，此数据非常有用。 测试筛选在 JUnit 4.x 测试中，您可以使用注解对测试运行进行配置。此功能可将向测试中添加样板文件和条件代码的需求降至最低。除了 JUnit 4 支持的标准注解外，测试运行器还支持 Android 特定的注解，包括： @RequiresDevice：指定测试仅在物理设备而不在模拟器上运行。 @SdkSupress：禁止在低于给定级别的 Android API 级别上运行测试。例如，要禁止在低于 18 的所有 API 级别上运行测试，请使用注解 - - @SDKSupress(minSdkVersion=18)。 @SmallTest、@MediumTest 和 @LargeTest：指定测试的运行时长以及运行频率。测试分片测试运行器支持将单一测试套件拆分成多个碎片，因此您可以将属于同一碎片的测试作为一个组在同一 Instrumentation 实例下运行。每个分片由一个索引号进行标识。运行测试时，使用 -e numShards 选项指定要创建的独立分片数量，并使用 -e shardIndex 选项指定要运行哪个分片。 例如，要将测试套件拆分成 10 个分片，且仅运行第二个碎片中的测试，请使用以下命令： adb shell am instrument -w -e numShards 10 -e shardIndex 2 要详细了解如何使用此测试运行器，请参阅 API 参考。 EspressoEspresso 测试框架提供了一组 API 来构建 UI 测试，用于测试应用中的用户流。利用这些 API，您可以编写简洁、运行可靠的自动化 UI 测试。Espresso 非常适合编写白盒自动化测试，其中测试代码将利用所测试应用的实现代码详情。 Espresso 测试框架的主要功能包括： 灵活的 API，用于目标应用中的视图和适配器匹配。如需了解详细信息，请参阅视图匹配。 一组丰富的操作 API，用于自动化 UI 交互。如需了解详细信息，请参阅操作 API。 UI 线程同步，用于提升测试可靠性。如需了解详细信息，请参阅 UI 线程同步。 要求 Android 2.2（API 级别 8）或更高版本。 视图匹配利用 Espresso.onView() 方法，您可以访问目标应用中的 UI 组件并与之交互。此方法接受 Matcher 参数并搜索视图层次结构，以找到符合给定条件的相应 View 实例。您可以通过指定以下条件来优化搜索： 视图的类名称 视图的内容描述 视图的 R.id 在视图中显示的文本 例如，要找到 ID 值为 my_button 的按钮，可以指定如下匹配器：1onView(withId(R.id.my_button)); 如果搜索成功，onView() 方法将返回一个引用，让您可以执行用户操作并基于目标视图对断言进行测试。 适配器匹配在 AdapterView 布局中，布局在运行时由子视图动态填充。如果目标视图位于某个布局内部，而该布局是从 AdapterView（例如 ListView 或 GridView）派生出的子类，则 onView() 方法可能无法工作，因为只有布局视图的子集会加载到当前视图层次结构中。 因此，请使用 Espresso.onData() 方法访问目标视图元素。Espresso.onData() 方法将返回一个引用，让您可以执行用户操作并根据 AdapterView 中的元素对断言进行测试。 操作 API通常情况下，您可以通过根据应用的用户界面执行某些用户交互来测试应用。借助 ViewActions API，您可以轻松地实现这些操作的自动化。您可以执行多种 UI 交互，例如： 视图点击 滑动 按下按键和按钮 键入文本 打开链接 例如，要模拟输入字符串值并按下按钮以提交该值，您可以像下面一样编写自动化测试脚本。ViewInteraction.perform() 和 DataInteraction.perform() 方法采用一个或多个 ViewAction 参数，并以提供的顺序运行操作。123456// Type text into an EditText view, then close the soft keyboardonView(withId(R.id.editTextUserInput)) .perform(typeText(STRING_TO_BE_TYPED), closeSoftKeyboard());// Press the button to submit the text changeonView(withId(R.id.changeTextBt)).perform(click()); UI 线程同步由于计时问题，Android 设备上的测试可能随机失败。此测试问题称为测试不稳定。在 Espresso 之前，解决方法是在测试中插入足够长的休眠或超时期或添加代码，以便重试失败的操作。Espresso 测试框架可以处理 Instrumentation 与 UI 线程之间的同步；这就消除了对之前的计时解决方法的需求，并确保测试操作与断言更可靠地运行。 要详细了解如何使用 Espresso，请参阅 API 参考和测试单个应用的 UI 培训。 UI AutomatorUI Automator 测试框架提供了一组 API 来构建 UI 测试，用于在用户应用和系统应用中执行交互。利用 UI Automator API，您可以执行在测试设备中打开“设置”菜单或应用启动器等操作。UI Automator 测试框架非常适合编写黑盒自动化测试，其中的测试代码不依赖于目标应用的内部实现详情。 UI Automator 测试框架的主要功能包括： 用于检查布局层次结构的查看器。如需了解详细信息，请参阅 UI Automator 查看器。 在目标设备上检索状态信息并执行操作的 API。如需了解详细信息，请参阅访问设备状态。 支持跨应用 UI 测试的 API。如需了解详细信息，请参阅 UI Automator API。 要求 Android 4.3（API 级别 18）或更高版本。 UI Automator 查看器uiautomatorviewer 工具提供了一个方便的 GUI，可以扫描和分析 Android 设备上当前显示的 UI 组件。您可以使用此工具检查布局层次结构，并查看在设备前台显示的 UI 组件属性。利用此信息，您可以使用 UI Automator（例如，通过创建与特定可见属性匹配的 UI 选择器）创建控制更加精确的测试。 uiautomatorviewer 工具位于 &lt;android-sdk&gt;/tools/目录中。 访问设备状态UI Automator 测试框架提供了一个 UiDevice 类，用于在目标应用运行的设备上访问和执行操作。您可以调用其方法来访问设备属性，如当前屏幕方向或显示尺寸。UiDevice 类还可用于执行以下操作： 更改设备旋转 按 D-pad 按钮 按“返回”、“主屏幕”或“菜单”按钮 打开通知栏 对当前窗口进行屏幕截图 例如，要模拟按下“主屏幕”按钮，请调用 UiDevice.pressHome() 方法。 UI Automator API利用 UI Automator API，您可以编写稳健可靠的测试，而无需了解目标应用的实现详情。您可以使用这些 API 在多个应用中捕获和操作 UI 组件： UiCollection：枚举容器的 UI 元素以便计算子元素个数，或者通过可见的文本或内容描述属性来指代子元素。 UiObject：表示设备上可见的 UI 元素。 UiScrollable：为在可滚动 UI 容器中搜索项目提供支持。 UiSelector：表示在设备上查询一个或多个目标 UI 元素。 Configurator：允许您设置运行 UI Automator 测试所需的关键参数。 例如，以下代码显示了如何编写可在设备中调用默认应用启动器的测试脚本：12345678910111213// Initialize UiDevice instancemDevice = UiDevice.getInstance(getInstrumentation());// Perform a short press on the HOME buttonmDevice.pressHome();// Bring up the default launcher by searching for// a UI component that matches the content-description for the launcher buttonUiObject allAppsButton = mDevice .findObject(new UiSelector().description(&quot;Apps&quot;));// Perform a click on the button to bring up the launcherallAppsButton.clickAndWaitForNewWindow(); 要详细了解如何使用 UI Automator，请参阅 API 参考和测试多个应用的 UI 培训。 测试支持库设置Android 测试支持库软件包在最新版本的 Android 支持存储库中提供，后者可作为辅助组件通过 Android SDK 管理器下载。 要通过 SDK 管理器下载 Android 支持存储库，请执行以下操作： 启动 Android SDK 管理器。 在 SDK 管理器窗口中，滚动到 Packages 列表末尾，找到 Extras 文件夹并展开（如有必要）以显示其内容。 选择 Android Support Repository 项。 点击 Install packages… 按钮。 下载后，此工具会将支持存储库文件安装到您现有的 Android SDK 目录中。库文件位于 SDK 的以下子目录中：&lt;sdk&gt;/extras/android/m2repository 目录。 Android 测试支持库的类位于 android.support.test 软件包中。 要在 Gradle 项目中使用 Android 测试支持库，请在 build.gradle 文件中添加这些依赖关系： 123456789dependencies &#123; androidTestCompile &apos;com.android.support.test:runner:0.4&apos; // Set this dependency to use JUnit 4 rules androidTestCompile &apos;com.android.support.test:rules:0.4&apos; // Set this dependency to build and run Espresso tests androidTestCompile &apos;com.android.support.test.espresso:espresso-core:2.2.1&apos; // Set this dependency to build and run UI Automator tests androidTestCompile &apos;com.android.support.test.uiautomator:uiautomator-v18:2.1.2&apos;&#125; 要将 AndroidJUnitRunner 设置为 Gradle 项目中的默认测试仪器运行器，请在 build.gradle 文件中指定此依赖关系： `` android { defaultConfig { testInstrumentationRunner “android.support.test.runner.AndroidJUnitRunner” } } ```]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试之(N):adb工具]]></title>
    <url>%2F2017%2F08%2F29%2Fat-android-adb%2F</url>
    <content type="text"><![CDATA[Android手机自动化测试过程离不开adb工具,介绍几个常用的adb命令. 1. adb forward命令示例: 1adb forward tcp:8000 tcp:9000 作用: 把PC端8000端口的数据, 转发到Android端的9000端口上,PC端的8000端口会被 adb 监听, 这个时候我们只需要往8000端口写数据, 这个数据就会发送到手机端的9000端口上. 2. adb connect命令示例: 1adb connect + IP 作用: 通过无线网络在PC端adb连接手机端 注意: 要链接的IP ，必须和自己的PC的网络在同一个局域网内，adb 不能跨局域网链接设备 如果通过usb链接Android设备，通过adb devices 可以看见设备列表，但是使用不了，可以参考下面的命令说明手机端的服务未开启,需要连接usb开启手机服务,默认端口5555:adb tcpip 5555,开启后拔掉usb通过adb connect 192.168.0.101:5555即可连接]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RecyclerView实现单选列表]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-recyclerview-selectable%2F</url>
    <content type="text"><![CDATA[常规方法： 在Javabean里增加一个boolean isSelected字段， 并在Adapter里根据这个字段的值设置“CheckBox”的选中状态。 在每次选中一个新优惠券时，改变数据源里的isSelected字段， 并notifyDataSetChanged()刷新整个列表。 这样实现起来很简单，代码量也很少，唯一不足的地方就是性能有损耗，不是最优雅。 So作为一个有追求 今天比较闲 的程序员，我决心分享一波优雅方案。 本文会列举分析一下在ListView和RecyclerView中, 列表实现单选的几种方案，并推荐采用定向刷新 部分绑定的方案，因为更高效and优雅 1常规方案:常规方案 请光速阅读，直接上码： Bean结构： 1234567public class TestBean extends SelectedBean &#123; private String name; public TestBean(String name,boolean isSelected) &#123; this.name = name; setSelected(isSelected); &#125;&#125; 我项目里有好多单选需求，懒得写isSelected字段，所以弄了个父类供子类继承。 123456789public class SelectedBean &#123; private boolean isSelected; public boolean isSelected() &#123; return isSelected; &#125; public void setSelected(boolean selected) &#123; isSelected = selected; &#125;&#125; Acitivity 和Adapter其他方法都是最普通的不再赘述。 Adapter的onBindViewHolder()如下： 1234567891011121314151617181920212223242526272829Log.d(&quot;TAG&quot;, &quot;onBindViewHolder() called with: holder = [&quot; + holder + &quot;], position = [&quot; + position + &quot;]&quot;); holder.ivSelect.setSelected(mDatas.get(position).isSelected());//“CheckBox” holder.tvCoupon.setText(mDatas.get(position).getName());//TextView holder.ivSelect.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; //实现单选，第一种方法，十分简单， Lv Rv通用,因为它们都有notifyDataSetChanged()方法 // 每次点击时，先将所有的selected设为false，并且将当前点击的item 设为true， 刷新整个视图 for (TestBean data : mDatas) &#123; data.setSelected(false); &#125; mDatas.get(position).setSelected(true); notifyDataSetChanged(); &#125; &#125;);ViewHolder： public static class CouponVH extends RecyclerView.ViewHolder &#123; private ImageView ivSelect; private TextView tvCoupon; public CouponVH(View itemView) &#123; super(itemView); ivSelect = (ImageView) itemView.findViewById(R.id.ivSelect); tvCoupon = (TextView) itemView.findViewById(R.id.tvCoupon); &#125; &#125; 方案优点：简单粗暴 方案缺点： 其实需要修改的Item只有两项： 一个当前处于选中状态的Item-&gt;普通状态 再将当前手指点击的这个Item-&gt;选中状态 但采用普通方案，则会刷新整个一屏可见的Item，重走他们的getView()/onBindViewHolder()方法。 其实一个屏幕一般最多可见10+个Item，遍历一遍也无伤大雅。 但咱们还是要有追求优雅的心，所以我们继续往下看。 2 利用Rv的notifyItemChanged()定向刷新:本方案可以中速阅读 本方案需要在Adapter里新增一个字段： 1private int mSelectedPos = -1;//实现单选 方法二，变量保存当前选中的position 在设置数据集时(构造函数，setData()方法等：)，初始化 mSelectedPos 的值。 123456//实现单选方法二： 设置数据集时，找到默认选中的posfor (int i = 0; i &lt; mDatas.size(); i++) &#123; if (mDatas.get(i).isSelected()) &#123; mSelectedPos = i; &#125;&#125; onClick里代码如下： 1234567891011//实现单选方法二： notifyItemChanged() 定向刷新两个视图//如果勾选的不是已经勾选状态的Itemif (mSelectedPos!=position)&#123; //先取消上个item的勾选状态 mDatas.get(mSelectedPos).setSelected(false); notifyItemChanged(mSelectedPos); //设置新Item的勾选状态 mSelectedPos = position; mDatas.get(mSelectedPos).setSelected(true); notifyItemChanged(mSelectedPos);&#125; 本方案由于调用了notifyItemChanged()，所以还会伴有“白光一闪”的动画。 方案优点： 本方案，较优雅了，不会重走一屏可见的Item的getView()/onBindViewHolder()方法， 但仍然会重走需要修改的两个Item的getView()/onBindViewHolder()方法， 方案缺点： 我们实际上需要修改的，只是里面“CheckBox”的值， 按照在DiffUtil一文学习到的姿势，术语应该是“Partial bind “， （安利时间,没听过DiffUtil和Partial bind的 戳-&gt;：【Android】详解7.0带来的新工具类：DiffUtil） 我们需要的只是部分绑定。 一个疑点： 使用方法2 在第一次选中其他Item时，切换selected状态时， 查看log，并不是只重走了新旧Item的onBindViewHolder()方法，还走了两个根本不在屏幕范围里的Item的onBindViewHolder()方法， 如，本例中 在还有item 0-3 在屏幕里，默认勾选item1，我选中item0后，log显示postion 4,5,0,1 依次执行了onBindViewHolder()方法。 但是再次切换其他Item时， 会符合预期：只走需要修改的两个Item的getView()/onBindViewHolder()方法。 原因未知，有朋友知道烦请告知，多谢。 3 Rv 实现部分绑定（推荐）:利用RecyclerView的 findViewHolderForLayoutPosition()方法，获取某个postion的ViewHolder，按照源码里这个方法的注释，它可能返回null。所以我们需要注意判空，（空即在屏幕不可见）。 与方法2只有onClick里的代码不一样，核心还是利用mSelectedPos 字段搞事情。 1234567891011121314//实现单选方法三： RecyclerView另一种定向刷新方法：不会有白光一闪动画 也不会重复onBindVIewHolderCouponVH couponVH = (CouponVH) mRv.findViewHolderForLayoutPosition(mSelectedPos);if (couponVH != null) &#123;//还在屏幕里 couponVH.ivSelect.setSelected(false);&#125;else &#123; //add by 2016 11 22 for 一些极端情况，holder被缓存在Recycler的cacheView里， //此时拿不到ViewHolder，但是也不会回调onBindViewHolder方法。所以add一个异常处理 notifyItemChanged(mSelectedPos);&#125;mDatas.get(mSelectedPos).setSelected(false);//不管在不在屏幕里 都需要改变数据//设置新Item的勾选状态mSelectedPos = position;mDatas.get(mSelectedPos).setSelected(true);holder.ivSelect.setSelected(true); 方案优点： 定向刷新两个Item，只修改必要的部分，不会重走onBindViewHolder()，属于手动部分绑定。代码量也适中，不多。 方案缺点： 没有白光一闪动画？？？（如果这算缺点） 4 Rv 利用payloads实现部分绑定(不推荐):本方案属于开拓思维，是在方案2的基础上，利用payloads和notifyItemChanged(int position, Object payload)搞事情。 不知道payloads是什么的，看不懂此方案的，我又要安利：（戳-&gt;：【Android】详解7.0带来的新工具类：DiffUtil） onClick代码如下： 123456789101112131415//实现单选方法四：if (mSelectedPos != position) &#123; //先取消上个item的勾选状态 mDatas.get(mSelectedPos).setSelected(false); //传递一个payload Bundle payloadOld = new Bundle(); payloadOld.putBoolean(&quot;KEY_BOOLEAN&quot;, false); notifyItemChanged(mSelectedPos, payloadOld); //设置新Item的勾选状态 mSelectedPos = position; mDatas.get(mSelectedPos).setSelected(true); Bundle payloadNew = new Bundle(); payloadNew.putBoolean(&quot;KEY_BOOLEAN&quot;, true); notifyItemChanged(mSelectedPos, payloadNew);&#125; 需要重写三参数的onBindViewHolder() 方法： 123456789101112@Overridepublic void onBindViewHolder(CouponVH holder, int position, List&lt;Object&gt; payloads) &#123; if (payloads.isEmpty()) &#123; onBindViewHolder(holder, position); &#125; else &#123; Bundle payload = (Bundle) payloads.get(0); if (payload.containsKey(&quot;KEY_BOOLEAN&quot;)) &#123; boolean aBoolean = payload.getBoolean(&quot;KEY_BOOLEAN&quot;); holder.ivSelect.setSelected(aBoolean); &#125; &#125;&#125; 方案优点： 同方法3 方案缺点： 代码量多，实现效果和方法三一样，仅做开拓思维用，所以选择方法三。 作者：张旭童 链接：http://www.jianshu.com/p/1ac13f74da63 來源：简书]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Activity任务和返回栈]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-activity-stack%2F</url>
    <content type="text"><![CDATA[问题:homeActivity为正常启动模式activity,另一个activity为singleTask Activity.从package installers启动homeaty,再启动另一个activity,桌面,再点击桌面图标进入应用,会重新打开homeaty,而不是另一个activity.但是如果是从桌面首次进入home再进入另一个activity,切换到到桌面回来是在正常的另一个activity.同事发现homeaty, 另一个aty,桌面重新回来的homeaty, taskid相同. 解决办法是使用application记录front activity. 实例化launcher activity 这个问题表现: 在package installers 安装界面安装完一个应用后，直接打开app，然后进入了 Activity_1, 此时再通过此activity用startActivity(intent)的方法打开 Activity_2. 然后按home键返回桌面，在桌面点击app图标进入，你觉得应该进入的是 Activity_2 ，实际上却是launcher Activity_1 . 然而还没完，这时候你按 back 返回键，会发现返回到了之前打开的 Activity_2，再按返回，又出现 launcherActivity_1. 也就是说系统重复实例化了Activity_1. 退出app后再次点击桌面图标进入，反复试验，没有再出现这个问题。也就是说，这个问题（bug ？）只出现在操作步骤（1）后才会产生. 以上问题我在一些知名厂商的app 上发现也存在这个BUG ： 百度云 陌陌 去哪儿旅行 …QQ没有出现这个问题 另外，如果以root方式静默安装的话不会出现这个问题，在eclipse里直接发布到模拟器上运行也没有出现这个问题 解决方案: 在super.onCreate(…)方法之后插入代码： 123456789if(!this.isTaskRoot()) &#123; //判断该Activity是不是任务空间的源Activity，“非”也就是说是被系统重新实例化出来 //如果你就放在launcher Activity中话，这里可以直接return了 Intent mainIntent=getIntent(); String action=mainIntent.getAction(); if(mainIntent.hasCategory(Intent.CATEGORY_LAUNCHER) &amp;&amp; action.equals(Intent.ACTION_MAIN)) &#123; finish(); return;//finish()之后该活动会继续执行后面的代码，你可以logCat验证，加return避免可能的exception &#125; &#125; 来源google ： https://code.google.com/p/android/issues/detail?id=14262 https://code.google.com/p/android/issues/detail?id=2373#c40 还有另一种方案： http://stackoverflow.com/questions/3042420/home-key-press-behaviour/4782423#4782423 以下引用自google官方文档 应用通常包含多个 Activity。每个 Activity 均应围绕用户可以执行的特定操作设计，并且能够启动其他 Activity。 例如，电子邮件应用可能有一个 Activity 显示新邮件的列表。用户选择某邮件时，会打开一个新 Activity 以查看该邮件。 一个 Activity 甚至可以启动设备上其他应用中存在的 Activity。例如，如果应用想要发送电子邮件，则可将 Intent 定义为执行“发送”操作并加入一些数据，如电子邮件地址和电子邮件。 然后，系统将打开其他应用中声明自己处理此类 Intent 的 Activity。在这种情况下，Intent 是要发送电子邮件，因此将启动电子邮件应用的“撰写”Activity（如果多个 Activity 支持相同 Intent，则系统会让用户选择要使用的 Activity）。发送电子邮件时，Activity 将恢复，看起来好像电子邮件 Activity 是您的应用的一部分。 即使这两个 Activity 可能来自不同的应用，但是 Android 仍会将 Activity 保留在相同的任务中，以维护这种无缝的用户体验。 任务是指在执行特定作业时与用户交互的一系列 Activity。 这些 Activity 按照各自的打开顺序排列在堆栈（即返回栈）中。 设备主屏幕是大多数任务的起点。当用户触摸应用启动器中的图标（或主屏幕上的快捷方式）时，该应用的任务将出现在前台。 如果应用不存在任务（应用最近未曾使用），则会创建一个新任务，并且该应用的“主”Activity 将作为堆栈中的根 Activity 打开。 当前 Activity 启动另一个 Activity 时，该新 Activity 会被推送到堆栈顶部，成为焦点所在。 前一个 Activity 仍保留在堆栈中，但是处于停止状态。Activity 停止时，系统会保持其用户界面的当前状态。 用户按“返回”按钮时，当前 Activity 会从堆栈顶部弹出（Activity 被销毁），而前一个 Activity 恢复执行（恢复其 UI 的前一状态）。 堆栈中的 Activity 永远不会重新排列，仅推入和弹出堆栈：由当前 Activity 启动时推入堆栈；用户使用“返回”按钮退出时弹出堆栈。 因此，返回栈以“后进先出”对象结构运行。 图 1 通过时间线显示 Activity 之间的进度以及每个时间点的当前返回栈，直观呈现了这种行为。 图 1. 显示任务中的每个新 Activity 如何向返回栈添加项目。 用户按“返回”按钮时，当前 Activity 随即被销毁，而前一个 Activity 恢复执行。 如果用户继续按“返回”，堆栈中的相应 Activity 就会弹出，以显示前一个 Activity，直到用户返回主屏幕为止（或者，返回任务开始时正在运行的任意 Activity）。 当所有 Activity 均从堆栈中移除后，任务即不复存在。 任务是一个有机整体，当用户开始新任务或通过“主页”按钮转到主屏幕时，可以移动到“后台”。 尽管在后台时，该任务中的所有 Activity 全部停止，但是任务的返回栈仍旧不变，也就是说，当另一个任务发生时，该任务仅仅失去焦点而已，如图 2 中所示。然后，任务可以返回到“前台”，用户就能够回到离开时的状态。 例如，假设当前任务（任务 A）的堆栈中有三个 Activity，即当前 Activity 下方还有两个 Activity。 用户先按“主页”按钮，然后从应用启动器启动新应用。 显示主屏幕时，任务 A 进入后台。新应用启动时，系统会使用自己的 Activity 堆栈为该应用启动一个任务（任务 B）。与该应用交互之后，用户再次返回主屏幕并选择最初启动任务 A 的应用。现在，任务 A 出现在前台，其堆栈中的所有三个 Activity 保持不变，而位于堆栈顶部的 Activity 则会恢复执行。 此时，用户还可以通过转到主屏幕并选择启动该任务的应用图标（或者，通过从概览屏幕选择该应用的任务）切换回任务 B。这是 Android 系统中的一个多任务示例。 图 2. 两个任务：任务 B 在前台接收用户交互，而任务 A 则在后台等待恢复。 注：后台可以同时运行多个任务。但是，如果用户同时运行多个后台任务，则系统可能会开始销毁后台 Activity，以回收内存资源，从而导致 Activity 状态丢失。请参阅下面有关 Activity 状态的部分。 由于返回栈中的 Activity 永远不会重新排列，因此如果应用允许用户从多个 Activity 中启动特定 Activity，则会创建该 Activity 的新实例并推入堆栈中（而不是将 Activity 的任一先前实例置于顶部）。 因此，应用中的一个 Activity 可能会多次实例化（即使 Activity 来自不同的任务），如图 3 所示。因此，如果用户使用“返回”按钮向后导航，则会按 Activity 每个实例的打开顺序显示这些实例（每个实例的 UI 状态各不相同）。 但是，如果您不希望 Activity 多次实例化，则可修改此行为。 具体操作方法将在后面的管理任务部分中讨论。 图 3. 一个 Activity 将多次实例化。 Activity 和任务的默认行为总结如下： 当 Activity A 启动 Activity B 时，Activity A 将会停止，但系统会保留其状态（例如，滚动位置和已输入表单中的文本）。如果用户在处于 Activity B 时按“返回”按钮，则 Activity A 将恢复其状态，继续执行。 用户通过按“主页”按钮离开任务时，当前 Activity 将停止且其任务会进入后台。 系统将保留任务中每个 Activity 的状态。如果用户稍后通过选择开始任务的启动器图标来恢复任务，则任务将出现在前台并恢复执行堆栈顶部的 Activity。 如果用户按“返回”按钮，则当前 Activity 会从堆栈弹出并被销毁。 堆栈中的前一个 Activity 恢复执行。销毁 Activity 时，系统不会保留该 Activity 的状态。 即使来自其他任务，Activity 也可以多次实例化。 保存 Activity 状态正如上文所述，当 Activity 停止时，系统的默认行为会保留其状态。 这样一来，当用户导航回到上一个 Activity 时，其用户界面与用户离开时一样。 但是，在 Activity 被销毁且必须重建时，您可以而且应当主动使用回调方法保留 Activity 的状态。 系统停止您的一个 Activity 时（例如，新 Activity 启动或任务转到前台），如果系统需要回收系统内存资源，则可能会完全销毁该 Activity。 发生这种情况时，有关该 Activity 状态的信息将会丢失。如果发生这种情况，系统仍会知道该 Activity 存在于返回栈中，但是当该 Activity 被置于堆栈顶部时，系统一定会重建 Activity（而不是恢复 Activity）。 为了避免用户的工作丢失，您应主动通过在 Activity 中实现 onSaveInstanceState() 回调方法来保留工作。 如需了解有关如何保存 Activity 状态的详细信息，请参阅 Activity 文档。 管理任务Android 管理任务和返回栈的方式（如上所述，即：将所有连续启动的 Activity 放入同一任务和“后进先出”堆栈中）非常适用于大多数应用，而您不必担心 Activity 如何与任务关联或者如何存在于返回栈中。 但是，您可能会决定要中断正常行为。 也许您希望应用中的 Activity 在启动时开始新任务（而不是放置在当前任务中）；或者，当启动 Activity 时，您希望将其现有实例上移一层（而不是在返回栈的顶部创建新实例）；或者，您希望在用户离开任务时，清除返回栈中除根 Activity 以外的所有其他 Activity。 通过使用 清单文件元素中的属性和传递给 startActivity() 的 Intent 中的标志，您可以执行所有这些操作以及其他操作。 在这一方面，您可以使用的主要 属性包括： taskAffinity launchMode allowTaskReparenting clearTaskOnLaunch alwaysRetainTaskState finishOnTaskLaunch 您可以使用的主要 Intent 标志包括： FLAG_ACTIVITY_NEW_TASK FLAG_ACTIVITY_CLEAR_TOP FLAG_ACTIVITY_SINGLE_TOP 在下文中，您将了解如何使用这些清单文件属性和 Intent 标志定义 Activity 与任务的关联方式，以及 Activity 在返回栈中的行为方式。 此外，我们还单独介绍了有关如何在概览屏幕中显示和管理任务与 Activity 的注意事项。 如需了解详细信息，请参阅概览屏幕。 通常，您应该允许系统定义任务和 Activity 在概览屏幕中的显示方法，并且无需修改此行为。 注意：大多数应用都不得中断 Activity 和任务的默认行为： 如果确定您的 Activity 必须修改默认行为，当使用“返回”按钮从其他 Activity 和任务导航回到该 Activity 时，请务必要谨慎并确保在启动期间测试该 Activity 的可用性。请确保测试导航行为是否有可能与用户的预期行为冲突。 定义启动模式启动模式允许您定义 Activity 的新实例如何与当前任务关联。 您可以通过两种方法定义不同的启动模式： 使用清单文件 在清单文件中声明 Activity 时，您可以指定 Activity 在启动时应该如何与任务关联。 使用 Intent 标志 调用 startActivity() 时，可以在 Intent 中加入一个标志，用于声明新 Activity 如何（或是否）与当前任务关联。 因此，如果 Activity A 启动 Activity B，则 Activity B 可以在其清单文件中定义它应该如何与当前任务关联（如果可能），并且 Activity A 还可以请求 Activity B 应该如何与当前任务关联。如果这两个 Activity 均定义 Activity B 应该如何与任务关联，则 Activity A 的请求（如 Intent 中所定义）优先级要高于 Activity B 的请求（如其清单文件中所定义）。 注：某些适用于清单文件的启动模式不可用作 Intent 标志，同样，某些可用作 Intent 标志的启动模式无法在清单文件中定义。 使用清单文件在清单文件中声明 Activity 时，您可以使用 元素的 launchMode 属性指定 Activity 应该如何与任务关联。 launchMode 属性指定有关应如何将 Activity 启动到任务中的指令。您可以分配给 launchMode 属性的启动模式共有四种： “standard”（默认模式） 默认。系统在启动 Activity 的任务中创建 Activity 的新实例并向其传送 Intent。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例。 “singleTop” 如果当前任务的顶部已存在 Activity 的一个实例，则系统会通过调用该实例的 onNewIntent() 方法向其传送 Intent，而不是创建 Activity 的新实例。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例（但前提是位于返回栈顶部的 Activity 并不是 Activity 的现有实例）。 例如，假设任务的返回栈包含根 Activity A 以及 Activity B、C 和位于顶部的 D（堆栈是 A-B-C-D；D 位于顶部）。收到针对 D 类 Activity 的 Intent。如果 D 具有默认的 “standard” 启动模式，则会启动该类的新实例，且堆栈会变成 A-B-C-D-D。但是，如果 D 的启动模式是 “singleTop”，则 D 的现有实例会通过 onNewIntent() 接收 Intent，因为它位于堆栈的顶部；而堆栈仍为 A-B-C-D。但是，如果收到针对 B 类 Activity 的 Intent，则会向堆栈添加 B 的新实例，即便其启动模式为 “singleTop” 也是如此。 注：为某个 Activity 创建新实例时，用户可以按“返回”按钮返回到前一个 Activity。 但是，当 Activity 的现有实例处理新 Intent 时，则在新 Intent 到达 onNewIntent() 之前，用户无法按“返回”按钮返回到 Activity 的状态。 “singleTask” 系统创建新任务并实例化位于新任务底部的 Activity。但是，如果该 Activity 的一个实例已存在于一个单独的任务中，则系统会通过调用现有实例的 onNewIntent() 方法向其传送 Intent，而不是创建新实例。一次只能存在 Activity 的一个实例。 注：尽管 Activity 在新任务中启动，但是用户按“返回”按钮仍会返回到前一个 Activity。 “singleInstance”. 与 “singleTask” 相同，只是系统不会将任何其他 Activity 启动到包含实例的任务中。该 Activity 始终是其任务唯一仅有的成员；由此 Activity 启动的任何 Activity 均在单独的任务中打开。 我们再来看另一示例，Android 浏览器应用声明网络浏览器 Activity 应始终在其自己的任务中打开（通过在 元素中指定 singleTask 启动模式）。这意味着，如果您的应用发出打开 Android 浏览器的 Intent，则其 Activity 与您的应用位于不同的任务中。相反，系统会为浏览器启动新任务，或者如果浏览器已有任务正在后台运行，则会将该任务上移一层以处理新 Intent。 无论 Activity 是在新任务中启动，还是在与启动 Activity 相同的任务中启动，用户按“返回”按钮始终会转到前一个 Activity。 但是，如果启动指定 singleTask 启动模式的 Activity，则当某后台任务中存在该 Activity 的实例时，整个任务都会转移到前台。此时，返回栈包括上移到堆栈顶部的任务中的所有 Activity。 图 4 显示了这种情况。 图 4. 显示如何将启动模式为“singleTask”的 Activity 添加到返回栈。 如果 Activity 已经是某个拥有自己的返回栈的后台任务的一部分，则整个返回栈也会上移到当前任务的顶部。 如需了解有关在清单文件中使用启动模式的详细信息，请参阅 元素文档，其中更详细地讨论了 launchMode 属性和可接受的值。 注：使用 launchMode 属性为 Activity 指定的行为可由 Intent 附带的 Activity 启动标志替代，下文将对此进行讨论。 使用 Intent 标志启动 Activity 时，您可以通过在传递给 startActivity() 的 Intent 中加入相应的标志，修改 Activity 与其任务的默认关联方式。可用于修改默认行为的标志包括： FLAG_ACTIVITY_NEW_TASK 在新任务中启动 Activity。如果已为正在启动的 Activity 运行任务，则该任务会转到前台并恢复其最后状态，同时 Activity 会在 onNewIntent() 中收到新 Intent。 正如前文所述，这会产生与 “singleTask”launchMode 值相同的行为。 FLAG_ACTIVITY_SINGLE_TOP 如果正在启动的 Activity 是当前 Activity（位于返回栈的顶部），则 现有实例会接收对 onNewIntent() 的调用，而不是创建 Activity 的新实例。 正如前文所述，这会产生与 “singleTop”launchMode 值相同的行为。 FLAG_ACTIVITY_CLEAR_TOP 如果正在启动的 Activity 已在当前任务中运行，则会销毁当前任务顶部的所有 Activity，并通过 onNewIntent() 将此 Intent 传递给 Activity 已恢复的实例（现在位于顶部），而不是启动该 Activity 的新实例。 产生这种行为的 launchMode 属性没有值。 FLAG_ACTIVITY_CLEAR_TOP 通常与 FLAG_ACTIVITY_NEW_TASK 结合使用。一起使用时，通过这些标志，可以找到其他任务中的现有 Activity，并将其放入可从中响应 Intent 的位置。 注：如果指定 Activity 的启动模式为 “standard”，则该 Activity 也会从堆栈中移除，并在其位置启动一个新实例，以便处理传入的 Intent。 这是因为当启动模式为 “standard” 时，将始终为新 Intent 创建新实例。 处理关联“关联”指示 Activity 优先属于哪个任务。默认情况下，同一应用中的所有 Activity 彼此关联。 因此，默认情况下，同一应用中的所有 Activity 优先位于相同任务中。 不过，您可以修改 Activity 的默认关联。 在不同应用中定义的 Activity 可以共享关联，或者可为在同一应用中定义的 Activity 分配不同的任务关联。 可以使用 元素的 taskAffinity 属性修改任何给定 Activity 的关联。 taskAffinity 属性取字符串值，该值必须不同于在 元素中声明的默认软件包名称，因为系统使用该名称标识应用的默认任务关联。 在两种情况下，关联会起作用： 启动 Activity 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志。 默认情况下，新 Activity 会启动到调用 startActivity() 的 Activity 任务中。它将推入与调用方相同的返回栈。 但是，如果传递给 startActivity() 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志，则系统会寻找其他任务来储存新 Activity。这通常是新任务，但未做强制要求。 如果现有任务与新 Activity 具有相同关联，则会将 Activity 启动到该任务中。 否则，将开始新任务。 如果此标志导致 Activity 开始新任务，且用户按“主页”按钮离开，则必须为用户提供导航回任务的方式。 有些实体（如通知管理器）始终在外部任务中启动 Activity，而从不作为其自身的一部分启动 Activity，因此它们始终将 FLAG_ACTIVITY_NEW_TASK 放入传递给 startActivity() 的 Intent 中。请注意，如果 Activity 能够由可以使用此标志的外部实体调用，则用户可以通过独立方式返回到启动的任务，例如，使用启动器图标（任务的根 Activity 具有 CATEGORY_LAUNCHER Intent 过滤器；请参阅下面的启动任务部分）。 Activity 将其 allowTaskReparenting 属性设置为 “true”。 在这种情况下，Activity 可以从其启动的任务移动到与其具有关联的任务（如果该任务出现在前台）。 提示：如果从用户的角度来看，一个 .apk 文件包含多个“应用”，则您可能需要使用 taskAffinity 属性将不同关联分配给与每个“应用”相关的 Activity。 清理返回栈如果用户长时间离开任务，则系统会清除所有 Activity 的任务，根 Activity 除外。 当用户再次返回到任务时，仅恢复根 Activity。系统这样做的原因是，经过很长一段时间后，用户可能已经放弃之前执行的操作，返回到任务是要开始执行新的操作。 您可以使用下列几个 Activity 属性修改此行为： alwaysRetainTaskState 如果在任务的根 Activity 中将此属性设置为 “true”，则不会发生刚才所述的默认行为。即使在很长一段时间后，任务仍将所有 Activity 保留在其堆栈中。 clearTaskOnLaunch 如果在任务的根 Activity 中将此属性设置为 “true”，则每当用户离开任务然后返回时，系统都会将堆栈清除到只剩下根 Activity。 换而言之，它与 alwaysRetainTaskState 正好相反。 即使只离开任务片刻时间，用户也始终会返回到任务的初始状态。 finishOnTaskLaunch 此属性类似于 clearTaskOnLaunch，但它对单个 Activity 起作用，而非整个任务。 此外，它还有可能会导致任何 Activity 停止，包括根 Activity。 设置为 “true” 时，Activity 仍是任务的一部分，但是仅限于当前会话。如果用户离开然后返回任务，则任务将不复存在。启动任务通过为 Activity 提供一个以 “android.intent.action.MAIN” 为指定操作、以 “android.intent.category.LAUNCHER” 为指定类别的 Intent 过滤器，您可以将 Activity 设置为任务的入口点。 例如：1234567&lt;activity ... &gt; &lt;intent-filter ... &gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt; &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt; &lt;/intent-filter&gt; ...&lt;/activity&gt; 此类 Intent 过滤器会使 Activity 的图标和标签显示在应用启动器中，让用户能够启动 Activity 并在启动之后随时返回到创建的任务中。 第二个功能非常重要：用户必须能够在离开任务后，再使用此 Activity 启动器返回该任务。 因此，只有在 Activity 具有 ACTION_MAIN 和 CATEGORY_LAUNCHER 过滤器时，才应该使用将 Activity 标记为“始终启动任务”的两种启动模式，即 “singleTask” 和 “singleInstance”。例如，我们可以想像一下如果缺少过滤器会发生什么情况： Intent 启动一个 “singleTask” Activity，从而启动一个新任务，并且用户花了些时间处理该任务。然后，用户按“主页”按钮。 任务现已发送到后台，而且不可见。现在，用户无法返回到任务，因为该任务未显示在应用启动器中。 如果您并不想用户能够返回到 Activity，对于这些情况，请将 元素的 finishOnTaskLaunch 设置为 “true”（请参阅清理堆栈）。 有关如何在概览屏幕中显示和管理任务与 Activity 的更多信息，请参阅概览屏幕。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[home后从service重新启动activity延迟问题]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-starting-an-activity-from-a-service-after-home-button%2F</url>
    <content type="text"><![CDATA[问题: 在Activity界面，按下HOME键后，点击悬浮层按钮，再启动Activity， Activity要延时5S后才出来。 经验证，这个问题不是应用自身的BUG。那怕该Activity是空的，也会有这个问题 Android为了避免应用在按下HOME键退出后还可以强制把自己启动，特意加的限制。 在现有的API情况下，不能解决这个问题，除非你的应用是一个启动器（Launcher）， 添加了home/ launcher intent filter。如果你不是启动器，又要从悬浮层启动一个Activity，就把该Activity也改成悬浮层吧 1. 不从后台启动 Activity 准则：在谷歌的 Android API Guides 中，特意提醒开发者不要在后台启动 activity，包括在 Service 和 BroadcastReceiver 中，这样的设计是为了避免在用户毫不知情的情况下突然中断用户正在进行的工作，在 http://developer.android.com/guide/practices/seamlessness.html#interrupt 中有如下解释： That is, don’t call startActivity() from BroadcastReceivers or Services running in the background. Doing so will interrupt whatever application is currently running, and result in an annoyed user. Perhaps even worse, your Activity may become a “keystroke bandit” and receive some of the input the user was in the middle of providing to the previous Activity. Depending on what your application does, this could be bad news. 2. 需要违反“不从后台启动 Activity”准则的特例：特例：即便如此，手机厂商的开发者们在开发基于系统级的应用的时候，可能仍然需要有从 Service 或 BroadcastReceiver 中 startActivity 的需求，往往这样的前提是连这样的 Service 或 BroadcastReceiver 也是由用户的某些操作而触发的，Service 或 BroadcastReceiver 只是充当了即将启动 activity 之前的一些代理参数检查工作以便决定是否需要 start 该 activity。 除非是上述笔者所述的特殊情况，应用开发者都应该遵循 “不要从后台启动 Activity”准则。 一个需要特别注意的问题是，特例中所述的情况还会遇到一个问题，就是当通过 home 键将当前 activity 置于后台时，任何在后台startActivity 的操作都将会延迟 5 秒，除非该应用获取了 “android.permission.STOP_APP_SWITCHES” 权限。 关于延迟 5 秒的操作在 com.android.server.am.ActivityManagerService 中的 stopAppSwitches() 方法中，系统级的应用当获取了 “android.permission.STOP_APP_SWITCHES” 后将不会调用到这个方法来延迟通过后台启动 activity 的操作，事实上 android 原生的 Phone 应用就是这样的情况，它是一个获取了”android.permission.STOP_APP_SWITCHES” 权限的系统级应用，当有来电时，一个从后台启动的 activity 将突然出现在用户的面前，警醒用户有新的来电，这样的设计是合理的。 所以，当你需要开发类似 Phone 这样的应用时，需要做如下工作： root 你的手机； 在 AndroidManifest.xml 中添加 “android.permission.STOP_APP_SWITCHES” 用户权限； 将你开发的应用程序 push 到手机的 /system/app 目录中。 3. 参考资料：无缝的设计之——不要中断你的用户 stackoverflow 中关于后台 startActivity 被延迟 5 秒的探讨]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下C开发使用小技巧]]></title>
    <url>%2F2017%2F08%2F06%2Ftips-c-language%2F</url>
    <content type="text"><![CDATA[基础类整形,字符串互转C语言提供了几个标准库函数，可以将任意类型(整型、长整型、浮点型等)的数字转换为字符串，下面列举了各函数的方法及其说明。 ● itoa()：将整型值转换为字符串。 ● ltoa()：将长整型值转换为字符串。 ● ultoa()：将无符号长整型值转换为字符串。 ● gcvt()：将浮点型数转换为字符串，取四舍五入。 ● ecvt()：将双精度浮点型值转换为字符串，转换结果中不包含十进制小数点。 ● fcvt()：指定位数为转换精度，其余同ecvt()。 除此外，还可以使用sprintf系列函数把数字转换成字符串，其比itoa()系列函数运行速度慢 以下是用itoa()函数将整数转换为字符串的一个例子： 12345678910# include &lt;stdio.h&gt;# include &lt;stdlib.h&gt;void main (void)&#123;int num = 100;char str[25];itoa(num, str, 10);printf(&quot;The number &apos;num&apos; is %d and the string &apos;str&apos; is %s. \n&quot; ,num, str);&#125; itoa()函数有3个参数：第一个参数是要转换的数字，第二个参数是要写入转换结果的目标字符串，第三个参数是转移数字时所用 的基数。在上例中，转换基数为10。10：十进制；2：二进制… itoa并不是一个标准的C函数，它是Windows特有的，如果要写跨平台的程序，请用sprintf。是Windows平台下扩展的，标准库中有sprintf，功能比这个更强，用法跟printf类似： 12char str[255];sprintf(str, &quot;%x&quot;, 100); //将100转为16进制表示的字符串。 cpp中string转int: 1234void str2int(int &amp;int_temp,const string &amp;string_temp) &#123; int_temp=atoi(string_temp.c_str()); &#125; cpp中int转string: 123456void int2str(const int &amp;int_temp,string &amp;string_temp) &#123; char s[12]; //设定12位对于存储32位int值足够 itoa(int_temp,s,10); //itoa函数亦可以实现，但是属于C中函数，在C++中推荐用流的方法 string_temp=s; &#125; 架构类Linux C代码实现主函数参数选项解析1. 手动解析版本使用argc、argv，逐个字符比较，得到要想的参数名字即进行判断、解析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;ctype.h&gt;int debug;void show_version(char* name)&#123; printf(&quot;%s by Late Lee, version: 1.0\n&quot;, name);&#125;void usage(char* name)&#123; show_version(name); printf(&quot; -h, --help short help\n&quot;); printf(&quot; -v, --version show version\n&quot;);&#125;int main(int argc, char *argv[])&#123; int i = 0; /* early check for debug and config parameter */ if (argc &gt; 1) &#123; for (i = 1; i &lt; argc; i++) &#123; if ((strcmp(argv[i], &quot;-D&quot;)==0) || (strcmp(argv[i], &quot;--debug&quot;)==0)) &#123; debug = 1; &#125; &#125; &#125; // /* parse parameters, maybe not the best way but... */ for (i = 1; i &lt; argc; i++) &#123; if (debug) printf(&quot;arg %d: \&quot;%s\&quot;\n&quot;,i,argv[i]); // help if ((strcmp(argv[i],&quot;-h&quot;)==0) || (strcmp(argv[i],&quot;--help&quot;)==0)) &#123; usage(argv[0]); return 0; &#125; // version else if ((strcmp(argv[i],&quot;-v&quot;)==0) || (strcmp(argv[i],&quot;--version&quot;)==0)) &#123; show_version(argv[0]); return 0; &#125; // debug else if ((strcmp(argv[i],&quot;-D&quot;)==0) || (strcmp(argv[i],&quot;--debug&quot;)==0)) &#123; debug=1; &#125; else if ((strcmp(argv[i],&quot;fpga&quot;)==0)) &#123; printf(&quot;test of fpga...\n&quot;); &#125; // string else if ((strcmp(argv[i],&quot;-i&quot;)==0) || (strcmp(argv[i],&quot;--iface&quot;)==0)) &#123; if (i+1&lt;argc) &#123; char interface[32] = &#123;0&#125;; strncpy(interface, argv[i+1], 32); if (debug) printf(&quot;Used interface: %s\n&quot;, interface); i++; continue; &#125; else &#123; printf(&quot;Error: Interface for -i missing.\n&quot;); return 1; &#125; &#125; // number else if ((strcmp(argv[i],&quot;-ru&quot;)==0) || (strcmp(argv[i],&quot;--rateunit&quot;))==0) &#123; if (i+1&lt;argc &amp;&amp; isdigit(argv[i+1][0])) &#123; int rateunit = 0; rateunit = atoi(argv[i+1]); if (rateunit &lt; 0 || rateunit &gt; 1) &#123; printf(&quot;Error: Invalid parameter \&quot;%d\&quot; for --rateunit.\n&quot;, rateunit); printf(&quot; Valid parameters:\n&quot;); printf(&quot; 0 - bytes\n&quot;); printf(&quot; 1 - bits\n&quot;); return 1; &#125; if (debug) printf(&quot;Rateunit changed: %d\n&quot;, rateunit); i++; continue; &#125; else &#123; &#125; &#125; // only one else if (strcmp(argv[i],&quot;--enable&quot;)==0) &#123; int enable = 0; enable = 1; &#125; else &#123; printf(&quot;Unknown parameter \&quot;%s\&quot;. Use --help for help.\n&quot;,argv[i]); return 1; &#125; &#125;&#125; 2. 利用getopt函数完成123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140/**解析命令选项示例#include &lt;unistd.h&gt;extern char *optarg; //选项的参数指针extern int optind, //下一次调用getopt的时，从optind存储的位置处重新开始检查选项。extern int opterr, //当opterr=0时，getopt不向stderr输出错误信息。extern int optopt; //当命令行选项字符不包括在optstring中或者选项缺少必要的参数时，该选项存储在optopt中，getopt返回&apos;？’、int getopt(int argc, char * const argv[], const char *optstring);使用：$ ./a.out -Wall -o hello.c*/#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdarg.h&gt;int debug_level = 0;#define _AUTHOR &quot;Late Lee&quot;#define _VERSION_STR &quot;1.0&quot;#define _DATE &quot;&quot;// 默认打印error等级enum&#123; MSG_ERROR = 0, MSG_WARNING, MSG_INFO, MSG_DEBUG, MSG_MSGDUMP, MSG_EXCESSIVE,&#125;;void ll_printf(int level, const char *fmt, ...) __attribute__ ((format (printf, 2, 3)));void ll_printf(int level, const char *fmt, ...)&#123; va_list ap; va_start(ap, fmt); if (debug_level &gt;= level) &#123;#ifdef CONFIG_DEBUG_SYSLOG if (wpa_debug_syslog) &#123; vsyslog(syslog_priority(level), fmt, ap); &#125; else &#123;#endif /* CONFIG_DEBUG_SYSLOG */ //debug_print_timestamp();#ifdef CONFIG_DEBUG_FILE if (out_file) &#123; vfprintf(out_file, fmt, ap); fprintf(out_file, &quot;\n&quot;); &#125; else &#123;#endif /* CONFIG_DEBUG_FILE */ vprintf(fmt, ap); printf(&quot;\n&quot;);#ifdef CONFIG_DEBUG_FILE &#125;#endif /* CONFIG_DEBUG_FILE */#ifdef CONFIG_DEBUG_SYSLOG &#125;#endif /* CONFIG_DEBUG_SYSLOG */ &#125; va_end(ap);&#125;void show_version(char* name)&#123; printf(&quot;%s by %s, version: %s\n&quot;, name, _AUTHOR, _VERSION_STR);&#125;void usage(char* name)&#123; show_version(name); printf(&quot; -h, short help\n&quot;); printf(&quot; -v, show version\n&quot;); printf(&quot; -d, debug level\n&quot;); exit(0);&#125;const char* my_opt = &quot;hOo:W:d:&quot;;int main(int argc, char *argv[])&#123; int c; const char* p1 = NULL; const char* p2 = NULL; const char* p3 = NULL; while(1) &#123; c = getopt(argc, argv, my_opt); printf(&quot;optind: %d\n&quot;, optind); if (c &lt; 0) &#123; break; &#125; printf(&quot;option char: %x %c\n&quot;, c, c); switch(c) &#123; case &apos;d&apos;: debug_level = atoi(optarg); printf(&quot;debug level: %d\n&quot;, debug_level); break; case &apos;O&apos;: printf(&quot;optimization flag is open.\n\n&quot;); break; case &apos;o&apos;: printf(&quot;the obj is: %s\n\n&quot;, optarg); p1 = optarg; break; case &apos;W&apos;: printf(&quot;optarg: %s\n\n&quot;, optarg); p2 = optarg; break; case &apos;:&apos;: fprintf(stderr, &quot;miss option char in optstring.\n&quot;); break; case &apos;?&apos;: case &apos;h&apos;: default: usage(argv[0]); break; //return 0; &#125; &#125; if (optind == 1) &#123; usage(argv[0]); &#125; ll_printf(MSG_ERROR, &quot;p1: %s p2: %s\n&quot;, p1, p2); return 0;&#125; 使用 getopt() 进行命令行处理 网络模块 日志模块读取配置文件模块内存池模块缓存库模块文件系统模块管理后台模块数据库模块技巧类Linux程序中预定义的几个调试宏Linux下C语言编程中有几个很实用的调试宏 1__LINE__ __FILE__ __FUNCTION__ __TIME__ __DATA__ 这几个预定义宏是属于ANSI标准的，内置于编译器，全局性的变量，可以方便地实现代码跟踪调试，不是在哪个头文件中包含的，见下例： 1234567891011#include &lt;stdio.h&gt;int main()&#123; printf(&quot;The file is %s.\n&quot;,__FILE__); printf( &quot;The date is %s.\n&quot;, __DATE__ ); printf( &quot;The time is %s.\n&quot;, __TIME__ ); printf( &quot;This is line %d.\n&quot;, __LINE__ ); printf( &quot;This function is %s.\n&quot;, __FUNCTION__ ); return 0;&#125; 运行结果: 12345The file is macro.c.The date is Aug 24 2012.The time is 23:13:26.This is line 8.This function is main. line 行数 文件名指令可以改变它的值，简单的讲，编译时，它们包含程序的当前行数和文件名。 DATE 宏指令含有形式为月/日/年的串,表示源文件被翻译到代码时的日期。 TIME 宏指令包含程序编译的时间。时间用字符串表示，其形式为时：分：秒 __func__代表这条语句所在的函数的函数名 联合体用途字节序有两种表示方法：大端法（big ending），小端法（little ending）。网络字节序采用的是大端法。主机字节序不同的CPU采用的方法不一样，可以通过代码来查看自己主机的字节序。 大端法：高位字节排放在内存低地址端，低位字节排放在内存的高地址端。 小端法：低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 看一个unsigned short 数据，它占2个字节，给它赋值0x1234。 若采用的大端法，则其低地址端应该存放的是0x12； 若采用的小端法，则其低地址端应该存放的是0x34； 可以通过联合体来获得其高低地址的数据。测试主机字节序的代码：123456789101112131415161718192021typedef union&#123; unsigned short value; unsigned char bytes[2];&#125;Test;int main(void)&#123; Test test_value; test_value.value = 0x1234; if(test_value.bytes[0] == 0x12 &amp;&amp; test_value.bytes[1] == 0x34) &#123; printf(&quot;big ending&quot;); &#125; else if(test_value.bytes[0] == 0x34 &amp;&amp; test_value.bytes[1] == 0x12) &#123; printf(&quot;little ending&quot;); &#125;else&#123; printf(&quot;use test_value error&quot;); &#125; return 0;&#125; 工具类自定义日志的调试打印信息12345678910111213141516171819202122232425#define TRACE_NONE 0#define TRACE_FATAL 1#define TRACE_ERROR 2#define TRACE_WARNING 3#define TRACE_INFO 4#define TRACE_DEBUG 5#define TRACE_LEN_MAX 64extern int *TraceLevel;extern char TraceName[TRACE_LEN_MAX + 1];#define Log(A, format,args...) \ ((TraceLevel == NULL || TraceName == NULL || *TraceLevel &lt; (A)) ? 0 : LogMsg(A, __FILE__, __LINE__, format, ##args))#define LogFatal(format,args...) \ Log(TRACE_FATAL, format, ##args)#define LogError(format,args...) \ Log(TRACE_ERROR, format, ##args)#define LogWarning(format,args...) \ Log(TRACE_WARNING, format, ##args)#define LogInfo(format,args...) \ Log(TRACE_INFO, format, ##args)#define LogDebug(format,args...) \ Log(TRACE_DEBUG, format, ##args) 12345678910111213141516171819202122232425262728293031int LogMsg(int level, const char *filename, int line, const char *fmt, ...)&#123; va_list ap; FILE *fp; char sLogFile[128 + 1]; char sCurrTime[6 + 1]; struct timeb tTimeB; char sMilliTM[4]; memset(sLogFile, 0, sizeof(sLogFile)); LogFile(sLogFile); GetTime_HHMMSS(sCurrTime); memset(&amp;tTimeB, 0, sizeof(tTimeB)); ftime(&amp;tTimeB); snprintf(sMilliTM, sizeof(sMilliTM), &quot;%03d&quot;, tTimeB.millitm); fp = fopen(sLogFile, &quot;a+&quot;); if (fp != (FILE*)NULL) &#123; fprintf(fp, &quot;[%08d][%.6s:%.3s][%16s][%04d][%7s]&quot;, getpid(), sCurrTime, sMilliTM, filename, line, g_LevelDsp[level]); va_start(ap, fmt); vfprintf(fp, fmt, ap); va_end(ap); fprintf(fp, &quot;\n&quot;); fflush(fp); fclose(fp); &#125; return 0;&#125; 再在后台进程中设置TraceLevel和TraceName即可。 获取当前系统日期、时间12345678910111213141516171819202122232425/***************************************************************************** ** 函数名称: GetDate ** 功能描述: 取当前系统日期 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psDate -- 系统日期, 格式为yyyymmdd ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetDate(char * psDate)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统日期, 格式：YYYYMMDD */ sprintf( psDate,&quot;%04d%02d%02d&quot;, pTM-&gt;tm_year + 1900, pTM-&gt;tm_mon + 1,pTM-&gt;tm_mday ); return 0;&#125; 12345678910111213141516171819202122232425/***************************************************************************** ** 函数名称: GetTime ** 功能描述: 取当前系统时间 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psTime -- 系统时间, 格式为HHMMSS ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetTime(char * psTime)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统时间, 格式：HHMMSS */ sprintf( psTime,&quot;%02d%02d%02d&quot;, pTM-&gt;tm_hour,pTM-&gt;tm_min, pTM-&gt;tm_sec); return 0;&#125; 1234567891011121314151617181920212223242526/***************************************************************************** ** 函数名称: GetDateTime ** 功能描述: 取当前系统日期和时间 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psDateTime -- 系统日期时间, 格式为yyyymmddHHMMSS ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetDateTime(char * psDateTime)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统日期和时间, 格式：yyyymmddHHMMSS */ sprintf( psDateTime,&quot;%04d%02d%02d%02d%02d%02d&quot;, pTM-&gt;tm_year + 1900, pTM-&gt;tm_mon + 1,pTM-&gt;tm_mday, pTM-&gt;tm_hour,pTM-&gt;tm_min, pTM-&gt;tm_sec ); return 0;&#125; 调用的时候定义一个char数组，大小为日期的长度大小加1，然后直接调用上面的函数，参数为数组名即可。 当然，还有其他许多关于日期、时间操作的函数，比如不同日期、时间格式间的转换等。]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FQA]]></title>
    <url>%2F2017%2F07%2F25%2FFQA%2F</url>
    <content type="text"><![CDATA[ssh连接服务器出错12345678910111213@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the RSA key sent by the remote host isda:f7:3e:ba:f7:00:e6:44:76:f2:58:6e:48:**.Please contact your system administrator.Add correct host key in /用户home目录/.ssh/known_hosts to get rid of this message.Offending RSA key in /用户home目录/.ssh/known_hosts:1RSA host key for ip地址 has changed and you have requested strict checking.Host key verification failed. 出现这个问题的原因是,第一次使用SSH连接时，会生成一个认证，储存在客户端的known_hosts中. 可使用以下指令查看: 1ssh-keygen -l -f ~/.ssh/known_hosts 由于服务器重新安装系统了，所以会出现以上错误。 解决办法: 1ssh-keygen -R 服务器端的ip地址 或者直接在known_hosts中删除对应ip的行]]></content>
  </entry>
  <entry>
    <title><![CDATA[Webrtc线程模型]]></title>
    <url>%2F2017%2F07%2F23%2Fwebrtc-source-thread%2F</url>
    <content type="text"><![CDATA[webrtc的base的 thread，是我见过的封装最帅的c++线程库，根据比qt的还好用,发个例子给你 1234567891011121314151617181920212223242526 using namespace webrtc;using namespace rtc;//std::cout&lt;&lt;&quot;Thread::Current()：&quot; &lt;&lt; Thread::Current()-&gt;GetId();//Thread::Current()-&gt;Start(); 不能调用start，因为不是我创建的，他已经开始了 //Thread::Current()-&gt;Run(); //阻塞当前线程进入线程循环Thread * thread = new Thread();//MyRunnable run;//thread-&gt;Start(&amp;run);//可以带一个Runnable参数运行,运行完就结束，否则运行Thread::Run进入消息循环thread-&gt;Start();//std::cout &lt;&lt; &quot;Thread::Invoke()：&quot;&lt;&lt; thread-&gt;Invoke&lt;bool&gt;(RTC_FROM_HERE, &amp;task)&lt;&lt; &quot; at &quot; &lt;&lt; Thread::Current()-&gt;GetId() &lt;&lt; std::endl;thread-&gt;Post(RTC_FROM_HERE, Bind(task2));//将最常用的auto handler= new MessageClient;//thread-&gt;PostAt(RTC_FROM_HERE, (int64_t)3000,handler);//thread-&gt;PostDelayed(RTC_FROM_HERE, (int64_t)5000, handler);//thread-&gt;Stop();Thread * thread2 = new Thread();thread2-&gt;Start();thread2-&gt;Post(RTC_FROM_HERE, Bind(task2));//将最常用的//thread2-&gt;Invoke() 非常有用，在任何地方可以指定我的代码运行在某个线程//api下的proxy机制，实际上就是设置要执行的线程，然后加锁等待线程执行结果。这是我设计对外接口可以在任何线程调用而不出错的常用方法//base的asyncinvoker与proxy类似的机制。 有ios的gdc，android的handler异曲同工 因为编写复杂稳定的多线程C++项目实在太难，所以一个好的跨平台C++基础库是我最求的目标,目前比较欣赏的项目有： Boost:大而全，缺少一些可以直接上手的东西如线程消息队列，智能指针并非线程安全。 QT core：非常好 C++11：也需要线程消息队列，线程安全智能指针。 chromium的base库：太大了 当我看到webrtc的base时，非常惊讶的发现它正是我想要的,特点： 小：只有几M 纯：基于c++标准库和各操作系统sdk 跨平台 对智能指针、线程、socket封装非常好。 不断更新（需要一直跟踪官方代码） 移植出来单独使用，方案有三： 把源码拷贝出来用通用的编译工具（makefile，cmake，qmake）管理。（makefile较复杂，cmake简单，qmake最简单） 把源码拷贝出来用基于自带的gn管理 在webrtc项目里面编译和合并需要的静态库和pdb 因为google官方说了：引用计数+引用计数的智能化（scoped_ref_ptr）+弱引用就可以解决问题。 shared_ptr不是线程安全的，因为shared_ptr有两个成员：引用计数，和源对象指针。没办法对两个成员同时实现原子操作。 但unique_ptr是个好东西 智能指针的使用： 不用再使用delete。 尽量使用unique_ptr。 多个线程读写同一个 shared_ptr 对象，那么需要加锁。 shared_ptr 和weak_ptr配合解决循环引用的问题。 weak_ptr必须，oc，swift的ViewControler和控件都是weak关系 内存管理模型的三种级别： 1 手动内存管理(c/c++的malloc与free，new与delete)：容易出错。 2 自动内存管理（oc的arc，c++的智能指针，scoped_ptr）：存在循环引用问题，通过程序员自己管理强弱引用关系解决。 3 垃圾回收机制（如java,python）：后台GC降低了程序效率，好的程序员仍然好考虑java的强引用[表情]引用/软引用/ 3 线程模型 1 生产者消费模型（mutex，condition）：最最常用的模型。 2 线程池模型：解决大量请求分配太多线程的问题。比如一个android和ios的app，http请求会很多很多。 3 (着重强调）串行模型：ios有GCD(Grand Central Dispatch，global queue是线程池），android有looper， win32有PostMessage，boost有strand 读写锁：特别只有写才会不安全的情况。 再结合其他的手段会让程序简洁优美易读：java的handler，oc的delegate和block、swift的闭包，mvc模式 ，c++的function/bind/lambda，python和javascript的function 而串行模型就成了解决这类多线程问题的首选，就是线程消息模型。 在android 系统里面，无数这样的例子。 模块处理线程Call构造方法中创建module_process_thread与pacer_thread两个ProcessThread.接着为module_process_thread注册CallStats, ReceiveSideCongestionController, SendSideCongestionController模块,为pacer_thread注册PacedSender, RemoteBitrateEstimator模块. Call::CreateVideoSendStream创建VideoSendStream时,将module_process_thread做构造参数传入,调用RegisterProcessThread方法,注册所有的rtc_rtcp模块到module_process_thread线程.同样的为VideoReceiveStream中设置.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidStudio常见问题]]></title>
    <url>%2F2017%2F07%2F23%2Ftips-androidstudio%2F</url>
    <content type="text"><![CDATA[如何解决Unsupported major.minor version 52.0问题？ http://www.jianshu.com/p/5eebd3c609d6 运行./gradlew :PandaAndroidDemo:release出现如下错误： 12345678910111213FAILURE: Build failed with an exception.* Where:Build file &apos;/Users/shitianci/work/Lab/panda.android/PandaAndroidDemo/build.gradle&apos; line: 1* What went wrong:A problem occurred evaluating project &apos;:PandaAndroidDemo&apos;.&gt; java.lang.UnsupportedClassVersionError: com/android/build/gradle/AppPlugin : Unsupported major.minor version 52.0* Try:Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.BUILD FAILED 直接点击 run按钮 或者 Build→Generate Build APK 却运行正常。 这里面有两个问题： 为什么出现Unsupported major.minor version 52.0？ 为什么gradle命令和android studio按钮运行结果不一样？ 问题一：为什么出现Unsupported major.minor version 52.0？在网上找了一圈，最后在stackoverflow找到了本质原因 12345You get this error because a Java 7 VM tries to load a class compiled for Java 8Java 8 has the class file version 52.0 but a Java 7 VM can only load class files up to version 51.0In your case the Java 7 VM is your gradle build and the class is com.android.build.gradle.AppPlugin 简单来说，就是java的编译环境版本太低，java 8 class file的版本是52，Java 7虚拟机只能支持到51。所以需要升级到java 8 vm才行。 问题二：为什么gradle命令和android studio按钮运行结果不一样？从问题1来看，肯定Android Studio按钮调用的是java 8 vm，所以查找一下系统配置，最终在Project Structure找到了如下设置： Android Studio 2.2.2使用了自带的JDK环境，其地址为 1/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home 而gradle命令的执行环境是在gradle.properties配置的，其指向为： 1org.gradle.java.home=/Library/Java/JavaVirtualMachines/jdk1.7.0_71.jdk/Contents/home 将其修改为： 1org.gradle.java.home=/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home INSTALL_PARSE_FAILED_NO_CERTIFICATES安装问题Android studio 更新到25后打包问题，打包后的应用安装提示：INSTALL_PARSE_FAILED_NO_CERTIFICATES Android N 引入一项新的应用签名方案 APK Signature Scheme v2，它能提供更快的应用安装时间和更多针对未授权 APK 文件更改的保护。 在默认情况下，Android Studio 2.2 和 Android Gradle 2.2 插件会使用 APK Signature Scheme v2 和传统签名方案来签署您的应用。 脏的解决方式：使用v1打包 INSTALL FAILED CONFLICTING PROVIDER问题完美解决方案在安装Android应用时出现INSTALL FAILED CONFLICTING PROVIDER问题，是不是感觉很抓狂呢，下面就跟大家分享一下出现这个问题的原因及解决方案。 问题原因: 在Android中authority要求必须是唯一的，比如你在定义一个provider时需要为它指定一个唯一的authority。如果你在安装一个带有provider的应用时，系统会检查当前已安装应用的authority是否和你要安装应用的authority相同，如果相同则会弹出上述警告，并且安装失败。 解决方案 在定义provider是，使用软编码的形式，如下： 123456789&lt;provider android:name=&quot;android.support.v4.content.FileProvider&quot; android:authorities=&quot;$&#123;applicationId&#125;.fileprovider&quot; android:grantUriPermissions=&quot;true&quot; android:exported=&quot;false&quot;&gt; &lt;meta-data android:name=&quot;android.support.FILE_PROVIDER_PATHS&quot; android:resource=&quot;@xml/file_paths&quot; /&gt;&lt;/provider&gt; 上述代码中通过${applicationId}.fileprovider的形式来指定provider的authorities，所以该provider的authorities会根据applicationId的不同而不同，从而避免了authorities的冲突问题。 那么如何使用刚才定义的authorities呢？ 我们在定义authorities是采用了applicationId+fileprovider的形式，在获取authorities的时候，我们就可以通过包名+fileprovider来获取，代码如下: 123public final static String getFileProviderName(Context context)&#123; return context.getPackageName()+&quot;.fileprovider&quot;;&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>AndroidStudio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RFC3550 RTP中文版]]></title>
    <url>%2F2017%2F07%2F22%2Fp-rfc-3550-zh%2F</url>
    <content type="text"><![CDATA[RFC3550 RTP：实时应用程序传输协议 摘要 本文描述RTP（real-time transport protocol），实时传输协议。RTP在多点传送（多播）或单点传送（单播）的网络服务上，提供端对端的网络传输功能，适合应用程序传输实时数据，如：音频，视频或者仿真数据。RTP没有为实时服务提供资源预留的功能，也不能保证QoS（服务质量）。数据传输功能由一个控制协议（RTCP）来扩展，通过扩展，可以用一种方式对数据传输进行监测控制，该协议（RTCP）可以升级到大型的多点传送（多播）网络，并提供最小限度的控制和鉴别功能。RTP和RTCP被设计成和下面的传输层和网络层无关。协议支持RTP标准的转换器和混合器的使用。 本文的大多数内容和旧版的RFC1889相同。在线路里传输的数据包格式没有改变，唯一的改变是使用协议的规则和控制算法。为了最小化传输，发送RTCP数据包时超过了设定的速率，而在这时，很多的参与者同时加入了一个会话，在这样的情况下，一个新加入到（用于计算的可升级的）计时器算法中的元素是最大的改变。 目录（Table of Contents） 1 引言 （Introduction） 1 1 术语（Terminology） 2 RTP使用场景（RTP Use Scenarios） 2 1 简单多播音频会议（ Simple Multicast Audio Conference） 2 2 音频和视频会议（Audio and Video Conference） 2 3 混频器和转换器（Mixers and Translators） 2 4 分层编码（Layered Encodings） 3 定义（Definitions） 4 字节序，校正和时间格式（Byte Order, Alignment, and Time Format） 5 RTP数据传输协议（RTP Data Transfer Protocol） 5 1 RTP固定头域（RTP Fixed Header Fields） 5 2 多路复用RTP会话（Multiplexing RTP Sessions） 5 3 RTP头的配置文件详细变更（Profile-Specific Modifications to the RTP Header） 5 3 1 RTP报头扩展（RTP Header Extension） 6 RTP控制协议（RTP Control Protocol） – RTCP 6 1 RTCP包格式（RTCP Packet Format） 6 2 RTCP传输间隔（RTCP Transmission Interval） 6 2 1 维护会话成员数目（Maintaining the number of session members） 6 3 RTCP包的发送与接收规则（RTCP Packet Send and Receive Rules） 6 3 1 计算RTCP传输间隔（Computing the RTCP Transmission Interval） 6 3 2 初始化（Initialization） 6 3 3 接收RTP或RTCP（非BYE)包（Receiving an RTP or Non-BYE RTCP Packet） 6 3 4 接收RTCP（BYE）包（Receiving an RTCP BYE Packet） 6 3 5 SSRC计时失效（Timing Out an SSRC） 6 3 6 关于传输计时器的到期（Expiration of Transmission Timer） 6 3 7 传输一个 BYE 包（Transmitting a BYE Packet） 6 3 8 更新we_sent（Updating we_sent） 6 3 9 分配源描述带宽（Allocation of Source Description Bandwidth） 6 4 发送方和接收方报告（Sender and Receiver Reports） 6 4 1 SR：发送方报告的RTCP包（SR: Sender report RTCP packet） 6 4 2 RR：接收方报告的RTCP包（RR: Receiver Report RTCP Packet） 6 4 3 扩展发送方和接收方报告（Extending the Sender and Receiver Reports ） 6 4 4 分析发送方和接收方报告（Analyzing Sender and Receiver Reports ） 6 5 SDES：源描述RTCP包（SDES: Source description RTCP packet） 6 5 1 CNAME：规范终端标识符的SDES数据项(CNAME: Canonical End-Point Identifier SDES Item） 6 5 2 NAME：用户名的SDES数据项（NAME: User name SDES item) 6 5 3 EMAIL:电子邮件地址的SDES数据项（EMAIL: Electronic Mail Address SDES Item） 6 5 4 PHONE：电话号码的SDES数据项（PHONE: Phone Number SDES Item） 6 5 5 LOC:地理用户地址的SDES数据项（LOC: Geographic User Location SDES Item） 6 5 6 TOOL：应用程序或工具名字的SDES数据项（TOOL: Application or Tool Name SDES Item） 6 5 7 NOTE：通知/状态的SDES数据项（NOTE: Notice/Status SDES Item） 6 5 8 PRIV:私有扩展的SDES数据项（PRIV: Private Extensions SDES Item） 6 6 BYE：Goodbye RTCP包（BYE: Goodbye RTCP packet） 6 7 APP:定义应用程序的RTCP包（APP: Application-Defined RTCP Packet） 7 RTP转换器和混频器（RTP Translators and Mixers） 7 1 概述（General Description ） 7 2 在转换器中的RTCP数据处理（RTCP Processing in Translators） 7 3 在混频器中的RTCP数据处理（RTCP Processing in Mixers ） 7 4 级联混频器（Cascaded Mixers） 8 SSRC标识符的分配和使用（SSRC Identifier Allocation and Use） 8 1 冲突概率（Probability of Collision ） 8 2 冲突解决和循环检测（Collision Resolution and Loop Detection） 8 3 在分层编码中使用（Use with Layered Encodings） 9 安全（Security ） 9 1 机密性（Confidentiality） 9 2 身份验证和消息完整性（Authentication and Message Integrity） 10 拥塞控制（Congestion Control） 11 网络和传输协议之上的RTP（RTP over Network and Transport Protocols） 12 协议常量摘要（Summary of Protocol Constants） 12 1 RTCP 包类型（RTCP Packet Types） 12 2 SDES 类型（SDES Types） 13 RTP概况和负载格式详细说明 （RTP Profiles and Payload Format Specifications） 14 安全考虑（Security Considerations） 15 IANA考虑（IANA Considerations） 16 知识产权声明（Intellectual Property Rights Statement） 17 鸣谢（Acknowledgments） 附录 A 算法（Algorithms） 附录 A 1 RTP数据头有效性检查（RTP Data Header Validity Checks ） 附录 A 2 RTCP数据头有效性检查（RTCP Header Validity Checks） 附录 A 3 确定RTP包预期数目和丢失数目（Determining Number of Packets Expected and Lost） 附录 A 4 生成SDES RTCP包（Generating RTCP SDES Packets） 附录 A 5 解析RTCP SDES包（Parsing RTCP SDES Packets） 附录 A 6 生成32位随机标识符（Generating a Random 32-bit Identifier 附录 A 7 计算RTCP传输间隔（Computing the RTCP Transmission Interval） 附录 A 8 估测两次到达间隔的抖动（Estimating the Interarrival Jitter） 附录 B 与RFC1889不同之外（Changes from RFC 1889） 参考书目（References） 标准化引用（Normative References ） 资料性引用（Informative References） 作者地址 完整的版权声明 1.绪论 本文详细的介绍实时传输协议RTP，RTP提供带有实时特性的端对端数据传输服务，传输的数据如：交互式的音频和视频。那些服务包括有效载荷类型定义，序列号，时间戳和传输监测控制。应用程序在UDP上运行RTP来使用它的多路技术和checksum服务。2种协议都提供传输协议的部分功能。不过，RTP可能被其他适当的下层网络和传输协议使用（见11节）。如果下层网络支持，RTP支持数据使用多播分发机制转发到多个目的地。 注意RTP本身没有提供任何的机制来确保实时的传输或其他的服务质量保证，而是由低层的服务来完成。它不保证传输或防止乱序传输，它不假定下层网络是否可靠，是否按顺序传送数据包。RTP包含的序列号允许接受方重构发送方的数据包顺序，但序列号也用来确定一个数据包的正确位置，例如，在视频解码的时候不用按顺序的对数据包进行解码。 但是RTP原先的设计是用来满足多参与者的多媒体会议的需要，它没有限定于专门的应用。连续数据的储存，交互分布式仿真，动态标记，以及控制和测量应用程序也可能会适合使用RTP。 该文档定义RTP，由2个密切联系的部分组成： ○实时传输协议RTP，用于实时传输数据。 ○RTP控制协议RTCP，用于监控服务质量和传达关于在一个正在进行的会议中的参与者的信息。后者对“宽松控制”的会议可能已经足够，但是并没有必要去支持一个应用程序所有的通讯控制条件。这个功能可能充分的或者部分的被一个单独的会议控制协议所包含，这超过了本文档的范围。 RTP表现了协议的一种新的类型，该类型由Clark和Tennenhouse提出[10]，遵循应用级（framing）框架和（integrated layer processing）统一层处理的原则。就是说，RTP被规定为可扩展的，用来提供一个专门的应用程序需要的信息，并将会经常性的被归并到应用程序的处理中，而不是作为一个单独的层被实现。RTP只是一个故意不完成的协议框架。本文档详细说明那些功能，希望这些功能能够普遍贯穿于所有适合使用RTP的应用程序。和常规的协议不同，额外的功能可能通过完善协议本身或者增加一个可能需要分析的选项机制来增加，RTP被规定为可以根据需要通过修改和/或增加操作，“剪裁”到报头。具体的例子见5.3和6.4.3节。 因此，除了本文档，用于专门应用程序的RTP完整的说明将还需要一个或者更多的同类文档（见13节）： ○ 一个框架（大致轮廓）的说明文档，该文档定义了一系列的有效载荷类型编码和它们与有效载荷格式之间的映射（例如，媒体编码）。一个框架可能也定义了应用程序对RTP的一些扩展和修改，详细到一个专门的类。典型的情况，一个应用程序将在一个框架下运行。一个用于音频和视频数据的框架可以在同类RFC3551[1]文档里找到。 ○有效载荷格式说明文档，该文档定义了一个像一个音频或者视频编码的特殊载荷，在RTP里是如何被传输的。 一个关于实时服务和算法如何实现的讨论和关于一些RTP设计结果的后台讨论能够在[11]中找到。 1.1术语 在这个文档里的关键词“一定要”，“一定不能”，“必需的”，“会”，“不会”，“应该”，“不应该”，“推荐”，“可能”和“可选” 将会像在BCP 14（Basic Control Program，基本控制程序），RFC2119[2]里描述一样的解释。并指出适合RTP实现的需要的级别。 2 RTP使用场景（RTP Use Scenarios） 2.1 简单多播音频会议（ Simple Multicast Audio Conference） 2.2 音频和视频会议（Audio and Video Conference） 2.3 混频器和转换器（Mixers and Translators） 2.4 分层编码（Layered Encodings） 以下章节描述了用到RTP的一些方面。所举例子用来说明RTP应用的基本操作，但RTP的用途不限于此。在这些例子中，RTP运行于IP和UDP之上，并且遵循RFC3551所描述的音频和视频的配置文件中的约定。 2.1 简单多播音频会议（Simple Multicast Audio Conference） IETF的一个工作组开会讨论最新协议草案时，使用Internet的IP多播服务来进行语音通讯。工作组中心分配到一个多播的组地址和一对端口。一个端口用于音频数据，另一个端口用于控制（RTCP）数据包。该地址和端口信息发布给预定的参与者。如果有私密性要求，则可用章节9.1中说明的方法，对数据和控制包进行加密，这时就需要生成和发布加密密钥。分配和发布机制的精确细节不在RTP的讨论范围之内。 每个与会者所使用的音频会议应用程序，都以小块形式（比方说持续２０秒时间）来发送音频数据。每个音频数据块都前导RTP报头；RTP报头和数据依次包含在UDP包里。RTP报头指明了各个包里音频编码的类型（如PCM,ADPCM,LPC），这样发送方可以在会议过程中改变编码方式，以适应状况的变化，例如，要加进一个低带宽接入的参与者，或是要应付网络拥塞。 Internet，像其他的报文分组网络一样，偶而会丢失和重排包，造成时长不等的延迟。为弥补这个不足，RTP报头里包含计时信息和一个序列号，允许接收方重建来自源的计时信息，比如前文例子中音频块以20s的间隔在扬声器中连续播放。会议中，对每个RTP包的源,单独地实施计时重建。序列号还被接收方用来评估丢失包数目。 由于会议期间不断有工作组成员加入或离开，因此有必要知道任一时刻的实际参与者及他们接收音频数据的状况好坏。出于这个目的，会议中每个音频应用程序的实例，都在RTCP（控制）端口上周期性地多播一个附加用户名的接收报告。接收报告指明了当前说话者被收听到的状况，可用于控制自适应性编码。除了用户名外，通过控制带宽限度，可以包含其他标识信息。一个站点在离开会议时发送RTCP BYE包（章节6.5）。 2.2 音频和视频会议（Audio and Video Conference） 一个会议如果同时使用音频和视频媒体，则二者传输时使用不同的RTP会话。也就是说，两种媒体中RTP包和RTCP包的传输，是使用两个不同的UDP端口对和（或）多播地址。在RTP层次，音频和视频会话没有直接的耦合，下面这种情况除外：一个同时参加两个会话的参与者，在两个会话的RTCP包中，使用了相同的规范名，这样两个会话就发生关联（耦合）了。 这样区隔开来的目的之一，是允许一些会议参与者只接受自己选择的单一媒体（或者音频，或者视频）。更进一步的说明在章节5.2给出。尽管两种媒体区分开来了，但通过两个会话RTCP包内载有的计时信息，同源的音频与视频还是能够同步回放。 2.3 混频器和转换器（Mixers and Translators） 到目前为止，我们皆假设所有站点都收到相同格式的媒体数据。然而这并不总是行得通。考虑一下这种情况，一个地方的参与者只能低速接入会议，而其他大部分参与者都能享受高速连接。与其让强迫大家都忍受低带宽，不如在只能低速接入的地方，放置一个减质量音频编码的RTP层次的中继（称作混频器）。混频器将重新同步输入的音频包，重建发送方产生的20ms固定间隔，混频已重建过的音频流为单一的流，转换音频编码为低带宽格式，最后通过低带宽连接转发数据包流（package stream)。这些包可能被单播到一个接收方，也可能多播到另一个的地址而发给多个接收方。RTP报头为混频器提供了一种方法，使其能辨识出对混频后的包有用的源，从而保证提供给接收方正确的说话者指示。 在音频会议中，一些预定参与者尽管有高带宽连接，但不能通过IP多播直接接入会议。例如，他们可能位于一个不允许任何IP包通过的应用层防火墙后面。对这些站点，可能就不需要混频，而需要另一种称为转换器的RTP层次中继。可以在防火墙两侧分别安装一个转换器，外侧转换器将所有多播包通过安全连接转入内侧转换器，内侧转换器再转发给内部网的一个多播组（multicast group)。 混频器和转换器可以设计成用于各种目的。比如，一个视频混频器在测量多个不同视频流中各人的单独影像后，将它们组合成一个单一视频流来模拟群组场景。又如，在只用IP/UDP和只用ST_II的两个主机群之间通过转换建立连接。再如，在没有重新同步或混频时，用packet-by-packet编码转换来自各个独立源的视频流。混频器和转换器的操作细节见章节7。 2.4 分层编码（Layered Encodings） 为了匹配接收方的能力（容量）以及适应网络拥塞，多媒体应用程序应当能够调整其传输速率。许多应用实现把调适传输速率的责任放在源端。这种做法在多播传输中并不好，因为不同接收方对带宽存在着冲突性需求。这经常导致最小公分母的场景，网格中最小的管道支配了全部实况多媒体“广播”的质量和保真度。 相反地，可以把分层编码和分层传输系统组合起来，从而把调适速率的责任放在接收端。在IP多播之上的RTP上下文中，对一个横跨多个RTP会话（每个会话在独自多播组上开展）的分级表示信号(a hierarchically represented signal)，源能够把它的分层（layers)分割成条。 接收方仅需合并适当的多播组子集，就能适应异种网络和控制接收带宽。 RTP分层编码的细节在章节6.3.9，8.3和11中给出。 3. 定义（definitions) RTP负载（RTP payload）：通过RTP传输的包中的数据，例如，音频样本或压缩好的视频数据。负载格式与解释不在本文讨论范围。 RTP包（RTP packet）：一种数据包，其组成部分有：一个固定RTP报头，一个可能为空的作用源（contributing sources）列表（见下文），以及负载数据。一些下层协议可能要求对RTP包的封装进行定义。一般地，下层协议的一个包包含一个RTP包，但若封装方法允许，也可包含数个RTP包（见章节11）。 RTCP包（RTCP packet）：一种控制包，其组成部分有：一个类似RTP包的固定报头，后跟一个结构化的部分，该部分具体元素依不同RTCP包的类型而定。格式的定义见章节６。一般地，多个RTCP包将在一个下层协议的包中以合成RTCP包的形式传输；这依靠RTCP包的固定报头中的长度字段来实现。 端口（Port）：“传输协议用来在同一主机中区分不同目的地的一种抽象。TCP/IP协议使用正整数来标识不同端口。”[12] OSI传输层使用的传输选择器（TSEL,the transport selectors）等同于这里的端口。RTP需依靠低层协议提供的多种机制，如“端口”用以多路复用会话中的RTP和RTCP包。 传输地址(Transport address)：是网络地址与端口的结合，用来标识一个传输层次的终端，例如一个IP地址与一个UDP端口。包是从源传输地址发送到目的传输地址。 RTP媒体类型（RTP media type）：一个RTP媒体类型是一个单独RTP会话所载有的负载类型的集合。RTP配置文件把RTP媒体类型指派给RTP负载类型。 多媒体会话（Multimedia session）：在一个参与者公共组中，并发的RTP会话的集合。例如，一个视频会议（为多媒体会话）可能包含一个音频RTP会话和一个视频RTP会话。 RTP会话（RTP session）：一群参与者通过RTP进行通信时所产生的关联。一个参与者可能同时参与多个RTP会话。在一个多媒体会话中，除非编码方式把多种媒体多路复用到一个单一数据流中，否则每种媒体都将使用各自的RTCP包，通过单独的RTP会话来传送。通过使用不同的目的传输地址对（一个网络地址加上一对分别用于RTP和RTCP的端口，构成了一个传输地址对）来接收不同的会话，参与者能把多个RTP会话区隔开来。单个RTP会话中的所有参与者，可能共享一个公用目的传输地址对，比如IP多播的情况；也可能各自使用不同的目的传输地址对，比如个体单播网络地址加上一个端口对。对于单播的情况，参与者可能使用相同端口对来收听其他所有参与者，也可能对来其他每个参与者使用不同的端口对来收听。 RTP会话间相互区别的特征，在于每个RTP会话都维护一个用于SSRC标识符的独立完整的空间。RTP会话所包含的参与者组，由能接收SSRC标识符的参与者组成，这些SSRC标识符由RTP（同步源或作用源）或RTCP中的任意参与者传递。例如，考虑下述情况，用单播UDP实现的三方会议，每方都用不同的端口对来收听其他两方。如果收到一方的数据，就只把RTCP反馈发送给那一方，则会议就相当于由三个单独的点到点RTP会话构成；如果收到一方的数据，却把RTCP反馈发送另两方，则会议就是由一个多方（multi-party)RTP会话构成。后者模拟了三方间进行IP多播通信时的行为。 RTP框架允许上述规定发生变化，但一个特定的控制协议或者应用程序在设计时常常对变化作出约束。 同步源(SSRC，Synchronization source)：RTP包流的源，用RTP报头中32位数值的SSRC标识符进行标识，使其不依赖于网络地址。一个同步源的所有包构成了相同计时和序列号空间的一部分，这样接收方就可以把一个同步源的包放在一起，来进行重放。举些同步源的例子，像来自同一信号源的包流的发送方，如麦克风、摄影机、RTP混频器（见下文）就是同步源。一个同步源可能随着时间变化而改变其数据格式，如音频编码。SSRC标识符是一个随机选取的值，它在特定的RTP会话中是全局唯一（globally unique）的（见章节8）。参与者并不需要在一个多媒体会议的所有RTP会话中，使用相同的SSRC标识符；SSRC标识符的绑定通过RTCP（见章节6.5.1）。如果参与者在一个RTP会话中生成了多个流，例如来自多个摄影机，则每个摄影机都必须标识成单独的同步源。 作用源（CSRC，Contributing source )：若一个RTP包流的源，对由RTP混频器生成的组合流起了作用，则它就是一个作用源。对特定包的生成起作用的源，其SSRC标识符组成的列表，被混频器插入到包的RTP报头中。这个列表叫做CSRC表。相关应用的例子如，在音频会议中，混频器向所有的说话人（talker)指出，谁的话语（speech)将被组合到即将发出的包中，即便所有的包都包含在同一个（混频器的）SSRC标识符中，也可让听者（接收者）可以清楚谁是当前说话人。 终端系统（End system)：一种应用程序，它产生发送出的RTP包中内容，或者使用接收到的RTP包中内容。在一个特定的RTP会话中，一个终端系统可以扮演一个或多个同步源角色，但通常是一个。 混频器（Mixer)：一种中间系统，它从一个或多个源中接收RTP包，可能改变其数据格式，再按某种方式把这些包组合成一个新的包，然后转发出去。由于多个输入源的计时一般不会同步，所以混频器会对各个流的计时作出调整，并为组合流生成一个新的计时。因此，混频器将被标识成它所产生所有数据包的同步源。 转换器（Translator)：一种中间系统，它转发RTP包而不改变各包的同步源标识符。转换器的例子如下：不作混频地转变编码的设备，把多播复制到单播的重复装置，以及防火墙里应用层次的过滤器。 监视器(Monitor)：一种应用程序，它接收RTP会话参与者所发送的RTCP包，特别是接收报告（reception report)，而且对当前服务质量进行评估，评估结果用于分配监视任务，故障诊断和长期统计。监视器常常被内建到参与会话的应用程序中，但也可以是一个的独立的应用程序——不参加会话、也不发送或接收RTP数据包（因为它们在不同的端口上）。这些被称作第三方监视器。还有一种情况也是可以接受的，第三方监视器只接收但不发送数据包，或者另外地算入到会话中。 非RTP途径（Non-RTP means)：为提供一个可用的服务，可能还需要其他的协议和机制。特别地，对多媒体会议来说，一个控制协议可以发布多播地址，发布加密密钥，协商所用的加密算法，以及为没有预定义负载类型值的格式，建立负载类型值和其所代表的负载格式之间的动态映射。其他协议的例子如下：会话初始化协议（SIRFC3261[13]），ITU推荐的H.323[14]，还有使用SDP(RFC2327[15])的应用程序，如RTSP(RFC 2326[16]). 对于简单的应用程序，电子邮件或者会议数据库也可能用到。对这些协议和机制的详细说明已经超出了本文档的讨论范围。 5 RTP数据传输协议 5.1 RTP固定头中的各字段 RTP头有以下格式:123456789101112 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|V=2|P|X| CC |M| PT | sequence number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| timestamp |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| synchronization source (SSRC) identifier |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+| contributing source (CSRC) identifiers || .... |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ RTP包头格式 前12个字节出现在每个RTP包中，仅仅在被混合器插入时，才出现CSRC识别符列表。这些域有以下意义： 版本(V)：2比特 此域定义了RTP的版本。此协议定义的版本是2。(值1被RTP草案版本使用，值0用在最初”vat”语音工具使用的协议中。) 填充(P)：1比特 若填料比特被设置，则此包包含一到多个附加在末端的填充比特，填充比特不算作负载的一部分。填充的最后一个字节指明可以忽略多少个填充比特。填充可能用于某些具有固定长度的加密算法，或者用于在底层数据单元中传输多个RTP包。 扩展(X)：1比特 若设置扩展比特，固定头(仅)后面跟随一个头扩展。 CSRC计数(CC)：4比特 CSRC计数包含了跟在固定头后面CSRC识别符的数目。 标志(M)：1比特 标志的解释由具体协议规定。它用来允许在比特流中标记重要的事件，如帧边界。 负载类型(PT)：7比特 此域定义了负载的格式，由具体应用决定其解释。协议可以规定负载类型码和负载格式之间一个默认的匹配。其他的负载类型码可以通过非RTP方法动态定义。RTP发送端在任意给定时间发出一个单独的RTP负载类型；此域不用来复用不同的媒体流。 序列号（sequence number）：16比特 每发送一个RTP数据包，序列号加1，接收端可以据此检测丢包和重建包序列。序列号的初始值是随机的(不可预测)，以使即便在源本身不加密时(有时包要通过翻译器，它会这样做)，对加密算法泛知的普通文本攻击也会更加困难。 时间戳（timestamp） 32比特时间戳反映了RTP数据包中第一个字节的采样时间。时钟频率依赖于负载数据格式，并在描述文件（profile）中进行描述。也可以通过RTP方法对负载格式动态描述。 如果RTP包是周期性产生的，那么将使用由采样时钟决定的名义上的采样时刻，而不是读取系统时间。例如，对一个固定速率的音频，采样时钟将在每个周期内增加1。如果一个音频从输入设备中读取含有160个采样周期的块，那么对每个块，时间戳的值增加160。 时间戳的初始值应当是随机的，就像序号一样。几个连续的RTP包如果是同时产生的。如：属于同一个视频帧的RTP包，将有相同的序列号。 不同媒体流的RTP时间戳可能以不同的速率增长。而且会有独立的随机偏移量。因此，虽然这些时间戳足以重构一个单独的流的时间，但直接比较不同的媒体流的时间戳不能进行同步。对于每一个媒体，我们把与采样时刻相关联的RTP时间戳与来自于参考时钟上的时间戳（NTP）相关联。因此参考时钟的时间戳就了数据的采样时间。（即：RTP时间戳可用来实现不同媒体流的同步，NTP时间戳解决了RTP时间戳有随机偏移量的问题。）参考时钟用于同步所有媒体的共同时间。这一时间戳对（RTP时间戳和NTP时间戳），用于判断RTP时间戳和NTP时间戳的对应关系，以进行媒体流的同步。它们不是在每一个数据包中都被发送，而在发送速率更低的RTCP的SR（发送者报告）中。 如果传输的数据是存贮好的，而不是实时采样等到的，那么会使用从参考时钟得到的虚的表示时间线（virtual presentation timeline）。以确定存贮数据中的每个媒体下一帧或下一个单元应该呈现的时间。此种情况下RTP时间戳反映了每一个单元应当回放的时间。真正的回放将由接收者决定。 SSRC：32比特 用以识别同步源。标识符被随机生成，以使在同一个RTP会话期中没有任何两个同步源有相同的SSRC识别符。尽管多个源选择同一个SSRC识别符的概率很低，所有RTP实现工具都必须准备检测和解决冲突。若一个源改变本身的源传输地址，必须选择新的SSRC识别符，以避免被当作一个环路源。 CSRC列表：0到15项，每项32比特 CSRC列表识别在此包中负载的所有贡献源。识别符的数目在CC域中给定。若有贡献源多于15个，仅识别15个。CSRC识别符由混合器插入，并列出所有贡献源的SSRC识别符。例如语音包，混合产生新包的所有源的SSRC标识符都被列出，以在接收端处正确指示参与者。 5.3.1 RTP头扩展 RTP提供扩展机制以允许实现个性化：某些新的与负载格式独立的功能要求的附加信息在RTP数据包头中传输。设计此方法可以使其它没有扩展的交互忽略此头扩展。RTP头扩展的格式如下图所示。 12345670 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | defined by profile | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | header extension | | .... | 若RTP头中的扩展比特位置1，则一个长度可变的头扩展部分被加到RTP固定头之后。头扩展包含16比特的长度域，指示扩展项中32比特字的个数，不包括4个字节扩展头(因此零是有效值)。RTP固定头之后只允许有一个头扩展。为允许多个互操作实现独立生成不同的头扩展，或某种特定实现有多种不同的头扩展，扩展项的前16比特用以识别标识符或参数。这16比特的格式由具体实现的上层协议定义。基本的RTP说明并不定义任何头扩展本身。 6 RTP控制协议RTCP RTP控制协议(RTCP)向会议中所有成员周期性发送控制包。它使用与数据包相同的传输机制。底层协议必须提供数据包和控制包的复用，例如用不同的UDP端口。RTCP提供以下四个功能：○基本功能是提供数据传输质量的反馈。这是RTP作为一种传输协议的主要作用，它与其他协议的流量和拥塞控制相关。反馈可能对自适应编码有直接作用，并且IP组播的实验表明它对于从接收端得到反馈信息以诊断传输故障也有决定性作用。向所有成员发送接收反馈可以使”观察员”评估这些问题是局部的还是全局的。利用类似多点广播的传输机制，可以使某些实体，诸如没有加入会议的网络业务观察员，接收到反馈信息并作为第三方监视员来诊断网络故障。反馈功能通过RTCP发送者和接收者报告实现。 ○RTCP为每个RTP源传输一个固定的识别符，称为规范名（CNAME）。由于当发生冲突或程序重启时SSRC可能改变，接收者要用CNAME来跟踪每个成员。接收者还要用CNAME来关联一系列相关RTP会话中来自同一个成员的多个数据流，例如同步语音和图像。 ○前两个功能要求所有成员都发送RTCP包，因此必须控制速率以使RTP成员数可以逐级增长。通过让每个成员向所有成员发送控制包，各个成员都可以独立地观察会议中所有成员的数目。此数目可以用来估计发包速率。 ○第四个可选的功能是传输最少的会议控制信息，例如在用户接口中显示参与的成员。这最可能在”松散控制”的会议中起作用，在”松散控制”会议里，成员可以不经过资格控制和参数协商而加入或退出会议。RTCP作为一个延伸到所有成员的方便通路，必须要支持具体应用所需的所有控制信息通信。 ○在RTP用于IP多点广播时，功能1-3是强制的，在所有情况下都推荐使用。建议RTP应用开发商避免使用只能用于单向广播而不能扩充到多用户的方法。 6.1 RTCP包格式这部分定义了几个RTCP包类型，可以传送不同的控制信息： ○SR：发送者报告，描述作为活跃发送者成员的发送和接收统计数字； ○RR：接收者报告，描述非活跃发送者成员的接收统计数字； ○SDES：源描述项，其中包括规范名CNAME。 ○BYE：表明参与者将结束会话。 ○APP：应用描述功能。 在本文中将详细介绍SR和RR。 每个RTCP包的开始部分是与RTP数据包相类似的固定部分，随后是一块结构化单元，它随负载类型不同长度发生变化，但是总以32比特终止。对齐要求和长度域使RTCP包可”堆栈”，即可以将多个RTCP包形成一个复合RTCP包，在底层协议(如UDP)中，通常都是将复合包作为一个包传输的。复合包中的每个RTCP单包可以单独处理，而无需考虑包复合的顺序。然而，为了实现某些协议功能，添加以下限制： ○接收数据的统计信息(在SR或RR中)。只要带宽允许应尽可能经常的发送，以达到统计数字的最大分辨率。因此每个周期发送的RTCP包必须包含一个报告包。 ○新的参与者需要尽快接收一个源的规范名以识别数据源并与媒体建立会话。因此，每个包中必须包含源描述项中的规范名。除非复合包进行了分割以进行部分加密（见9.1节的描述）。 ○必须限制首次在复合包中出现的包类型的数目，以增加在第一个字中常数比特的数目，这样可以增加RTCP包的有效性，以区分误传的RTP包和其他无关的包。因此，所有RTCP包必须以复合包的形式发送。复合包中至少有两个单个的RTCP包。具有以下格式： ○加密前缀：当且仅当复合包被加密时，对每个RTCP复合包加32比特的前缀。 ○SR或RR：复合包中的第一个RTCP包必须是一个报告包。即使没有数据发送和接收，此时发送空的RR包，或者复合包中其他的唯一包是BYE包，也必须发送报告包。 ○附加的RR：若被报告的接收统计源数目超过SR/RR包中最大允许的31个，附加的RR必须跟在最初的报告包后面。 ○源描述SDES ○BYE或APP包 每个RTP参与者在一个报告间隔内应只发送一个RTCP复合包，以便正确估计每个参与者的RTCP带宽。除非像9.1节描述的情况——把一个RTCP复合包分割以进行加密。如果数据源的个数太多，以至于不能把所有的RR包都放到同一个RTCP包中而不超过网络路径的最大传输单元（maximum transport unit MTU），那么可在每个间隔中发送其中的一部分包。在多个发送间隔中，所有的包应该被等概率的选中。这样就可以报告所有数据源的接收数据的情况。如果一个RTCP复合包的长度超过了网络路径的MTU，则它应当被分割为多个更短的RTCP包来传输。这不会影响对RTCP带宽的估计，因为每一个复合包至少代表了一个参与者。要注意的是每个RTCP复合包必须以SR或RR包开头。 1234567891011| |[--------- packet --------][---------- packet ----------][-packet-] | | receiver chunk chunk V reports item item item item -------------------------------------------------------------------- R[SR #sendinfo #site1#site2][SDES #CNAME PHONE #CNAME LOC][BYE##why] -------------------------------------------------------------------- | | |&lt;----------------------- compound packet -----------------------&gt;| |&lt;-------------------------- UDP packet -------------------------&gt;| #: SSRC/CSRC identifier 图1: RTCP复合包举例 6.2 RTCP传输时间间隔 RTP被设计为允许应用自动适应不同的规模的会话――从几个参与者到几千个参与者的会话。 对每一个会话，我们假定数据传输受到一个上限――会话带宽的限制。会话带宽分配给所有的参与者。这个带宽会被预留，并由网络所限制。如果没有预留，基于环境的其他约束将会确定合理的最大带宽供会话使用，这就是会话带宽。会话带宽在一定程度上独立于媒体编码，但媒体编码却依赖于会话带宽。 在涉及媒体应用时，会话带宽参数最好由一个会话控制应用提供。但媒体应用可能设置一个默认参数。此参数由单个发送者选择的编码方式的数据带宽算出。会话管理可能会基于多播范围的规则或其他标准确定带宽限制。所有的参与者应使用相同的会话带宽值以保证计算出相同的RTCP间隔。 控制传输带宽应当是会话带宽的一小部分，这部分所占总的会话带宽的百分比应是已知的。一小部分：传输协议的首要功能是传输数据；已知：控制传输带宽可以被放进带宽描述中提供给资源预留协议，并且使每个参与者都可以独立的计算出他所占有的带宽份额。 控制传输带宽作为额外的一部分加入到会话带宽中。建议RTCP控制传输带宽为RTCP会话带宽的5%。其中的1/4分配给发送者；当发送者的比例超过所有参与者的1/4时，其RTCP控制带宽相应增加。所有的会话参与者必须使用相同的常数（以上提到的百分比），以便计算出相同的发送时间间隔。这些常数应在一个特殊的描述文件中确定。 计算出的RTCP复合包的发送时间间隔应该有一个下限，以免参与者数量较少时大量发送RTCP包。这也使网络暂时断开时，发送间隔不会太小。在应用开始时，一个延迟应加到第一个的TCP复合包发送之前，以便从其他参与者接收RTCP复合包。这样，发送时间间隔能更快的收敛到正确的值。这个延迟可以设为最小时间间隔的一半。固定的时间间隔建议为5秒。 一个实现可能使RTCP最小发送时间间隔与会话带宽参数成比例。则应满足下列约束： ○对多播会话，只有活动的数据发送者使用减小的最小化的值计算RTCP复合包的发送时间间隔。 ○对单播会话，减小的值也可能被不是活动的数据发送者使用，发送初始的RTCP复合包之前的延迟可能是0。 ○对所有会话，在计算参与者的离开时间时，这个固定最小值会被用到。因此，不使用减小的值进行RTCP包的发送，就不会被其他参与者提前宣布超时。 ○减小的最小时间间隔建议为：360/sb(秒)，其中sb：会话带宽（千字节/秒）。当sb&gt;72kb/s时，最小时间间隔将小于5s。 6.3节所描述的算法和附录A.7将实现本节列出的目标： ○计算出的RTCP包的时间间隔与组中参与者的人数成正比。（参与者越多，发送时间间隔越长，每个参与者占有的RTCP带宽越小）。 ○RTCP包的（真实）时间间隔是计算出的时间间隔的0.5～1.5倍之间某个随机的值，以避免所有的参与者意外的同步。 ○RTCP复合包的平均大小将会被动态估计，包括所有发送的包和接收的包。以自动适应携带的控制信息数量的变化。 ○由于计算出的时间间隔依赖于组中的人数。因此，当一个的用户加入一个已经存在的会话或者大量的用户几乎同时加入一个新的会话时，就会有意外的初始化效应。这些新用户将在开始时错误的估计组中的人数（估计太小）。因此他们的RTCP包的发送时间间隔就会太短。如果许多用户同时加入一个会话，这个问题就很重要了。为了处理这处问题考虑了一种叫“时间重估”的算法。这个算法使得组中人数增加时，用户能够支持RTCP包的传输。 当有用户离开会话，不管是发送BYE包还是超时，组中的人数会减少。计算出的时间间隔也应当减少。因此，应用“逆向重估”算法，使组中的成员更快的减少他们的时间间隔，以对组中的人数减少做出响应。 ○BYE包的处理和其他RTCP包的处理不同。BYE包的发送用到一个“放弃支持”算法。以避免大量的BYE包同时发送，使大量参与者同时离开会话。 这个算法适用于所有参与者都允许RTCP包的情况。此时，会话带宽＝每个发送者的带宽×会话中参与者的总人数。详细算法见随后小节，附录A.7给出了算法的一个实现。 6.2.1维持会话成员的人数 当侦听到新的站点的时候，应当把他们加入计数。每一个登录都应在表中创建一条记录，并以SSRC或CSRC进行索引。新的登录直到接收到含有SSRC的包或含有与此SSRC相联系的规范名的SDES包才视为有效（见附录A.1）。当一个与SSRC标识符相对RTCP BYE包收到时，登录会被从表中删除。除非一个“掉队”的数据包到达，使登录重新创建。 如果在几个RTCP报告时间间隔内没有RTP或RTCP包收到，一个参与者可能标记另外一个站点静止，并删除它。这是针对丢包提供的一个很强健的机制。所有站点对这个超时时间间隔乘子应大体相同，以使这种超时机制正常工作。因此这个乘子应在特别的描述文件中确定。 对于一个有大量参与者的会话，维持并存贮一个有所有参与者的SSRC及各项信息的表几乎是不可能的因此，只可以只存贮SSRC。其他算法类似。关键的问题就是，任何算法都不应当低估组的规模，虽然它有可能被高估。 6.3 RTCP包的发送和接收规则 下面列出了如何发送RTCP包，当接收到的TCP包时该干什么的规则。 为执行规则，一个会话参与者就维持下列变量： tp: RTCP包发送的最后时间。 tc: 当前时间。 tn: 估计的下一个RTCP包要发送的时间。 pmembers: tn最后被重新计算时，会计的会话成员的人数。 members: 会话成员人数的当前估计。 senders: 会话成员中发送者人数的估计。 rtcp_bw: 目标RTCP带宽。例如用于会话中所有成员的RTCP带宽。单位bit/s。这将是程序开始时，指定给“会话带宽”参数的一部分。 we_sent: 自当前第二个前面的RTCP发送后，应用程序又发送了数据，则此项为true。 avg_rtcp_size: 此参与者收到的和发送的RTCP复合包的平均大小。单位：bit。按6.2节，此大小包括底层传输层和网络层协议头。 initial: 如果应用程序还未发送RTCP包，则标记为true。 许多规则都用到了RTCP包传输的“计算时间间隔”。此时间间隔将在随后的小节描述。 6.3.1计算RTCP传输时间间隔 一个会话参与者包的平均发送时间间隔应当和所在会话组中人数成正比。这个间隔称为计算时间间隔。它由上面提到的各个状态参量结合起来计算得出。计算时间间隔T的计算如下： 1（1）如果发送者人数≤会话总人数×25%。则T取决于此参与者是否是发送者（we_sent的值）；否则，发送者和接收者将统一处理。 1234567891011121314senders&lt;=25%*memberswe_sentc=avg_rtcp_size/(0.25*rtcp_bw);n=senders;c=avg_rtcp_size/(0.75*rtcp_bw);n=members-senders;c=avg_rtcp_size/rtcp_bw;n=members;notyesyesnot 图：确定c ，n 如6.2节所述，RTP描述文件可能用两个独立的参数（S，R）确定发送者与非发送者。此时，25%和75%只要相应的换成S/(S+R),R/(S+R)即可。注意R＝0的情况。 2 如果initial为true(则未发送过RTCP包)，则设Tmin=2.5s;否则设Tmin=5s。 3 决定性的计算时间间隔（deterministic calculated interval）Td=max(Tmin ,nc)。 4 T=Tdλ；其中λ~U(0.5,1.5)。即λ服从0.5到1.5之间的均匀分布。 5 T=T/(e-0.5)≈T/1.21828，补偿时间重估算法，使之收敛到比计算出的平均RTCP带宽小的一个值。 这个算法产生了一个随机的计算时间间隔，并把至少25%的RTCP带宽分配给发送者，其余的分给接收者。若发送者超过会话总人数的25%，此算法将把带宽平均分给所有的参与者。 6 3.2初始化 一加入会话，参与者的各状态参量初始化为：tp=0； tc=0； senders=0； pmembers=1； members=1； vw_sent=false； rtcp_bw:由会话带宽参数的相应部分得到；initial=true；avg_rtcp_size:初始化为应用程序稍后将发送的RTCP包的可能大小；T：如6.3.1节；tn=T（这意味着，一个计时器将经T时间后被唤醒）；应用程序可以用任何它需要的方式实现计时器。 参与者把它自己的SSRC加到成员列表中。 6.3.3接收到的TP包或一个非BYE的RTCP包 当收到一个参与者的RTP或RTCP包时，若其SSRC不在成员列表中，将其SSRC加入列表；若此参与者被确认有效（如6.2.1节描述），就把列表中成员的值更新。对每个有效的RTP包中的CSRC执行相同的过程。 当收到一个参与者的RTP包时，若其SSRC不在发送者列表中，则将其SSRC加入发送者列表，更新相应的值。 每收到一个RTCP复合包，avg_rtcp_size更新为avg_rtcp_size = 1/16 packet_size + 15/16 avg_rtcp_size ；其中packet_size是刚收到的RTCP复合包的大小。 6.3.4接收RTCP BYE包 除6.3.7小节描述的发送RTCP BYE包之外，如果收到一个RTCP BYE包，则检测成员列表。若SSRC存在；先移除之，并更新成员的值。 另外，为使RTCP包的发送速率与组中人数变化更加协调，当收到一个BYE包使得members的值pmembers时，下面的逆向重估算法应当执行： （1）tn的更新：tn = tc + ( members / pmembers ) ( tn –tc )； （2）tp的更新：tp = tc – ( members / pmembers ) ( tc – tp )；下一个RTCP包将在时刻tn 被发送，比更新前更早一些。 （3）pmembers的更新：pmembers=members； 这个算法并没有防止组的大小被错误的在短时间内估计为0的情况。如：在一个较多人数的会话中，多数参与者几乎同时离开而少数几个参与者没有离开的情况。这个算法并没有使估计迅速返回正确的值。因为这种情况较罕见，且影响不大。 6.3.5 SSRC超时 在随机的时间间隔中，一个参与者必须检测其他参与者是否已经超时。为此，对接收者（we_sent为false），要计算决定性时间间隔Td，如果从时刻Tc-MTd(M为超时因子，默认为5秒)开始，未发送过RTP或RTCP包，则超时。其SSRC将被从列表中移除，成员被更新。在发送者列表中也要进行类似的检测。发送者列表中，任何从时间tc-2T(在最后两个RTCP报告时间间隔内)未发送RTP包的发送者，其SSRC从发送者列表中移除，列表更新。 如果有成员超时，应该执行6.3.4节中的逆向检测算法。每个参与者在一个RTCP包发送时间间隔内至少要进行一次这样的检测。 6.3.6发送时钟到时了 当包传输的发送时钟到时，参与者执行下列操作： （1）按6.3.1节的办法计算T。 （2）更新发送时钟的定时时间，判断是否发送RTCP包，更新pmembers。如图： tp+T&lt;=tc 发送RTCP包 tp=tc; tn=tc+T; initial=false; avg_rtcp_size=1/16 packet_size + 15/16 avg_rtcp_size tn=tp+T Pmemvers=members yes no //不发送RTCP包 图：发送时钟到时的操作 6.3.7发送一个BTE包 当一个参与者离开会话时，应发送BYE包，通知其他参与者。为避免大量参与者同时离开系统时，大量BYE包的发送，若会话人数超过50，则参与者在要离开会话时，应执行下面的算法。这个算法实际上“篡夺”了一般可变成员的角色来统计BYE包。 （1）tp=tc ； members=1； pmembers=1； sinitial=1； we_sent=false； senders=0； rtcp_size:设置为将要发送的RTCP包大小；计算“计算时间间隔”T；tn=tc+T；(BYE包预计在时刻tn被发送)。 (2)每当从另外一个参与者接收到BYE包时，成员人数加1。不管此成员是否存在于成员列表中，也不管SSRC采样何时使用及BYE包的SSRC是否包含在采样之中。如果收到RTP包或甚的RTCP包（除BYE包之外的RTCP包），成员人数不增加。类似，只有在收到BYE包时，avg_rtcp_size才更新。当RTP包到达时，发送者人数senders不更新，保持为0。 （3）在此基础上，BYE包的传输服从上面规定的一般的RTCP包的传输。 （BYE包的传输，是专注于统计会话中发送BYE包的人数的。） 这允许BYE包被立即发送，并控制总的带宽使用。在最坏情况下上，这可能会使RTCP控制包使用两倍于正常水平的带宽，达到10%――其中5%给BYE包的RTCP包，其余5%给BYE包。 一个参与者若不想用上面的机制进行RTCP包的发送，可以直接离开会话，而根本不发送BYE包。他会被其他参与者因超时而删除。 一个参与者想离开会话时，如果组中的人数会计数目小于50，则参与者可以直接发送BYE包。 另外，一个从未发送过RTP或RTCP包的参与者，在离开会话时，不能发送BYE包。 6.3.8更新we_sent变量 如果一个参与者最近发过RTP包，则变量we_sent值为true,否则为false。相同的机制可以管理发送者中的其他参与者。如果参与者发送了TPT包而此时，其对应的we_sent变量值为false,则就把它自己加到发送者列表中，并设置其we_sent变量为true。6.3.4节中描述的逆向重估算法（reverse reconsideration algorithm）应当被执行。以可能减少发送SR包前的延迟。每次发送一个RTP包，其相应的传输时间都会记录在表中。一般发送者的超时算法应用到参与者自身：从tc-2T时开始，一直没有发送RTP包，则此参与者就从发送者列表中将其自身移除，减少发送者总数，并设置we_sent变量值为false。 6.3.9源描述带宽的分配 这里定义了几种源描述项，强制性的规范名（CNAME）除外。例如，个人姓名（NAME）和电子邮件地址（EMAIL）。它也提供了方法定义新的RTCP包的类型。应用程序在给这些额外信息分配带宽时应额外小心。因为这会降低接收报告及CNAME的发送速率，可能破坏协议发挥作用。建议分配给一个参与者用于传输这些额外信息的带宽不超过总的RTCP带宽的20%。另外，并非所有的源描述项都将包含进每一个应用程序中。包含进应用程序的源描述项应根据其用途分配给相应的带宽百分比。建议不要动态会计这些百分比，而应根据一个源描述项的典型长度将所占带宽的百分比的转化为报告间隔。 例如，一个应用程序可能仅发送CNAME，NAME和EMAIL，而不需要其他项。NAME可能会比EMAIL给予更高的优先级。因为NAME可能会在应用程序的用户界面上持续显示，但EMAIL可能仅仅在需要时才会显示。在每一个RTCP时间间隔内，一个包含CNAME项的SDES包和一个RR包将会被发送。最小的会话时间间隔平均为5秒。每经过3个时间间隔（15秒），一个额外的项将会包含进这个SDES包中。7/8的时间是NAME项，每经过8个这样的间隔（15s8=2min）,将会是EMAIL项。 当多个会话考虑使用一个通用的规范名为每个参与者进行绑定时，如在一个RTP会话组成的多媒体会议中，额外的SDES信息可能只在一次RTP会话中被发送。其余的会话将只发送CNAME。特别，这个办法也应该用在分层编码的多个会话中。 6.4 发送者和接收者报告 RTP接收者利用RTCP报告包提供接收质量反馈。根据接收者是否同时还是发送者，RTCP包采取两种不同的形式。发送者报告(SR)和接收者报告(RR)格式中唯一的不同，除包类型码之外，在于发送者报告包括20字节的发送者信息。 SR包和RR包都包括零到多个接收报告块。针对该接收者发出上一个报告块后接收到RTP包的起始同步源，每个源一个块。报告不发送给CSRC列表中的贡献源。每个接收报告块提供从特定数据源接收到数据的统计信息。由于SR/RR包最多允许31个接收报告块，故可以在最初的SR或RR包之后附加RR包，以包含从上一个报告以来的间隔内收听到的所有源的接收报告。如果数据源太多，致使若把所有的RR包放到同一个RTCP复合包中会超出网络的MTU。那么就在一个周期内选择上面RR包的一部分以不超过MTU。这些RR包的选取应让各个包都有同等的几率被取到。这样在几个发送周期间隔中，对所有的数据源就都发送接收报告了。 以下部分定义了两种报告的格式。如果应用程序需要其他信息，他们可以被扩展。 6.4.1 SR：发送者报告RTCP包 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| RC | PT=SR=200 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ sender | NTP timestamp, most significant word | info +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | NTP timestamp, least significant word | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | RTP timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender’s packet count | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender’s octet count | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_1 (SSRC of first source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 1 | fraction lost | cumulative number of packets lost | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | extended highest sequence number received | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | interarrival jitter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | last SR (LSR) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | delay since last SR (DLSR) | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_2 (SSRC of second source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 2 : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | profile-specific extensions | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 发送者报告包由3部分组成，若定义，可能跟随第4个面向协议的扩展部分。 第一部分，头部，8字节长。该域有以下意义： 版本(V)：2比特 RTP版本识别符，在RTCP包内的意义与RTP包中的相同。此协议中定义的版本号为2。 填充(P)：1比特 若设置填充比特，该RTCP包在末端包含一些附加填充比特，并不是控制信息的基本部分。填充的最后一个比特统计了多少个字节必须被忽略。填充可能会用于需要固定长度块的加密算法。在复合RTCP包中，复合包作为一个整体加密，填料比特只能加在最后一个单个RTCP包的后面。 接收报告块计数(RC)：5比特 该包中所含接收报告块的数目。零值有效。 包类型(PT)：8比特 包含常数200，用以识别这个为SR包。 长度：16比特 该RTCP包的长度减1。其单位是32比特字，包括头和任何填充字节。(偏移量1保证零值有效，避免了在扫描RTCP包长度时可能发生的无限循环，同时以32比特为单位避免了对以4为倍数的有效性检测。) SSRC：32比特 SR包发送者的同步源标识符。 第二部分，发送者信息，20字节长。在每个发送者报告包中出现。它概括了从此发送者发出的数据传输情况。此域有以下意义： NTP时间戳：64比特 指示了此报告发送时的背景时钟（wallclock）时刻，它可以与从其它接收者返回的接收报告块中的时间标志结合起来，计算往返每个接收者所花的时间。接收者应让NTP时间戳的精度远大于其他时间戳的精度。时间戳测量的不确定性不可知，因此也无需指示。一个系统可能没有背景时钟的概念，而只有系统指定的时钟，如系统时间（system uptime）。在这样的系统中，此时钟可以作为参考计算相对NTP时间戳。选择一个公用的时名是非常重要的。这样多个独立的应用都可以使用相同的时钟。到2036年，相对和绝对NTP时间戳会产生大的差异。到那时，我们希望不再需要相对时钟。一个发送者，如果不用背景时钟时间或逝去时间，可以设置此项为零。 RTP时间戳：32比特 与以上的NTP时间标志对应同一时刻。与数据包中的RTP时间戳具有相同的单位和偏移量。这个一致性可以用来让NTP时间标志已经同步的源之间进行媒体内/间同步，还可以让与媒体无关的接收者估计名义RTP时钟频率。注意在大多数情况下此时间戳不等于任何临近的RTP包中的时间戳。RTP时间戳可以由相应的NTP时间戳计算得到。依据的是“RTP时间戳计数器”和“在采样时通过周期性检测背景时钟时间得到的实际时间”两者之间的关系。 （在RTCP SR包中有NTP时间戳、RTP时间戳，它们可以计算背景时钟和RTP时钟之间的对应关系，通过这个关系，可以由RTP数据包中的RTP时间戳计算也相应的回放时刻。这样就可以进行多个流的同步了。之所以要有NTP时间戳，是因为不同流的RTP时间戳有不同的随机偏移量，无法直接进行同步：笔者注。） 发送的报文数：32比特 从开始传输到此SR包产生时该发送者发送的RTP数据包总数。若发送者改变SSRC识别符，该计数器重设。 发送的字节文数：32比特 从开始传输到此SR包产生时该发送者在RTP数据包发送的字节总数(不包括头和填充)。若发送者改变SSRC识别符，该计数器重设。此域可以用来估计平均的负载数据发送速率。 第三部分：零到多个接收报告块。块数等于从上一个报告以来该发送者侦听到的其它源（不包括自身）的数目。每个接收报告块传输从某个同步源来的数据包的接收统计信息。若数据源因冲突而改变其SSRC标识符，接收者重新设置统计信息。这些统计信息有： SSRC_n(同步源标识符)：32比特 在此接收报告块中信息所属源的SSRC标识符。 丢包率：8比特 自从前一SR包或RR包发送以来，从SSRC_n传来的RTP数据包的丢失比例。以定点小数的形式表示。该值定义为损失包数／期望接收的包数。若由于包重复而导致包丢失数为负值，丢包率设为零。注意在收到上一个包后，接收者无法知道以后的包是否丢失。如：若在上一个接收报告间隔内从某个源发出的所有数据包都丢失，那么将不为此数据源发送接收报告块。 累计包丢失数：24比特 从开始接收到现在，从源SSRC_n发到本源的RTP数据包的丢包总数。该值定义为：期望接收的包数－实际接收的包数。接收的包括复制的或迟到的。由于迟到的包不算作损失，在发生复制时丢包数可能为负值。期望接收的包数定义为：扩展的上一接收序号(随后定义)减去最初接收序号。 接收到的扩展的最高序列号：32比特 低16比特包含从源SSRC_n来的最高接收序列号，高16比特用相应的序列号周期计数器扩展该序列号。注意在同一会议中的不同接收者，若启动时间明显不同，将产生不同的扩展项。 到达间隔抖动：32比特 RTP数据包到达时刻统计方差的估计值。测量单位同时间戳单位，用无符号整数表达。到达时间抖动定义为一对包中接收者相对发送者的时间间隔差值的平均偏差(平滑后的绝对值)。如以下等式所示，该值等于两个包相对传输时间的差值。相对传输时间是指：包的RTP时间戳和到达时刻接收者时钟时间的差值。若Si是包i中的RTP时间戳，Ri是包i到达时刻（单位为：RTP时间戳单位）。对于两个包i和j，D可以表示为 D(i，j)=(Rj-Sj)-(Ri-Si)； 到达时刻抖动可以在收到从源SSRC_n来的每个数据包i后连续计算。利用该包和前一包i-1的偏差D(按到达顺序，而非序号顺序)，根据公式J=J+(|D(i-1，i)|-J)/16计算。无论何时发送接收报告，都用当前的J值。 此处描述的抖动计算允许与协议独立的监视器对来自不同实现的报告进行有效的解释。 上一SR报文 (LSR)：32比特 接收到的来自源SSRC_n的最新RTCP发送者报告(SR)的64位NTP时间标志的中间32位。若还没有接收到SR，该域值为零。 自上一SR的时间(DLSR)：32比特 是从收到来自SSRC_n的SR包到发送此接收报告块之间的延时，以1/65536秒为单位。若还未收到来自SSRC_n的SR包，该域值为零。 假设SSRC_r为发出此接收报告块的接收者。源SSRC_n可以通过记录收到此接收报告块的时刻A来计算到SSRC_r的环路传输时延。可以利用最新的SR时间标志(LSR)计算整个环路时间A-LSR，然后减去此DLSR域得到环路传输的时延。 如下图所示。 [10 Nov 1995 11:33:25.125 UTC] [10 Nov 1995 11:33:36.5 UTC] n SR(n) A=b710:8000 (46864.500 s) —————————————————————-&gt; v ^ ntp_sec =0xb44db705 v ^ dlsr=0x0005:4000 ( 5.250s) ntp_frac=0x20000000 v ^ lsr =0xb705:2000 (46853.125s) (3024992005.125 s) v ^ r v ^ RR(n) —————————————————————-&gt; |&lt;-DLSR-&gt;| (5.250 s) A 0xb710:8000 (46864.500 s) DLSR -0x0005:4000 ( 5.250 s) LSR -0xb705:2000 (46853.125 s) delay 0x0006:2000 ( 6.125 s) 图2: 往返路程时间的计算举例 可以用此来近似测量到一组接收者的距离，尽管有些连接可能有非常不对称的时延。 6.4.2 RR：接收者报告包 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| RC | PT=RR=201 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of packet sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_1 (SSRC of first source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 1 | fraction lost | cumulative number of packets lost | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | extended highest sequence number received | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | interarrival jitter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | last SR (LSR) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | delay since last SR (DLSR) | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_2 (SSRC of second source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 2 : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | profile-specific extensions | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 接收者报告包(RR)与发送者报告包基本相同，除了包类型域包含常数201和没有发送者信息的5个字(NTP和RTP时间标志和发送者包和字节计数)。余下区域与SR包意义相同。若没有发送和接收据报告，在RTCP复合包头部加入空的RR包(RC=0)。 6.4.3发送者和接收者报告扩展 如果有额外的关于发送者和接收者的信息要周期性的，描述文件（profile）应该定义接收者报告和发送者报告描述文件扩展。此时，应采用这里的办法，而不是定义另外的RTCP包。因为这种办法需要的头部信息更少。 扩展部分是发送报告包和接收报告包的第四部分。如果有的话，应紧跟在接收报告块的后面。如果需要更多的发送者信息，它应当跟在发送者报告的开关，而不应在报告中出现。如果要包含进接收者的信息，它应该以块数组的方式放到接收报告块的后面。即这些块也应被计入RC字段中。 6.4.4分析发送者和接收者报告 接收质量反馈不仅对发送者有用，而且对于其它接收者和第三方监视器也有作用。发送者可以基于反馈修正发送信息量；接收者可以判断问题是本地的，区域内的还是全局的；网络管理者可以利用与协议无关的监视器(只接收RTCP包而不接收相应的RTP包)去评估多点传送网络的性能。 在发送者信息和接收者报告块中都连续统计丢包数，因此可以计算任何两个报告块中的差别。在短时间和长时间内都可以进行测算。最近收到的两个包之间差值可以评估当前传输质量。包中有NTP时间戳，可以用两个报告间隔的差值计算传输速率。由于此时间间隔与数据编码速率独立，因此可以实现与编码及协议独立的质量监视。 一个例子是计算两个报告间隔时间内的丢包率。丢包率＝此间隔内丢失的包／此间隔内期望收到的包。如果此值与“丢失比例”字段中的值相同，说明包是连续的；若否，说明包不是连续的。间隔时间内的丢包率／间隔时间＝每秒的丢包率。 从发送者信息中，第三方监视器可以在一个时间间隔内计算平均负载数据发送速率和平均发包速率，而无需考虑数据接收。两个值的比就是平均负载大小（平均每个包的负载大小）。（即：平均负载大小＝平均负载数据发送速率／平均发包率。）若能假定丢包与包的大小无关，那么某个特定接收者收到的包数乘以平均负载大小(或相应的包大小)就得出接收者可得到的外在吞吐量。 除了累计计数允许利用报告间差值进行长期包损测量外，单个报告的“丢包比例”字段提供一个短时测量数据。当会话规模增加到无法为所有接收者保存接收状态信息，或者报告间隔变得足够长以至于从一个特定接收者只能收到一个报告时，短时测量数据变得更重要。 到达间隔抖动字段提供另一个有关网络阻塞的短时测量量。丢包反映了长期阻塞，抖动测量反映出短时间的阻塞。抖动测量可以在导致丢包前预示阻塞。由于到达间隔抖动字段仅仅是发送报告时刻抖动的一个快照，因此需要在一个网络内在一段时间内分析来自某个接收者的报告，或者分析来自多个接收者的报告。 6.5源描述RTCP包 源描述（SDES）包由一个头及0个或多个块组成。每个块都由块中所标识的数据源的标识符及其后的各个描述构成。 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| SC | PT=SDES=202 | length | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ chunk | SSRC/CSRC_1 | 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SDES items | | … | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ chunk | SSRC/CSRC_2 | 2 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SDES items | | … | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ 6.6 BYE（BYE包） 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| SC | PT=BYE=203 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC/CSRC | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ (opt) | length | reason for leaving … +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ BYE包表明一个或多个源将要离开。如果混合器收到BYE包，混合器应当发送这个BYE包，并保持SSRC/CSRC不变。如果混合器关闭，应向贡献源列表中的所有SSRC，包括它自己的SSRC发送BYE包。BYE包可能会有选择的包含8个字节的统计字段，其后跟上几个字节的文本表明离开的原因。文本字符串编码格式和SDES中描述的相同。 9安全性 底层协议将最终提供由RTP应用要求的所有安全服务，包括真实性、完整性、保密性。这些服务在参考文献[27]中的IP协议有详细描述。由于使用RTP的初始音频和视频应用在IP层可用之前就要求保密性服务，因此，随后的一小节描述了使用RTP和RTCP的保密性服务。新的RTP应用可以实现这里描述的RTP保密性服务，以用于向后兼容，也可以实现替代这里的安全服务。这种安全服务的RTP开销是比较小的。因此，如果这项服务被将来的某种服务所替代，代价也是比较小的。 另一方面，RTP的其他服务，服务的其他实现及其他的算法可能会在将来定义。特别是为RTP负载提供可靠性的实时安全传输协议（ Secure Real-time Transport, SRTP）正在制定中。它可以使RTP头部不被加密。这样，链路层的头部压缩算法可以继续使用。SRTP基于高级企业标准（Advanced Encryption Standard, AES）制定。它比这里描述的服务提供更强健的安全性。 密钥和证书分配超出了本文的范围。 9.1 保密性 保密性意味着只有特定的接收者才能够对收到的包进行解码；对其他人，包里含有的都是无用信息。内容的保密性通过加密来实现。 当用这节指定的方法RTP、RTCP加密时，为了传输而封装的所有字节将在底层的包中作为一个单元加密。对RTCP，每个单元在加密之前必须在前面附加一个32字节的随机数。对RTP，不必在前面加前缀，而是让序列号和时间戳字段都用随机偏移量初始化。由于较差的随机性质。这其实是一个弱的初始化向量（initialization vector, IV）。另外，如果其后的SSRC字段被攻击者得到，则加密算法将出现新的薄弱点。 对RTCP，一个应用程序可能将RTCP复合包中的一个RTCP包分割成两个RTCP复合包。其中，一个在发送时加密，另一个发送时不加密。例如，SDES信息可能会被加密，但接收者报告却不加密，以适用于没有密钥的第三方监视者。如图4所示。源描述信息后必须附加没有报告的空RR包，以满足所有RTCP复合包必须以SR或RR包开头的要求。SDES的CNAME字段包含在加密或未加密的包中之一即可，但并不都需要包含。相同的源描述信息不应在两个包中都携带。否则会使加密算法不安全。 UDP packet UDP packet [random][RR][SDES #CNAME …] [SR #senderinfo #site1 #site2] encrypted not encrypted #: SSRC identifier 图4: 加密的和未加密的RTCP包 接收者加密的使用和正确密钥的使用通过头或负载的有效性检查进行确认。RTP和RTCP头的有效性检查由附录A.1和A.2给出。 为和RFC1889中RTP初始描述中的实现相一致。默认的算法是链式加密块模式（cipher block chaining (CBC) mode）下的数据加密算法，见RFC1423中1.1节的描述。除非出现由5.1节描述指明的填充多个字节的情况，否则，初始的随机向量是0，因为随机值由RTP头或RTCP复合包的随机前缀提供。CBC初始向量的细节见参考文献[30]。支持本节的加密算法的实现也应当支持CBC下的DES算法。因为此算法可实现最大程度的交互可操作性。采用这种方法的原因是，因特网上通过音频、视频工具做实验证明它简便且有效。但DES被发现很容易被破解。建议用更强健的加密算法，例如三层DES加密算法来代替默认的加密算法。另外，安全CBC模式要求每个包的第一个块和一个随机数求异或。对于RTCP，这通过在每个包前附加一个32位的随机数实现。每个包的随机数相互独立。对RTP，时间戳和序列号将从附加的数值开始，但对连续的包，它们并不是被独立的随机化的。应该注意到对RTP和RTCP，这种随机性都受到了限制。高安全性的应用应当考虑其他更加简捷安全的方法。其他加密算法应通过非RTP方法对一个会话动态指定。特别是基于AES的SRTP描述文件（见参考文献[23]）将会是未来的一个不错的选择。以上描述了IP层或RTP层加密。作为它的替代，描述文件可以定义另外的负载类型以用于加密、编码。这些编码必须描述如何填充，以及编码的其他方面如何控制。这种方法可以按照应用的要求，只加密数据，不加密头部。这可能对同时处理解密和解码的硬件服务特别重要。这也可能对RTP和底层头部的链路层的应用很有用。既然头部的加密已经进行了压缩，负载（而不是地址）的保密性就足够了。 9.2 真实性和信息完整性 真实性和信息完整性没有在RTP层定义，因为这些服务离不开密钥管理体系。可以期望真实性和信息完整性将由底层协议完成。 10 拥塞控制 因特网上的所有传输协议都需要通过一些方法进行地址拥塞控制（见参考文献[31]），RTP也不例外。但由于RTP数据传输经常缺少弹性（以固定的或控制好的速率产生包）。因此，RTP的拥塞控制方法和其他的传输协议，如TCP很不相同。在某种程度上，缺乏弹性意味着降低了拥塞的风险。因为RTP流不会像TCP流那样增长到消耗掉所有可用的带宽程度。但是，缺乏弹性也意味着RTP流不能任意减小它在网络上的负载量，以在出现拥塞时消除之。 由于RTP可能会在许多不同的情况下用于相当广的。因此就没有一个全都通用一个拥塞控制机制。因此，拥塞控制应当在描述文件中定义。对于某些描述，可能加上可应用性陈述以限制描述应用在已设计消除拥塞的环境中。对其它描述，可能需要特别的方法，如基于RTCP反馈的自适应数据传输速率。 参考文献： 正式参考文献 [1] Schulzrinne, H. and S. Casner, “音频和视频会议最小控制的RTP描述”, RFC 3551, 2003.6 [2] Bradner, S., “表示需求层的RFC关键字”, BCP 14, RFC 2119, 1997.3 [3] Postel, J., “网络协议”, STD 5, RFC 791, 1981.9 [4] Mills, D., “网络时间协议（第三版）描述、实现和分析”, RFC 1305,1992.3 [5] Yergeau, F., “UTF-8, 一个ISO 10646传输格式”, RFC 2279,1998.1 [6] Mockapetris, P., “域名――概念和工具”, STD 13, RFC 1034,1987.11 [7] Mockapetris, P., “域名――实现和描述”, STD 13, RFC 1035,1987.1 [8] Braden, R., “因特网主机需求――应用和支持”, STD 3, RFC 1123,1989.10 [9] Resnick, P., “因特网信息格式”, RFC 2822,2001.4 非正式参考文献 [10] Clark, D. and D. Tennenhouse, “新一代协议的建构考虑,” 关于通信体系结构和协议的数据通信专业组讨论班, (宾夕法尼亚州，费城), IEEE 计算机通信回顾 卷. 20(4), 200－208页,1990.9 [11] Schulzrinne, H., “关于设计音频、视频会话传输协议及其它多参与者实时应用的讨论”, 1993.10 [12] Comer, D., TCP/IP网络协议 ,卷1. Englewood Cliffs, New Jersey: Prentice Hall, 1991. [13] Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A.,Peterson, J., Sparks, R., Handley, M. and E. Schooler, “SIP:会话初始协议”, RFC 3261,2002.6 [14] International Telecommunication Union, “对不保证质量的局域网的可视电话系统和设备”, Recommendation H.323,ITU的无线电通讯标准一节, Geneva, Switzerland, 2003.7 [15] Handley, M. and V. Jacobson, “SDP: 会话描述协议”, RFC 2327,1998.4 [16] Schulzrinne, H., Rao, A. and R. Lanphier, “实时流协议(RTSP)”, RFC 2326,1998.4 [17] Eastlake 3rd, D., Crocker, S. and J. Schiller, “关于安全性的随机化建议”, RFC 1750, 1994.12 [18] Bolot, J.-C., Turletti, T. and I. Wakeman, “因特网多播视频分布的可升级的反馈控制”,关于通信体系结构和协议的数据通信专业组讨论班（英国，伦敦）, ACM,58—67页, 1994.8 [19] Busse, I., Deffner, B. and H. Schulzrinne, “基于RTP的多媒体应用的动态 QoS控制”, 计算机通讯,卷19,49—58页,1996.1 [20] Floyd, S. and V. Jacobson, “周期性路由信息的同步”,关于通信体系结构和协议的数据通信专业组讨论班 (旧金山,加利福尼亚), 33—44页, ACM,1993.9 并参见[34]. [21] Rosenberg, J. and H. Schulzrinne, “RTP中成员组的采样”, RFC 2762,2000.2 [22] Cadzow, J., “纽约数字信号处理和数据分析基础” 纽约: Macmillan, 1987. [23] Hinden, R. and S. Deering, “IPv6地址结构”, RFC 3513,2003.4 [24] Rekhter, Y., Moskowitz, B., Karrenberg, D., de Groot, G. and E.Lear, “保密因特网中的地址分配”, RFC 1918,1996.2 [25] Lear, E., Fair, E., Crocker, D. and T. Kessler, “考虑可能有害的网络10 (一些实现不应成为标准)”, RFC 1627,1994.7 [26] Feller, W.,概率论及其应用入门,卷1. 纽约: John Wiley and Sons , 1968. [27] Kent, S. and R. Atkinson, “因特网协议的安全体系”, RFC 2401,1998.11 [28] Baugher, M., Blom, R., Carrara, E., McGrew, D., Naslund, M.,Norrman, K. and D. Oran, “安全实时传输协议”,2003.4 [29] Balenson, D., “增强因特网电子邮件的保密性:第三部分”, RFC 1423,1993.2 [30] Voydock, V. and S. Kent, “高层网络协议的安全机制”, ACM 计算调查,卷15,135-171页,1983.6 [31] Floyd, S., “拥塞控制原理”, BCP 41, RFC 2914,2000.9 [32] Rivest, R., “MD5通讯――算法摘要”, RFC 1321,1992.4 [33] Stubblebine, S., “多媒体会话的安全服务”, 第16届国际安全会议，(巴尔的摩,马里兰州),391—395页,1993.9 [34] Floyd, S. and V. Jacobson, “周期路由信息同步”, IEEE/ACM 网络传输,卷2,122—136页,1994.4]]></content>
      <categories>
        <category>RFC</category>
      </categories>
      <tags>
        <tag>协议</tag>
        <tag>RTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc-source-android]]></title>
    <url>%2F2017%2F07%2F15%2Fwebrtc-source-android%2F</url>
    <content type="text"><![CDATA[nativeCreateVideoSource 初始化PeerConnectionFactory(pc/peerconnectionfactory) 创建PeerConnection方法中: 12345678910111213141516171819202122232425262728293031rtc::scoped_refptr&lt;PeerConnectionInterface&gt;PeerConnectionFactory::CreatePeerConnection( const PeerConnectionInterface::RTCConfiguration&amp; configuration, std::unique_ptr&lt;cricket::PortAllocator&gt; allocator, std::unique_ptr&lt;rtc::RTCCertificateGeneratorInterface&gt; cert_generator, PeerConnectionObserver* observer) &#123; RTC_DCHECK(signaling_thread_-&gt;IsCurrent()); if (!cert_generator.get()) &#123; // No certificate generator specified, use the default one. cert_generator.reset( new rtc::RTCCertificateGenerator(signaling_thread_, network_thread_)); &#125; if (!allocator) &#123; allocator.reset(new cricket::BasicPortAllocator( default_network_manager_.get(), default_socket_factory_.get())); &#125; network_thread_-&gt;Invoke&lt;void&gt;( RTC_FROM_HERE, rtc::Bind(&amp;cricket::PortAllocator::SetNetworkIgnoreMask, allocator.get(), options_.network_ignore_mask)); rtc::scoped_refptr&lt;PeerConnection&gt; pc( new rtc::RefCountedObject&lt;PeerConnection&gt;(this)); if (!pc-&gt;Initialize(configuration, std::move(allocator), std::move(cert_generator), observer)) &#123; return nullptr; &#125; return PeerConnectionProxy::Create(signaling_thread(), pc);&#125; 构造PeerConnection对象pc,并调用初始化方法Initialize,Initialize中: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182ool PeerConnection::Initialize( const PeerConnectionInterface::RTCConfiguration&amp; configuration, std::unique_ptr&lt;cricket::PortAllocator&gt; allocator, std::unique_ptr&lt;rtc::RTCCertificateGeneratorInterface&gt; cert_generator, PeerConnectionObserver* observer) &#123; TRACE_EVENT0(&quot;webrtc&quot;, &quot;PeerConnection::Initialize&quot;); if (!allocator) &#123; LOG(LS_ERROR) &lt;&lt; &quot;PeerConnection initialized without a PortAllocator? &quot; &lt;&lt; &quot;This shouldn&apos;t happen if using PeerConnectionFactory.&quot;; return false; &#125; if (!observer) &#123; // TODO(deadbeef): Why do we do this? LOG(LS_ERROR) &lt;&lt; &quot;PeerConnection initialized without a &quot; &lt;&lt; &quot;PeerConnectionObserver&quot;; return false; &#125; observer_ = observer; port_allocator_ = std::move(allocator); // The port allocator lives on the network thread and should be initialized // there. if (!network_thread()-&gt;Invoke&lt;bool&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnection::InitializePortAllocator_n, this, configuration))) &#123; return false; &#125; // Call must be constructed on the worker thread. factory_-&gt;worker_thread()-&gt;Invoke&lt;void&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnection::CreateCall_w, this)); session_.reset(new WebRtcSession( call_.get(), factory_-&gt;channel_manager(), configuration.media_config, event_log_.get(), factory_-&gt;network_thread(), factory_-&gt;worker_thread(), factory_-&gt;signaling_thread(), port_allocator_.get(), std::unique_ptr&lt;cricket::TransportController&gt;( factory_-&gt;CreateTransportController( port_allocator_.get(), configuration.redetermine_role_on_ice_restart)),#ifdef HAVE_SCTP std::unique_ptr&lt;cricket::SctpTransportInternalFactory&gt;( new cricket::SctpTransportFactory(factory_-&gt;network_thread()))#else nullptr#endif )); stats_.reset(new StatsCollector(this)); stats_collector_ = RTCStatsCollector::Create(this); // Initialize the WebRtcSession. It creates transport channels etc. if (!session_-&gt;Initialize(factory_-&gt;options(), std::move(cert_generator), configuration)) &#123; return false; &#125; // Register PeerConnection as receiver of local ice candidates. // All the callbacks will be posted to the application from PeerConnection. session_-&gt;RegisterIceObserver(this); session_-&gt;SignalState.connect(this, &amp;PeerConnection::OnSessionStateChange); session_-&gt;SignalVoiceChannelCreated.connect( this, &amp;PeerConnection::OnVoiceChannelCreated); session_-&gt;SignalVoiceChannelDestroyed.connect( this, &amp;PeerConnection::OnVoiceChannelDestroyed); session_-&gt;SignalVideoChannelCreated.connect( this, &amp;PeerConnection::OnVideoChannelCreated); session_-&gt;SignalVideoChannelDestroyed.connect( this, &amp;PeerConnection::OnVideoChannelDestroyed); session_-&gt;SignalDataChannelCreated.connect( this, &amp;PeerConnection::OnDataChannelCreated); session_-&gt;SignalDataChannelDestroyed.connect( this, &amp;PeerConnection::OnDataChannelDestroyed); session_-&gt;SignalDataChannelOpenMessage.connect( this, &amp;PeerConnection::OnDataChannelOpenMessage); configuration_ = configuration; return true;&#125; 调用CreateCall_w创建call对象: 12345678910111213141516void PeerConnection::CreateCall_w() &#123; RTC_DCHECK(!call_); const int kMinBandwidthBps = 30000; const int kStartBandwidthBps = 300000; const int kMaxBandwidthBps = 2000000; webrtc::Call::Config call_config(event_log_.get()); call_config.audio_state = factory_-&gt;channel_manager() -&gt;media_engine()-&gt;GetAudioState(); call_config.bitrate_config.min_bitrate_bps = kMinBandwidthBps; call_config.bitrate_config.start_bitrate_bps = kStartBandwidthBps; call_config.bitrate_config.max_bitrate_bps = kMaxBandwidthBps; call_.reset(webrtc::Call::Create(call_config));&#125; 使用call对象以及PeerConnectionFactory中channelmanager(PeerConnectionFactory中Initialize中创建)构造WebRtcSession对象session,调用Initialize方法初始化session,初始化session槽函数等.session_初始化方法中创建WebRtcSessionDescriptionFactory对象webrtc_session_descfactory. 创建ChannelWebRtcSession::SetLocalDescription: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051bool WebRtcSession::SetLocalDescription(SessionDescriptionInterface* desc, std::string* err_desc) &#123; RTC_DCHECK(signaling_thread()-&gt;IsCurrent()); // Takes the ownership of |desc| regardless of the result. std::unique_ptr&lt;SessionDescriptionInterface&gt; desc_temp(desc); // Validate SDP. if (!ValidateSessionDescription(desc, cricket::CS_LOCAL, err_desc)) &#123; return false; &#125; // Update the initial_offerer flag if this session is the initial_offerer. Action action = GetAction(desc-&gt;type()); if (state() == STATE_INIT &amp;&amp; action == kOffer) &#123; initial_offerer_ = true; transport_controller_-&gt;SetIceRole(cricket::ICEROLE_CONTROLLING); &#125; if (action == kAnswer) &#123; current_local_description_.reset(desc_temp.release()); pending_local_description_.reset(nullptr); current_remote_description_.reset(pending_remote_description_.release()); &#125; else &#123; pending_local_description_.reset(desc_temp.release()); &#125; // Transport and Media channels will be created only when offer is set. if (action == kOffer &amp;&amp; !CreateChannels(local_description()-&gt;description())) &#123; // TODO(mallinath) - Handle CreateChannel failure, as new local description // is applied. Restore back to old description. return BadLocalSdp(desc-&gt;type(), kCreateChannelFailed, err_desc); &#125; // Remove unused channels if MediaContentDescription is rejected. RemoveUnusedChannels(local_description()-&gt;description()); if (!UpdateSessionState(action, cricket::CS_LOCAL, err_desc)) &#123; return false; &#125; if (remote_description()) &#123; // Now that we have a local description, we can push down remote candidates. UseCandidatesInSessionDescription(remote_description()); &#125; pending_ice_restarts_.clear(); if (error() != ERROR_NONE) &#123; return BadLocalSdp(desc-&gt;type(), GetSessionErrorMsg(), err_desc); &#125; return true;&#125; action为offer时CreateChannel创建channels: 123456789101112131415161718192021222324252627282930313233343536373839bool WebRtcSession::CreateChannels(const SessionDescription* desc) &#123; const cricket::ContentGroup* bundle_group = nullptr; if (bundle_policy_ == PeerConnectionInterface::kBundlePolicyMaxBundle) &#123; bundle_group = desc-&gt;GetGroupByName(cricket::GROUP_TYPE_BUNDLE); if (!bundle_group) &#123; LOG(LS_WARNING) &lt;&lt; &quot;max-bundle specified without BUNDLE specified&quot;; return false; &#125; &#125; // Creating the media channels and transport proxies. const cricket::ContentInfo* voice = cricket::GetFirstAudioContent(desc); if (voice &amp;&amp; !voice-&gt;rejected &amp;&amp; !voice_channel_) &#123; if (!CreateVoiceChannel(voice, GetBundleTransportName(voice, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create voice channel.&quot;; return false; &#125; &#125; const cricket::ContentInfo* video = cricket::GetFirstVideoContent(desc); if (video &amp;&amp; !video-&gt;rejected &amp;&amp; !video_channel_) &#123; if (!CreateVideoChannel(video, GetBundleTransportName(video, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create video channel.&quot;; return false; &#125; &#125; const cricket::ContentInfo* data = cricket::GetFirstDataContent(desc); if (data_channel_type_ != cricket::DCT_NONE &amp;&amp; data &amp;&amp; !data-&gt;rejected &amp;&amp; !rtp_data_channel_ &amp;&amp; !sctp_transport_) &#123; if (!CreateDataChannel(data, GetBundleTransportName(data, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create data channel.&quot;; return false; &#125; &#125; return true;&#125; CreateChannels中创建三个Channel,其中CreateVideoChannel创建视频Channel: 123456789101112131415161718192021222324252627282930313233343536373839404142bool WebRtcSession::CreateVideoChannel(const cricket::ContentInfo* content, const std::string* bundle_transport) &#123; bool require_rtcp_mux = rtcp_mux_policy_ == PeerConnectionInterface::kRtcpMuxPolicyRequire; std::string transport_name = bundle_transport ? *bundle_transport : content-&gt;name; cricket::DtlsTransportInternal* rtp_dtls_transport = transport_controller_-&gt;CreateDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); cricket::DtlsTransportInternal* rtcp_dtls_transport = nullptr; if (!require_rtcp_mux) &#123; rtcp_dtls_transport = transport_controller_-&gt;CreateDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTCP); &#125; video_channel_.reset(channel_manager_-&gt;CreateVideoChannel( call_, media_config_, rtp_dtls_transport, rtcp_dtls_transport, transport_controller_-&gt;signaling_thread(), content-&gt;name, SrtpRequired(), video_options_)); if (!video_channel_) &#123; transport_controller_-&gt;DestroyDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); if (rtcp_dtls_transport) &#123; transport_controller_-&gt;DestroyDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); &#125; return false; &#125; video_channel_-&gt;SignalRtcpMuxFullyActive.connect( this, &amp;WebRtcSession::DestroyRtcpTransport_n); video_channel_-&gt;SignalDtlsSrtpSetupFailure.connect( this, &amp;WebRtcSession::OnDtlsSrtpSetupFailure); SignalVideoChannelCreated(); video_channel_-&gt;SignalSentPacket.connect(this, &amp;WebRtcSession::OnSentPacket_w); return true;&#125; 调用channel_manager的CreateVideoChannel创建BaseChannel基类的cricket::VideoChannel. VideoChannel需要传入VideoMediaChannel作为构造参数: 1234567891011121314151617181920212223242526272829303132//pc/channelmanager.h/ccVideoChannel* ChannelManager::CreateVideoChannel_w( webrtc::Call* call, const cricket::MediaConfig&amp; media_config, DtlsTransportInternal* rtp_dtls_transport, DtlsTransportInternal* rtcp_dtls_transport, rtc::PacketTransportInternal* rtp_packet_transport, rtc::PacketTransportInternal* rtcp_packet_transport, rtc::Thread* signaling_thread, const std::string&amp; content_name, bool srtp_required, const VideoOptions&amp; options) &#123; RTC_DCHECK(initialized_); RTC_DCHECK(worker_thread_ == rtc::Thread::Current()); RTC_DCHECK(nullptr != call); VideoMediaChannel* media_channel = media_engine_-&gt;CreateVideoChannel( call, media_config, options); if (media_channel == NULL) &#123; return NULL; &#125; VideoChannel* video_channel = new VideoChannel( worker_thread_, network_thread_, signaling_thread, media_channel, content_name, rtcp_packet_transport == nullptr, srtp_required); if (!video_channel-&gt;Init_w(rtp_dtls_transport, rtcp_dtls_transport, rtp_packet_transport, rtcp_packet_transport)) &#123; delete video_channel; return NULL; &#125; video_channels_.push_back(video_channel); return video_channel;&#125; VideoMediaChannel实例media_channel由MediaEngineInterface对象media_engine创建,media_engine由ChannelManager构造方法传入并初始化,ChannelManager由PeerConnectionFactory创建,在PeerConnection初始化方法中,media_engine被创建: 123456789101112131415161718192021222324252627282930313233343536373839404142//pc/peerconnectionfactory.ccbool PeerConnectionFactory::Initialize() &#123; RTC_DCHECK(signaling_thread_-&gt;IsCurrent()); rtc::InitRandom(rtc::Time32()); default_network_manager_.reset(new rtc::BasicNetworkManager()); if (!default_network_manager_) &#123; return false; &#125; default_socket_factory_.reset( new rtc::BasicPacketSocketFactory(network_thread_)); if (!default_socket_factory_) &#123; return false; &#125; std::unique_ptr&lt;cricket::MediaEngineInterface&gt; media_engine = worker_thread_-&gt;Invoke&lt;std::unique_ptr&lt;cricket::MediaEngineInterface&gt;&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnectionFactory::CreateMediaEngine_w, this)); channel_manager_.reset(new cricket::ChannelManager( std::move(media_engine), worker_thread_, network_thread_)); channel_manager_-&gt;SetVideoRtxEnabled(true); if (!channel_manager_-&gt;Init()) &#123; return false; &#125; return true;&#125;std::unique_ptr&lt;cricket::MediaEngineInterface&gt;PeerConnectionFactory::CreateMediaEngine_w() &#123; RTC_DCHECK(worker_thread_ == rtc::Thread::Current()); return std::unique_ptr&lt;cricket::MediaEngineInterface&gt;( cricket::WebRtcMediaEngineFactory::Create( default_adm_.get(), audio_encoder_factory_, audio_decoder_factory_, video_encoder_factory_.get(), video_decoder_factory_.get(), external_audio_mixer_));&#125; WebRtcMediaEngine2继承自CompositeMediaEngine,CompositeMediaEngine父类MediaEngineInterface有WebRtcVoiceEngine voice与WebRtcVideoEngine2 video两个对象 WebRtcVideoEngine2WebRtcVideoEngine2定义在media/engine/webrtcvideoengine2.h下,用于创建WebRtcVideoChannel2(定义在同一头文件),WebRtcVideoChannel2定义了WebRtcVideoSendStream与WebRtcVideoReceiveStream两个内部类.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRtc源码分析(1) PeerConnection]]></title>
    <url>%2F2017%2F07%2F11%2Fwebrtc-source-peerconnection%2F</url>
    <content type="text"><![CDATA[ChannelManagerpc/channelmanager.h 12345678// ChannelManager allows the MediaEngine to run on a separate thread, and takes// care of marshalling calls between threads. It also creates and keeps track of// voice and video channels; by doing so, it can temporarily(暂时的) pause all the// channels when a new audio or video device is chosen. The voice and video// channels are stored in separate vectors, to easily allow operations on just// voice or just video channels.// ChannelManager also allows the application to discover what devices it has// using device manager. WebRtcSession构造中通过MediaControllerInterface初始化ChannelManager变量channelmanager , ChannelManager通过构造传入MediaEngineInterface. WebRtcSessionpc/webrtcsession.h 1234567// A WebRtcSession manages general session state. This includes negotiation// of both the application-level and network-level protocols: the former// defines what will be sent and the latter defines how it will be sent. Each// network-level protocol is represented by a Transport object. Each Transport// participates in the network-level negotiation. The individual streams of// packets are represented by TransportChannels. The application-level protocol// is represented by SessionDecription objects. MediaControllerInterfacepc/mediacontroller.h 123// The MediaController currently owns shared state between media channels.// Abstract interface is defined here such that it can be faked/mocked for// tests, but no other real reason. 实现类MediaController,管理ChannelManager,cricket::ChannelManager* const channel_manager_;,在PeerConnection的Initialize方法中,通过PeerConnectionFactory创建.PeerConnectionFactory中Initialize中真正创建ChannelManager,创建ChannelManager之前,先创建出MediaEngine,实际在PeerConnectionFactory::CreateMediaEngine_w中通过cricket::WebRtcMediaEngineFactory::Create创建. 7&gt; Downloading src/resources/voice_engine/audio_tiny44.wav… 4&gt; Downloading src/resources/voice_engine/audio_tiny48.wav… 2&gt; Downloading src/resources/voice_engine/audio_tiny8.wav… Hook ‘download_from_google_storage –directory –recursive –num_threads=10 –no_auth –quiet –bucket chromium-webrtc-resources src/resources’ took 528.97 secs WARNING: ‘src/testing/gmock’ has been moved from DEPS to a higher level checkout. The git folder containing all the local branches has been saved to /Users/shenjunwei/soft-source/webrtc/old_src_testing_gmock.git. If you don’t care about its state you can safely remove that folder to free up space. WARNING: ‘src/testing/gtest’ has been moved from DEPS to a higher level checkout. The git folder containing all the local branches has been saved to /Users/shenjunwei/soft-source/webrtc/old_src_testing_gtest.git. If you don’t care about its state you can safely remove that folder to free up space.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于内存对齐那些事]]></title>
    <url>%2F2017%2F07%2F09%2Ftips-about-data-structure-alignment%2F</url>
    <content type="text"><![CDATA[Wrote by mutouyun. 1. 内存对齐（Data Structure Alignment）是什么内存对齐，或者说字节对齐，是一个数据类型所能存放的内存地址的属性（Alignment is a property of a memory address）。 这个属性是一个无符号整数，并且这个整数必须是2的N次方（1、2、4、8、……、1024、……）。 当我们说，一个数据类型的内存对齐为8时，意思就是指这个数据类型所定义出来的所有变量，其内存地址都是8的倍数。 当一个基本数据类型（fundamental types）的对齐属性，和这个数据类型的大小相等时，这种对齐方式称作自然对齐（naturally aligned）。 比如，一个4字节大小的int型数据，默认情况下它的字节对齐也是4。 2. 为什么我们需要内存对齐这是因为，并不是每一个硬件平台都能够随便访问任意位置的内存的。 微软的MSDN里有这样一段话： Many CPUs, such as those based on Alpha, IA-64, MIPS, and SuperH architectures, refuse to read misaligned data. When a program requests that one of these CPUs access data that is not aligned, the CPU enters an exception state and notifies the software that it cannot continue. On ARM, MIPS, and SH device platforms, for example, the operating system default is to give the application an exception notification when a misaligned access is requested. 大意是说，有不少平台的CPU，比如Alpha、IA-64、MIPS还有SuperH架构，若读取的数据是未对齐的（比如一个4字节的int在一个奇数内存地址上），将拒绝访问，或抛出硬件异常。 另外，在维基百科里也记载着如下内容： Data alignment means putting the data at a memory offset equal to some multiple of the word size, which increases the system’s performance due to the way the CPU handles memory. 意思是，考虑到CPU处理内存的方式（32位的x86 CPU，一个时钟周期可以读取4个连续的内存单元，即4字节），使用字节对齐将会提高系统的性能（也就是CPU读取内存数据的效率。比如你一个int放在奇数内存位置上，想把这4个字节读出来，32位CPU就需要两次。但对齐之后一次就可以了）。 3. 内存对齐带来的数据结构大小变化因为有了内存对齐，因此数据在内存里的存放就不是紧挨着的，而是可能会出现一些空隙（Data Structure Padding，也就是用于填充的空白内容）。因此对基本数据类型来说可能还好说，对于一个内部有多个基本类型的结构体（struct）或类而言，sizeof的结果往往和想象中不大一样。 让我们来看一个例子： 12345678struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; 我们可以看到，MyStruct中有5个成员，如果直接相加的话大小应该是16，但在32位MSVC里它的sizeof结果是32。 之所以结果出现偏差，为了保证这个结构体里的每个成员都应该在它对齐了的内存位置上，而在某些位置插入了Padding。 下面我们尝试考虑内存对齐，来计算一下这个结构体的大小。首先，我们可以假设MyStruct的整体偏移从0x00开始，这样就可以暂时忽略MyStruct本身的对齐。这时，结构体的整体内存分布如下图所示： 我们可以看到，char和int之间；short和long long之间，为了保证成员各自的对齐属性，分别插入了一些Padding。 因此整个结构体会被填充得看起来像这样： 123456789101112struct MyStruct &#123; char a; // 1 byte char pad_0[3]; // Padding 3 int b; // 4 bytes short c; // 2 bytes char pad_1[6]; // Padding 6 long long d; // 8 bytes char e; // 1 byte char pad_2[7]; // Padding 7 &#125;; 注意到上面加了Padding的示意结构体里，e的后面还跟了7个字节的填充。这是因为结构体的整体大小必须可被对齐值整除，所以“char e”的后面还会被继续填充7个字节好让结构体的整体大小是8的倍数32。 我们可以在gcc + 32位linux中尝试计算sizeof(MyStruct)，得到的结果是24。 这是因为gcc中的对齐规则和MSVC不一样，不同的平台下会使用不同的默认对齐值（The default alignment is fixed for a particular target ABI）。在gcc + 32位linux中，大小超过4字节的基本类型仍然按4字节对齐。因此MyStruct的内存布局这时看起来应该像这个样子： 下面我们来确定这个结构体类型本身的内存对齐是多少。为了保证结构体内的每个成员都能够放在它自然对齐的位置上，对这个结构体本身来说最理想的内存对齐数值应该是结构体里内存对齐数值最大的成员的内存对齐数。 也就是说，对于上面的MyStruct，结构体类型本身的内存对齐应该是8。并且，当我们强制对齐方式小于8时，比如设置MyStruct对齐为2，那么其内部成员的对齐也将被强制不能超过2。 为什么？因为对于一个数据类型来说，其内部成员的位置应该是相对固定的。假如上面这个结构体整体按1或者2字节对齐，而成员却按照各自的方式自然对齐，就有可能出现成员的相对偏移量随内存位置而改变的问题。 比如说，我们可以画一下整个结构体按1字节对齐，并且结构体内的每个成员按自然位置对齐的内存布局： 上面的第一种情况，假设MyStruct的起始地址是0x01（因为结构体本身的偏移按1字节对齐），那么char和int之间将会被填充2个字节的Padding，以保证int的对齐还是4字节。 如果第二次分配MyStruct的内存时起始地址变为0x03，由于int还是4字节对齐，则char和int之间将不会填充Padding（填充了反而不对齐了）。 以此类推，若MyStruct按1字节对齐时不强制所有成员的对齐均不超过1的话，这个结构体里的相对偏移方式一共有4种。 因此对于结构体来说，默认的对齐将等于其中对齐最大的成员的对齐值。并且，当我们限定结构体的内存对齐时，同时也限定了结构体内所有成员的内存对齐不能超过结构体本身的内存对齐。 4. 指定内存对齐在C++98/03里，对内存对齐的操作在不同的编译器里可能有不同的方法。 在MSVC中，一般使用#progma pack来指定内存对齐： 12345678910#pragma pack(1) // 指定后面的内容内存对齐为1 struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; #pragma pack() // 还原默认的内存对齐 这时，MyStruct由于按1字节对齐，其中的所有成员都将变为1字节对齐，因此sizeof(MyStruct)将等于16。 还有另外一个简单的方法： 12345678__declspec(align(64)) struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; __declspec(align(64))将指定内存对齐为64。比较坑的是，这种方法不能指定内存对齐小于默认对齐，也就是说它只能调大不能调小（__declspec(align(#)) can only increase alignment restrictions）。因此下面这样写会忽略掉declspec： 12__declspec(align(1)) struct MyStruct // ... // warning C4359: &apos;MyStruct&apos;: Alignment specifier is less than actual alignment (8), and will be ignored. 微软的__declspec(align(#))，其#的内容可以是预编译宏，但不能是编译期数值： 12345678#define XX 32 struct __declspec(align(XX)) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY&gt; struct __declspec(align(YY)) MyStruct_2 &#123;&#125;; // error C2059: syntax error: &apos;identifier&apos; static const unsigned ZZ = 32; struct __declspec(align(ZZ)) MyStruct_3 &#123;&#125;; // error C2057: expected constant expression 在Visual C++ Compiler November 2013 CTP之后，微软终于支持编译期数值的写法了： 123template &lt;size_t YY&gt; struct __declspec(align(YY)) MyStruct_2 &#123;&#125;; // OK in 2013 CTP __declspec(align(#))最大支持对齐为8192（Valid entries are integer powers of two from 1 to 8192）。 下面再来看gcc。gcc和MSVC一样，可以使用#pragma pack： 123456#pragma pack(1) struct MyStruct &#123; // ... &#125;; #pragma pack() 另外，也可以使用__attribute__((__aligned__((#))))： 123456789struct __attribute__((__aligned__((1)))) MyStruct_1 &#123; // ... &#125;; struct MyStruct_2 &#123; // ... &#125; __attribute__((__aligned__((1)))); 这东西写上面写下面都是可以的，但是不能写在struct前面。 和MSVC一样，__attribute__也只能把字节对齐改大，不能改小（The aligned attribute can only increase the alignment）。比较坑的是当你试图改小的时候，gcc没有任何编译提示信息。 gcc可以接受一个宏或编译期数值： 12345678910#define XX 1 struct __attribute__((__aligned__((XX)))) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY&gt; struct __attribute__((__aligned__((YY)))) MyStruct_2 &#123;&#125;; // OK static const unsigned ZZ = 1; struct __attribute__((__aligned__((ZZ)))) MyStruct_3 &#123;&#125;; // ^ // error: requested alignment is not an integer constant gcc的__attribute__((__aligned__((#))))支持的上限受限于链接器（Note that the effectiveness of aligned attributes may be limited by inherent limitations in your linker）。 5. 获得内存对齐同样的，在C++98/03里，不同的编译器可能有不同的方法来获得一个类型的内存对齐。 MSVC使用__alignof操作符获得内存对齐大小： 123MyStruct xx; std::cout &lt;&lt; __alignof(xx) &lt;&lt; std::endl; std::cout &lt;&lt; __alignof(MyStruct) &lt;&lt; std::endl; gcc则使用__alignof__： 123MyStruct xx; std::cout &lt;&lt; __alignof__(xx) &lt;&lt; std::endl; std::cout &lt;&lt; __alignof__(MyStruct) &lt;&lt; std::endl; 需要注意的是，不论是__alignof还是__alignof__，对于对齐的计算都发生在编译期。因此像下面这样写： 123int a; char&amp; c = reinterpret_cast&lt;char&amp;&gt;(a); std::cout &lt;&lt; __alignof__(c) &lt;&lt; std::endl; 得到的结果将是1。 如果需要在运行时动态计算一个变量的内存对齐，比如根据一个void*指针指向的内存地址来判断这个地址的内存对齐是多少，我们可以用下面这个简单的方法： 1234__declspec(align(128)) long a = 0; size_t x = reinterpret_cast&lt;size_t&gt;(&amp;a); x &amp;= ~(x - 1); // 计算a的内存对齐大小 std::cout &lt;&lt; x &lt;&lt; std::endl; 用这种方式得到的内存对齐大小可能比实际的大，因为它是切实的获得这个内存地址到底能被多大的2^N整除。 6. 堆内存的内存对齐我们在讨论内存对齐的时候很容易忽略掉堆内存。我们经常会使用malloc分配内存，却不理会这块内存的对齐方式，仿佛堆内存不需要考虑内存对齐一样。 实际上，malloc一般使用当前平台默认的最大内存对齐数对齐内存。比如MSVC在32位下一般是8字节对齐；64位下则是16字节（In Visual C++, the fundamental alignment is the alignment that’s required for a double, or 8 bytes. In code that targets 64-bit platforms, it’s 16 bytes）。这样对于常规的数据都是没有问题的。 但是如果我们自定义的内存对齐超出了这个范围，则是不能直接使用malloc来获取内存的。 当我们需要分配一块具有特定内存对齐的内存块时，在MSVC下应当使用_aligned_malloc；而在gcc下一般使用memalign等函数。 其实自己实现一个简易的aligned_malloc是很容易的： 1234567891011121314151617181920212223242526#include &lt;assert.h&gt; inline void* aligned_malloc(size_t size, size_t alignment) &#123; // 检查alignment是否是2^N assert(!(alignment &amp; (alignment - 1))); // 计算出一个最大的offset，sizeof(void*)是为了存储原始指针地址 size_t offset = sizeof(void*) + (--alignment); // 分配一块带offset的内存 char* p = static_cast&lt;char*&gt;(malloc(offset + size)); if (!p) return nullptr; // 通过“&amp; (~alignment)”把多计算的offset减掉 void* r = reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;size_t&gt;(p + offset) &amp; (~alignment)); // 将r当做一个指向void*的指针，在r当前地址前面放入原始地址 static_cast&lt;void**&gt;(r)[-1] = p; // 返回经过对齐的内存地址 return r; &#125; inline void aligned_free(void* p) &#123; // 还原回原始地址，并free free(static_cast&lt;void**&gt;(p)[-1]); &#125; 7. C++11中对内存对齐的操作C++11标准里统一了内存对齐的相关操作。 指定内存对齐使用alignas说明符： 12345678910alignas(32) long long a = 0; #define XX 1 struct alignas(XX) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY = 1&gt; struct alignas(YY) MyStruct_2 &#123;&#125;; // OK static const unsigned ZZ = 1; struct alignas(ZZ) MyStruct_3 &#123;&#125;; // OK 注意到MyStruct_3编译是OK的。在C++11里，只要是一个编译期数值（包括static const）都支持alignas（the assignment-expression shall be an integral constant expression，参考ISO/IEC-14882:2011，7.6.2 Alignment specifier，第2款）。 但是需要小心的是，目前微软的编译器（Visual C++ Compiler November 2013 CTP）在MyStruct_3的情况下仍然会报error C2057。 另外，alignas同前面介绍的__declspec、__attribute__一样，只能改大不能改小（参考ISO/IEC-14882:2011，7.6.2 Alignment specifier，第5款）。如果需要改小，比如设置对齐为1的话，仍然需要使用#pragma pack。或者，可以使用C++11里#pragma的等价物_Pragma（微软暂不支持这个）： 12345678910_Pragma(&quot;pack(1)&quot;) struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; _Pragma(&quot;pack()&quot;) 除了这些之外，alignas比__declspec、这个char就按int的方式对齐了。 获取内存对齐使用alignof操作符：强大的地方在于它还可以这样用： 1alignas(int) char c; 这个char就按int的方式对齐了。 获取内存对齐使用alignof操作符： 123MyStruct xx; std::cout &lt;&lt; alignof(xx) &lt;&lt; std::endl; std::cout &lt;&lt; alignof(MyStruct) &lt;&lt; std::endl; 相关注意点和前面介绍的__alignof、__alignof__并无二致。 除了alignas和alignof，C++11中还提供了几个有用的工具。 A. std::alignment_of 功能是编译期计算类型的内存对齐。 std里提供这个是为了补充alignof的功能。alignof只能返回一个size_t，而alignment_of则继承自std::integral_constant，因此拥有value_type、type、operator()等接口（或者说操作）。 B. std::aligned_storage 这是个好东西。我们知道，很多时候需要分配一块单纯的内存块，比如new char[32]，之后再使用placement new在这块内存上构建对象： 12char xx[32]; ::new (xx) MyStruct; 但是char[32]是1字节对齐的，xx很有可能并不在MyStruct指定的对齐位置上。这时调用placement new构造内存块，可能会引起效率问题或出错，这时我们应该使用std::aligned_storage来构造内存块： 12std::aligned_storage&lt;sizeof(MyStruct), alignof(MyStruct)&gt;::type xx; ::new (&amp;xx) MyStruct; 需要注意的是，当使用堆内存的时候我们可能还是需要aligned_malloc。因为现在的编译器里new并不能在超出默认最大对齐后，还能保证内存的对齐是正确的。比如在MSVC 2013里，下面的代码： 1234567891011struct alignas(32) MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; void* p = new MyStruct; // warning C4316: &apos;MyStruct&apos; : object allocated on the heap may not be aligned 32 将会得到一个编译警告。 C. std::max_align_t 返回当前平台的最大默认内存对齐类型。malloc返回的内存，其对齐和max_align_t类型的对齐大小应当是一致的。 我们可以通过下面这个方式获得当前平台的最大默认内存对齐数： 12std::cout &lt;&lt; alignof(std::max_align_t) &lt;&lt; std::endl; D. std::align 这货是一个函数，用来在一大块内存当中获取一个符合指定内存要求的地址。 看下面这个例子： 1234char buffer[] = &quot;------------------------&quot;; void * pt = buffer; std::size_t space = sizeof(buffer) - 1; std::align(alignof(int), sizeof(char), pt, space); 意思是，在buffer这个大内存块中，指定内存对齐为alignof(int)，找一块sizeof(char)大小的内存，并在找到这块内存后，将地址放入pt，将buffer从pt开始的长度放入space。 关于这个函数的更多信息，可以参考这里。 关于内存对齐，该说的就是这么多了。我们经常会看到内存对齐的应用，是在网络收发包中。一般用于发送的结构体，都是1字节对齐的，目的是统一收发双方（可能处于不同平台）之间的数据内存布局，以及减少不必要的流量消耗。 C++11中为我们提供了不少有用的工具，可以让我们方便的操作内存对齐。但是在堆内存方面，我们很可能还是需要自己想办法。不过在平时的应用中，因为很少会手动指定内存对齐到大于系统默认的对齐数，所以倒也不比每次new/delete的时候都提心吊胆。 参考文章： Data structure alignment About Data Alignment #pragma pack align (C++) __alignof Operator 6.57.8 Structure-Packing Pragmas 5.32 Specifying Attributes of Types C/C++ Data alignment 及 struct size深入分析 C++ 内存对齐 结构/类对齐的声明方式 字节对齐（强制对齐以及自然对齐） malloc函数字节对齐很经典的问题 C语言字节对齐 网络编程(9)内存对齐对跨平台通讯的影响 Usage Issue of std::align std::align and std::aligned_storage for aligned allocation of memory blocks http://www.cnblogs.com/fangkm/p/4370492.html]]></content>
      <categories>
        <category>Memory</category>
      </categories>
      <tags>
        <tag>Memory</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRTC的模块处理机制]]></title>
    <url>%2F2017%2F07%2F06%2Fwebrtc-modules%2F</url>
    <content type="text"><![CDATA[对于实时音视频应用来讲，媒体数据从采集到渲染，在数据流水线上依次完成一系列处理。流水线由不同的功能模块组成，彼此分工协作：数据采集模块负责从摄像头/麦克风采集音视频数据，编解码模块负责对数据进行编解码，RTP模块负责数据打包和解包。数据流水线上的数据处理速度是影响应用实时性的最重要因素。与此同时，从服务质量保证角度讲，应用需要知道数据流水线的运行状态，如视频采集模块的实时帧率、当前网络的实时速率、接收端的数据丢包率，等等。各个功能模块可以基于这些运行状态信息作相应调整，从而在质量、速度等方面优化数据流水线的运行，实现更快、更好的用户体验。 WebRTC采用模块机制，把数据流水线上功能相对独立的处理点定义为模块，每个模块专注于自己的任务，模块之间基于数据流进行通信。与此同时，专有线程收集和处理模块内部的运行状态信息，并把这些信息反馈到目标模块，实现模块运行状态监控和服务质量保证。本文在深入分析WebRTC源代码基础上，学习研究其模块处理机制的实现细节，从另一个角度理解WebRTC的技术原理。 1 WebRTC数据流水线我们可以把WebRTC看作是一个专注于实时音视频通信的SDK。其对外的API主要负责PeerConnection建立、MediaStream创建、NAT穿透、SDP协商等工作，对内则主要集中于音视频数据的处理，从数据采集到渲染的整个处理过程可以用一个数据流水线来描述，如图1所示。 音视频数据首先从采集端进行采集，一般来说音频数据来自麦克风，视频数据来自摄像头。在某些应用场景下，音频数据来自扬声器，视频数据来自桌面共享。采集端的输出是音视频Raw Data。然后Raw Data到达编码模块，数据被编码器编码成符合语法规则的NAL单元，到达发送端缓冲区PacedSender处。接下来PacedSender把NAL单元发送到RTP模块打包为RTP数据包，最后经过网络模块发送到网络。 在接收端，RTP数据包经过网络模块接收后进行解包得到NAL单元，接下来NAL单元到达接收端缓冲区(JitterBuffer或者NetEQ)进行乱序重排和组帧。一帧完整的数据接收并组帧之后，调用解码模块进行解码，得到该帧数据的Raw Data。最后Raw Data交给渲染模块进行播放/显示。 在数据流水线上，还有一系列模块负责服务质量监控，如丢帧策略，丢包策略，编码器过度使用保护，码率估计，前向纠错，丢包重传，等等。 WebRTC数据流水线上的功能单元被定义为模块，每个模块从上游模块获取输入数据，在本模块进行加工后得到输出数据，交给下游模块进行下一步处理。WebRTC的模块处理机制包括模块和模块处理线程，前者把WebRTC数据流水线上的功能部件封装为模块，后者驱动模块内部状态更新和模块之间状态传递。模块一般挂载到模块处理线程上，由处理线程驱动模块的处理函数。下面分别描述之。 WebRTC模块WebRTC模块虚基类Module定义在webrtc/modules/include/modue.h中，如图2所示。 Module虚基类对外提供三个函数作为API：TimeUntilNextProcess()用来计算距下次调用处理函数Process()的时间间隔；Process()是模块的处理函数，负责模块内部运行监控、状态更新和模块间通信；ProcessThreadAttached()用来把模块挂载到模块处理线程，或者从模块处理线程分离出来，实际实现中这个函数暂时没有被用到。 Module的派生类分布在WebRTC数据流水线上的不同部分，各自承担自己的数据处理和服务质量保证任务。 3 WebRTC模块处理线程WebRTC模块处理线程是模块处理机制的驱动器，它的核心作用是对所有挂载在本线程下的模块，周期性调用其Process()处理函数处理模块内部事务，并处理异步任务。其虚基类ProcessThread和派生类ProcessThreadImpl如图3所示。 ProcessThread基类提供一系列API完成线程功能：Start()/Stop()函数用来启动和结束线程；WakeUp()函数用来唤醒挂载在本线程下的某个模块，使得该模块有机会马上执行其Process()处理函数；PostTask()函数用来邮递一个任务给本线程；RegisterModule()和DeRegisterModule()用来向线程注册/注销模块。 WebRTC基于ProcessThread线程实现派生类ProcessThreadImpl，如图3所示。在成员变量方面，wakeup用来唤醒处于等待状态的线程；thread是平台相关的线程实现如POSIX线程；modules是注册在本线程下的模块集合；queue_是邮递给本线程的任务集合；threadname是线程名字。在成员函数方面，Process()完成ProcessThread的核心任务，其伪代码如下所示。 1234567891011121314151617181920212223bool ProcessThreadImpl::Process() &#123; for (ModuleCallback&amp; m : modules_) &#123; if (m.next_callback == 0) m.next_callback = GetNextCallbackTime(m.module, now); if (m.next_callback &lt;= now || m.next_callback == kCallProcessImmediately) &#123; m.module-&gt;Process(); m.next_callback = GetNextCallbackTime(m.module, rtc::TimeMillis();); &#125; if (m.next_callback &lt; next_checkpoint) next_checkpoint = m.next_callback; &#125; while (!queue_.empty()) &#123; ProcessTask* task = queue_.front(); queue_.pop(); task-&gt;Run(); delete task; &#125; &#125; int64_t time_to_wait = next_checkpoint - rtc::TimeMillis(); if (time_to_wait &gt; 0) wake_up_-&gt;Wait(static_cast&lt;unsigned long&gt;(time_to_wait)); return true;&#125; Process()函数首先处理挂载在本线程下的模块，这也是模块处理线程的核心任务：针对每个模块，计算其下次调用模块Process()处理函数的时刻(调用该模块的TimeUntilNextProcess()函数)。如果时刻是当前时刻，则调用模块的Process()处理函数，并更新下次调用时刻。需要注意，不同模块的执行频率不一样，线程在本轮调用末尾的等待时间和本线程下所有模块的最近下次调用时刻相关。 接下来线程Process()函数处理ProcessTask队列中的异步任务，针对每个任务调用Run()函数，然后任务出队列并销毁。等模块调用和任务都处理完后，则把本次时间片的剩余时间等待完毕，然后返回。如果在等待期间其他线程向本线程Wakeup模块或者邮递一个任务，则线程被立即唤醒并返回，进行下一轮时间片的执行。 至此，关于WebRTC的模块和模块处理线程的基本实现分析完毕，下一节将对WebRTC SDK内模块实例和模块处理线程实例进行详细分析。 4 WebRTC模块处理线程实例WebRTC关于模块和处理线程的实现在webrtc/modules目录下，该目录汇集了所有派生类模块和模块处理线程的实现及实例分布。本节对这些内容进行总结。 WebRTC目前创建三个ProcessThreadImpl线程实例，分别是负责处理音频的VoiceProcessTread，负责处理视频和音视频同步的ModuleProcessThread，以及负责数据平滑发送的PacerThread。这三个线程和挂载在线程下的模块如图4所示。 VoiceProcessThread线程由Worker线程在创建VoiceEngine时创建，负责音频端模块的处理。挂载在该线程下的模块如图4所示，其中MonitorModule负责对音频数据混音处理过程中产生的警告和错误进行处理，AudioDeviceModuleImpl负责对音频设备采集和播放音频数据时产生的警告和错误进行处理，ModuleRtpRtcpImpl负责音频RTP数据包发送过程中的码率计算、RTT更新、RTCP报文发送等内容。 ModuleProcessThread线程由Worker线程在创建VideoChannel时创建，负责视频端模块的处理。挂载在该线程下的模块如图4所示，其中CallStats负责Call对象统计数据(如RTT)的更新，CongestionController负责拥塞控制[1][2]，VideoSender负责视频发送端统计数据的更新，VideoReceiver负责视频接收端统计数据更新和处理状态反馈(如请求关键帧)，ModuleRtpRtcpImpl负责视频RTP数据包发送过程中的码率计算、RTT更新、RTCP报文发送等内容，OveruseFrameDetector负责视频帧采集端过载监控，ReceiveStatisticsImpl负责由接收端统计数据触发的码率更新过程，ViESyncModule负责音视频同步。 PacerThread线程由Worker线程在创建VideoChannel时创建，负责数据平滑发送。挂载在该线程下的PacedSender负责发送端数据平滑发送；RemoteEstimatorProxy派生自RemoteBitrateEstimator，负责在启用发送端码率估计的情况下把接收端收集到的反馈信息发送回发送端。 由以上分析可知，WebRTC创建的模块处理线程实例基本上涵盖了音视频数据从采集到渲染过程中的大部分数据操作。但还有一些模块不依赖于模块线程工作，这部分模块是少数，本文不展开具体的描述。 参考文献[1] WebRTC基于GCC的拥塞控制(上) – 算法分析 [2] WebRTC基于GCC的拥塞控制(下) - 实现分析 转至]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android应用性能优化]]></title>
    <url>%2F2017%2F07%2F03%2Ftips-android-performance%2F</url>
    <content type="text"><![CDATA[Android手机由于其本身的后台机制和硬件特点，性能上一直被诟病，所以软件开发者对软件本身的性能优化就显得尤为重要；本文将对Android开发过程中性能优化的各个方面做一个回顾与总结。 Cache优化 ListView缓存： ListView中有一个回收器，Item滑出界面的时候View会回收到这里，需要显示新的Item的时候，就尽量重用回收器里面的View；每次在getView函数中inflate新的item之前会先判断回收器中是否有缓存的view，即判断convertView是否为null，是则inflate一个新的item View，否则重用回收器中的item。 此外，ListView还使用静态的ViewHolder减少findViewById的次数 ListView中有getViewTypeCount()函数用于获取列表有几种布局类型，getItemViewType(int position)用于获取在position位置上的布局类型; 我们可以利用ViewType来给不同类型的item创建不同的View，这样可以利于ListView的回收 对Item中图片进行适当压缩, 并进行异步加载；如果快速滑动，不加载图片；实现数据的分页加载 IO缓存：在文件和网络IO中使用具有缓存策略的输入流，BufferedInputStream替代InputStream，BufferedReader替代Reader，BufferedReader替代BufferedInputStream data缓存(空间换时间)：①缓存数据库的查询结果，比如缓存数据库表中的数据条数，这样就可以避免多次的select count查询 ②缓存磁盘文件中需要频繁访问的数据到内存中 ③缓存耗时计算的结果 Battery优化 cpu的使用率和使用频率将直接或间接的影响电量的分配和使用，cpu降频可以节约电量 service优化 service作为一个运行在主线程中的后台服务，应该尽量避免耗时动作，而应该尽量新开线程去处理耗时动作 监听系统广播看service是否存活，否则kill掉；降低service优先级使得系统内存吃紧时会被自动kill掉 使用Android提供的IntentService代替service，因为IntentService会在运行完成之后自动停止，而service需要手动调用stopService()才能停止运行 定时执行任务的Alarm机制：Android的定时任务有两种实现方式，Timer类和Alarm机制；Timer不适合长期后台运行的定时任务。因为每种手机都会有自己的休眠策略，Android手机就会在长时间不操作的情况下自动让CPU进入到睡眠状态，这就有可能导致Timer中的定时任务无法正常运行。而Alarm机制则不存在这种情况，它具有唤醒CPU的功能，即可以保证每次需要执行定时任务的时候CPU能正常工作。然而从Android4.4之后，Alarm任务的触发时间将会变得不准确，有可能会延迟一段时间后任务才能得到执行。这不是bug，而是系统在耗电性方面进行的优化。系统会自动检测目前有多少Alarm任务存在，然后将触发时间将近的几个任务放在一起执行，这就可以大幅度的减少CPU被唤醒的次数，从而有效延长电池的使用时间 渲染层优化 Android 界面卡顿的原因？ UI线程中做耗时操作，比如进行网络请求,磁盘读取，位图修改，更新UI等耗时操作，从而导致UI线程卡顿 布局Layout过于复杂，无法在16ms内完成渲染，或者嵌套层次过深 View过度绘制或者频繁的触发measure、layout，同一时间动画执行的次数过多，导致CPU或GPU负载过重 冗余资源及逻辑等导致加载和执行缓慢 Android 界面卡顿怎么处理？ xml布局优化：尽量使用include、merge、ViewStub标签，尽量不存在冗余嵌套及过于复杂布局（譬如10层就会直接异常），例如使用RelativeLayout代替LinearLayout可以减少布局层次和复杂性，View的嵌套层次不能过深，尽量使用GONE替换INVISIBLE，使用weight后尽量将width和heigh设置为0dp，减少运算，Item存在非常复杂的嵌套时考虑使用自定义Item View来取代，减少measure与layout次数等。 ListView及Adapter优化；尽量复用getView方法中的相关View，不重复获取实例导致卡顿，列表尽量在滑动过程中不进行UI元素刷新等。 背景和图片等内存分配优化；尽量减少不必要的背景设置，图片尽量压缩处理显示，尽量避免频繁内存抖动等问题出现；尽可能为不同分辨率创建资源，以减少不必要的硬件缩放 自定义View等绘图与布局优化；尽量避免在draw、measure、layout中做过于耗时及耗内存操作，尤其是draw方法中，尽量减少draw、measure、layout等执行次数，避免过度渲染和绘制；减少不必要的inflate，尽量使用全局变量缓存View 避免ANR，不要在UI线程中做耗时操作，譬如多次数据库操作等 Layout常用的标签 include标签：该标签可以用于将布局文件中的公共部分提取出来给其它布局文件复用，从而使得布局模块化，代码轻量化; 注意点: ①如果标签已经定义了id，而嵌入布局文件的root布局文件也定义了id，标签的id会覆盖掉嵌入布局文件root的id，如果include标签没有定义id则会使用嵌入文件root的id ②如果想使用标签覆盖嵌入布局root布局属性，必须同时覆盖layout_height和layout_width属性，否则会直接报编译时语法错误 viewstub标签：该标签与include一样用于引入布局模块，只是引入的布局默认不会扩张，既不会占用显示也不会占用位置，从而在解析layout时节省cpu和内存，只有通过调用setVisibility函数或者Inflate函数才会将其要装载的目标布局给加载出来，从而达到延迟加载的效果；例如条目详情、进度条标识或者未读消息等，这些情况如果在一开始初始化，虽然设置可见性View.GONE,但是在Inflate的时候View仍然会被Inflate，仍然会创建对象。 merge标签：该标签在layout中会被自动忽略，从而减少一层布局嵌套，其主要用处是当一个布局作为子布局被其他布局include时，使用merge当作该布局的顶节点来代替layout顶节点就可以减少一层嵌套 hierarchy viewer：该工具可以方便的查看Activity的布局，各个View的属性、measure、layout、draw的时间，如果耗时较多会用红色标记，否则显示绿色 网络优化 异步请求网络数据，避免频繁请求数据（例如如果某个页面内请求过多，可以考虑做一定的请求合并），尽可能的减少网络请求次数和减小网络请求时间间隔 网络应用传输中使用高效率的数据格式，譬如使用JSON代替XML，使用WebP代替其他图片格式,并对数据进行Gzip压缩数据，比如post请求的body和header内容 及时缓存数据到内存/文件/数据库 执行某些操作前尽量先进行网络状态判断，比如wifi传输数据比蜂窝数据更省电，所以尽量在wifi下进行数据的预加载 httpClient和httpUrlConnection对比： httpClient是apache的开源实现，API数量多，非常稳定 httpUrlConnection是java自带的模块: ①可以直接支持GZIP压缩,而HttpClient虽然也支持GZIP，但要自己写代码处理 ②httpUrlConnection直接在系统层面做了缓存策略处理，加快重复请求的速度 ③API简单，体积较小,而且直接支持系统级连接池，即打开的连接不会直接关闭，在一段时间内所有程序可共用 HttpURLConnection在Android2.2之前有个重大Bug，调用close()函数会影响连接池，导致连接复用失效，需要关闭keepAlive;因此在2.2之前http请求都是用httpClient，2.2之后则是使用HttpURLConnection 但是!!!现在!!!Android不再推荐这两种方式！二是直接使用OKHttp这种成熟方案！支持Android 2.3及其以上版本 数据结构优化 ArrayList和LinkedList的选择：ArrayList根据index取值更快，LinkedList更占内存、随机插入删除更快速、扩容效率更高 ArrayList、HashMap、LinkedHashMap、HashSet的选择：hash系列数据结构查询速度更优，ArrayList存储有序元素，HashMap为键值对数据结构，LinkedHashMap可以记住加入次序的hashMap，HashSet不允许重复元素 HashMap、WeakHashMap选择：WeakHashMap中元素可在适当时候被系统垃圾回收器自动回收，所以适合在内存紧张时使用 Collections.synchronizedMap和ConcurrentHashMap的选择：ConcurrentHashMap为细分锁，锁粒度更小，并发性能更优；Collections.synchronizedMap为对象锁，自己添加函数进行锁控制更方便 Android中性能更优的数据类型：如SparseArray、SparseBooleanArray、SparseIntArray、Pair；Sparse系列的数据结构是为key为int情况的特殊处理，采用二分查找及简单的数组存储，加上不需要泛型转换的开销，相对Map来说性能更优 内存优化 Android应用内存溢出OOM 内存溢出的主要导致原因有如下几类：①应用代码存在内存泄露，长时间积累无法释放导致OOM；②应用的某些逻辑操作疯狂的消耗掉大量内存（譬如加载一张不经过处理的超大超高清图片等）导致超过阈值OOM 解决思路①在内存引用上做些处理，常用的有软引用、弱引用 ②在内存中加载图片时直接在内存中做处理，如：边界压缩 ③动态回收内存，手动recyle bitmap，回收对象 ④优化Dalvik虚拟机的堆内存分配 ⑤自定义堆内存大小]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多媒体之术语]]></title>
    <url>%2F2017%2F06%2F27%2Fmedia-terminology%2F</url>
    <content type="text"><![CDATA[一.编解码术语1.GOP/码流/比特率/帧速率/分辨率1.1GOP（Group of picture）关键帧的周期，也就是两个IDR帧之间的距离，一个帧组的最大帧数，一般而言，每一秒视频至少需要使用 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。 需要说明的是，通过提高GOP值来提高图像质量是有限度的，在遇到场景切换的情况时，H.264编码器会自动强制插入一个I帧，此时实际的GOP值被缩短了。另一方面，在一个GOP中，P、B帧是由I帧预测得到的，当I帧的图像质量比较差时，会影响到一个GOP中后续P、B帧的图像质量，直到下一个GOP开始才有可能得以恢复，所以GOP值也不宜设置过大。 同时，由于P、B帧的复杂度大于I帧，所以过多的P、B帧会影响编码效率，使编码效率降低。另外，过长的GOP还会影响Seek操作的响应速度，由于P、B帧是由前面的I或P帧预测得到的，所以Seek操作需要直接定位，解码某一个P或B帧时，需要先解码得到本GOP内的I帧及之前的N个预测帧才可以，GOP值越长，需要解码的预测帧就越多，seek响应的时间也越长。 1.12CABAC/CAVLCH.264/AVC标准中两种熵编码方法，CABAC叫自适应二进制算数编码，CAVLC叫前后自适应可变长度编码， CABAC：是一种无损编码方式，画质好，X264就会舍弃一些较小的DCT系数，码率降低，可以将码率再降低10-15%（特别是在高码率情况下），会降低编码和解码的速速。 CAVLC将占用更少的CPU资源，但会影响压缩性能。 其他: 帧：当采样视频信号时，如果是通过逐行扫描，那么得到的信号就是一帧图像，通常帧频为25帧每秒（PAL制）、30帧每秒（NTSC制）； 场：当采样视频信号时，如果是通过隔行扫描（奇、偶数行），那么一帧图像就被分成了两场，通常场频为50Hz（PAL制）、60Hz（NTSC制）； 帧频、场频的由来：最早由于抗干扰和滤波技术的限制，电视图像的场频通常与电网频率（交流电）相一致，于是根据各地交流电频率不同就有了欧洲和中国等PAL制的50Hz和北美等NTSC制的60Hz，但是现在并没有这样的限制了，帧频可以和场频一样，或者场频可以更高。 帧编码、场编码方式：逐行视频帧内邻近行空间相关性较强，因此当活动量非常小或者静止的图像比较适宜采用帧编码方式；而场内相邻行之间的时间相关性较强，对运动量较大的运动图像则适宜采用场编码方式。 1.1.3Deblocking开启会减少块效应. 1.1.4FORCE_IDR是否让每个I帧变成IDR帧，如果是IDR帧，支持随机访问。 1.1.5frame,tff,bff–frame 将两场合并作为一帧进行编码,–tff Enable interlaced mode (开启隔行编码并设置上半场在前),–bff Enable interlaced mode。 PAFF 和MBAFF：当对隔行扫描图像进行编码时，每帧包括两个场，由于两个场之间存在较大的扫描间隔，这样，对运动图像来说，帧中相邻两行之间的空间相关性相对于逐行扫描时就会减小，因此这时对两个场分别进行编码会更节省码流。 对帧来说，存在三种可选的编码方式：将两场合并作为一帧进行编码(frame 方式)或将两场分别编码(field 方式)或将两场合并起来作为一帧，但不同的是将帧中垂直相邻的两个宏块合并为宏块对进行编码；前两种称为PAFF 编码，对运动区域进行编码时field 方式有效，对非运区域编码时，由于相邻两行有较大的相关性，因而frame 方式会更有效。当图像同时存在运动区域和非运动区域时，在MB 层次上，对运动区域采取field 方式，对非运动区域采取frame 方式会更加有效，这种方式就称为MBAFF，预测的单位是宏块对。 1.2码流/码率码流(Data Rate)是指视频文件在单位时间内使用的数据流量，也叫码率或码流率，通俗一点的理解就是取样率,是视频编码中画面质量控制中最重要的部分，一般我们用的单位是kb/s或者Mb/s。一般来说同样分辨率下，视频文件的码流越大，压缩比就越小，画面质量就越高。码流越大，说明单位时间内取样率越大，数据流，精度就越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。 当然，码流越大，文件体积也越大，其计算公式是文件体积=时间X码率/8。例如，网络上常见的一部90分钟1Mbps码流的720P RMVB文件，其体积就=5400秒×1Mb/8=675MB。 通常来说，一个视频文件包括了画面及声音，例如一个RMVB的视频文件，里面包含了视频信息和音频信息，音频及视频都有各自不同的采样方式和比特率，也就是说，同一个视频文件音频和视频的比特率并不是一样的。而我们所说的一个视频文件码流率大小，一般是指视频文件中音频及视频信息码流率的总和。 以以国内最流行，大家最熟悉的RMVB视频文件为例，RMVB中的VB，指的是VBR，即Variable Bit Rate的缩写，中文含义是可变比特率，它表示RMVB采用的是动态编码的方式，把较高的采样率用于复杂的动态画面(歌舞、飞车、战争、动作等)，而把较低的采样率用于静态画面，合理利用资源，达到画质与体积可兼得的效果。 码率和取样率最根本的差别就是码率是针对源文件来讲的。 1.3采样率采样率（也称为采样速度或者采样频率）定义了每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示。采样率是指将模拟信号转换成数字信号时的采样频率，也就是单位时间内采样多少点。一个采样点数据有多少个比特。比特率是指每秒传送的比特(bit)数。单位为 bps(Bit Per Second)，比特率越高，传送的数据越大，音质越好.比特率 =采样率 x 采用位数 x声道数. 采样率类似于动态影像的帧数，比如电影的采样率是24赫兹，PAL制式的采样率是25赫兹，NTSC制式的采样率是30赫兹。当我们把采样到的一个个静止画面再以采样率同样的速度回放时，看到的就是连续的画面。同样的道理，把以44.1kHZ采样率记录的CD以同样的速率播放时，就能听到连续的声音。显然，这个采样率越高，听到的声音和看到的图像就越连贯。当然，人的听觉和视觉器官能分辨的采样率是有限的，基本上高于44.1kHZ采样的声音，绝大部分人已经觉察不到其中的分别了。 而声音的位数就相当于画面的颜色数，表示每个取样的数据量，当然数据量越大，回放的声音越准确，不至于把开水壶的叫声和火车的鸣笛混淆。同样的道理，对于画面来说就是更清晰和准确，不至于把血和西红柿酱混淆。不过受人的器官的机能限制，16位的声音和24位的画面基本已经是普通人类的极限了，更高位数就只能靠仪器才能分辨出来了。比如电话就是3kHZ取样的7位声音，而CD是44.1kHZ取样的16位声音，所以CD就比电话更清楚。 当你理解了以上这两个概念，比特率就很容易理解了。以电话为例，每秒3000次取样，每个取样是7比特，那么电话的比特率是21000。 而CD是每秒 44100次取样，两个声道，每个取样是13位PCM编码，所以CD的比特率是44100213=1146600，也就是说CD每秒的数据量大约是 144KB，而一张CD的容量是74分等于4440秒，就是639360KB＝640MB。 码率和取样率最根本的差别就是码率是针对源文件来讲的 1.4比特率比特率是指每秒传送的比特(bit)数。单位为bps(Bit Per Second)，比特率越高，传送的数据越大。在视频领域,比特率常翻译为码率 !!! 比特率表示经过编码（压缩）后的音、视频数据每秒钟需要用多少个比特来表示，而比特就是二进制里面最小的单位，要么是0，要么是1。比特率与音、视频压缩的关系，简单的说就是比特率越高，音、视频的质量就越好，但编码后的文件就越大；如果比特率越少则情况刚好相反。 比特率是指将数字声音、视频由模拟格式转化成数字格式的采样率，采样率越高，还原后的音质、画质就越好。 常见编码模式： VBR（Variable Bitrate）动态比特率 也就是没有固定的比特率，压缩软件在压缩时根据音频数据即时确定使用什么比特率，这是以质量为前提兼顾文件大小的方式，推荐编码模式； ABR（Average Bitrate）平均比特率 是VBR的一种插值参数。LAME针对CBR不佳的文件体积比和VBR生成文件大小不定的特点独创了这种编码模式。ABR在指定的文件大小内，以每50帧（30帧约1秒）为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量，可以做为VBR和CBR的一种折衷选择。 CBR（Constant Bitrate），常数比特率 指文件从头到尾都是一种位速率。相对于VBR和ABR来讲，它压缩出来的文件体积很大，而且音质相对于VBR和ABR不会有明显的提高。 1.5帧速率帧速率也称为FPS(Frames PerSecond)的缩写——帧/秒。是指每秒钟刷新的图片的帧数，也可以理解为图形处理器每秒钟能够刷新几次。越高的帧速率可以得到更流畅、更逼真的动画。每秒钟帧数(FPS)越多，所显示的动作就会越流畅。 1.6分辨率就是帧大小每一帧就是一副图像。 640*480分辨率的视频，建议视频的码速率设置在700以上，音频采样率44100就行了 一个音频编码率为128Kbps，视频编码率为800Kbps的文件，其总编码率为928Kbps，意思是经过编码后的数据每秒钟需要用928K比特来表示。 视频分辨率是指视频成像产品所成图像的大小或尺寸。常见的视像分辨率有352×288，176×144，640×480，1024×768。在成像的两组数字中，前者为图片长度，后者为图片的宽度，两者相乘得出的是图片的像素，长宽比一般为4：3. 目前监控行业中主要使用Qcif(176×144）、CIF(352×288）、HALF D1(704×288）、D1(704×576）等几种分辨率。 D1是数字电视系统显示格式的标准，共分为以下5种规格： D1：480i格式（525i）：720×480（水平480线，隔行扫描），和NTSC模拟电视清晰度相同，行频为15.25kHz，相当于我们所说的4CIF(720×576) D2：480P格式（525p）：720×480（水平480线，逐行扫描），较D1隔行扫描要清晰不少，和逐行扫描DVD规格相同，行频为31.5kHz D3：1080i格式（1125i）：1920×1080（水平1080线，隔行扫描），高清方式采用最多的一种分辨率，分辨率为1920×1080i/60Hz，行频为33.75kHz D4：720p格式（750p）：1280×720（水平720线，逐行扫描），虽然分辨率较D3要低，但是因为逐行扫描，市面上更多人感觉相对于1080I（实际逐次540线）视觉效果更加清晰。不过个人感觉来说，在最大分辨率达到1920×1080的情况下，D3要比D4感觉更加清晰，尤其是文字表现力上，分辨率为1280×720p/60Hz，行频为45kHz D5：1080p格式（1125p）：1920×1080（水平1080线，逐行扫描），目前民用高清视频的最高标准，分辨率为1920×1080P/60Hz，行频为67.5KHZ。 其中D1 和D2标准是我们一般模拟电视的最高标准，并不能称的上高清晰，D3的1080i标准是高清晰电视的基本标准，它可以兼容720p格式，而D5的1080P只是专业上的标准。 计算输出文件大小公式： （音频编码率（KBit为单位）/8 +视频编码率（KBit为单位）/8）×影片总长度（秒为单位）=文件大小（MB为单位） 2.高清视频目前的720P以及1080P采用了很多种编码，例如主流的MPEG2，VC-1以及H.264，还有Divx以及Xvid，至于封装格式更多到令人发指，ts、mkv、wmv以及蓝光专用等等。 720和1080代表视频流的分辨率，前者1280720，后者19201080，不同的编码需要不同的系统资源，大概可以认为是H.264&gt;VC-1&gt;MPEG2。 VC-1是最后被认可的高清编码格式，不过因为有微软的后台，所以这种编码格式不能小窥。相对于MPEG2，VC-1的压缩比更高，但相对于H.264而言，编码解码的计算则要稍小一些，目前来看，VC-1可能是一个比较好的平衡，辅以微软的支持，应该是一只不可忽视的力量。一般来说，VC-1多为 “.wmv”后缀，但这都不是绝对的，具体的编码格式还是要通过软件来查询。 总的来说，从压缩比上来看，H.264的压缩比率更高一些，也就是同样的视频，通过H.264编码算法压出来的视频容量要比VC-1的更小，但是VC-1 格式的视频在解码计算方面则更小一些，一般通过高性能的CPU就可以很流畅的观看高清视频。相信这也是目前NVIDIA Geforce 8系列显卡不能完全解码VC-1视频的主要原因。 PS&amp;TS是两种视频或影片封装格式，常用于高清片。扩展名分别为VOB/EVO和TS等；其文件编码一般用MPEG2/VC-1/H.264 高清，英文为“High Definition”，即指“高分辨率”。 高清电视(HDTV)，是由美国电影电视工程师协会确定的高清晰度电视标准格式。现在的大屏幕液晶电视机，一般都支持1080i和720P，而一些俗称的“全高清”(Full HD)，则是指支持1080P输出的电视机。 目前的高清视频编码格式主要有H.264、VC-1、MPEG-2、MPEG-4、DivX、XviD、WMA-HD以及X264。事实上，现在网络上流传的高清视频主要以两类文件的方式存在：一类是经过MPEG-2标准压缩，以tp和ts为后缀的视频流文件;一类是经过WMV-HD(Windows Media Video HighDefinition)标准压缩过的wmv文件，还有少数文件后缀为avi或mpg，其性质与wmv是一样的。真正效果好的高清视频更多地以H.264与VC-1这两种主流的编码格式流传。 一般来说，H.264格式以“.avi”、“.mkv”以及“.ts”封装比较常见。 3.位率（定码率，变码率）位率又称为“码率”。指单位时间内，单个录像通道所产生的数据量，其单位通常是bps、Kbps或Mbps。可以根据录像的时间与位率估算出一定时间内的录像文件大小。 位率是一个可调参数，不同的分辨率模式下和监控场景下，合适的位率大小是不同的。在设置时，要综合考虑三个因素： 分辨率:分辨率是决定位率（码率）的主要因素，不同的分辨率要采用不同的位率。总体而言，录像的分辨率越高，所要求的位率（码率）也越大，但并不总是如此，图1说明了不同分辨率的合理的码率选择范围。所谓“合理的范围”指的是，如果低于这个范围，图像质量看起来会变得不可接受；如果高于这个范围，则显得没有必要，对于网络资源以及存储资源来说是一种浪费。 场景:监控的场景是设置码率时要考虑的第二个因素。在视频监控中，图像的运动剧烈程度还与位率有一定的关系，运动越剧烈，编码所要求的码率就越高。反之则越低。因此在同样的图像分辨率条件下，监控人多的场景和人少的场景，所要求的位率也是不同的。 存储空间:最后需要考量的因素是存储空间，这个因素主要是决定了录像系统的成本。位率设置得越高，画质相对会越好，但所要求的存储空间就越大。所以在工程实施中，设置合适的位率即可以保证良好的回放图像质量，又可以避免不必要的资源浪费。 QP(quantizer parameter) 介于0~31之间，值越小，量化越精细，图像质量就越高，而产生的码流也越长。 PSNR 允许计算峰值信噪比(PSNR,Peak signal-to-noise ratio),编码结束后在屏幕上显示PSNR计算结果。开启与否与输出的视频质量无关，关闭后会带来微小的速度提升。 profile level 分别是BP、EP、MP、HP： BP-Baseline Profile：基本画质。支持I/P 帧，只支持无交错（Progressive）和CAVLC； EP-Extended profile：进阶画质。支持I/P/B/SP/SI 帧，只支持无交错（Progressive）和CAVLC； MP-Main profile：主流画质。提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），也支持CAVLC 和CABAC 的支持； HP-High profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码和更多的YUV 格式； H.264规定了三种档次，每个档次支持一组特定的编码功能，并支持一类特定的应用。 基本档次：利用I片和P片支持帧内和帧间编码，支持利用基于上下文的自适应的变长编码进行的熵编码（CAVLC）。主要用于可视电话、会议电视、无线通信等实时视频通信； 主要档次：支持隔行视频，采用B片的帧间编码和采用加权预测的帧内编码；支持利用基于上下文的自适应的算术编码（CABAC）。主要用于数字广播电视与数字视频存储； 扩展档次：支持码流之间有效的切换（SP和SI片）、改进误码性能（数据分割），但不支持隔行视频和CABAC。主要用于网络的视频流，如视频点播。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Image Stride(内存图像行跨度)]]></title>
    <url>%2F2017%2F06%2F27%2Fmedia-graphic-image-stride%2F</url>
    <content type="text"><![CDATA[When a video image is stored in memory, the memory buffer might contain extra padding bytes after each row of pixels. The padding bytes affect how the image is store in memory, but do not affect how the image is displayed. 当视频图像存储在内存时，图像的每一行末尾也许包含一些扩展的内容，这些扩展的内容只影响图像如何存储在内存中，但是不影响图像如何显示出来； The stride is the number of bytes from one row of pixels in memory to the next row of pixels in memory. Stride is also called pitch. If padding bytes are present, the stride is wider than the width of the image, as shown in the following illustration. Stride 就是这些扩展内容的名称，Stride 也被称作 Pitch，如果图像的每一行像素末尾拥有扩展内容，Stride 的值一定大于图像的宽度值，就像下图所示： Two buffers that contain video frames with equal dimensions can have two different strides. If you process a video image, you must take into the stride into account. 两个缓冲区包含同样大小（宽度和高度）的视频帧，却不一定拥有同样的 Stride 值，如果你处理一个视频帧，你必须在计算的时候把 Stride 考虑进去； In addition, there are two ways that an image can be arranged in memory. In a top-down image, the top row of pixels in the image appears first in memory. In a bottom-up image, the last row of pixels appears first in memory. The following illustration shows the difference between a top-down image and a bottom-up image. 另外，一张图像在内存中有两种不同的存储序列（arranged），对于一个从上而下存储（Top-Down） 的图像，最顶行的像素保存在内存中最开头的部分，对于一张从下而上存储（Bottom-Up）的图像，最后一行的像素保存在内存中最开头的部分，下面图示展示了这两种情况： A bottom-up image has a negative stride, because stride is defined as the number of bytes need to move down a row of pixels, relative to the displayed image. YUV images should always be top-down, and any image that is contained in a Direct3D surface must be top-down. RGB images in system memory are usually bottom-up. 一张从下而上的图像拥有一个负的 Stride 值，因为 Stride 被定义为[从一行像素移动到下一行像素时需要跨过多少个像素]，仅相对于被显示出来的图像而言；而 YUV 图像永远都是从上而下表示的，以及任何包含在 Direct3D Surface 中的图像必须是从上而下，RGB 图像保存在系统内存时通常是从下而上； Video transforms in particular need to handle buffers with mismatched strides, because the input buffer might not match the output buffer. For example, suppose that you want to convert a source image and write the result to a destination image. Assume that both images have the same width and height, but might not have the same pixel format or the same image stride. 尤其是视频变换，特别需要处理不同 Stride 值的图像，因为输入缓冲也许与输出缓冲不匹配，举个例子，假设你想要将源图像转换并且将结果写入到目标图像，假设两个图像拥有相同的宽度和高度，但是其像素格式与 Stride 值也许不同； The following example code shows a generalized approach for writing this kind of function. This is not a complete working example, because it abstracts many of the specific details. 下面代码演示了一种通用方法来编写这种功能，这段代码并不完整，因为这只是一个抽象的算法，没有完全考虑到真实需求中的所有细节； 12345678910111213141516171819202122void ProcessVideoImage( BYTE* pDestScanLine0, LONG lDestStride, const BYTE* pSrcScanLine0, LONG lSrcStride, DWORD dwWidthInPixels, DWORD dwHeightInPixels )&#123; for (DWORD y = 0; y &lt; dwHeightInPixels; y++) &#123; SOURCE_PIXEL_TYPE *pSrcPixel = (SOURCE_PIXEL_TYPE*)pDestScanLine0; DEST_PIXEL_TYPE *pDestPixel = (DEST_PIXEL_TYPE*)pSrcScanLine0; for (DWORD x = 0; x &lt; dwWidthInPixels; x +=2) &#123; pDestPixel[x] = TransformPixelValue(pSrcPixel[x]); &#125; pDestScanLine0 += lDestStride; pSrcScanLine0 += lSrcStride; &#125;&#125; This function takes six parameters: A pointer to the start of scan line 0 in the destination image. The stride of the destination image. A pointer to the start of scan line 0 in the source image. The stride of the source image. The width of the image in pixels. The height of the image in pixels. 这个函数需要六个参数： 目标图像的起始扫描行的内存指针 目标图像的 Stride 值 源图像的起始扫描行的内存指针 源图像的 Stride 值 图像的宽度值（以像素为单位） 图像的高度值（以像素为单位） The general idea is to process one row at a time, iterating over each pixel in the row. Assume that SOURCE_PIXEL_TYPE and DEST_PIXEL_TYPE are structures representing the pixel layout for the source and destination images, respectively. (For example, 32-bit RGB uses the RGBQUAD structure. Not every pixel format has a pre-defined structure.) Casting the array pointer to the structure type enables you to access the RGB or YUV components of each pixel. At the start of each row, the function stores a pointer to the row. At the end of the row, it increments the pointer by the width of the image stride, which advances the pointer to the next row. 这里的要点是如何一次处理一行像素，遍历一行里面的每一个像素，假设源像素类型与目标像素类型各自在像素的层面上已经结构化来表示一个源图像与目标图像的像素，（举个例子，32 位 RGB 像素使用 RGBQUAD 结构体，并不是每一种像素类型都有预定义结构体的）强制转换数组指针到这样的结构体指针，可以方便你直接读写每一个像素的 RGB 或者 YUV 值，在每一行的开头，这个函数保存了一个指向这行像素的指针，函数的最后一行，通过图像的 Stride 值直接将指针跳转到图像的下一行像素的起始点； This example calls a hypothetical function named TransformPixelValue for each pixel. This could be any function that calculates a target pixel from a source pixel. Of course, the exact details will depend on the particular task. For example, if you have a planar YUV format, you must access the chroma planes independently from the luma plane; with interlaced video, you might need to process the fields separately; and so forth. To give a more concrete example, the following code converts a 32-bit RGB image into an AYUV image. The RGB pixels are accessed using an RGBQUAD structure, and the AYUV pixels are accessed using aDXVA2_AYUVSample8 Structure structure. 引用: 如果你用的是 MSDN Library For Visual Studio 2008 SP1，那么你应该能够在下面地址中找到这篇文章的原文： ms-help://MS.MSDNQTR.v90.chs/medfound/html/13cd1106-48b3-4522-ac09-8efbaab5c31d.htm http://blog.csdn.net/g0ose/article/details/52116453]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL混色]]></title>
    <url>%2F2017%2F06%2F27%2Fgl-glBlendFunc%2F</url>
    <content type="text"><![CDATA[混合就是把两种颜色混在一起。具体一点，就是把某一像素位置原来的颜色和将要画上去的颜色，通过某种方式混在一起，从而实现特殊的效果。 假设我们需要绘制这样一个场景：透过红色的玻璃去看绿色的物体，那么可以先绘制绿色的物体，再绘制红色玻璃。在绘制红色玻璃的时候，利用“混合”功能，把将要绘制上去的红色和原来的绿色进行混合，于是得到一种新的颜色，看上去就好像玻璃是半透明的。 要使用OpenGL的混合功能，只需要调用：glEnable(GL_BLEND);即可。要关闭OpenGL的混合功能，只需要调用：glDisable(GL_BLEND);即可。 注意： 只有在RGBA模式下，才可以使用混合功能，颜色索引模式下是无法使用混合功能的。 1.源因子和目标因子混合需要把原来的颜色和将要画上去的颜色找出来，经过某种方式处理后得到一种新的颜色。这里把将要画上去的颜色称为“源颜色”，把原来的颜色称为“目标颜色”。 OpenGL 会把源颜色和目标颜色各自取出，并乘以一个系数（源颜色乘以的系数称为“源因子”，目标颜色乘以的系数称为“目标因子”），然后相加，这样就得到了新的颜 色。（也可以不是相加，新版本的OpenGL可以设置运算方式，包括加、减、取两者中较大的、取两者中较小的、逻辑运算等） 下面用数学公式来表达一下这个运算方式。假设源颜色的四个分量（指红色，绿色，蓝色，alpha值）是(Rs, Gs, Bs, As)，目标颜色的四个分量是(Rd, Gd, Bd, Ad)，又设源因子为(Sr, Sg, Sb, Sa)，目标因子为(Dr, Dg, Db, Da)。则混合产生的新颜色可以表示为： (Rs*Sr+Rd*Dr, Gs*Sg+Gd*Dg, Bs*Sb+Bd*Db, As*Sa+Ad*Da) 如果颜色的某一分量超过了1.0，则它会被自动截取为1.0，不需要考虑越界的问题。 源因子和目标因子是可以通过glBlendFunc函数来进行设置的。glBlendFunc有两个参数，前者表示源因子，后者表示目标因子。这两个参数可以是多种值，下面介绍比较常用的几种。 GL_ZERO：表示使用0.0作为因子，实际上相当于不使用这种颜色参与混合运算。 GL_ONE：表示使用1.0作为因子，实际上相当于完全的使用了这种颜色参与混合运算。 GL_SRC_ALPHA：表示使用源颜色的alpha值来作为因子。 GL_DST_ALPHA：表示使用目标颜色的alpha值来作为因子。 GL_ONE_MINUS_SRC_ALPHA：表示用1.0减去源颜色的alpha值来作为因子。 GL_ONE_MINUS_DST_ALPHA：表示用1.0减去目标颜色的alpha值来作为因子。 GL_SRC_COLOR: 把源颜色的四个分量分别作为因子的四个分量 GL_ONE_MINUS_SRC_COLOR GL_DST_COLOR GL_ONE_MINUS_DST_COLOR GL_SRC_COLOR与GL_ONE_MINUS_SRC_COLOR在OpenGL旧版本中只能用于设置目标因子，GL_DST_COLOR与GL_ONE_MINUS_DST_COLOR在OpenGL 旧版本中只能用于设置源因子。新版本的OpenGL则没有这个限制，并且支持新的GL_CONST_COLOR（设定一种常数颜色，将其四个分量分别作为 因子的四个分量）、GL_ONE_MINUS_CONST_COLOR、GL_CONST_ALPHA、 GL_ONE_MINUS_CONST_ALPHA。另外还有GL_SRC_ALPHA_SATURATE。新版本的OpenGL还允许颜色的alpha 值和RGB值采用不同的混合因子。 2.模式示例 如果设置了glBlendFunc(GL_ONE, GL_ZERO);，则表示完全使用源颜色，完全不使用目标颜色，因此画面效果和不使用混合的时候一致（当然效率可能会低一点点）。如果没有设置源因子和目标因子，则默认情况就是这样的设置。 如果设置了glBlendFunc(GL_ZERO, GL_ONE);，则表示完全不使用源颜色，因此无论你想画什么，最后都不会被画上去了。（但这并不是说这样设置就没有用，有些时候可能有特殊用途） 如果设置了glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);，则表示源颜色乘以自身的alpha 值，目标颜色乘以1.0减去源颜色的alpha值，这样一来，源颜色的alpha值越大，则产生的新颜色中源颜色所占比例就越大，而目标颜色所占比例则减 小。这种情况下，我们可以简单的将源颜色的alpha值理解为“不透明度”。这也是混合时最常用的方式。 如果设置了glBlendFunc(GL_ONE, GL_ONE);，则表示完全使用源颜色和目标颜色，最终的颜色实际上就是两种颜色的简单相加。例如红色(1, 0, 0)和绿色(0, 1, 0)相加得到(1, 1, 0)，结果为黄色。 注意： 所谓源颜色和目标颜色，是跟绘制的顺序有关的。假如先绘制了一个红色的物体，再在其上绘制绿色的物体。则绿色是源颜色，红色是目标颜色。如果顺序反过来，则 红色就是源颜色，绿色才是目标颜色。在绘制时，应该注意顺序，使得绘制的源颜色与设置的源因子对应，目标颜色与设置的目标因子对应。 3.对两种示例模式的具体解释:模式一: 12GLES20.glEnable(GLES20.GL_BLEND); GLES20.glBlendFunc(GLES20.GL_SRC_ALPHA, GLES20.GL_ONE_MINUS_SRC_ALPHA); 模式二: 12GLES20.glEnable(GLES20.GL_BLEND); GLES20.glBlendFunc(GLES20.GL_ONE, GLES20.GL_ONE_MINUS_SRC_ALPHA); 模式一是传统的alpha通道混合，这种模式下颜色和alpha值是分立的，rgb决定颜色，alpha决定..（英文是决定how solid it is 水平有限找不到准确的中文来表达） 在数学上表达式是：blend(source, dest) = (source.rgb * source.a) + (dest.rgb * (1 – source.a)).要注意的是这种模式下，透明只跟alpha有关，跟rgb值无关，一个透明的颜色，不透明的颜色有相同的rgb值，只要alpha=0即可。 模式二是alpha预乘的混合（Premultiplied Alpha Blending），这种模式下rgb与alpha是联系在一起的，数学上的表达式是 blend(source, dest) = source.rgb + (dest.rgb * (1 – source.a)),在这种模式下，透明的表示是rgb值都为0. 4.EGLSurface背景透明设置在OpenGL绘制中,除了设置混色外,还要设置EGLSurface配置支持Alpha,如果不设置EGL相关的EGLSurface支持透明,就算OpenGL函数中开启混色,绘制完成后仍是有黑色背景. 4.1GLSurfaceView在onSurfaceCreated里，调用GLES20.glClearColor(0f, 0f, 0f, 0f);alpha为0，即透明。 然后，对surfaceview要作一定处理： 12345mGLSurfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0);TestRenderer renderer = new TestRenderer();mGLSurfaceView.setRender(renderer);mGLSurfaceView.getHolder().setFormat(PixelFormat.TRANSLUCENT);mGLSurfaceView.setZOrderOnTop(true); 4.2SurfaceTexture或Surface构造的SurfaceEGL14.eglChooseConfig中config数组增加EGL10.EGL_ALPHA_SIZE配置: 12345678int[] CONFIG_RGBA = &#123; EGL10.EGL_RED_SIZE, 8, EGL10.EGL_GREEN_SIZE, 8, EGL10.EGL_BLUE_SIZE, 8, EGL10.EGL_ALPHA_SIZE, 8, EGL10.EGL_RENDERABLE_TYPE, EGL_OPENGL_ES2_BIT, EGL10.EGL_NONE &#125;; 5.实现三维混合在进行三维场景的混合时必须注意的是深度缓冲。 深度缓冲是这样一段数据，它记录了每一个像素距离观察者有多近。在启用深度缓冲测试的情况下，如果将要绘制的像素比原来的像素更近，则像素将被绘制。否则,像素就会被忽略掉，不进行绘制。这在绘制不透明的物体时非常有用——不管是先绘制近的物体再绘制远的物体，还是先绘制远的物体再绘制近的物体，或者干脆以 混乱的顺序进行绘制，最后的显示结果总是近的物体遮住远的物体。 然而在你需要实现半透明效果时，发现一切都不是那么美好了。如果你绘制了一个近距离的半透明物体，则它在深度缓冲区内保留了一些信息，使得远处的物体将无法再被绘制出来。虽然半透明的物体仍然半透明，但透过它看到的却不是正确的内容了。 要 解决以上问题，需要在绘制半透明物体时将深度缓冲区设置为只读，这样一来，虽然半透明物体被绘制上去了，深度缓冲区还保持在原来的状态。如果再有一个物体 出现在半透明物体之后，在不透明物体之前，则它也可以被绘制（因为此时深度缓冲区中记录的是那个不透明物体的深度）。以后再要绘制不透明物体时，只需要再 将深度缓冲区设置为可读可写的形式即可。怎么绘制一个一部分半透明一部分不透明的物体？这个好办，只需要把物体分为两个部分，一部分全是半透明 的，一部分全是不透明的，分别绘制就可以了。 即使使用了以上技巧，我们仍然不能随心所欲的按照混乱顺序来进行绘制。必须是先绘制不透明的物体，然 后绘制透明的物体。否则，假设背景为蓝色，近处一块红色玻璃，中间一个绿色物体。如果先绘制红色半透明玻璃的话，它先和蓝色背景进行混合，则以后绘制中间 的绿色物体时，想单独与红色玻璃混合已经不能实现了。 总结起来，绘制顺序就是：首先绘制所有不透明的物体。如果两个物体都是不透明的，则谁先谁后 都没有关系。然后，将深度缓冲区设置为只读。接下来，绘制所有半透明的物体。如果两个物体都是半透明的，则谁先谁后只需要根据自己的意愿（注意了，先绘制 的将成为“目标颜色”，后绘制的将成为“源颜色”，所以绘制的顺序将会对结果造成一些影响）。最后，将深度缓冲区设置为可读可写形式。 调用glDepthMask(GL_FALSE);可将深度缓冲区设置为只读形式。调用glDepthMask(GL_TRUE);可将深度缓冲区设置为可读可写形式。 glBlendFunc函数官网文档]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android系统编码MediaCodec]]></title>
    <url>%2F2017%2F06%2F25%2Ftips-android-mediacodec%2F</url>
    <content type="text"><![CDATA[android编码器局限性1. 颜色格式问题MediaCodec在初始化的时候，在configure的时候，需要传入一个MediaFormat对象，当作为编码器使用的时候，我们一般需要在MediaFormat中指定视频的宽高，帧率，码率，I帧间隔等基本信息，除此之外，还有一个重要的信息就是，指定编码器接受的YUV帧的颜色格式。这个是因为由于YUV根据其采样比例，UV分量的排列顺序有很多种不同的颜色格式，而对于Android的摄像头在onPreviewFrame输出的YUV帧格式，如果没有配置任何参数的情况下，基本上都是NV21格式，但Google对MediaCodec的API在设计和规范的时候，显得很不厚道，过于贴近Android的HAL层了，导致了NV21格式并不是所有机器的MediaCodec都支持这种格式作为编码器的输入格式！ 因此，在初始化MediaCodec的时候，我们需要通过codecInfo.getCapabilitiesForType来查询机器上的MediaCodec实现具体支持哪些YUV格式作为输入格式，一般来说，起码在4.4+的系统上，这两种格式在大部分机器都有支持： 12MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420PlannderMediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420SemiPlannder 两种格式分别是YUV420P和NV21，如果机器上只支持YUV420P格式的情况下，则需要先将摄像头输出的NV21格式先转换成YUV420P，才能送入编码器进行编码，否则最终出来的视频就会花屏，或者颜色出现错乱 这个算是一个不大不小的坑，基本上用上了MediaCodec进行视频编码都会遇上这个问题 2. 编码器支持特性相当有限如果使用MediaCodec来编码H264视频流，对于H264格式来说，会有一些针对压缩率以及码率相关的视频质量设置，典型的诸如Profile(baseline, main, high)，Profile Level, Bitrate mode(CBR, CQ, VBR)，合理配置这些参数可以让我们在同等的码率下，获得更高的压缩率，从而提升视频的质量，Android也提供了对应的API进行设置，可以设置到MediaFormat中这些设置项: 123MediaFormat.KEY_BITRATE_MODEMediaFormat.KEY_PROFILEMediaFormat.KEY_LEVEL 但问题是，对于Profile，Level, Bitrate mode这些设置，在大部分手机上都是不支持的，即使是设置了最终也不会生效，例如设置了Profile为high，最后出来的视频依然还会是Baseline…. 这个问题，在7.0以下的机器几乎是必现的，其中一个可能的原因是，Android在源码层级hardcode了profile的的设置： 12345//XXXXif(h264type.eProfile != OMX_VIDEO_AVCProfileBaseline)&#123; ALOGW(&quot;Use baseline profile instead of %d for AVC recording&quot;, h264type.eProfile); h264type.eProfile = OMX_VIDEO_AVCProfileBaseline;&#125; Android直到7.0之后才取消了这段地方的Hardcode: 123456if(h264type.eProfile == OMX_VIDEO_AVCProfileBaseline)&#123; ....&#125;else if(h264type.eProfile == OMX_VIDEO_AVCProfileMain || h264type.eProfile == OMX_VIDEO_AVCProfileBaseHigh) .....&#125; 这个问题可以说间接导致了MediaCodec编码出来的视频质量偏低，同等码率下，难以获得跟软编码甚至iOS那样的视频质量。 3. 16位对齐要求前面说到，MediaCodec这个API在设计的时候，过于贴近HAL层，这在很多Soc的实现上，是直接把传入MediaCodec的buffer，在不经过任何前置处理的情况下就直接送入了Soc中。而在编码h264视频流的时候，由于h264的编码块大小一般是16x16，于是乎在一开始设置视频的宽高的时候，如果设置了一个没有对齐16的大小，例如960x540，在某些cpu上，最终编码出来的视频就会直接花屏！ 很明显这还是因为厂商在实现这个API的时候，对传入的数据缺少校验以及前置处理导致的，目前来看，华为，三星的Soc出现这个问题会比较频繁，其他厂商的一些早期Soc也有这种问题，一般来说解决方法还是在设置视频宽高的时候，统一设置成对齐16位之后的大小就好了。 4.软编解码介绍除了使用MediaCodec进行编码之外，另外一种比较流行的方案就是使用ffmpeg+x264/openh264进行软编码，ffmpeg是用于一些视频帧的预处理。这里主要是使用x264/openh264作为视频的编码器。 x264基本上被认为是当今市面上最快的商用视频编码器，而且基本上所有h264的特性都支持，通过合理配置各种参数还是能够得到较好的压缩率和编码速度的，限于篇幅，这里不再阐述h264的参数配置，有兴趣可以看下这两篇文章对x264编码参数的调优： https://www.nmm-hd.org/d/index.php?title=X264%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D&amp;variant=zh-cn http://www.cnblogs.com/wainiwann/p/5647521.html openh264(https://github.com/cisco/openh264)则是由思科开源的另外一个h264编码器，项目在2013年开源，对比起x264来说略显年轻，不过由于思科支付满了h264的年度专利费，所以对于外部用户来说，相当于可以直接免费使用了，另外，firefox直接内置了openh264，作为其在webRTC中的视频的编解码器使用。 但对比起x264，openh264在h264高级特性的支持比较差： Profile只支持到baseline, level 5.2 多线程编码只支持slice based，不支持frame based的多线程编码 从编码效率上来看，openh264的速度也并不会比x264快，不过其最大的好处，还是能够直接免费使用吧。 参考微信Android视频编码爬过的那些坑 android编码器支持参数Supported Media FormatsVideo encoding recommendations The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the H.264 Baseline Profile codec. The same recommendations apply to the Main Profile codec, which is only available in Android 6.0 and later. SD (Low quality) SD (High quality) HD 720p (N/A on all devices) Video resolution 176 x 144 px 480 x 360 px 1280 x 720 px Video frame rate 12 fps 30 fps 30 fps Video bitrate 56 Kbps 500 Kbps 2 Mbps Audio codec AAC-LC AAC-LC AAC-LC Audio channels 1 (mono) 2 (stereo) 2 (stereo) Audio bitrate 24 Kbps 128 Kbps 192 Kbps The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the VP8 media codec. SD (Low quality) SD (High quality) HD 720p (N/A on all devices) HD 1080p (N/A on all devices) Video resolution 320 x 180 px 640 x 360 px 1280 x 720 px 1920 x 1080 px Video frame rate 30 fps 30 fps 30 fps 30 fps Video bitrate 800 Kbps 2 Mbps 4 Mbps 10 Mbps CamcorderProfileRetrieves the predefined camcorder profile settings for camcorder applications. These settings are read-only. The compressed output from a recording session with a given CamcorderProfile contains two tracks: one for audio and one for video. Each profile specifies the following set of parameters: The file output format Video codec format Video bit rate in bits per second Video frame rate in frames per second Video frame width and height, Audio codec format Audio bit rate in bits per second, Audio sample rate Number of audio channels for recording. Android编码器常见问题MediaCodec KEY_FRAME_RATE seems to be ignored总结起来就是和输入编码器的帧率有关系 I am trying to modify the source for screenrecord in android 4.4 and lower the captured frame rate, but no matter what value I put in: 1format-&gt;setFloat(&quot;frame-rate&quot;, 5); the result is always the same ( a very high frame rate ) Is the encoder ignoring this property ? how can I control the frame rate ? The frame-rate value is not ignored, but it doesn’t do what you want. The combination of frame-rate and i-frame-interval determines how often I-frames (also called “sync frames”) appear in the encoded output. The frame rate value might also play a role in meeting the bitrate target on some devices, but I’m not sure about that (see e.g. this post). The MediaCodec encoder does not drop frames. If you want to reduce the frame rate, you have to do so by sending fewer frames to it. The screenrecord command doesn’t “sample” the screen at a fixed frame rate. Instead, every frame it receives from the surface compositor (SurfaceFlinger) is sent to the encoder, with an appropriate time stamp. If screenrecord receives 60 frames per seconds, you’ll have 60fps output. If it receives 10 frames in quick succession, followed by nothing for 5 seconds, followed by a couple more, you’ll have exactly that in the output file. You can modify screenrecord to drop frames, but you have to be a bit careful. If you try to reduce the maximum frame rate from 60fps to 30fps by dropping every-other frame, you run the risk that in a “frame0 - frame1 - long_pause - frame2” sequence you’ll drop frame1, and the video will hold on frame0 instead, showing a not-quite-complete animation. So you need to buffer up a frame, and then encode or drop frame N-1 if the difference in presentation times between that and frame N is ~17ms. The tricky part is that screenrecord, in its default operating mode, directs the frames to the encoder without touching them, so all you see is the encoded output. You can’t arbitrarily drop individual frames of encoded data, so you really want to prevent the encoder from seeing them in the first place. If you use the screenrecord v1.1 sources you can tap into “overlay” mode, used for –bugreport, to have the frames pass through screenrecord on their way to the encoder. In some respects it might be simpler to write a post-processor that reduces the frame rate. I don’t know how much quality would be lost by decoding and re-encoding the video.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>多媒体</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[media-storage-and-transfer]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-storage-and-transfer%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[media-compress]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-compress%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[media-video]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-video%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[多媒体技术(二)之声音]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-audio%2F</url>
    <content type="text"><![CDATA[信息论的观点来看，描述信源的数据是信息和数据冗余之和，即：数据=信息+数据冗余。音频信号在时域和频域上具有相关性，也即存在数据冗余。将音频作为一个信源，音频编码的实质是减少音频中的冗余。 自然界中的声音非常复杂，波形极其复杂，通常我们采用的是脉冲代码调制编码，即PCM编码。PCM通过抽样、量化、编码三个步骤将连续变化的模拟信号转换为数字编码。 内容介绍采样率和采样大小声音其实是一种能量波，因此也有频率和振幅的特征，频率对应于时间轴线，振幅对应于电平轴线。波是无限光滑的，弦线可以看成由无数点组成，由于存储空间是相对有限的，数字编码过程中，必须对弦线的点进行采样。采样的过程就是抽取某点的频率值，很显然，在一秒中内抽取的点越多，获取得频率信息更丰富，为了复原波形，一次振动中，必须有2个点的采样，人耳能够感觉到的最高频率为20kHz，因此要满足人耳的听觉要求，则需要至少每秒进行40k次采样，用40kHz表达，这个40kHz就是采样率。我们常见的CD，采样率为44.1kHz。光有频率信息是不够的，我们还必须获得该频率的能量值并量化，用于表示信号强度。量化电平数为2的整数次幂，我们常见的CD位16bit的采样大小，即2的16次方。采样大小相对采样率更难理解，因为要显得抽象点，举个简单例子：假设对一个波进行8次采样，采样点分别对应的能量值分别为A1-A8，但我们只使用2bit的采样大小，结果我们只能保留A1-A8中4个点的值而舍弃另外4个。如果我们进行3bit的采样大小，则刚好记录下8个点的所有信息。采样率和采样大小的值越大，记录的波形更接近原始信号。 有损和无损根据采样率和采样大小可以得知，相对自然界的信号，音频编码最多只能做到无限接近，至少目前的技术只能这样了，相对自然界的信号，任何数字音频编码方案都是有损的，因为无法完全还原。在计算机应用中，能够达到最高保真水平的就是PCM编码，被广泛用于素材保存及音乐欣赏，CD、DVD以及我们常见的WAV文件中均有应用。因此，PCM约定俗成了无损编码，因为PCM代表了数字音频中最佳的保真水准，并不意味着PCM就能够确保信号绝对保真，PCM也只能做到最大程度的无限接近。我们而习惯性的把MP3列入有损音频编码范畴，是相对PCM编码的。强调编码的相对性的有损和无损，是为了告诉大家，要做到真正的无损是困难的，就像用数字去表达圆周率，不管精度多高，也只是无限接近，而不是真正等于圆周率的值。 使用音频压缩技术的原因要算一个PCM音频流的码率是一件很轻松的事情，采样率值×采样大小值×声道数 bps。一个采样率为44.1KHz，采样大小为16bit，双声道的PCM编码的WAV文件，它的数据速率则为 44.1K×16×2 =1411.2 Kbps。我们常说128K的MP3，对应的WAV的参数，就是这个1411.2 Kbps，这个参数也被称为数据带宽，它和ADSL中的带宽是一个概念。将码率除以8,就可以得到这个WAV的数据速率，即176.4KB/s。这表示存储一秒钟采样率为44.1KHz，采样大小为16bit，双声道的PCM编码的音频信号，需要176.4KB的空间，1分钟则约为10.34M，这对大部分用户是不可接受的，尤其是喜欢在电脑上听音乐的朋友，要降低磁盘占用，只有2种方法，降低采样指标或者压缩。降低指标是不可取的，因此专家们研发了各种压缩方案。由于用途和针对的目标市场不一样，各种音频压缩编码所达到的音质和压缩比都不一样，在后面的文章中我们都会一一提到。有一点是可以肯定的，他们都压缩过。 频率与采样率的关系采样率表示了每秒对原始信号采样的次数，我们常见到的音频文件采样率多为44.1KHz，这意味着什么呢？假设我们有2段正弦波信号，分别为20Hz和20KHz，长度均为一秒钟，以对应我们能听到的最低频和最高频，分别对这两段信号进行40KHz的采样，我们可以得到一个什么样的结果呢？结果是：20Hz的信号每次振动被采样了40K/20=2000次，而20K的信号每次振动只有2次采样。显然，在相同的采样率下，记录低频的信息远比高频的详细。这也是为什么有些音响发烧友指责CD有数码声不够真实的原因，CD的44.1KHz采样也无法保证高频信号被较好记录。要较好的记录高频信号，看来需要更高的采样率，于是有些朋友在捕捉CD音轨的时候使用48KHz的采样率，这是不可取的！这其实对音质没有任何好处，对抓轨软件来说，保持和CD提供的44.1KHz一样的采样率才是最佳音质的保证之一，而不是去提高它。较高的采样率只有相对模拟信号的时候才有用，如果被采样的信号是数字的，请不要去尝试提高采样率。 流特征随着网络的发展，人们对在线收听音乐提出了要求，因此也要求音频文件能够一边读一边播放，而不需要把这个文件全部读出后然后回放，这样就可以做到不用下载就可以实现收听了；也可以做到一边编码一边播放，正是这种特征，可以实现在线的直播，架设自己的数字广播电台成为了现实。 编码分类根据编码方式的不同，音频编码技术分为三种：波形编码、参数编码和混合编码。一般来说，波形编码的话音质量高，但编码速率也很高；参数编码的编码速率很低，产生的合成语音的音质不高；混合编码使用参数编码技术和波形编码技术，编码速率和音质介于它们之间。 1、波形编码波形编码是指不利用生成音频信号的任何参数，直接将时间域信号变换为数字代码，使重构的语音波形尽可能地与原始语音信号的波形形状保持一致。波形编码的基本原理是在时间轴上对模拟语音信号按一定的速率抽样，然后将幅度样本分层量化，并用代码表示。 波形编码方法简单、易于实现、适应能力强并且语音质量好。不过因为压缩方法简单也带来了一些问题：压缩比相对较低，需要较高的编码速率。一般来说，波形编码的复杂程度比较低，编码速率较高、通常在16 kbit/s以上，质量相当高。但编码速率低于16 kbit/s时，音质会急剧下降。 最简单的波形编码方法是PCM（Pulse Code Modulation，脉冲编码调制），它只对语音信号进行采样和量化处理。优点是编码方法简单，延迟时间短，音质高，重构的语音信号与原始语音信号几乎没有差别。不足之处是编码速率比较高（64 kbit/s），对传输通道的错误比较敏感。 2、参数编码参数编码是从语音波形信号中提取生成语音的参数，使用这些参数通过语音生成模型重构出语音，使重构的语音信号尽可能地保持原始语音信号的语意。也就是说，参数编码是把语音信号产生的数字模型作为基础，然后求出数字模型的模型参数，再按照这些参数还原数字模型，进而合成语音。 参数编码的编码速率较低，可以达到2.4 kbit/s，产生的语音信号是通过建立的数字模型还原出来的，因此重构的语音信号波形与原始语音信号的波形可能会存在较大的区别、失真会比较大。而且因为受到语音生成模型的限制，增加数据速率也无法提高合成语音的质量。不过，虽然参数编码的音质比较低，但是保密性很好，一直被应用在军事上。典型的参数编码方法为LPC（Linear Predictive Coding，线性预测编码）。 3、混合编码混合编码是指同时使用两种或两种以上的编码方法进行编码。这种编码方法克服了波形编码和参数编码的弱点，并结合了波形编码高质量和参数编码的低编码速率，能够取得比较好的效果。 编码格式PCM编码PCM 脉冲编码调制是Pulse Code Modulation的缩写。前面的文字我们提到了PCM大致的工作流程，我们不需要关心PCM最终编码采用的是什么计算方式，我们只需要知道PCM编码的音频流的优点和缺点就可以了。PCM编码的最大的优点就是音质好，最大的缺点就是体积大。我们常见的Audio CD就采用了PCM编码，一张光盘的容量只能容纳72分钟的音乐信息。 WAV格式 这是一种古老的音频文件格式，由微软开发。WAV是一种文件格式，符合RIFF (Resource Interchange File Format) 规范。所有的WAV都有一个文件头，这个文件头包含了音频流的编码参数。WAV对音频流的编码没有硬性规定，除了PCM之外，还有几乎所有支持ACM规范的编码都可以为WAV的音频流进行编码。很多朋友没有这个概念，我们拿AVI做个示范，因为AVI和WAV在文件结构上是非常相似的，不过AVI多了一个视频流而已。我们接触到的AVI有很多种，因此我们经常需要安装一些Decode才能观看一些AVI，我们接触到比较多的DivX就是一种视频编码，AVI可以采用DivX编码来压缩视频流，当然也可以使用其他的编码压缩。同样，WAV也可以使用多种音频编码来压缩其音频流，不过我们常见的都是音频流被PCM编码处理的WAV，但这不表示WAV只能使用PCM编码，MP3编码同样也可以运用在WAV中，和AVI一样，只要安装好了相应的Decode，就可以欣赏这些WAV了。 在Windows平台下，基于PCM编码的WAV是被支持得最好的音频格式，所有音频软件都能完美支持，由于本身可以达到较高的音质的要求，因此，WAV也是音乐编辑创作的首选格式，适合保存音乐素材。因此，基于PCM编码的WAV被作为了一种中介的格式，常常使用在其他编码的相互转换之中，例如MP3转换成WMA。 MP3编码动态图像专家组-1或动态图像专家组-2 音频层III（MPEG-1 or MPEG-2 Audio Layer III），经常称为MP3，是当今相当流行的一种数字音频编码和有损压缩格式，它被设计来大幅降低音频数据量，它舍弃PCM音讯资料中，对人类听觉不重要的资料，从而达到了压缩成较小的档案。而对于大多数用户的听觉感受来说，MP3的音质与最初的不压缩音频相比没有明显的下降。它是在1991年，由位于德国埃尔朗根的研究组织Fraunhofer-Gesellschaft的一组工程师发明和标准化的。MP3的普及，曾对音乐产业造成冲击与影响。 MP3是一个数据压缩格式。它舍弃脉冲编码调制（PCM）音频数据中，对人类听觉不重要的数据（类似于JPEG是一个有损图像压缩），从而达到了压缩成小得多的文件大小。 在MP3中使用了许多技术，其中包括心理声学，以确定音频的哪一部分可以丢弃。MP3音频可以按照不同的比特率进行压缩，提供了权衡数据大小和音质之间的依据。 MP3格式使用了混合的转换机制将时域信号转换成频域信号： 32波段多相积分滤波器（PQF） 36或者12 tap 改良离散余弦滤波器（MDCT）；每个子波段大小可以在0…1和2…31之间独立选择 混叠衰减后处理 尽管有许多创造和推广其他格式的重要努力，如 MPEG 标准中的 AAC（Advanced Audio Coding）和 Xiph.Org 开源无专利的 Ogg Vorbis。然而，由于MP3的空前的流通，在目前来说，其他格式不可能威胁其地位。MP3不仅有广泛的用户端软体支持，也有很多的硬件支持，比如便携式数位音频播放器（泛指MP3播放器）、移动电话、DVD和CD播放器。 MP3作为目前最为普及的音频压缩格式，为大家所大量接受，各种与MP3相关的软件产品层出不穷，而且更多的硬件产品也开始支持MP3，我们能够买到的VCD/DVD播放机都很多都能够支持MP3，还有更多的便携的MP3播放器等等，虽然几大音乐商极其反感这种开放的格式，但也无法阻止这种音频压缩的格式的生存与流传。MP3发展已经有10个年头了，他是MPEG(MPEG：Moving Picture Experts Group) Audio Layer-3的简称，是MPEG1的衍生编码方案，1993年由德国Fraunhofer IIS研究院和汤姆生公司合作发展成功。MP3可以做到12:1的惊人压缩比并保持基本可听的音质，在当年硬盘天价的日子里，MP3迅速被用户接受，随着网络的普及，MP3被数以亿计的用户接受。MP3编码技术的发布之初其实是非常不完善的，由于缺乏对声音和人耳听觉的研究，早期的mp3编码器几乎全是以粗暴方式来编码，音质破坏严重。随着新技术的不断导入，mp3编码技术一次一次的被改良，其中有2次重大技术上的改进。 发展 MPEG-1 Audio Layer II编码开始时是德国Deutsche Forschungs- und Versuchsanstalt für Luft- und Raumfahrt（后来称为Deutsches Zentrum für Luft- und Raumfahrt, 德国太空中心）Egon Meier-Engelen管理的数字音频广播（DAB）项目。这个项目是欧盟作为EUREKA研究项目资助的，它的名字通常称为EU-147。EU-147的研究期间是1987年到1994年。 到了1991年，就已经出现了两个提案：Musicam（称为Layer 2）和ASPEC（自适应频谱感知熵编码）。荷兰飞利浦公司、法国CCETT和德国Institut für Rundfunktechnik提出的Musicam方法由于它的简单、出错时的稳定性以及在高质量压缩时较少的计算量而被选中。基于子带编码的Musicam格式是确定MPEG音频压缩格式（采样率、帧结构、数据头、每帧采样点）的一个关键因素。这项技术和它的设计思路完全融合到了ISO MPEG Audio Layer I、II以及后来的Layer III（MP3）格式的定义中。在Mussmann教授（汉诺威大学）的主持下，标准的制定由Leon van de Kerkhof（Layer I）和Gerhard Stoll（Layer II）完成。 一个由荷兰Leon Van de Kerkhof、德国Gerhard Stoll、法国Yves-François Dehery和德国Karlheinz Brandenburg组成的工作小组吸收了Musicam和ASPEC的设计思想，并添加了他们自己的设计思想从而开发出了MP3，MP3能够在128kbit/s达到MP2 192kbit/s音质。 所有这些算法最终都在1992年成为了MPEG的第一个标准组MPEG-1的一部分，并且生成了1993年公布的国际标准ISO／IEC 11172-3。MPEG音频上的更进一步的工作最终成为了1994年制定的第二个MPEG标准组MPEG-2标准的一部分，这个标准正式的称呼是1995年首次公布的ISO／IEC 13818-3。 编码器的压缩效率通常由比特率定义，因为压缩率依赖于位数（bit depth）和输入信号的采样率。然而，经常有产品使用CD参数（44.1kHz、两个通道、每通道16位或者称为2x16位）作为压缩率参考，使用这个参考的压缩率通常较高，这也说明了压缩率对于有损压缩存在的问题。 Karlheinz Brandenburg使用CD介质的Suzanne Vega的歌曲Tom’s Diner来评价MP3压缩算法。使用这首歌是因为这首歌的柔和、简单旋律使得在回放时更容易听到压缩格式中的缺陷。一些人开玩笑地将Suzanne Vega称为“MP3之母”。来自于EBU V3/SQAM参考CD的更多一些严肃和critical音频选段（钟琴，三角铁，手风琴，…）被专业音频工程师用来评价MPEG音频格式的主观感受质量。 MP3走向大众 为了生成位兼容的MPEG Audio文件（Layer 1、Layer 2、Layer 3），ISO MPEG Audio委员会成员用C语言开发的一个称为ISO 11172-5的参考模拟软件。在一些非实时操作系统上它能够演示第一款压缩音频基于DSP的实时硬件解码。一些其他的MPEG Audio实时开发出来用于面向消费接收机和机顶盒的数字广播（无线电DAB和电视DVB）。 后来，1994年7月7日Fraunhofer-Gesellschaft发布了第一个称为l3enc的MP3编码器。 Fraunhofer开发组在1995年7月14日选定扩展名：”.mp3”（以前扩展名是”.bit”）。使用第一款实时软件MP3播放器Winplay3（1995年9月9日发布）许多人能够在自己的个人电脑上编码和回放MP3文件。由于当时的硬盘相对较小（如500MB），这项技术对于在计算机上存储娱乐音乐来说是至关重要的。 MP2、MP3与因特网 1993年10月，MP2（MPEG-1 Audio Layer 2）文件在因特网上出现，它们经常使用Xing MPEG Audio Player播放，后来又出现了Tobias Bading为Unix开发的MAPlay。MAPlay于1994年2月22日首次发布，现在已经移植到微软视窗平台上。 刚开始仅有的MP2编码器产品是Xing Encoder和CDDA2WAV，CDDA2WAV是一个将CD音轨转换成WAV格式的CD抓取器。 Internet Underground Music Archive（IUMA）通常被认为是在线音乐革命的鼻祖，IUMA是因特网上第一个高保真音乐网站，在MP3和网络流行之前它有数千首授权的MP2录音。 从1995年上半年开始直到整个九十年代后期，MP3开始在因特网上蓬勃发展。MP3的流行主要得益于如Nullsoft于1997年发布的Winamp和于1999年发布的Napster，这样的公司和软件包的成功，并且它们相互促进发展。这些程序使得普通用户很容易地播放、制作、共享和收集MP3文件。 关于MP3文件的点对点技术文件共享的争论在最近几年迅速蔓延—这主要是由于压缩使得文件共享成为可能，未经压缩的文件过于庞大难于共享。由于MP3文件通过因特网大量传播，一些主要唱片厂商通过法律起诉Napster来保护它们的版权（参见知识产权）。 如iTunes Store这样的商业在线音乐发行服务通常选择其他或者专有的支持数字版权管理（DRM）的音乐文件格式以控制和限制数字音乐的使用。支持DRM的格式的使用是为了防止受版权保护的素材免被侵犯版权，但是大多数的保护机制都能被一些方法破解。这些方法能够被计算机高手用来生成能够自由复制的解锁文件。如果希望得到一个压缩的音频文件，这个录制的音频流必须进行压缩且代价是音质的降低。 比特率 比特率对于MP3文件来说是可变的。总的原则是比特率越高则声音文件中包含的原始声音信息越多，这样回放时声音质量也越高。在MP3编码的早期，整个文件使用一个固定的比特率，称为固定码率（CBR）。 MPEG-1 Layer 3允许使用的比特率是32、40、48、56、64、80、96、112、128、160、192、224、256和320 kbit/s，允许的采样频率是32、44.1和48kHz。44.1kHz是最为经常使用的速度（与CD的采样速率相同），128kbit/s是事实上“好品质”的标准，尽管320kbit/s在P2P文件共享网络上越来越受到欢迎。MPEG-2和[非正式的]MPEG-2.5包括其他一些比特率：6、12、24、32、40、48、56、64、80、96、112、128、144、160kbit/s。 可变码率（VBR）也是可能的。MP3文件的中的音频切分成有自己不同比特率的帧，这样在文件编码的时候就可以动态地改变比特率。尽管在最初的实现中并没有这项功能。VBR技术现在音频/视频编码领域已经得到了广泛的应用，这项技术使得在声音变化大的部分使用较大的比特率而在声音变化小的部分使用较小的比特率成为可能。这个方法类似于声音控制的磁带录音机不记录静止部分节省磁带消耗。一些编码器在很大程度上依赖于这项技术。 高达640kbit/s的比特率可以使用LAME编码器和自由格式来实现，但是由于它并非标准比特率之一，有些低端或早期的MP3播放器不能够播放这些文件。 MP3的音频质量 因为MP3是一种有损压缩格式，它提供了多种不同“比特率”（bit rate）的选项—也就是用来表示每秒音频所需的编码数据位数。典型的速度介于128kbps和320kbps（kbit/s）之间。与此对照的是，CD上未经压缩的音频比特率是1411.2 kbps（16位／采样点× 44100采样点／秒× 2通道）。 使用较低比特率编码的MP3文件通常回放质量较低。使用过低的比特率，“压缩噪声（compression artifact）”（原始录音中没有的声音）将会在回放时出现。说明压缩噪声的一个好例子是：压缩欢呼的声音；由于它的随机性和急剧变化，所以编码器的错误就会更明显，并且听起来就象回声。 除了编码文件的比特率之外；MP3文件的质量，也与编码器的质量以及编码信号的难度有关。使用优质编码器编码的普通信号，一些人认为128kbit/s的MP3以及44.1kHz的CD采样的音质近似于CD音质，同时得到了大约11:1的压缩率。在这个比率下正确编码的MP3只能够获得比调频广播更好的音质，这主要是那些模拟介质的带宽限制、信噪比和其他一些限制。然而，听力测试显示经过简单的练习测试听众能够可靠地区分出128kbit/s MP3与原始CD的区别[来源请求]。在许多情况下他们认为MP3音质不佳是不可接受的，然而其他一些听众或者换个环境（如在嘈杂的车中或者聚会上）他们又认为音质是可接受的。很显然，MP3编码的瑕疵在低端声卡或者扬声器上比较不明显，而在连接到计算机的高质量立体声系统，尤其是使用高保真音响设备或者高质量的耳机时则比较明显。 Fraunhofer Gesellschaft（FhG）在他们的官方网站上，公布了下面的MPEG-1 Layer 1/2/3的压缩率和数据速率用于比较： Layer 1: 384 kbit/s，压缩率4:1 Layer 2: 192 - 256 kbit/s，压缩率8:1-6:1 Layer 3: 112 - 128 kbit/s，压缩率12:1-10:1 不同层面之间的差别是因为它们使用了不同的心理声学模型导致的；Layer 1的算法相当简单，所以透明编码就需要更高的比特率。然而，由于不同的编码器使用不同的模型，很难进行这样的完全比较。 许多人认为所引用的速率，出于对Layer 2和Layer 3记录的偏爱，而出现了严重扭曲。他们争辩说实际的速率如下所列： Layer 1: 384 kbit/s优秀 Layer 2: 256 - 384 kbit/s优秀，224 - 256 kbit/s很好，192 - 224 kbit/s好 Layer 3: 224 - 320 kbit/s优秀，192 - 224 kbit/s很好，128 - 192 kbit/s好 当比较压缩机制时，很重要的是要使用同等音质的编码器。将新编码器与基于过时技术甚至是带有缺陷的旧编码器比较可能会产生对于旧格式不利的结果。由于有损编码会丢失信息这样一个现实，MP3算法通过创建人类听觉总体特征的模型尽量保证丢弃的部分不被人耳识别出来（例如，由于noise masking），不同的编码器能够在不同程度上实现这一点。 一些可能的编码器： Mike Cheng在1998年早些时候首次开发的LAME。与其他相比，它是一个完全遵循LGPL的MP3编码器，它有良好的速度和音质，甚至对MP3技术的后继版本形成了挑战[来源请求]。 Fraunhofer Gesellschaft：有些编码器不错，有些有缺陷。 有许多的早期编码器现在已经不再广泛使用： ISO dist10 Xing BladeEnc ACM Producer Pro. 好的编码器能够在128到160kbit/s下达到可接受的音质，在160到192kbit/s下达到接近透明的音质。所以不在特定编码器或者最好的编码器话题内说128kbit/s或者192kbit/s下的音质是容易引起误解的。一个好的编码器在128kbit/s下生成的MP3有可能比一个不好的编码器在192kbit/s下生成的MP3音质更好。另外，即使是同样的编码器同样的文件大小，一个不变比特率的MP3可能比一个变比特率的MP3音质要差很多。 需要注意的一个重要问题是音频信号的质量是一个主观判断。安慰效果（Placebo effect）是很严重的，许多用户声明要有一定水准的透明度。许多用户在A/B测试中都没有通过，他们无法在更低的比特率下区分文件。一个特定的比特率对于有些用户来说是足够的，对于另外一些用户来说是不够的。每个人的声音感知可能有所不同，所以一个能够满足所有人的特定心理声学模型并不明显存在。仅仅改变试听环境，如音频播放系统或者环境可能就会显现出有损压缩所产生的音质降低。上面给出的数字只是大多数人的一个大致有效参考，但是在有损压缩领域真正有效的压缩过程质量测试手段就是试听音频结果。 如果你的目标是实现没有质量损失的音频文件或者用在演播室中的音频文件，就应该使用无损压缩（Lossless）算法，目前能够将16位PCM音频数据压缩到38%并且声音没有任何损失，这样的无损压缩编码有LA、Sony ATRAC Advanced Lossless、Dolby TrueHD、DTS Master Lossless Audio、MLP、Sony Reality Audio、WavPack、Apple Lossless、TTA、FLAC、Windows Media Audio 9 Lossless（WMA）和APE（Monkey’s Audio）等等。 对于需要进行编辑、混合处理的音频文件要尽量使用无损格式，否则有损压缩产生的误差可能在处理后无法预测，多次编码产生的损失将会混杂在一起，在处理之后进行编码这些损失将会变得更加明显。无损压缩在降低压缩率的代价下能够达到最好的结果。 一些简单的编辑操作，如切掉音频的部分片段，可以直接在MP3数据上操作而不需要重新编码。对于这些操作来说，只要使用合适的软件（”mp3DirectCut”和”MP3Gain”），上面提到的问题可以不必考虑。 MP3的设计限制 MP3格式存有设计限制，即使使用更好的编码器仍旧不能克服这些限制。一些新的压缩格式如AAC、Ogg Vorbis等不再有这些限制。 按照技术术语，MP3有如下一些限制： 编码的比特率位速最高质量可达320Kbps，基本不损失原本音效质量[4]。 时间分辨率相对于变化迅速的信号来说太低。 采样频率最高为48kHz，对于超过48kHz采样频率的音频无法编码在MP3内，而CD经常使用的采样速率为44.1kHz。 联合立体声（Joint stereo）是基于帧与帧完成的。 没有定义编码器／解码器的整体时延，这就意味着gapless playback缺少一个正式的规定。 然而，即使有这些限制，一个经良好的调整MP3编码器仍能够提供与其他格式相提并论或更高的编码质量。 MPEG-1标准中没有MP3编码器的一个精确规范，然而与此相反，解码算法和文件格式却进行了细致的定义。人们设想编码的实现是设计自己的适合去除原始音频中部分信息的算法（或者是它在频域中的修正离散余弦（MDCT）表示）。在编码过程中，576个时域样本被转换成576个频域样本，如果是瞬变信号就使用192而不是576个采样点，这是限制量化噪声随着随瞬变信号短暂扩散。 这是听觉心理学的研究领域：人类主观声音感知。 这样带来的结果就是出现了许多不同的MP3编码器，每种生成的声音质量都不相同。有许多它们的比较结果，这样一个潜在用户很容易选择合适的编码器。需要记住的是高比特率编码表现优秀的编码器（如LAME这个在高比特率广泛使用的编码器）未必在低比特率的表现也同样好。 MP3音频编码 MPEG-1标准中没有MP3编码器的一个精确规范，然而与此相反，解码算法和文件格式却进行了细致的定义。人们设想编码的实现是设计自己的适合去除原始音频中部分信息的算法（或者是它在频域中的修正离散余弦（MDCT）表示）。在编码过程中，576个时域样本被转换成576个频域样本，如果是瞬变信号就使用192而不是576个采样点，这是限制量化噪声随着随瞬变信号短暂扩散。 这是听觉心理学的研究领域：人类主观声音感知。 这样带来的结果就是出现了许多不同的MP3编码器，每种生成的声音质量都不相同。有许多它们的比较结果，这样一个潜在用户很容易选择合适的编码器。需要记住的是高比特率编码表现优秀的编码器（如LAME这个在高比特率广泛使用的编码器）未必在低比特率的表现也同样好。 MP3音频解码 另一方面，解码在标准中进行了细致的定义。 多数解码器是bitstream compliant，也就是说MP3文件解码出来的非压缩输出信号将与标准文档中数学定义的输出信号一模一样（在规定的近似误差范围内）。 MP3文件有一个标准的格式，这个格式就是包括384、576、或者1152个采样点（随MPEG的版本和层不同而不同）的帧，并且所有的帧都有关联的头信息（32位）和辅助信息（9、17或者32字节，随着MPEG版本和立体声或者单通道的不同而不同）。头和辅助信息能够帮助解码器正确地解码相关的霍夫曼编码数据。 所以，大多数的解码器比较几乎都是完全基于它们的计算效率（例如，它们在解码过程中所需要的内存或者CPU时间）。 关于VBR VBR：MP3格式的文件有一个有意思的特征，就是可以边读边放，这也符合流媒体的最基本特征。也就是说播放器可以不用预读文件的全部内容就可以播放，读到哪里播放到哪里，即使是文件有部分损坏。虽然mp3可以有文件头，但对于mp3格式的文件却不是很重要，正因为这种特性，决定了MP3文件的每一段每一帧都可以单独的平均数据速率，而无需特别的解码方案。于是出现了一种叫VBR（Variable bitrate，动态数据速率）的技术，可以让MP3文件的每一段甚至每一帧都可以有单独的bitrate，这样做的好处就是在保证音质的前提下最大程度的限制了文件的大小。这种技术的优越性是显而易见的，但要运用确实是一件难事，因为这要求编码器知道如何为每一段分配bitrate，这对没有波形分析的编码器而言，这种技术如同虚设。正是如此，VBR技术并没有一出现就显得光彩夺目。 专家们通过长期的声学研究，发现人耳存在 遮蔽效应。声音信号实际是一种能量波，在空气或其他媒介中传播，人耳对声音能量的多少即响度或声压最直接的反应就是听到这个声音的大小，我们称它为响度，表示响度这种能量的单位为分贝（dB）。即使是同样响度的声音，人们也会因为它们频率不同而感觉到声音大小不同。人耳最容易听到的就是4000Hz的频率，不管频率是否增高或降低，即使是响度在相同的情况下，大家都会觉得声音在变小。但响度降到一定程度时，人耳就听不到了，每一个频率都有着不同的值。 可以看到这条曲线基本成一个V字型，当频率超过15000Hz时，人耳的会感觉到声音很小，很多听觉不是很好的人，根本就听不到20000Hz的频率，不管响度有多大。当人耳同时听到两个不同频率、不同响度的声音时，响度较小的那个也会被忽略，例如：在白天我们很难听到电脑中散热风扇的声音，晚上却成了噪声源，根据这种原理，编码器可以过滤掉很多听不到的声音，以简化信息复杂度，增加压缩比，而不明显的降低音质。这种遮蔽被称为同时遮蔽效应。但声音A被声音B遮蔽，如果A处于B为中心的遮蔽范围内，遮蔽会更明显,这个范围叫临界带宽。每一种频率的临界带宽都不一样，频率越高的临界带宽越宽。 频率(Hz) 临界带宽(Hz) 频率(Hz) 临界带宽(Hz) 根据这种效应，专家们设计出人耳听觉心理模型，这个模型被导入到mp3编码中后，导致了一场翻天覆地的音质革命，mp3编码技术一直背负着音质差的恶名，但这个恶名现在已经逐渐被洗脱。到了此时，一直被埋没的VBR技术光彩四射，配合心理模型的运用便现实出强大的诱惑力与杀伤力。 长期来，很多人对MP3印象不好，更多人认为WMA的最佳音质要好过MP3，这种说法是不正确的，在中高码率下，编码得当的MP3要比WMA优秀很多，可以非常接近CD音质，在不太好的硬件设备支持下，没有多少人可以区分两者的差异，这不是神话故事，尽管你以前盲听就可以很轻松区分MP3和CD，但现在你难保证你可以分辨正确。因为MP3是优秀的编码，以前被埋没了。 OGG编码网络上出现了一种叫Ogg Vorbis的音频编码，号称MP3杀手！Ogg Vorbis究竟什么来头呢？OGG是一个庞大的多媒体开发计划的项目名称，将涉及视频音频等方面的编码开发。整个OGG项目计划的目的就是向任何人提供完全免费多媒体编码方案！OGG的信念就是：OPEN！FREE！Vorbis这个词汇是特里·普拉特柴特的幻想小说《Small Gods》中的一个”花花公子”人物名。这个词汇成为了OGG项目中音频编码的正式命名。目前Vorbis已经开发成功，并且开发出了编码器。 Ogg Vorbis是高质量的音频编码方案，官方数据显示：Ogg Vorbis可以在相对较低的数据速率下实现比MP3更好的音质！Ogg Vorbis这种编码也远比90年代开发成功的MP3先进，它可以支持多声道，这意味着什么？这意味着Ogg Vorbis在SACD、DTSCD、DVD AUDIO抓轨软件（目前这种软件还没有）的支持下，可以对所有的声道进行编码，而不是MP3只能编码2个声道。多声道音乐的兴起，给音乐欣赏带来了革命性的变化，尤其在欣赏交响时，会带来更多临场感。这场革命性的变化是MP3无法适应的。 和MP3一样，Ogg Vorbis是一种灵活开放的音频编码，能够在编码方案已经固定下来后还能对音质进行明显的调节和新算法的改良。因此，它的声音质量将会越来越好，和MP3相似，Ogg Vorbis更像一个音频编码框架，可以不断导入新技术逐步完善。和MP3一样，OGG也支持VBR。 MPC编码MPC是又是另外一个令人刮目相看的实力派选手，它的普及过程非常低调，也没有什么复杂的背景故事，她的出现目的就只有一个，更小的体积更好的音质！MPC以前被称作MP+，很显然，可以看出她针对的竞争对手是谁。但是，只要用过这种编码的人都会有个深刻的印象，就是她出众的音质。 mp3PRO编码2001年6月14日，美国汤姆森多媒体公司(Thomson Multimedia SA)与佛朗赫弗协会(Fraunhofer Institute)于6月14日发布了一种新的音乐格式版本，名称为mp3PRO，这是一种基于mp3编码技术的改良方案，从官方公布的特征看来确实相当吸引人。从各方面的资料显示，mp3PRO并不是一种全新的格式，完全是基于传统mp3编码技术的一种改良，本身最大的技术亮点就在于SBR（Spectral Band Replication 频段复制），这是一种新的音频编码增强算法。它提供了改善低位率情况下音频和语音编码的性能的可能。这种方法可在指定的位率下增加音频的带宽或改善编码效率。SBR最大的优势就是在低数据速率下实现非常高效的编码，与传统的编码技术不同的是，SBR更像是一种后处理技术，因此解码器的算法的优劣直接影响到音质的好坏。高频实际上是由解码器（播放器）产生的，SBR编码的数据更像是一种产生高频的命令集，或者称为指导性的信号源，这有点駇idi的工作方式。我们可以看到，mp3PRO其实是一种mp3信号流和SBR信号流的混合数据流编码。有关资料显示，SBR技术可以改善低数据流量下的高频音质，改善程度约为30%，我们不管这个30%是如何得来的，但可以事先预知这种改善可以让64kbps的mp3达到128kbps的mp3的音质水平（注：在相同的编码条件下，数据速率的提升和音质的提升不是成正比的，至少人耳听觉上是这样的），这和官方声称的64kbps的mp3PRO可以媲美128kbps的mp3的宣传基本是吻合的。 WMA格式WMA就是Windows Media Audio编码后的文件格式，由微软开发，WMA针对的不是单机市场，是网络！竞争对手就是网络媒体市场中著名的Real Networks。微软声称，在只有64kbps的码率情况下，WMA可以达到接近CD的音质。和以往的编码不同，WMA支持防复制功能，她支持通过Windows Media Rights Manager 加入保护，可以限制播放时间和播放次数甚至于播放的机器等等。WMA支持流技术，即一边读一边播放，因此WMA可以很轻松的实现在线广播，由于是微软的杰作，因此，微软在Windows中加入了对WMA的支持，WMA有着优秀的技术特征，在微软的大力推广下，这种格式被越来越多的人所接受。 RA格式RA就是RealAudio格式，这是各位网虫接触得非常多的一种格式，大部分音乐网站的在线试听都是采用了RealAudio，这种格式完全针对的就是网络上的媒体市场，支持非常丰富的功能。最大的闪烁点就是这种格式可以根据听众的带宽来控制自己的码率，在保证流畅的前提下尽可能提高音质。RA可以支持多种音频编码，包括ATRAC3。和WMA一样，RA不但都支持边读边放，也同样支持使用特殊协议来隐匿文件的真实网络地址，从而实现只在线播放而不提供下载的欣赏方式。这对唱片公司和唱片销售公司很重要，在各方的大力推广下，RA和WMA是目前互联网上，用于在线试听最多的音频媒体格式。 APE格式APE是Monkey’s Audio提供的一种无损压缩格式。Monkey’s Audio提供了Winamp的插件支持，因此这就意味着压缩后的文件不再是单纯的压缩格式，而是和MP3一样可以播放的音频文件格式。这种格式的压缩比远低于其他格式，但能够做到真正无损，因此获得了不少发烧用户的青睐。在现有不少无损压缩方案种，APE是一种有着突出性能的格式，令人满意的压缩比以及飞快的压缩速度，成为了不少朋友私下交流发烧音乐的唯一选择。 格式特点各种各样的音频编码都有其技术特征及不同场合的适用性，我们大致讲解一下如何去灵活应用这些音频编码。 PCM编码的WAV前面就提到过，PCM编码的WAV文件是音质最好的格式，Windows平台下，所有音频软件都能够提供对她的支持。Windows提供的WinAPI中有不少函数可以直接播放wav，因此，在开发多媒体软件时，往往大量采用wav，用作事件声效和背景音乐。PCM编码的wav可以达到相同采样率和采样大小条件下的最好音质，因此，也被大量用于音频编辑、非线性编辑等领域。 特点：音质非常好，被大量软件所支持。 适用于：多媒体开发、保存音乐和音效素材。 MP3MP3具有不错的压缩比，使用LAME编码的中高码率的mp3，听感上已经非常接近源WAV文件。使用合适的参数，LAME编码的MP3很适合于音乐欣赏。由于MP3推出年代已久，加之还算不错的音质及压缩比，不少游戏也使用mp3做事件音效和背景音乐。几乎所有著名的音频编辑软件也提供了对MP3的支持，可以将mp3象wav一样使用，但由于mp3编码是有损的，因此多次编辑后，音质会急剧下降，mp3并不适合保存素材，但作为作品的demo确实相当优秀的。mp3长远的历史和不错的音质，使之成为应用最广的有损编码之一，网络上可以找到大量的mp3资源，mp3player日渐成为一种时尚。不少VCDPlayer、DVDPlayer甚至手机都可以播放mp3，mp3是被支持的最好的编码之一。MP3也并非完美，在较低码率下表现不好。MP3也具有流媒体的基本特征，可以做到在线播放。 特点：音质好，压缩比比较高，被大量软件和硬件支持，应用广泛。 适用于：适合用于比较高要求的音乐欣赏。OGGOgg是一种非常有潜力的编码，在各种码率下都有比较惊人的表现，尤其中低码率下。Ogg除了音质好之外，她还是一个完全免费的编码，这对ogg被更多支持打好了基础。Ogg有着非常出色的算法，可以用更小的码率达到更好的音质，128kbps的Ogg比192kbps甚至更高码率的mp3还要出色。Ogg的高音具有一定的金属味道，因此在编码一些高频要求很高的乐器独奏时，Ogg的这个缺陷会暴露出来。OGG具有流媒体的基本特征，但现在还没有媒体服务软件支持，因此基于ogg的数字广播还无法实现。Ogg目前的被支持的情况还不够好，无论是软件的还是硬件的，都无法和mp3相提并论。 特点：可以用比mp3更小的码率实现比mp3更好的音质，高中低码率下均具有良好的表现。 适用于：用更小的存储空间获得更好的音质（相对MP3）。 MPC和OGG一样，MPC的竞争对手也是mp3，在中高码率下，MPC可以做到比竞争对手更好音质，在中等码率下，MPC的表现不逊色于Ogg，在高码率下，MPC的表现更是独孤求败，MPC的音质优势主要表现在高频部分，MPC的高频要比MP3细腻不少，也没有Ogg那种金属味道，是目前最适合用于音乐欣赏的有损编码。由于都是新生的编码，和Ogg际遇相似，也缺乏广泛的软件和硬件支持。MPC有不错的编码效率，编码时间要比OGG和LAME短不少。 特点：中高码率下，具有有损编码中最佳的音质表现，高码率下，高频表现极佳。 适用于：在节省大量空间的前提下获得最佳音质的音乐欣赏。WMA微软开发的WMA同样也是不少朋友所喜爱的，在低码率下，有着好过mp3很多的音质表现，WMA的出现，立刻淘汰了曾经风靡一时的VQF编码。有微软背景的WMA获得了很好的软件及硬件支持，Windows Media Player就能够播放WMA，也能够收听基于WMA编码技术的数字电台。因为播放器几乎存在于每一台PC上，越来越多的音乐网站都乐意使用WMA作为在线试听的首选了。除了支持环境好之外，WMA在64-128kbps码率下也具有相当出色的表现，虽然不少要求较高的朋友并不够满意，但更多要求不高的朋友接受了这种编码，WMA很快的普及开了。 特点：低码率下的音质表现难有对手。 适用于：数字电台架设、在线试听、低要求下的音乐欣赏。 mp3PRO作为mp3的改良版本的mp3PRO表现出了相当不错的素质，高音丰满，虽然mp3PRO是通过SBR技术在播放过程中插入的，但实际听感相当不错，虽然显得有点单薄，但在64kbps的世界里已经没有对手了，甚至超过了128kbps的mp3，但很遗憾的是，mp3PRO的低频表现也象mp3一样的破，所幸的是，SBR的高频插值可以或多或少的掩盖掉这个缺陷，因此mp3PRO的低频弱势反而不如WMA那么明显。大家可以在使用RCA mp3PRO Audio Player的PRO开关来切换PRO模式和普通模式时深深的感觉到。整体而言，64kbps的mp3PRO达到了128kbps的mp3的音质水平，在高频部分还略有胜出。 特点：低码率下的音质之王。 适用于：低要求下的音乐欣赏。 APE一种新兴的无损音频编码，可以提供50-70%的压缩比，虽然比起有损编码来太不值得一提了，但对于追求完美音质的朋友简直是天大的福音。APE可以做到真正的无损，而不仅是听起来无损，压缩比也要比类似的无损格式要好。 特点：音质非常好。 适用于：最高品质的音乐欣赏及收藏。 音频编码技术比较 说明：质量评价共五个等级（1、2、3、4、5），其中5.0为最高分。 上表中各种算法、应用领域中缩略语的中文和英文全称参见下面说明。 PCM：Pulse Code Modulation，脉冲编码调制。 ADPCM：Adaptive Differential Pulse Code Modulation，自适应差分脉冲编码调制。 SB-ADPCM：Subband Adaptive Differential Pulse Code Modulation，子带-自适应差分脉冲编码调制。 LPC：Linear Predictive Coding，线性预测编码。 CELPC：Code Excited Linear Predictive Coding，码激励线性预测编码。 VSELPC：Vector Sum Excited Linear Predictive Coding，矢量和激励线性预测编码。 RPE-LTP：Regular Pulse Excited-Long Term Predictive，规则脉冲激励长时预测。 LD-CELP：Low Delay-Code Excited Linear Predictive，低时延码激励线性预测。 MPE：Multi-Pulse Excited，多脉冲激励。 PSTN：Public Switched Telephone Network，公共交换电话网。 ISDN：Integrated Services Digital Network，综合业务数字网。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多媒体技术(一)之图形图像]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-graphic%2F</url>
    <content type="text"><![CDATA[1.图形与图像的基本概念1.1图形与图像的颜色模型1.1.1颜色的基本概念1.1.1.1 物体的颜色物体的颜色不同是因为他们对光的吸收和反射的属性不同.物体的颜色是由该物体所反射的光的波长来决定的. 人眼看到的物体的颜色不仅取决于该物体所反射的光的波长,还与照射它的光源有关.如果用单一蓝色去照射绿色的树叶, 则此时的树叶只能是黑色的.因为蓝色光源中没有绿色成分,树叶吸收了全部蓝色而呈现黑色. 在彩色显示器中,为了使颜色具有较好的还原度和真实感,通常采用类似自然光作为照明光源. 1.1.1.2 彩色三要素颜色信息对人的视觉反应,可通过色调,色饱和度和亮度这三个参量来表示: 色调:用来描述颜色的不同类别的物理量称为色调,如红,橙,黄,绿,青,蓝,紫.色调取决于该种颜色的主要波长. 色饱和度:色饱和度则是描述颜色的深浅程度的物理量,它按该种颜色混入白光的比例来表示,当某色光的饱和度为100%时,就是表示该色光是完全没有混入白色光的单色光饱和度越高则颜色也越浓.如果大量混入白色光使饱和度降低,人视觉会感到颜色变淡.例如,在浓的的红色光中混入大量的白光,由于饱和度降低就变成了粉红色,但是因为红色是基本色,所以色调并不改变.在某颜色中混入白光与增强白光对某颜色物体的照射是不同的.前者是在摄入人眼的眸色光中混入白光,而后者的结果则是加强了某色物体的反射光的强度,在摄入人眼的反射光中并没有混入白光,因此它并没有改变该色的饱和度. 亮度:用来描述色光的明暗变化的强度的物理量成为亮度.亮度是色光能量的一种描述,是指色调和色饱和度已经固定的光,当它的全部能量增强时感觉明亮,否则感觉暗淡. 色调和色饱和度统称为色度. 1.1.1.3 三基色原理三基色原理认为自然界中景物的绝大多数的彩色光,能分解为互相独立的红(R),绿(G),蓝(B)三种基色光;反之,用互相独立的红,绿,蓝3种基色光以不同的比例混合,可模拟出自然界中绝大多数景色的光.RGB三基色相互独立的含义是指,任一种基色都不能由另外两种基色混合而产生.三基色的选择并不是唯一的. 1.1.1.4 像素(pixel)像素是计算机图形与图像中能被单独处理的最小基本单元. 从像素的视觉属性看,它是一个最小可是单位.一幅彩色图像可以看成是由许多很小的可是点组成的,这个点就是像素.每个像素点都有确定的颜色和亮度,这个颜色就是有互相独立的红,绿,蓝三种基色光以不同的比例混合而成的. 从像素的量值属性看,它的数据结构应同时显示地址,色彩,亮度等数据信息,这些数据就称为像素值. 1.1.2 颜色模型颜色模型(或称色彩模型)就是定量颜色方法.在不同的领域应用于图像时,为了尽可能多地,有效地描述各种颜色,往往采用不同的颜色模型,例如,用显示器这类发光物体显示时采用的是RGB模型,用打印机这类吸光物体输出图像时用CMY模型,进行彩色电视信号的显示与传输时采用YUV模型,从事艺术绘画时习惯采用HSL模型. 1.1.2.1 RGB模型RGB模型也称为加色法混色模型.其混色规律是:以等量的红,绿,蓝基色光混合时: 红 + 绿 = 黄色 红 + 蓝 = 品红色 绿 + 蓝 = 青色 红 + 绿 + 蓝 = 白色 3种基色光全无 = 黑色 加色法的混色规律可以使用下图表示,3个圆分别红绿蓝3种基色,圆与圆的叠加区域表示以等量的基色相混合时所合成的颜色,其色调如该区域的文字表示.当3种基色等量相加时,就会得到白色.其中,又尝尝把品红色成为绿色的补色,青色称为红色的补色,黄色称为蓝色的补色. 物体的颜色是丰富多彩的,任何一种颜色和这3种基色之间的关系可以用下面的配色方程式来描述: F(物体颜色)=R(红色的百分比) + G(绿色的百分比) + B(蓝色的百分比) 由于人类的视觉特性,两种或3种基色产生混色效果,不一定要同时和同一空间位置混合.例如,在心理学实验中有一个色轮实验,它是在可旋转的圆盘上按扇形面积均等的分成3部分,并涂上3种基色,当圆盘慢慢旋转时能够分辨出3中基色,但当圆盘旋转的频率提高到闪光融合频率以上时,人眼不再能分辨出3种基色,而产生白颜色的感觉,以达到混色的效果.这就是 “时间混色法” .最初的顺序制彩色电视就应用了人的这一视觉效果.例如,很细小的红点和旅店均匀间置互相靠的很近,只有在近距离仔细观看才能区分出来,当观看距离很远时就只感觉到黄色的一篇了,这就是 “空间混色法” .目前广泛使用的彩色显像管以及大型LED真彩色广告屏就是利用了这一混色视觉效应. 在多媒体技术中,RGB颜色模型是最基本的模型,因为彩色显示器只有按RGB分量式输入,才能在显示屏幕上合成任意颜色. 1.1.2.2 CMY模型CMY(Cyan Magenta Yellow)模型是采用青,品红,黄色3种基本颜色按一定比例合成颜色的方法.CMY模型又称为减色法混色模型,因为色彩的显示不是直接来自于光线的色彩,而是光线被物体吸收掉一部分之后发射回来的剩余光线所产生的.光线都被吸收时称为黑色,当光线都被反射时成为白色.这种模式适合于彩色打印机等用彩色墨水或颜料进行混合显示的情况. 在相减混色中,当3种基本颜色等量相减时得到黑色;等量黄色(Y)和品红(M)相减而青色为0时,等到红色(R);等量青色(C)和品红(M)相减而黄色为0时,得到蓝色(B);等量黄色(Y)和青色(C)相减而品红(M)为0时,得到绿色(G). 由于颜料的化学特性,实际上等量的CMY混合后并不能产生真正的黑色,因此在印刷时通常再加上黑色(Black),这样又称为CMYK模式,四色印刷便是由此而来. 显然,RGB与CMY模型是颜色互补的模型,它们之间可以互相转换.如果按每个像素每种颜色用一位二进制数表示的话,RGB与CMY模型之间的颜色关系如下表所示.利用它们之间的关系,可以把显示器显示的颜色转换成打印的颜色.但实际上因为发射光与反射光的性质完全不同,显示器上的颜色不可能精确地在打印机上复制出来,因此实际的转换过程会利用一定的算法进行一定程度上的失真补偿. |RGB|CMY|颜色| |—|—|—| |000|111|黑| |001|110|蓝| |010|101|绿| |011|100|青| |100|011|红| |101|010|品红| |110|001|黄| |111|000|白| 1.1.2.3 YUV与YIQ模型在彩色电视系统中不采用RGB颜色模型,而采用YUV或YIQ模型表示彩色图像.YUV适用于PAL(Phase Altermation Line,同行倒相制式)和SECAM(法文)(Sequential C欧了让Memo,顺序传送彩色与存储制式)彩色电视制式,而YIQ适用于美国国家电视标准委员会(NTSC,National Television System Committee)彩色电视制式. Y是亮度信号,U和V则是两个色差信号,分别传送红基色分量和蓝基色分量与亮度分量的差值信号. 采用YUV颜色模型的好处是:其一,亮度信号Y解决了彩色电视与黑白电视的兼容性问题;其二,由于人眼对颜色细节的分辨率低于对亮度细节的分辨率,所以可以用一个通道来传送,Y,U,V这3个信号,给亮度信号较大的带宽(6MHz)来传送图像的细节,而给色差信号较小的带宽(1.3MHz)来进行大面积涂色.这样,总的传输数据量和RGB模型相比,要明显小一些,起到了一种数据压缩节省存储空间的作用,而对于这种数据压缩带来的画面变化人眼一般是感觉不到的. 电视系统通常采用摄像机把摄得的彩色图像信号经分色,放大和校正分成RGB这3个分量的信号,再经过矩阵变换电路将彩色信号分解成亮度信号Y和色差信号,U,V,而后对其进行编码,用同一信道发送出去.接收端再通过编码及矩阵逆变换还原成3个基色显示. 在NTSC彩色电视制式中使用YIQ模型,其特性与YUV模型相近.其中的Y表示亮度,I,Q也是两个色差分量,但它们在色度矢量图中与U,V的位置不同.Q,I正交坐标轴与U,V正交坐标轴之间有33度夹角,如图所示: I,Q与U,V之间的关系如下: I = Vcos33 - Usin33 Q = Vsin33 + Ucos33 人眼的彩色视觉特性表明,人眼分辨红与黄之间的颜色变化的能力最强,而分辨蓝,紫之间颜色变化的能力最弱.因此YIQ模型在色度矢量图中,选择I轴正好处于夹角123度处,即人眼具有最大彩色分辨率的红与黄之间的橙色和青色(相角为303度)处,选择与I轴正交的色度信号轴为Q轴(相角为33度),正是人眼最不敏感的色轴位置.因而YIQ模型传送分辨力较强的I信号时,用较宽的频带(1.3MHz~1.5MHz),传送分辨力弱的Q信号时,可用较窄的频带(0.5MHz),这就可以在保证较好的颜色传输特性情况下,最大限度地节省存储空间. 1.1.2.4 HSI颜色模型HSI或HSL是Hue Saturation Intensity(Lightness)的英文缩写,颜色模型用H,S,I这三个参数描述颜色特性,其中H定义颜色的波长,称为色调;S表示颜色的深浅程度,称为饱和度;I表示强度或亮度,这正是颜色的三要素. HSI模型更接近人对颜色更接近人对彩色的认识,符合人眼对颜色的感知方式,是一种从事艺术绘画的画家们习惯使用的描述色彩的方法.它比RGB模型使用更方便,从而能减少彩色图像处理的复杂性,增加快速性,因此一般的图像处理软件中,都提供了这种定量色彩的方式. 1.1.3 颜色模型的转换无论采用什么颜色模型来表示彩色图形与图像,由于所有的显示器都需要RGB值来驱动,所以在显示每个像素之前,必须要把彩色分量值转换成RGB值. 1.1.3.1 YUV与RGB颜色模型变换RGB与YUV的对应关系可以近似地用下面的方程表示: Y = 0.299R + 0.587G + 0.114B U = -0.147R - 0.289G + 0.436B V = 0.615R - 0.515G - 0.096B1.1.3.2 YIQ与RGB颜色模型变换YIQ与RGB的对应关系可以近似地用下面的方程表示: Y = 0.229R + 0.587G + 0.114B I = 0.596R - 0.275G - 0.321B Q = 0.212R - 0.523G + 0.311B HSI 与 RGB颜色变换HSI与RGB空间的转换关系可以用下面的方程表示: H = [90 - arctan(F/sqr(3)) + [0, G&gt;B;180,G&lt;B]]/360 S = 1 - min(R,G,B)/I I = (R+G+B)/3 其中,F=(2R-G-B)/(G-B),sqr为求平方根 1.2图形与图像的基本属性一幅彩色图像可以看成二维连续函数f(x,y),其彩色幅度是位置(x,y)的函数.计算机多媒体技术从其图像的生成,显示,处理和存储的机制出发,需要对彩色图像数字化.数字化一幅彩色图像就是要把连续函数f(x,y)在空间的坐标和彩色幅度进行离散和量化.空间坐标x,y的离散化通常以分辨率来表征,而彩色幅度的离散化则由像素的颜色深度来表征. 1.2.1分辨率分辨率是一个统称,分为显示分辨率,图像分辨率,扫描分辨率和打印分辨率等. 1.2.1.1显示分辨率是指某一种显示方式下,显示屏上能够显示出的像素数目,以水平和垂直的像素表示.例如,显示分辨率为640*480表示显示屏分成480行,每行显示640个像素,整个显示屏就含有307200个显像点.屏幕上的像素越多,分辨率就越高,显示出来的图像也就越细腻,显示的图像质量也就约高.屏幕能够显示的最大像素数目越多,也说明显示设备的最大分辨率越高.显示屏上的每个彩色像素由代表R,G,B这3种模拟信号的相对强度决定,这些彩色像素点就构成一幅彩色图像. 1.2.1.2图像分辨率图像分辨率指数字化图像的大小,以水平和垂直的像素数表示.如果组成图像的像素数目越多,则说明图像的分辨率越高,看起来就越逼真,图像分辨率实际上决定了图像的显示质量,也就是说,即使提高了显示分辨率,也无法真正改善图像的质量.图像分辨率与显示分辨率是两个不同的概念.图像分辨率的确定组成一幅图像的像素数目,而显示分辨率是确定显示图像的区域大小.当图像分辨率与屏幕分辨率一致时,图像正好占据满屏;当图像分辨率小于屏幕分辨率时,图像占据屏幕的一部分;当图像分辨率大于屏幕分辨率时,则屏幕仅能显示图像的一部分. 1.2.1.3扫描分辨率和打印分辨率在用于扫描仪扫描图像时,通常要指定扫描的分辨率,用每英寸包含的点(d/i,dots per inch)表示.如果用300d/i来扫描一幅86的彩色图像,就得到一幅24001800个像素的图像.分辨率越高,像素就越多. 打印分辨率是指图像打印时每英寸可识别的点数,也使用d/i(dots per inch)为衡量单位.两种分辨率之间是有区别的,扫描分辨率反映了扫描后的图像与原始图像之间的差异程度,分辨率越高,差异越小.打印分辨率反映了打印的图像与原数字图像之间的差异程度,分辨率越接近原图像的分辨率,打印质量越高.两种分辨率的最高值都受到设备的限制. 1.2.2颜色深度颜色深度是指图像中每个像素的颜色(或亮度)信息所占的二进制数位数,记做位/像素(b/p,bits per pixel).屏幕上的每一个像素都占有一个或多个位,用于存放与它相关的颜色信息.颜色深度决定了构成图像的每个像素可能出现的最大颜色数,因而颜色深度值越高,显示的图像色彩越丰富.反之,颜色深度太浅,会影响图像的质量,图像看起来让人觉得很粗糙和很不自然.常见颜色深度有一下5种: 4bit:这是VGA标准支持的颜色深度,共2的四次方16种颜色; 8bit:这是多媒体应用中的最低颜色深度,共2的8次方256种颜色,称为索引彩色图(由颜色查找决定); 16bit:在16bit中,用其中的15bit表示RGB这3种颜色,每种颜色5bit,用剩余的以为表示图像的其他属性,如透明度.所以16bit的颜色深度实际可以表示为2的15次方323232共32768种颜色.称为HI-Color(高彩色)图像. 24bit:用3个8bit分别表示RGB,可生成的颜色数2的24次16777216种,约16M种颜色,这已经成为真彩色; 32bit:同24bit颜色深度一样,也是用3个bit分别表示RGB这三种颜色,剩余的8bit用来表示图像的其他属性,如透明度等. 虽然像素的颜色颜色深度值越大图像色彩越丰富,但由于设备的限制,人眼分辨率的限制,不一定要追求特别深的颜色深度,一般来说,32bit的颜色深度已经足够.此外,像素颜色深度越深,所占用的存储空间越大. 一个像素的颜色深度位数除R,G,B分量占用固定bit数表示颜色外,一般要腾出1bit或几bit作为属性(Attribute)位.属性位用来指定该像素应具有的性质.例如,像素的颜色深度为32bit时,R,G,B分别用8bit表示,那么余下的8bit常称为a通道(Alpha Channel)位,或称为覆盖(Overlay)位,中断位,属性位,它用来控制该像素点的透明度.假如定义一个像素值(A,R,G,B)的4个分量(其中A为Alpha属性位数值)都用归一化的数值表示,那么像素91,1,0,0)时显示红色.当像素为(0.5,1,0,0)时,预乘的结果就变成了(0.5.0.5,0,0),这表示现在显示的红色的强度减低一半.用这种定义像素属性的办法可以实现两幅彩色图像之间的透明叠加效果.当Alpha数值很小时,渲染出来的效果是几乎透明的,如玻璃;当Alpha数值处于中间的位置时,则可以得到一种半透明的效果;当Alpha数值接近255时,是几乎不透明的效果.这种属性位的加入为实现透明和半透明的显示掉过带来了方便. 1.2.3文件的大小图形和图像文件的大小(也称为数据量)是指在磁盘上存储整幅图像所有点的字节数(Bytes),反映了图像所需数据存储空间的大小,可按下面的公式计算: 文件字节数 = 图像分辨率 * 图像深度/8 从公式看,图像文件的大小与图像的颜色和内容无关.其实在实际应用中,为了节省存储空间,总要对图像应用某种压缩文件格式.这样,不同的图像会因为内容的不同而使文件的大小有所不同.相对于颜色层次多,图形复杂的图像文件较大.但各种图像文件的最大值(文件字节数)都不会超越由上式决定的字节数. 1.2.4 真彩色,伪彩色与直接色 真彩色(True Color):真彩色是指在组成一幅彩色图像的每个像素值中,有R,G,B这3个基色分量,每个基色分量直接决定显示设备的基色强度,这样产生的彩色称为真彩色.例如,用RGB的8:8:8方式表示一幅彩色图像,就是R,G,B都用8bit来表示,每个基色分量占一个字节,共3个字节,每个像素的颜色就是由这3字节中的数值直接决定,可生成的颜色数就是2的24次中,共计16777216中. 伪彩色(Pseudo Color) 伪彩色图像是每个像素的颜色不是由每个基色分量的数值直接决定,而是把像素值当做彩色查找表(CLUT,Color-Look-Up Table)的表项入口地址,去查找一个显示图像时使用的RGB强度值,用查找出的R,G,B强度值产生的彩色称为伪彩色.彩色查找表是一个事先制作好的表,表项入口地址也称为索引号.彩色图像本身的像素值和彩色查找表中的索引号有一个变换关系,也可以是用自己定义的变换关系.使用查找得到的数值在显示器上显示的颜色是真的,但不是图像本身真正的颜色,因此称其为伪彩色; 直接色(Direct Color):把像素值的R,G,B分量作为单独的索引值,通过相应的彩色变换表找出R,G,B各自的基色程度,用这个强度值产生的彩色称其为直接色.真彩色系统虽然也是采用R,G,B分量来决定基色强度,但这是由R,G,B经变换后决定的,这与直接用R,G,B决定基色基色强度产生的颜色就有差别.比较而言,直接色在显示器上显示彩色图像看起来更真实,更自然. 伪彩色系统是把整个像素当做查找表的索引值进行彩色变换,而直接色系统是对R,G,B分量分别采用查找表进行变换,因此伪彩色系统色彩还原度自然就查多了. 1.3图形与图像的基本类型1.3.1位图与矢量图 位图(Bit-mapped Graphics) 矢量图(Vector Graphic) 位图和矢量图的关系 1.3.2 图形与图像的区别与联系2.图形与图像的处理2.1图形与图像的获取2.1.1 图形与图像的数字化2.1.2 图形的获取2.1.3 图像的获取2.2图形与图像的存储2.2.1静态图形与图像常见文件存储格式2.2.2 动态图形与图像常见文件存储格式2.2.3 文件存储格式的数据结构2.3图形与图像的显示2.3.1映射显示原理2.3.2硬复制设备2.4图形与图像的处理2.4.1 图形与图像处理的基本内容2.4.2 图像处理实例分析-图像识别2.4.3 图形与图像处理软件3.计算机动画3.1计算机动画的原理3.2计算机动画的类型3.3计算机动画的制作3.4虚拟现实动画技术4.图像术语4.1 高反差保留高反差保留主要是将图像中颜色、明暗反差较大两部分的交界处保留下来，比如图像中有一个人和一块石头，那么石头的轮廓线和人的轮廓线以及面部、服装等有明显线条的地方会变被保留，而其他大面积无明显明暗变化的地方则生成中灰色。要配合混合模式的使用才有实际效果 实际用途： 比如有一种算不上高清的图片，把它拉到PS中，CTRL+J复制一层，在复制的层上做高反差保留，然后将这层的混合模式（图层面板的最上端）改为“柔光”，你会发现图像的清晰度增加了。 4.2 柔光根据混合色的情况选择使基色层图像变暗或变亮.使颜色变亮或变暗，具体取决于混合色。此效果与发散的聚光灯照在图像上相似。 如果混合色（光源）比 50%灰色亮，则图像变亮，就像被减淡了一样。如果混合色（光源）比 50%灰色暗，则图像变暗，就象被加深了一样。用纯黑色或纯白色绘画会产生明显较暗或较亮的区域，但不会产生纯黑色或纯白色。 它的作用效果如同是打上一层色调柔和的光，因而被我们称之为柔光。作用时将上层图像以柔光的方式施加到下层。当底层图层的灰阶趋于高或低，则会调整图层合成结果的阶调趋于中间的灰阶调，而获得色彩较为柔和的合成效果。形成的结果是：图像的中亮色调区域变得更亮，暗色区域变得更暗，图像反差增大类似于柔光灯的照射图像的效果。变暗还是提亮画面颜色，取决于上层颜色信息。产生的效果类似于为图像打上一盏散射的聚光灯。如果上层颜色（光源）亮度高于50%灰，底层会被照亮（变淡）。如果上层颜色（光源）亮度低于50%灰，底层会变暗，就好像被烧焦了似的。如果直接使用黑色或白色去进行混合的话，能产生明显的变暗或者提亮效应，但是不会让覆盖区域产生纯黑或者纯白。 Soft Light模式根据背景中的颜色色调，把颜色用于变暗或加亮背景图像。例如，如果在背景图像上涂了50％黑色，这是一个从黑色到白色的梯度，那着色时梯度的较暗区域变得更暗，而较亮区域呈现出更亮的色调。 4.3 灰度图Gray Scale Image 或是Grey Scale Image，又称灰阶图。把白色与黑色之间按对数关系分为若干等级，称为灰度。灰度分为256阶。 灰度就是没有色彩，RGB色彩分量全部相等.]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下打包qt程序成dmg]]></title>
    <url>%2F2017%2F06%2F18%2Ftips-qt-pack%2F</url>
    <content type="text"><![CDATA[参考http://doc.qt.digia.com/4.7-snapshot/appicon.html 图片格式在线转换http://iconverticons.com/，可以生成icns格式图片。 Test.pro中添加macx{ICON = Test.icns} （记得把Test.icns添加到工程中） 发布dmb包 QT在mac下有个发布命令：macdeployqt 我的mac上macdeployqt目录如下：/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin 将macdeployqt的路径添加到环境变量里面 终端里 vim /etc/profile（如果在保存时有问题，可以用 sudo vim /etc/profile）1234567891011121314#在最后添加一行，如下所示：# System-wide .profile for sh(1)if [ -x /usr/libexec/path_helper ]; then eval `/usr/libexec/path_helper -s`fiif [ &quot;$&#123;BASH-no&#125;&quot; != &quot;no&quot; ]; then [ -r /etc/bashrc ] &amp;&amp; . /etc/bashrcfi export PATH=/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin:$PATH cd进入到Test.app所在目录，然后执行macdeployqt extractor.app -verbose=1 -dmg，即可生成Test.dmg包。]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>QT</tag>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mpeg编码seekto方法精确定位到指定帧]]></title>
    <url>%2F2017%2F06%2F18%2Ftips-seekto%2F</url>
    <content type="text"><![CDATA[MediaExtractor有一个方法如下: 12//All selected tracks seek near the requested time according to the specified mode.public void seekTo (long timeUs, int mode) timeUs是要seek的时间戳，mode是seek的模式，可以是SEEK_TO_PREVIOUS_SYNC, SEEK_TO_CLOSEST_SYNC, SEEK_TO_NEXT_SYNC，分别是seek指定帧的上一帧，最近帧和下一帧。 此方法可用于视频播放时动态定位播放帧，用于动态改变视频播放进度，比如使用seekBar来跟踪视频播放进度，同时可拖动来动态改变播放进度。 mpeg编码决定seekTo方法无法精确定位到指定帧。即使使用的是某一帧精确的时间戳作为seekTo方法的输入参数也无法实现精确定位。 在google, stackoverlfow查询得出的结论是：在每次seekTo方法调用后，MediaCodec必须从关键帧开始解码。因此seekTo方法只会seek到最近的／上一个／下一个关键帧，也就是I-Frame(key frame = I frame = sync frame)。之所以要从关键帧开始解码，是因为每一帧不一定是单独编码的，只有I frame才是帧内编码，而P, B frame都是要参考别的帧来进行编码，因此单独拿出来是不完整的一帧。 stackoverflow上有人对此的做法是：seekTo的输入参数mode设置为SEEK_TO_PREVIOUS_SYNC,即seek的是指定帧的上一个关键帧。然后判断当前的时间戳是否小于定位关键帧的时间戳，如果是就调用MediaExtractor的advance方法，“快进”到指定帧。 1234extractor.seekTo(expectedPts, MediaExtractor.SEEK_TO_PREVIOUS_SYNC); while (currentPts &lt; expectedPts) &#123; extractor.advance(); &#125; 但是这个方法仍不理想，如果seek的位置和当前位置比较远的话，会有一定延迟。而且视频内容偶尔会出现不完整的帧的闪现。 经过一段时间的研究，终于解决了这个问题，现在播放时可以根据seekBar随时拖动到视频任何一帧，不会有任何延迟，甚至可以实现倒播了。 因为之前播放视频的是自己用MediaCodec, MediaMuxer等编码合成的视频文件，在编码参数设置的时候，将关键帧间隔KEY_I_FRAME_INTERVAL设置为了1（因为要求参数为整数）。注意这个参数的单位是秒，而不是帧数！网上看到很多例子包括fadden的bigflake和Grafika上都将这里设置为了20几。搞得我一开始还以为是每隔二十几帧就有一个关键帧。如果设置为20几，那么就是说你用MediaCodec编码录制一段20多秒的视频，只有开头的一个关键帧！剩下的都是P或者B帧。 这显然是不合理的。一般来说是每隔1秒有一个关键帧，这样就可以seek到对应秒的关键帧。或者说1秒内如果有30帧，那么这30帧至少有一个关键帧。因此我将KEY_I_FRAME_INTERVAL设置为了1。 1mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 1); 这也是为什么我在播放用这种参数编码的视频的时候，使用seekTo方法不能准确定位帧了。之前有讲，seekTo是定位到关键帧的，如果不是关键帧，那么它会去找上一个／最近一个／下一个关键帧，这取决于你输入参数mode的设置。 因此如果想使用seekBar准确拖动定位到任何一帧播放，必须保证每一帧都是关键帧。 于是，我将KEY_I_FRAME_INTERVAL设置为了0： 1mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 0); 事实也证明这样可以保证录制的每一帧都是关键帧，因此在使用seekTo方法的时候终于可以准确定位任何一帧了。拖动seekBar的时候视频内容也会立刻改变，无论是往前还是往后，都不会有任何延迟和画面不完整的情况. 但是，把视频每一帧都设置为关键帧是否合理呢？是否会占太大空间呢？ 带着这个疑问，我使用ffmpeg查看了我测试使用的手机（Lenovo X2)内置相机录制的视频。 只需一行代码： 1ffprobe -show_frames video.mp4 &gt; frames.txt 打开frames.txt可以看到每一帧的key_frame=1，表示是关键帧 这说明了手机本来录像就是把每一帧都作为关键帧的。 当然，不能以偏概全，于是我使用iPhone 6s录制的一段普通视频和慢动作视频。使用ffmpeg查看，发现每一帧也都是关键帧（慢动作视频1秒有240帧也都全部作为关键帧也是蛮拼的）。 目前我测试的两部手机都是如此，具体为什么手机录的视频每一帧都是关键帧我也不明白。而视频文件体积大小和是否将每一帧设为关键帧似乎不成线性关系，所以将KEY_I_FRAME_INTERVAL设置为0的方案是可行的。 因此只要保证视频每帧都是关键帧，那么seekTo方法就可以精确定位指定帧了。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>多媒体</tag>
        <tag>Mpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多媒体技术简介]]></title>
    <url>%2F2017%2F06%2F07%2Fmedia-intro%2F</url>
    <content type="text"><![CDATA[关键帧间隔关键帧包含了显示帧需要的所有信息 所有的视频都至少包含一个关键帧，作为文件的第一个帧。其它的关键帧可用来改善视频的质量，不过它们也会增加文件大小。一般而言，每一秒视频至少需要使用 1 个关键帧。若使用此公式，在每秒播放 25个帧的视频中，每 25 个帧就会有 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。 两种彩电视频制式： NTSC (525 lines @ 59.94 Hz) 29.97 fps PAL (625 lines @ 50 Hz) 25 fps NTSC和PAL属于全球两大主要的电视广播制式，但是由于系统投射颜色影像的频率而有所不同。NTSC是National Television System Committee的缩写，其标准主要应用于日本、美国，加拿大、墨西哥等等，PAL 则是Phase Alternating Line的缩写，主要应用于中国，香港、中东地区和欧洲一带。 GOP最大可含帧数目：18 (NTSC) / 15 (PAL) GOP是由固定模式的一系列I帧、P帧、B帧组成。 I帧编码是为了减少空间域冗余，P帧和B帧是为了减少时间域冗余。 常用的结构由15个帧组成，具有以下形式IBBPBBPBBPBBPBB。简称GOP(4,2)，指的是该图像组除了一个I帧外，包含了4个P帧，并且任何两个P帧或者I、P之间都有两个B帧。 GOP（Group of Pictures）策略影响编码质量：所谓GOP，意思是画面组，一个GOP就是一组连续的画面。MPEG编码将画面（即帧）分为I、P、B三种，I是内部编码帧，P是前向预测帧，B是双向内插帧。简单地讲，I帧是一个完整的画面，而P帧和B帧记录的是相对于I帧的变化。没有I帧，P帧和B帧就无法解码，这就是MPEG格式难以精确剪辑的原因，也是我们之所以要微调头和尾的原因。 MPEG-2 帧结构 MPEG-2压缩的帧结构有两个参数，一个是GOP（Group Of Picture）图像组的长度，一般可按编码方式从1－15；另一个是I帧和P帧之间B帧的数量，一般是1－2个。前者在理论上记录为N，即多少帧里面出现一次I帧；后者描述为多少帧里出现一次P帧，记录为M。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jni介绍]]></title>
    <url>%2F2017%2F06%2F07%2Fjni-intro%2F</url>
    <content type="text"><![CDATA[NDK技巧 加快ndk-build编译速度 NDK编译时加上-j参数,如:1ndk-build -j4 # -j4,让make最多允许4个编译命令同时执行 测试后编译速度至少可以提高一倍 native崩溃分析定位crash错误位置首先我们要先把Logcat里的show only selected application选项改成No Filters, 这时就能看到系统打印出的DEBUG信息. 在DEBUG信息里找到backtrace, 这段就是系统给出的造成崩溃的信息, 但仅仅给出了是哪个函数, 而没有准确给出是那一行代码造成的崩溃. 记下#00 pc 00013122(红框3)这个信息, 这个信息就是用来定位崩溃代码的地址 123456789101112131415161718192021222312-27 10:45:41.580 6189-6761/com.wodekouwei.demo E/HwDecodeWrapper: dequeueOutputBuffer = -112-27 10:45:41.580 6189-6761/com.wodekouwei.demo E/mediacodec: [oar_mediacodec_receive_frame():266]outbufidx:-112-27 10:45:41.590 6189-6761/com.wodekouwei.demo E/HwDecodeWrapper: dequeueOutputBuffer = -112-27 10:45:41.590 6189-6761/com.wodekouwei.demo E/mediacodec: [oar_mediacodec_receive_frame():266]outbufidx:-112-27 10:45:41.595 4901-4901/? I/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***12-27 10:45:41.595 4901-4901/? I/DEBUG: Build fingerprint: &apos;Huawei/H60-L03/hwH60:5.1.1/HDH60-L03/C01B535:user/release-keys&apos;12-27 10:45:41.595 4901-4901/? I/DEBUG: Revision: &apos;0&apos;12-27 10:45:41.595 4901-4901/? I/DEBUG: ABI: &apos;arm&apos;12-27 10:45:41.595 4901-4901/? I/DEBUG: pid: 6189, tid: 6762, name: Thread-4510 &gt;&gt;&gt; com.wodekouwei.demo &lt;&lt;&lt;12-27 10:45:41.595 4901-4901/? I/DEBUG: signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0x428d738d12-27 10:45:41.610 4901-4901/? I/DEBUG: r0 428d737d r1 b86eae00 r2 00000001 r3 0000000012-27 10:45:41.610 4901-4901/? I/DEBUG: r4 b8836580 r5 b88365c0 r6 b8836580 r7 9e4e0d4812-27 10:45:41.610 4901-4901/? I/DEBUG: r8 b8836588 r9 b8836588 sl b6da8871 fp 9e4e0dd012-27 10:45:41.610 4901-4901/? I/DEBUG: ip a1ca2c90 sp 9e4e0cc0 lr a1c358c7 pc a1c35b4c cpsr 200f003012-27 10:45:41.610 4901-4901/? I/DEBUG: backtrace:12-27 10:45:41.610 4901-4901/? I/DEBUG: #00 pc 000ccb4c /data/app/com.wodekouwei.demo-1/lib/arm/liboarp-lib.so12-27 10:45:41.610 4901-4901/? I/DEBUG: #01 pc 000cc8c3 /data/app/com.wodekouwei.demo-1/lib/arm/liboarp-lib.so (oar_player_gl_thread+214)12-27 10:45:41.610 4901-4901/? I/DEBUG: #02 pc 0001688f /system/lib/libc.so (__pthread_start(void*)+30)12-27 10:45:41.610 4901-4901/? I/DEBUG: #03 pc 000148a3 /system/lib/libc.so (__start_thread+6)12-27 10:45:42.005 3655-3655/? E/Thermal-daemon: [ap] temp_new :34 temp_old :3312-27 10:45:42.385 5083-5397/? E/WifiStateMachine: ConnectedState !CMD_RSSI_POLL 16 0 &quot;wonxing-H3C&quot; 3c:8c:40:e1:dd:b1 rssi=-50 f=2437 sc=100 link=72 tx=5.5, 0.0, 0.0 rx=1.0 bcn=0 [on:0 tx:0 rx:0 period:3001] from screen [on:0 period:-1780713098] gl hn u24 rssi=-45 ag=0 hr ticks 0,1,56 ls-=0 [56,56,60,60,65] brc=0 lrc=012-27 10:45:42.385 5083-5397/? E/WifiStateMachine: L2ConnectedState !CMD_RSSI_POLL 16 0 &quot;wonxing-H3C&quot; 3c:8c:40:e1:dd:b1 rssi=-50 f=2437 sc=100 link=72 tx=5.5, 0.0, 0.0 rx=1.0 bcn=0 [on:0 tx:0 rx:0 period:1] from screen [on:0 period:-1780713097] gl hn u24 rssi=-45 ag=0 hr ticks 0,1,56 ls-=0 [56,56,60,60,65] brc=0 lrc=012-27 10:45:42.390 5083-5397/? E/WifiStateMachine: fetchRssiLinkSpeedAndFrequencyNative rssi=-49 linkspeed=26 SSID=&quot;wonxing-H3C&quot; 想要准确定位崩溃代码的地址的话我们就需要用到ndk工具包里的adrr2line这个工具了 首先先找到这个工具, linux系统这个工具在如下位置 1/home/gavinandre/Documents/Android/android-sdk-linux/ndk-bundle/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/bin/arm-linux-androideabi-addr2line 在该目录下做个软链接后就能在任何目录使用这个命令了 1sudo ln -s arm-linux-androideabi-addr2line /usr/local/bin/addr2line 找到造成崩溃的so文件地址, 在app目录下搜索so文件 1234567find . -name &quot;liboarp-lib.so&quot; ✘./app/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/liboarp-lib.so./app/build/intermediates/transforms/stripDebugSymbol/debug/0/lib/armeabi-v7a/liboarp-lib.so./srsrtmpplayer/build/intermediates/cmake/debug/obj/armeabi-v7a/liboarp-lib.so./srsrtmpplayer/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/liboarp-lib.so./srsrtmpplayer/build/intermediates/transforms/stripDebugSymbol/debug/0/lib/armeabi-v7a/liboarp-lib.so./srsrtmpplayer/build/intermediates/intermediate-jars/debug/jni/armeabi-v7a/liboarp-lib.so 可以看到android studio编译后生成了许多so文件, 以我的经验正确的so文件一般是这个文件:./srsrtmpplayer/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/liboarp-lib.so 然后就可以使用addrline命令了, 格式是addr2line -e 文件位置 崩溃地址: 1addr2line -e ./srsrtmpplayer/build/intermediates/transforms/mergeJniLibs/debug/0/lib/armeabi-v7a/liboarp-lib.so 000ccb4c 如果so文件正确的话会打印如下信息,oar_player_gl_thread.c就是崩溃的cpp文件, 152, 然后检查下定位出来的位置是否在DEBUG信息里给出的函数里 1oar_player_gl_thread.c:152 如果so文件错误的话会打印问号或者一个不对的位置, 这时就要换so文件多尝试了 C回调JAVA c中返回一个字符串 1（*env）-&gt;NewStringUTF(env,&quot;Huazi 华仔&quot;); c中返回一个数组 12345678910..................... int i = 0; jintArray array; array =(*env)-&gt;NewIntArray(env,8); for(;i&lt;8;i++) // 赋值成 0 ~ 7 (*env)-&gt;SetObjectArrayElement(env,array,i,i); &#125; return array; c中使用调用传入的参数是数组array 是传入的数组 123456789......... int sum =0, i; int len = (*env)-&gt;GetArrayLength(env,array); jint *element =(*env)-&gt;GetIntArrayElement(env,array,0); for(i=0;i&lt;len;i++) &#123; sum+= *(element+i); &#125; return sum; c中调用java中类的方法 没有参数 只有返回值String 1234567//()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型 JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123; jmethodID mid; jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名 mid =(*env)-&gt;GetMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);//TestMethod java中的方法名 jstring msg =(*env)-&gt;CallObjectMethod(env,object,mid); //object 注意下是jni传过来的jobject return msg; c中调用java中类的静态方法 没有参数 只有返回值String 12345678//@&quot;()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123; jmethodID mid; jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名 mid =(*env)-&gt;GeStatictMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);// TestMethod java中的方法名 jstring msg =(*env)-&gt;CallStaticObjectMethod(env,cls,mid); //object 注意下是jni传过来的jobject return msg; &#125;]]></content>
      <tags>
        <tag>Android</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG编译之Mac]]></title>
    <url>%2F2017%2F06%2F07%2Fffmpeg-compile-mac%2F</url>
    <content type="text"><![CDATA[Mac下FFMPEG使用There are a few ways to get FFmpeg on OS X. One is to build it yourself. Compiling on Mac OS X is as easy as any other *nix machine, there are just a few caveats(警告). The general procedure is get the source, then ./configure ; make &amp;&amp; sudo make install, though specific configure flags are possible. Another is to use some “build helper” tool, to install it for you. For example, homebrew or macports, see the homebrew section in this document. Alternatively, if you are unable to compile, or do not want to install homebrew, you can simply download a static build for OS X, but it may not contain the features you want. Typically this involves unzipping an FFmpeg distribution file [like .zip file], then running it from within the newly extracted files/directories. 手动编译FFMPEG1.下载FFMPEG源码使用git clone https://github.com/FFmpeg/FFmpeg从github下载ffmpeg源码,切换到要使用的目标分支(这里使用release/3.3):git checkout -b r3.3 origin/release/3.3,或者直接从github下载分支release/3.3的压缩包,解压. 2.准备XcodeStarting with Lion 10.7, Xcode is available for free from the Mac App Store and is required to compile anything on your Mac. Make sure you install the Command Line Tools from Preferences &gt; Downloads &gt; Components. Older versions are still available with an AppleID and free Developer account at ​developer.apple.com. 3.准备HomeBrew工具To get ffmpeg for OS X, you first have to install ​Homebrew. If you don’t want to use Homebrew, see the section below. 1ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Then: 12brew install automake fdk-aac git lame libass libtool libvorbis libvpx \opus sdl shtool texi2html theora wget x264 x265 xvid yasm Mac OS X Lion comes with Freetype already installed (older versions may need ‘X11’ selected during installation), but in an atypical location: /usr/X11. Running freetype-config in Terminal can give the locations of the individual folders, like headers, and libraries, so be prepared to add lines like CFLAGS=freetype-config --cflags LDFLAGS=freetype-config --libs PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig:/usr/lib/pkgconfig:/usr/X11/lib/pkgconfig before ./configure or add them to your $HOME/.profile file. 4.编译Once you have compiled all of the codecs/libraries you want, you can now download the FFmpeg source either with Git or the from release tarball links on the website. Study the output of ./configure –help and make sure you’ve enabled all the features you want, remembering that –enable-nonfree and –enable-gpl will be necessary for some of the dependencies above. A sample command is: 123456git clone http://source.ffmpeg.org/git/ffmpeg.git ffmpegcd ffmpeg./configure --prefix=/usr/local/ffmpeg --enable-gpl --enable-nonfree --enable-libass \--enable-libfdk-aac --enable-libfreetype --enable-libmp3lame \--enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libopus --enable-libxvidmake &amp;&amp; sudo make install --prefix指定编译完成后安装路径,这里指定到/usr/local/ffmpeg,安装完成会在/usr/local/ffmpeg下生成:bin,include,lib,share四个目录 安装环境介绍A package consists of several related files which are installed in several directories. The configure step usually allows the user to specify the so-called install prefix, and is usually specified through the configure option configure –prefix=PREFIX, where PREFIX usually is by default /usr/local. The prefix specifies the common directory where all the components are installed. The following directories are usually involved in the installation: PREFIX/bin: contains the generated binaries (e.g. ffmpeg, ffplay, ffprobe etc. in the case of FFmpeg) PREFIX/include: contains the library headers (e.g. libavutil/avstring.h, libavcodec/avcodec.h, libavformat/avformat.h etc. in case of FFmpeg) required to compile applications linked against the package libraries PREFIX/lib: contains the generated libraries (e.g. libavutil, libavcodec, libavformat etc. in the case of FFmpeg) PREFIX/share: contains various system-independent components; especially documentation files and examples By specifying the prefix it is possible to define the installation layout. By using a shared prefix like /usr/local/, different packages will be installed in the same directory, so in general it will be more difficult to revert the installation. Using a prefix like /opt/PROJECT/, the project will be installed in a dedicated directory, and to remove from the system you can simply remove the /opt/PREFIX path. On the other hand, such installation will require to edit all the environment variables to point to the custom path. Environment variablesSeveral variables defined in the environment affect your package install. In particular, depending on your installation prefix, you may need to update some of these variables in order to make sure that the installed components can be found by the system tools. The list of environment variables can be shown through the command env. A list of the affected variables follows: PATH: defines the list of :-separated paths where the system looks for binaries. For example if you install your package in /usr/local/, you should update the PATH so that it will contain /usr/local/bin. This can be done for example through the command export PATH=/usr/local/bin:$PATH. LD_LIBRARY_PATH: contains the :-separated paths where the system looks for libraries. For example if you install your package in /usr/local/, you should update the LD_LIBRARY_PATH so that it will contain /usr/local/lib. This can be done for example through the command export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH. This variable is sometimes deprecated in favor of the use of ldconfig. CFLAGS: contains flags used by the C compiler, and usually includes preprocessing directives like -IPREFIX/include or compilation flags. Custom CFLAGS are usually prefixed to the source package compiler flags by the source package build system. Alternatively many build systems allow to specify the configure option -extra-cflags. LDFLAGS: these are directives used by the linker, and usually include linking directives like -LPREFIX/lib needed to find libraries installed in custom paths. Custom LDFLAGS are usually prefixed to the source package linker flags by the source package build system. Alternatively, many build systems allow to specify the configure option -extra-ldflags. PKG_CONFIG_PATH: contains the :-separated paths used by pkg-config to detect the pkg-config files used by many build systems to detect the custom CFLAGS/LDFLAGS used by a specific library. In case you installed a package in a non standard path, you need to update these environment libraries so that system tools will be able to detect the package components. This is especially required when running a configure script for a package relying on other installed libraries/headers/tools. Environment variables are usually defined in the profile file, for example .profile defined in the user directory for sh/bash users, and in /etc/profile. This file can be edited to permanently set the custom environment. Alternatively, the variables can be set in a script or in a particular shell session. Remember to export the variables to the child process, e.g. using the export command. Read the fine documentation of your shell for more detailed information. MAC下的动态链接库扩展名Windows下.DLL,Linux下.so,Mac OS X下的扩展名是.dylib。 .dylib是Mach-O格式，也就是Mac OS X下的二进制文件格式。Mac OS X提供了一系列 工具，用于创建和访问动态链接库。 编译器/usr/bin/cc，也就是gcc了，Apple改过的。这个主要还是一个壳，去调用其他 的一些部件。当然同时还有/usr/bin/c++，等等。 汇编器/usr/bin/as 链接器/usr/bin/ld MAC下创建动态链接库步骤: 首先是生成module文件，也就是.o文件。这跟一般的unix没什么区别。例如cc -c a.c b.c,就得到a.o和b.o 可以用ld来合并.o文件，比如ld -r -o c.o a.o b.o 然后可以用libtool来创建动态链接库:libtool -dynamic -o c.dylib a.o b.o.（ 这里也可以用libtool -static -o c.a a.o b.o就创建静态库） 如果用gcc直接编译，我记得linux下一般是可以: gcc -shared -o c.so a.c b.c 而在Mac OS X下需要: gcc -dynamiclib -o c.dylib a.c b.c 动态链接库的工具nm是最常用的，这个用法跟linux下差不多:nm c.dylib,可以看到导出符号表，等等。 另一个常用的工具是otool，这个是Mac OS X独有的。比如想看看c.dylib的依赖关系otool -L c.dylib 官网方法 CompilationGuide-Generic CompilationGuide-MacOSX 编译ffmpeg3.3结果没有ffplay因为系统没有sdl环境或sdl版本不匹配,ffmpeg3.3需要sdl2 http://www.libsdl.org/download-2.0.php 下载Source Code SDL2-2.0.5.zip - GPG signed,解压缩,执行命令: 123./configure make sudo make install 进行编译]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL Frame Buffer Object(FBO)]]></title>
    <url>%2F2017%2F06%2F03%2Fgl-fbo%2F</url>
    <content type="text"><![CDATA[Update: Framebuffer object extension is promoted as a core feature of OpenGL version 3.0, and is approved by ARB combining the following extensions; EXT_framebuffer_object EXT_framebuffer_blit EXT_framebuffer_multisample EXT_packed_depth_stencil OverviewIn OpenGL rendering pipeline, the geometry data and textures are transformed and passed several tests, and then finally rendered onto a screen as 2D pixels. The final rendering destination of the OpenGL pipeline is called framebuffer. Framebuffer is a collection of 2D arrays or storages utilized by OpenGL; colour buffers, depth buffer, stencil buffer and accumulation buffer. By default, OpenGL uses the framebuffer as a rendering destination that is created and managed entirely by the window system. This default framebuffer is called window-system-provided framebuffer. 在OpenGL渲染管线中，几何数据和纹理经过多次转化和多次测试，最后以二维像素的形式显示在屏幕上。OpenGL管线的最终渲染目的地被称作帧缓存（framebuffer）。帧缓冲是一些二维数组和OpenG所使用的存储区的集合：颜色缓存、深度缓存、模板缓存和累计缓存。一般情况下，帧缓存完全由window系统生成和管理，由OpenGL使用。这个默认的帧缓存被称作“window系统生成”（window-system-provided）的帧缓存。 The OpenGL extension, GL_ARB_framebuffer_object provides an interface to create additional non-displayable framebuffer objects (FBO). This framebuffer is called application-created framebuffer in order to distinguish from the default window-system-provided framebuffer. By using framebuffer object (FBO), an OpenGL application can redirect the rendering output to the application-created framebuffer object (FBO) other than the traditional window-system-provided framebuffer. And, it is fully controlled by OpenGL. 在OpenGL扩展中，GL_EXT_framebuffer_object提供了一种创建额外的不能显示的帧缓存对象的接口。为了和默认的“window系统生成”的帧缓存区别，这种帧缓冲成为应用程序帧缓存（application-createdframebuffer）。通过使用帧缓存对象（FBO），OpenGL可以将显示输出到引用程序帧缓存对象，而不是传统的“window系统生成”帧缓存。而且，它完全受OpenGL控制。 Similar to window-system-provided framebuffer, a FBO contains a collection of rendering destinations; color, depth and stencil buffer. (Note that accumulation buffer is not defined in FBO.) These logical buffers in a FBO are called framebuffer-attachable images, which are 2D arrays of pixels that can be attached to a framebuffer object. 相似于window系统提供的帧缓存，一个FBO也包含一些存储颜色、深度和模板数据的区域。（注意：没有累积缓存）我们把FBO中这些逻辑缓存称之为“帧缓存关联图像”，它们是一些能够和一个帧缓存对象关联起来的二维数组像素。 There are two types of framebuffer-attachable images; texture images and renderbuffer images. If an image of a texture object is attached to a framebuffer, OpenGL performs “render to texture”. And if an image of a renderbuffer object is attached to a framebuffer, then OpenGL performs “offscreen rendering”. 有两种类型的“帧缓存关联图像”：纹理图像（texture images）和渲染缓存图像（renderbuffer images）。如果纹理对象的图像数据关联到帧缓存，OpenGL执行的是“渲染到纹理”（render to texture）操作。如果渲染缓存的图像数据关联到帧缓存，OpenGL执行的是离线渲染（offscreen rendering）。 By the way, renderbuffer object is a new type of storage object defined in GL_ARB_framebuffer_object extension. It is used as a rendering destination for a single 2D image during rendering process. 这里要提到的是，渲染缓存对象是在GL_EXT_framebuffer_object扩展中定义的一种新的存储类型。在渲染过程中它被用作存储单幅二维图像。 The following diagram shows the connectivity among the framebuffer object, texture object and renderbuffer object. Multiple texture objects or renderbuffer objects can be attached to a framebuffer object through the attachment points. 下面这幅图显示了帧缓存对象、纹理对象和渲染缓存对象之间的联系。多多个纹理对象或者渲染缓存对象能够通过关联点关联到一个帧缓存对象上。 There are multiple color attachment points (GL_COLOR_ATTACHMENT0,…, GL_COLOR_ATTACHMENTn), one depth attachment point (GL_DEPTH_ATTACHMENT), and one stencil attachment point (GL_STENCIL_ATTACHMENT) in a framebuffer object. The number of color attachment points is implementation dependent, but each FBO must have at least one color attachement point. You can query the maximum number of color attachement points with GL_MAX_COLOR_ATTACHMENTS, which are supported by a graphics card. The reason that a FBO has multiple color attachement points is to allow to render the color buffer to multiple destinations at the same time. This “multiple render targets” (MRT) can be accomplished by GL_ARB_draw_buffers extension. Notice that the framebuffer object itself does not have any image storage(array) in it, but, it has only multiple attachment points. 在一个帧缓存对象中有多个颜色关联点（GL_COLOR_ATTACHMENT0_EXT,…,GL_COLOR_ATTACHMENTn_EXT），一个深度关联点（GL_DEPTH_ATTACHMENT_EXT），和一个模板关联点（GL_STENCIL_ATTACHMENT_EXT）。每个FBO中至少有一个颜色关联点，其数目与实体显卡相关。可以通过GL_MAX_COLOR_ATTACHMENTS_EXT来查询颜色关联点的最大数目。FBO有多个颜色关联点的原因是这样可以同时将颜色而换成渲染到多个FBO关联区。这种“多渲染目标”（multiple rendertargets,MRT）可以通过GL_ARB_draw_buffers扩展实现。需要注意的是：FBO本身并没有任何图像存储区，只有多个关联点。 Framebuffer object (FBO) provides an efficient switching mechanism; detach the previous framebuffer-attachable image from a FBO, and attach a new framebuffer-attachable image to the FBO. Switching framebuffer-attachable images is much faster than switching between FBOs. FBO provides glFramebufferTexture2D() to switch 2D texture objects, and glFramebufferRenderbuffer() to switch renderbuffer objects. FBO提供了一种高效的切换机制；将前面的帧缓存关联图像从FBO分离，然后把新的帧缓存关联图像关联到FBO。在帧缓存关联图像之间切换比在FBO之间切换要快得多。FBO提供了glFramebufferTexture2DEXT()来切换2D纹理对象和glFramebufferRenderbufferEXT()来切换渲染缓存对象。 Creating Frame Buffer Object (FBO)Creating framebuffer objects is similar to generating vertex buffer objects (VBO). 创建FBO和产生VBO类似。 12void glGenFramebuffers(GLsizei n, GLuint* ids)void glDeleteFramebuffers(GLsizei n, const GLuint* ids) glGenFramebuffers() requires 2 parameters; the first one is the number of framebuffers to create, and the second parameter is the pointer to a GLuint variable or an array to store a single ID or multiple IDs. It returns the IDs of unused framebuffer objects. ID 0 means the default framebuffer, which is the window-system-provided framebuffer. glGenFramebuffersEXT()需要两个参数：第一个是要创建的帧缓存的数目，第二个是指向存储一个或者多个ID的变量或数组的指针。它返回未使用的FBO的ID。ID为0表示默认帧缓存，即window系统提供的帧缓存。 And, FBO may be deleted by calling glDeleteFramebuffers() when it is not used anymore. 当FBO不再被使用时，FBO可以通过调用glDeleteFrameBuffersEXT()来删除。 1glBindFramebuffer() Once a FBO is created, it has to be bound before using it. 一旦一个FBO被创建，在使用它之前必须绑定。 1void glBindFramebuffer(GLenum target, GLuint id) The first parameter, target, should be GL_FRAMEBUFFER, and the second parameter is the ID of a framebuffer object. Once a FBO is bound, all OpenGL operations affect onto the current bound framebuffer object. The object ID 0 is reserved for the default window-system provided framebuffer. Therefore, in order to unbind the current framebuffer (FBO), use ID 0 in glBindFramebuffer(). 第一个参数target应该是GL_FRAMEBUFFER_EXT，第二个参数是FBO的ID号。一旦FBO被绑定，之后的所有的OpenGL操作都会对当前所绑定的FBO造成影响。ID号为0表示缺省帧缓存，即默认的window提供的帧缓存。因此，在glBindFramebufferEXT()中将ID号设置为0可以解绑定当前FBO。 Renderbuffer ObjectIn addition, renderbuffer object is newly introduced for offscreen rendering. It allows to render a scene directly to a renderbuffer object, instead of rendering to a texture object. Renderbuffer is simply a data storage object containing a single image of a renderable internal format. It is used to store OpenGL logical buffers that do not have corresponding texture format, such as stencil or depth buffer. 另外，渲染缓存是为离线渲染而新引进的。它允许将一个场景直接渲染到一个渲染缓存对象中，而不是渲染到纹理对象中。渲染缓存对象是用于存储单幅图像的数据存储区域。该图像按照一种可渲染的内部格式存储。它用于存储没有相关纹理格式的OpenGL逻辑缓存，比如模板缓存或者深度缓存。 glGenRenderbuffers()12void glGenRenderbuffers(GLsizei n, GLuint* ids)void glDeleteRenderbuffers(GLsizei n, const Gluint* ids) Once a renderbuffer is created, it returns non-zero positive integer. ID 0 is reserved for OpenGL. 一旦一个渲染缓存被创建，它返回一个非零的正整数。ID为0是OpenGL保留值。 glBindRenderbuffer()1void glBindRenderbuffer(GLenum target, GLuint id) Same as other OpenGL objects, you have to bind the current renderbuffer object before referencing it. The target parameter should be GL_RENDERBUFFER for renderbuffer object. 和OpenGL中其他对象一样，在引用渲染缓存之前必须绑定当前渲染缓存对象。他target参数应该是GL_RENDERBUFFER_EXT。 glRenderbufferStorage()1234void glRenderbufferStorage(GLenum target, GLenum internalFormat, GLsizei width, GLsizei height) When a renderbuffer object is created, it does not have any data storage, so we have to allocate a memory space for it. This can be done by using glRenderbufferStorage(). The first parameter must be GL_RENDERBUFFER. The second parameter would be color-renderable (GL_RGB, GL_RGBA, etc.), depth-renderable (GL_DEPTH_COMPONENT), or stencil-renderable formats (GL_STENCIL_INDEX). The width and height are the dimension of the renderbuffer image in pixels. 当一个渲染缓存被创建，它没有任何数据存储区域，所以我们还要为他分配空间。这可以通过用glRenderbufferStorageEXT()实现。第一个参数必须是GL_RENDERBUFFER_EXT。第二个参数可以是用于颜色的（GL_RGB，GL_RGBA，etc.），用于深度的（GL_DEPTH_COMPONENT），或者是用于模板的格式（GL_STENCIL_INDEX）。Width和height是渲染缓存图像的像素维度。 The width and height should be less than GL_MAX_RENDERBUFFER_SIZE, otherwise, it generates GL_INVALID_VALUE error. width和height必须比GL_MAX_RENDERBUFFER_SIZE_EXT小，否则将会产生GL_UNVALID_VALUE错误。 glGetRenderbufferParameteriv()123void glGetRenderbufferParameteriv(GLenum target, GLenum param, GLint* value) You also get various parameters of the currently bound renderbuffer object. target should be GL_RENDERBUFFER, and the second parameter is the name of parameter. The last is the pointer to an integer variable to store the returned value. The available names of the renderbuffer parameters are; 我们也可以得到当前绑定的渲染缓存对象的一些参数。Target应该是GL_RENDERBUFFER_EXT，第二个参数是所要得到的参数名字。最后一个是指向存储返回值的整型量的指针。渲染缓存的变量名有如下: 12345678910GL_RENDERBUFFER_WIDTHGL_RENDERBUFFER_HEIGHTGL_RENDERBUFFER_INTERNAL_FORMATGL_RENDERBUFFER_RED_SIZEGL_RENDERBUFFER_GREEN_SIZEGL_RENDERBUFFER_BLUE_SIZEGL_RENDERBUFFER_ALPHA_SIZEGL_RENDERBUFFER_DEPTH_SIZEGL_RENDERBUFFER_STENCIL_SIZE Attaching images to FBOFBO itself does not have any image storage(buffer) in it. Instead, we must attach framebuffer-attachable images (texture or renderbuffer objects) to the FBO. This mechanism allows that FBO quickly switch (detach and attach) the framebuffer-attachable images in a FBO. It is much faster to switch framebuffer-attachable images than to switch between FBOs. And, it saves unnecessary data copies and memory consumption. For example, a texture can be attached to multiple FBOs, and its image storage can be shared by multiple FBOs. FBO本身没有图像存储区。我们必须帧缓存关联图像（纹理或渲染对象）关联到FBO。这种机制允许FBO快速地切换（分离和关联）帧缓存关联图像。切换帧缓存关联图像比在FBO之间切换要快得多。而且，它节省了不必要的数据拷贝和内存消耗。比如，一个纹理可以被关联到多个FBO上，图像存储区可以被多个FBO共享。 Attaching a 2D texture image to FBO12345glFramebufferTexture2D(GLenum target, GLenum attachmentPoint, GLenum textureTarget, GLuint textureId, GLint level) glFramebufferTexture2D() is to attach a 2D texture image to a FBO. The first parameter must be GL_FRAMEBUFFER, and the second parameter is the attachment point where to connect the texture image. A FBO has multiple color attachment points (GL_COLOR_ATTACHMENT0, …, GL_COLOR_ATTACHMENTn), GL_DEPTH_ATTACHMENT, and GL_STENCIL_ATTACHMENT. The third parameter, “textureTarget” is GL_TEXTURE_2D in most cases. The fourth parameter is the identifier of the texture object. The last parameter is the mipmap level of the texture to be attached. glFramebufferTexture2DEXT()把一幅纹理图像关联到一个FBO。第一个参数一定是GL_FRAMEBUFFER_EXT，第二个参数是关联纹理图像的关联点。第三个参数textureTarget在多数情况下是GL_TEXTURE_2D。第四个参数是纹理对象的ID号。最后一个参数是要被关联的纹理的mipmap等级 If the textureId parameter is set to 0, then, the texture image will be detached from the FBO. If a texture object is deleted while it is still attached to a FBO, then, the texture image will be automatically detached from the currently bound FBO. However, if it is attached to multiple FBOs and deleted, then it will be detached from only the bound FBO, but will not be detached from any other un-bound FBOs. 如果参数textureId被设置为0，那么纹理图像将会被从FBO分离。如果纹理对象在依然关联在FBO上时被删除，那么纹理对象将会自动从当前帮的FBO上分离。然而，如果它被关联到多个FBO上然后被删除，那么它将只被从绑定的FBO上分离，而不会被从其他非绑定的FBO上分离。 Attaching a Renderbuffer image to FBO1234void glFramebufferRenderbuffer(GLenum target, GLenum attachmentPoint, GLenum renderbufferTarget, GLuint renderbufferId) A renderbuffer image can be attached by calling glFramebufferRenderbuffer(). The first and second parameters are same as glFramebufferTexture2D(). The third parameter must be GL_RENDERBUFFER, and the last parameter is the ID of the renderbuffer object. 通过调用glFramebufferRenderbufferEXT()可以关联渲染缓存图像。前两个参数和glFramebufferTexture2DEXT()一样。第三个参数只能是GL_RENDERBUFFER_EXT，最后一个参数是渲染缓存对象的ID号。 If renderbufferId parameter is set to 0, the renderbuffer image will be detached from the attachment point in the FBO. If a renderbuffer object is deleted while it is still attached in a FBO, then it will be automatically detached from the bound FBO. However, it will not be detached from any other non-bound FBOs. 如果参数renderbufferId被设置为0，渲染缓存图像将会从FBO的关联点分离。如果渲染缓存图像在依然关联在FBO上时被删除，那么纹理对象将会自动从当前绑定的FBO上分离，而不会从其他非绑定的FBO上分离。 FBO with MSAA (Multi Sample Anti Aliasing)When you render to a FBO, anti-aliasing is not automatically enabled even if you properly create a OpenGL rendering context with the multisampling attribute (SAMPLEBUFFERS_ARB) for window-system-provided framebuffer. In order to activate multisample anti-aliasing mode for rendering to a FBO, you need to prepare and attach multisample images to a FBO’s color and/or depth attachement points. FBO extension provides glRenderbufferStorageMultisample() to create a renderbuffer image for multisample anti-aliasing rendering mode. 12345void glRenderbufferStorageMultisample(GLenum target, GLsizei samples, GLenum internalFormat, GLsizei width, GLsizei height) It adds new parameter, samples on top of glRenderbufferStorage(), which is the number of multisamples for anti-aliased rendering mode. If it is 0, then no MSAA mode is enabled and glRenderbufferStorage() is called instead. You can query the maximum number of samples with GL_MAX_SAMPLES token in glGetIntegerv(). The following code is to create a FBO with multisample colorbuffer and depthbuffer images. Note that if multiple images are attached to a FBO, then all images must have the same number of multisamples. Otherwise, the FBO status is incomplete. 12345678910111213141516171819202122232425262728293031323334// create a 4x MSAA renderbuffer object for colorbufferint msaa = 4;GLuint rboColorId;glGenRenderbuffers(1, &amp;rboColorId);glBindRenderbuffer(GL_RENDERBUFFER, rboColorId);glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_RGB8, width, height);// create a 4x MSAA renderbuffer object for depthbufferGLuint rboDepthId;glGenRenderbuffers(1, &amp;rboDepthId);glBindRenderbuffer(GL_RENDERBUFFER, rboDepthId);glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_DEPTH_COMPONENT, width, height);// create a 4x MSAA framebuffer objectGLuint fboId;glGenFramebuffers(1, &amp;fboMsaaId);glBindFramebuffer(GL_FRAMEBUFFER, fboMsaaId);// attach colorbuffer image to FBOglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_COLOR_ATTACHMENT0, // 2. color attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboColorId); // 4. rbo ID// attach depthbuffer image to FBOglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_DEPTH_ATTACHMENT, // 2. depth attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboDepthId); // 4. rbo ID// check FBO statusGLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);if(status != GL_FRAMEBUFFER_COMPLETE) fboUsed = false; It is important to know that glRenderbufferStorageMultisample() only enables MSAA rendering to FBO. However, you cannot directly use the result from MSAA FBO. If you need to transfer the result to a texture or other non-multisampled framebuffer, you have to convert (downsample) the result to single-sample image using glBlitFramebuffer(). 1234void glBlitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, // source rectangle GLint dstX0, GLint dstY0, GLint dstX1, GLint dstY1, // destination rect GLbitfield mask, GLenum filter) glBlitFramebuffer() copies a rectangle of images from the source (GL_READ_BUFFER) to the destination framebuffer (GL_DRAW_BUFFER). The “mask” parameter is to specify which buffers are copied, GL_COLOR_BUFFER_BIT, GL_DEPTH_BUFFER_BIT and/or GL_STENCIL_BUFFER_BIT. The last parameter, “filter” is to specify the interpolation mode if the source and destination rectangles are not same. It is either GL_NEAREST or GL_LINEAR. The following code is to transfer a multisampled image from a FBO to another non-multisampled FBO. Notice it requires an additional FBO to get the result of MSAA rendering. Please see fboMsaa.zip for details to perform render-to-texture with MSAA. 12345678910// copy rendered image from MSAA (multi-sample) to normal (single-sample)// NOTE: The multi samples at a pixel in read buffer will be converted// to a single sample at the target pixel in draw buffer.glBindFramebuffer(GL_READ_FRAMEBUFFER, fboMsaaId); // src FBO (multi-sample)glBindFramebuffer(GL_DRAW_FRAMEBUFFER, fboId); // dst FBO (single-sample)glBlitFramebuffer(0, 0, width, height, // src rect 0, 0, width, height, // dst rect GL_COLOR_BUFFER_BIT, // buffer mask GL_LINEAR); // scale filter Checking FBO StatusOnce attachable images (textures and renderbuffers) are attached to a FBO and before performing FBO operation, you must validate if the FBO status is complete or incomplete by using glCheckFramebufferStatus(). If the FBO is not complete, then any drawing and reading command (glBegin(), glCopyTexImage2D(), etc) will be failed. 一旦关联图像（纹理和渲染缓存）被关联到FBO上，在执行FBO的操作之前，你必须检查FBO的状态，这可以通过调用glCheckFramebufferStatusEXT()实现。如果这个FBObuilding完整，那么任何绘制和读取命令（glBegin(),glCopyTexImage2D(), etc）都会失败。 1GLenum glCheckFramebufferStatus(GLenum target) glCheckFramebufferStatus() validates all its attached images and framebuffer parameters on the currently bound FBO. And, this function cannot be called within glBegin()/glEnd() pair. The target parameter should be GL_FRAMEBUFFER. It returns non-zero value after checking the FBO. If all requirements and rules are satisfied, then it returns GL_FRAMEBUFFER_COMPLETE. Otherwise, it returns a relevant error value, which tells what rule is violated. glCheckFramebufferStatusEXT()检查当前帧缓存的关联图像和帧缓存参数。这个函数不能在glBegin()/glEnd()之间调用。Target参数必须为GL_FRAMEBUFFER_EXT。它返回一个非零值。如果所有要求和准则都满足，它返回GL_FRAMEBUFFER_COMPLETE_EXT。否则，返回一个相关错误代码告诉我们哪条准则没有满足。 The rules of FBO completeness are: The width and height of framebuffer-attachable image must be not zero. If an image is attached to a color attachment point, then the image must have a color-renderable internal format. (GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc) If an image is attached to GL_DEPTH_ATTACHMENT, then the image must have a depth-renderable internal format. (GL_DEPTH_COMPONENT, GL_DEPTH_COMPONENT24, etc) If an image is attached to GL_STENCIL_ATTACHMENT, then the image must have a stencil-renderable internal format. (GL_STENCIL_INDEX, GL_STENCIL_INDEX8, etc) FBO must have at least one image attached. All images attached a FBO must have the same width and height. All images attached the color attachment points must have the same internal format. FBO完整性准则有： 帧缓存关联图像的宽度和高度必须非零。 如果一幅图像被关联到一个颜色关联点，那么这幅图像必须有颜色可渲染的内部格式（GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc)。 如果一幅被图像关联到GL_DEPTH_ATTACHMENT_EXT，那么这幅图像必须有深度可渲染的内部格式(GL_DEPTH_COMPONENT,GL_DEPTH_COMPONENT24_EXT, etc)。 如果一幅被图像关联到GL_STENCIL_ATTACHMENT_EXT，那么这幅图像必须有模板可渲染的内部格式(GL_STENCIL_INDEX,GL_STENCIL_INDEX8_EXT, etc)。 FBO至少有一幅图像关联。 被关联到FBO的缩影图像必须有相同的宽度和高度。 被关联到颜色关联点上的所有图像必须有相同的内部格式。 Note that even though all of the above conditions are satisfied, your OpenGL driver may not support some combinations of internal formats and parameters. If a particular implementation is not supported by OpenGL driver, then glCheckFramebufferStatus() returns GL_FRAMEBUFFER_UNSUPPORTED. 注意：即使以上所有条件都满足，你的OpenGL驱动也可能不支持某些格式和参数的组合。如果一种特别的实现不被OpenGL驱动支持，那么glCheckFramebufferStatusEXT()返回GL_FRAMEBUFFER_UNSUPPORTED_EXT。 The sample code provides some utility functions to report the information of the current FBO; printFramebufferInfo() and checkFramebufferStatus(). Java Code Examples for javax.media.opengl.GL.GL_FRAMEBUFFER_COMPLETE_EXT GL_EXT_discard_framebufferOverviewThis extension provides a new command, DiscardFramebufferEXT, which causes the contents of the named framebuffer attachable images to become undefined. The contents of the specified buffers are undefined until a subsequent operation modifies the content, and only the modified region is guaranteed to hold valid content. Effective usage of this command may provide an implementation with new optimization opportunities. Some OpenGL ES implementations cache framebuffer images in a small pool of fast memory. Before rendering, these implementations must load the existing contents of one or more of the logical buffers (color, depth, stencil, etc.) into this memory. After rendering, some or all of these buffers are likewise stored back to external memory so their contents can be used again in the future. In many applications, some or all of the logical buffers are cleared at the start of rendering. If so, the effort to load or store those buffers is wasted. Even without this extension, if a frame of rendering begins with a full-screen Clear, an OpenGL ES implementation may optimize away the loading of framebuffer contents prior to rendering the frame. With this extension, an application can use DiscardFramebufferEXT to signal that framebuffer contents will no longer be needed. In this case an OpenGL ES implementation may also optimize away the storing back of framebuffer contents after rendering the frame. Issues1) Should DiscardFramebufferEXT’s argument be a list of COLOR_ATTACHMENTx enums, or should it use the same bitfield from Clear and BlitFramebuffer? RESOLVED: We’ll use a sized list of framebuffer attachments. This will give us some future-proofing for when MRTs and multisampled FBOs are supported. 2) What happens if the app discards only one of the depth and stencil attachments, but those are backed by the same packed_depth_stencil buffer? a) Generate an error b) Both images become undefined c) Neither image becomes undefined d) Only one of the images becomes undefined RESOLVED: (b) which sort of falls out of Issue 4. 3) How should DiscardFramebufferEXT interact with the default framebuffer? a) Generate an error b) Ignore the hint silently c) The contents of the specified attachments become undefined RESOLVED: (c), with appropriate wording to map FBO attachments to the corresponding default framebuffer’s logical buffers 4) What happens when you discard an attachment that doesn’t exist? This is the case where a framebuffer is complete but doesn’t have, for example, a stencil attachment, yet the app tries to discard the stencil attachment. a) Generate an error b) Ignore the hint silently RESOLVED: (b) for two reasons. First, this is just a hint anyway, and if we required error detection, then suddenly an implementation can’t trivially ignore it. Second, this is consistent with Clear, which ignores specified buffers that aren’t present. Example: Render To TextureSometimes, you need to generate dynamic textures on the fly. The most common examples are generating mirroring/reflection effects, dynamic cube/environment maps and shadow maps. Dynamic texturing can be accomplished by rendering the scene to a texture. A traditional way of render-to-texture is to draw a scene to the framebuffer as normal, and then copy the framebuffer image to a texture by using glCopyTexSubImage2D(). 有时候，你需要产生动态纹理。比较常见的例子是产生镜面反射效果、动态环境贴图和阴影等效果。动态纹理可以通过把场景渲染到纹理来实现。渲染到纹理的一种传统方式是将场景绘制到普通的帧缓存上，然后调用glCopyTexSubImage2D()拷贝帧缓存图像至纹理。 Using FBO, we can render a scene directly onto a texture, so we don’t have to use the window-system-provided framebuffer at all. Further more, we can eliminate an additional data copy (from framebuffer to texture). 使用FBO，我们能够将场景直接渲染到纹理，所以我们不必使用window系统提供的帧缓存。并且，我们能够去除额外的数据拷贝（从帧缓存到纹理）；。 This demo program performs render to texture operation with/without FBO, and compares the performance difference. Other than performance gain, there is another advantage of using FBO. If the texture resolution is larger than the size of the rendering window in traditional render-to-texture mode (without FBO), then the area out of the window region will be clipped. However, FBO does not suffer from this clipping problem. You can create a framebuffer-renderable image larger than the display window. 这个demo实现了使用FBO和不使用FBO两种情况下渲染到纹理的操作，并且比较了性能差异。除了能够获得性能上的提升，使用FBO的还有另外一个优点。在传统的渲染到纹理的模式中（不使用FBO），如果纹理分辨率比渲染窗口的尺寸大，超出窗口区域的部分将被剪切掉。然后，使用FBO就不会有这个问题。你可以产生比显示窗口大的帧缓存渲染图像。 The following codes is to setup a FBO and framebuffer-attachable images before the rendering loop is started. Note that not only a texture image is attached to the FBO, but also, a renderbuffer image is attached to the depth attachment point of the FBO. We do not actually use this depth buffer, however, the FBO itself needs it for depth test. If we don’t attach this depth renderable image to the FBO, then the rendering output will be corrupted because of missing depth test. If stencil test is also required during FBO rendering, then additional renderbuffer image should be attached to GL_STENCIL_ATTACHMENT. 以下代码在渲染循环开始之前，对FBO和帧缓存关联图像进行了初始化。注意只有一幅纹理图像被关联到FBO，但是，一个深度渲染图像被关联到FBO的深度关联点。实际上我们并没有使用这个深度缓存，但是FBO本身需要它进行深度测试。如果我们不把这个深度可渲染的图像关联到FBO，那么由于缺少深度测试渲染输出结果是不正确的。如果在FBO渲染期间模板测试也是必要的，那么也需要把额外的渲染图像和GL_STENCIL_ATTACHMENT_EXT关联起来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748...// create a texture objectGLuint textureId;glGenTextures(1, &amp;textureId);glBindTexture(GL_TEXTURE_2D, textureId);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);glTexParameteri(GL_TEXTURE_2D, GL_GENERATE_MIPMAP, GL_TRUE); // automatic mipmapglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, TEXTURE_WIDTH, TEXTURE_HEIGHT, 0, GL_RGBA, GL_UNSIGNED_BYTE, 0);glBindTexture(GL_TEXTURE_2D, 0);// create a renderbuffer object to store depth infoGLuint rboId;glGenRenderbuffers(1, &amp;rboId);glBindRenderbuffer(GL_RENDERBUFFER, rboId);glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, TEXTURE_WIDTH, TEXTURE_HEIGHT);glBindRenderbuffer(GL_RENDERBUFFER, 0);// create a framebuffer objectGLuint fboId;glGenFramebuffers(1, &amp;fboId);glBindFramebuffer(GL_FRAMEBUFFER, fboId);// attach the texture to FBO color attachment pointglFramebufferTexture2D(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_COLOR_ATTACHMENT0, // 2. attachment point GL_TEXTURE_2D, // 3. tex target: GL_TEXTURE_2D textureId, // 4. tex ID 0); // 5. mipmap level: 0(base)// attach the renderbuffer to depth attachment pointglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_DEPTH_ATTACHMENT, // 2. attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboId); // 4. rbo ID// check FBO statusGLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);if(status != GL_FRAMEBUFFER_COMPLETE) fboUsed = false;// switch back to window-system-provided framebufferglBindFramebuffer(GL_FRAMEBUFFER, 0);... The rendering procedure of render-to-texture is almost same as normal drawing. We only need to switch the rendering destination from the window-system-provided to the non-displayable, application-created framebuffer (FBO). 渲染到纹理的过程和普通的绘制过程基本一样。我们只需要把渲染的目的地由window系统提供的帧缓存改成不可显示的应用程序创建的帧缓存（FBO）就可以了。 123456789101112131415161718192021...// set rendering destination to FBOglBindFramebuffer(GL_FRAMEBUFFER, fboId);// clear buffersglClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);// draw a scene to a texture directlydraw();// unbind FBOglBindFramebuffer(GL_FRAMEBUFFER, 0);// trigger mipmaps generation explicitly// NOTE: If GL_GENERATE_MIPMAP is set to GL_TRUE, then glCopyTexSubImage2D()// triggers mipmap generation automatically. However, the texture attached// onto a FBO should generate mipmaps manually via glGenerateMipmap().glBindTexture(GL_TEXTURE_2D, textureId);glGenerateMipmap(GL_TEXTURE_2D);glBindTexture(GL_TEXTURE_2D, 0);... Note that glGenerateMipmap() is also included as part of FBO extension in order to generate mipmaps explicitly after modifying the base level texture image. If GL_GENERATE_MIPMAP is set to GL_TRUE, then glTex{Sub}Image2D() and glCopyTex{Sub}Image2D() trigger automatic mipmap generation (in OpenGL version 1.4 or greater). However, FBO operation does not generate its mipmaps automatically when the base level texture is modified because FBO does not call glCopyTex{Sub}Image2D() to modify the texture. Therefore, glGenerateMipmap() must be explicitly called for mipmap generation. 注意到，glGenerateMipmapEXT()也是作为FBO扩展的一部分，用来在改变了纹理图像的基级之后显式生成mipmap的。如果GL_GENERATE_MIPMAP被设置为GL_TRUE，那么glTex{Sub}Image2D()和 glCopyTex{Sub}Image2D()将会启用自动mipmap生成（在OpenGL版本1.4或者更高版本中）。然后，当纹理基级被改变时，FBO操作不会自动产生mipmaps。因为FBO不会调用glCopyTex{Sub}Image2D()来修改纹理。因此，要产生mipmap，glGenerateMipmapEXT()必须被显示调用。 If you need to a post processing of the texture, it is possible to combine with Pixel Buffer Object (PBO) to modify the texture efficiently.PBuffer vs FBOopengles2.0渲染到纹理的方法有三种： 使用glCopyTexImage2D或者glCopyTexSubImage2D，这两个函数，复制framebuffer中的像素到纹理缓存里面，但这两个函数性能比较低下，并且要求纹理的尺寸必须小于等于framebuffer的尺寸。 使用一个附加到纹理的pbuffer，来执行渲染到纹理的操作。我们知道，窗口系统为我们提供的surface必须添加到一个渲染环境里面，但是，在某些平台上要求每个pbuffer和窗口系统提供的surface都需要一个单独的context，所以如果要渲染到pbuffer里面的话，就会发生context的切换，这种切换操作时很耗时的。 使用fbo，rbo等，这种是最高效的。 pbuffer跟framebuffer功能是一样的，都是用来做渲染到一个off-screen surface上的，但是如果要做的是渲染到一个纹理上，还是使用framebuffer，效率高些。pbuffer的用途是：渲染到纹理上，随后这个纹理可以给其他API用的，比如openVG。创建pbuffer的过程跟创建窗口surface差不多的： 1EGLSurface eglCreatePbufferSurface(EGLDisplay display,EGLConfig config,const EGLint *attribList); 需要在attribList指定一些pbuffer的属性。选择config的时候需要指定：EGL_SURFACE_TYPE：EGL_PBUFFER_BIT 频繁的在自己创建的fbo和窗口系统创建的vbo之间切换，比较影响性能。不要在每一帧都去创建，销毁fbo，vbo对象。要一次创建多次使用。如果一个纹理attach到一个fbo的attachment point，就要尽量避免调用glTexImage2D或glTexSubImage2D,glCopyTexImage2D等去修改纹理的值。 Presumably eglSwapBuffers has no effect on PBufferSurface (since it is not double-buffer surface) but if it is you would try to read pixels from undefined buffer, with undefined result..引用 原文 译文 GL_EXT_discard_framebuffer]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android textureview处理预览摄像头变形问题]]></title>
    <url>%2F2017%2F05%2F04%2Fandroid-view-textureview%2F</url>
    <content type="text"><![CDATA[当TextureView的大小和匹配到的摄像头PreviewSize宽高比例不完全一致时,TextureView可通过setTransform函数对预览画面进行处理后再显示到TextureView,如下对图形居中裁剪: 1234567891011121314151617181920212223242526272829303132333435363738public void sizeNotify(Camera.Size size) &#123; float viewWidth = getWidth(); float viewHeight = getHeight(); float scaleX = 1.0f; float scaleY = 1.0f; int mPreviewWidth = size.width; int mPreviewHeight = size.height; if(viewWidth &lt; viewHeight) &#123; mPreviewWidth = size.height; mPreviewHeight = size.width; &#125; if (mPreviewWidth &gt; viewWidth &amp;&amp; mPreviewHeight &gt; viewHeight) &#123; scaleX = mPreviewWidth / viewWidth; scaleY = mPreviewHeight / viewHeight; &#125; else if (mPreviewWidth &lt; viewWidth &amp;&amp; mPreviewHeight &lt; viewHeight) &#123; scaleY = viewWidth / mPreviewWidth; scaleX = viewHeight / mPreviewHeight; &#125; else if (viewWidth &gt; mPreviewWidth) &#123; scaleY = (viewWidth / mPreviewWidth) / (viewHeight / mPreviewHeight); &#125; else if (viewHeight &gt; mPreviewHeight) &#123; scaleX = (viewHeight / mPreviewHeight) / (viewWidth / mPreviewWidth); &#125; // Calculate pivot points, in our case crop from center int pivotPointX = (int) (viewWidth / 2); int pivotPointY = (int) (viewHeight / 2); Matrix matrix = new Matrix(); matrix.setScale(scaleX, scaleY, pivotPointX, pivotPointY); /*Log.e(TAG, &quot;viewsize:&quot; + viewWidth + &quot; * &quot; + viewHeight + &quot;;prviewSize:&quot; + mPreviewWidth + &quot; * &quot; + mPreviewHeight + &quot;;scale:&quot; + scaleX + &quot; * &quot; + scaleY + &quot;;pivot:&quot; + pivotPointX + &quot; * &quot; + pivotPointY);*/ setTransform(matrix); &#125; TextureView中setTransform函数说明: Sets the transform to associate with this texture view. The specified transform applies to the underlying surface texture and does not affect the size or position of the view itself, only of its content. Some transforms might prevent the content from drawing all the pixels contained within this view’s bounds. In such situations, make sure this texture view is not marked opaque.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>view</tag>
        <tag>TextureView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之Native APIs]]></title>
    <url>%2F2017%2F05%2F03%2Fwebrtc-nativeapis%2F</url>
    <content type="text"><![CDATA[Block diagram Calling sequencesSet up a call Receive a call Close down a call Threading modelWebRTC native APIs use two globally available threads: the signaling thread and the worker thread. Depending on how the PeerConnection factory is created, the application can either provide those 2 threads or just let them be created internally. The calls to the Stream APIs and the PeerConnection APIs will be proxied to the signaling thread which means that the application can call those APIs from whatever thread. All callbacks will be made on the signaling thread. The application should return the callback as quickly as possible to avoid blocking the signaling thread. Resource intensive processes should be posted to a different thread. The worker thread is used to handle more resource intensive processes such as data streaming. https://sites.google.com/site/webrtc/native-code/native-apis]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之api]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-api%2F</url>
    <content type="text"><![CDATA[api目录下封装了webrtc相关的供外部调用接口. datachannel.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/datachannel.h&quot; datachannelinterface.h DataChannelObserver:Used to implement RTCDataChannel events.The code responding to these callbacks should unwind the stack before using any other webrtc APIs; re-entrancy is not supported. DataChannelInterface: dtmfsenderinterface.h DtmfSenderObserverInterface:DtmfSender callback interface, used to implement RTCDtmfSender events.Applications should implement this interface to get notifications from the DtmfSender. DtmfSenderInterface:The interface of native implementation of the RTCDTMFSender defined by the WebRTC W3C Editor’s Draft. fakemetricsobserver.h/cc FakeMetricsObserver jsep.h IceCandidateInterface:Class representation of an ICE candidate.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateIceCandidate. IceCandidateCollection:This class represents a collection of candidates for a specific m= section.Used in SessionDescriptionInterface. SessionDescriptionInterface:Class representation of an SDP session description.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateSessionDescription. CreateSessionDescriptionObserver:CreateOffer and CreateAnswer callback interface. SetSessionDescriptionObserver:SetLocalDescription and SetRemoteDescription callback interface. jsepicecandidate.h JsepIceCandidate:继承自IceCandidateInterface JsepCandidateCollection:继承自IceCandidateCollection jsepsessiondescription.h JsepSessionDescription:Implementation of SessionDescriptionInterface. mediaconstraintsinterface.h/cc MediaConstraintsInterface:Interface used for passing arguments about media constraints to the MediaStream and PeerConnection implementation.Constraints may be either “mandatory”, which means that unless satisfied,the method taking the constraints should fail, or “optional”, which means they may not be satisfied.. mediastream.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/mediastream.h&quot; mediastreaminterface.h/cc OberverInterface NotifierInterface MediaSourceInterface:Base class for sources. A MediaStreamTrack has an underlying source that provides media. A source can be shared by multiple tracks.继承自notifierInterface MediaStreamTrackInterface:继承自notifierInterface VideoTrackSourceInterface:VideoTrackSourceInterface is a reference counted source used for VideoTracks. The same source can be used by multiple VideoTracks.继承自MediaSourceinterface与VideoSourceInterface VideoTrackInterface: 继承自MediaStreamTrackInterface与VideoSourceInterface AudioTrackSinkinterface: AudioSourceInterface:AudioSourceInterface is a reference counted source used for AudioTracks.The same source can be used by multiple AudioTracks.继承自MediaSourceInterface. AudioProcessorInterface:Interface of the audio processor used by the audio track to collect statistics. AudioTrackInterface:继承自MediaStreamTrackInterface MediaStreamInterface: A major difference is that remote audio/video tracks (received by a PeerConnection/RtpReceiver) are not synchronized simply by adding them to the same stream; a session description with the correct “a=msid” attributes must be pushed down.Thus, this interface acts as simply a container for tracks. mediastreamproxy.hMove this to .cc file and out of api/. What threads methods // are called on is an implementation detail. mediastreamtrack.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/mediastreamtrack.h&quot; mediatypes.h/ccmediatype到string转换 notifier.h Notifier: peerconnectionfactoryproxy.hpeerconnectioninterface.h12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// This file contains the PeerConnection interface as defined in// http://dev.w3.org/2011/webrtc/editor/webrtc.html#peer-to-peer-connections.//// The PeerConnectionFactory class provides factory methods to create// PeerConnection, MediaStream and MediaStreamTrack objects.//// The following steps are needed to setup a typical call using WebRTC://// 1. Create a PeerConnectionFactoryInterface. Check constructors for more// information about input parameters.//// 2. Create a PeerConnection object. Provide a configuration struct which// points to STUN and/or TURN servers used to generate ICE candidates, and// provide an object that implements the PeerConnectionObserver interface,// which is used to receive callbacks from the PeerConnection.//// 3. Create local MediaStreamTracks using the PeerConnectionFactory and add// them to PeerConnection by calling AddTrack (or legacy method, AddStream).//// 4. Create an offer, call SetLocalDescription with it, serialize it, and send// it to the remote peer//// 5. Once an ICE candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. The candidates must also be serialized and// sent to the remote peer.//// 6. Once an answer is received from the remote peer, call// SetRemoteDescription with the remote answer.//// 7. Once a remote candidate is received from the remote peer, provide it to// the PeerConnection by calling AddIceCandidate.//// The receiver of a call (assuming the application is &quot;call&quot;-based) can decide// to accept or reject the call; this decision will be taken by the application,// not the PeerConnection.//// If the application decides to accept the call, it should://// 1. Create PeerConnectionFactoryInterface if it doesn&apos;t exist.//// 2. Create a new PeerConnection.//// 3. Provide the remote offer to the new PeerConnection object by calling// SetRemoteDescription.//// 4. Generate an answer to the remote offer by calling CreateAnswer and send it// back to the remote peer.//// 5. Provide the local answer to the new PeerConnection by calling// SetLocalDescription with the answer.//// 6. Provide the remote ICE candidates by calling AddIceCandidate.//// 7. Once a candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. Send these candidates to the remote peer. StreamCollectionInterface StatsObserver PeerConnectionInterface PeerConnectionObserver:PeerConnection callback interface, used for RTCPeerConnection events. Application should implement these methods. PeerConnectionFactoryInterface:PeerConnectionFactoryInterface is the factory interface used for creating PeerConnection, MediaStream and MediaStreamTrack objects.The simplest method for obtaiing one, CreatePeerConnectionFactory will create the required libjingle threads, socket and network manager factory classes for networking if none are provided, though it requires that the application runs a message loop on the thread that called the method (see explanation below) If an application decides to provide its own threads and/or implementation of networking classes, it should use the alternate CreatePeerConnectionFactory method which accepts threads as input, and use the CreatePeerConnection version that takes a PortAllocator as an argument. peerconnectionproxy.hproxy.h12345678910111213141516171819202122232425262728293031323334353637383940// This file contains Macros for creating proxies for webrtc MediaStream and// PeerConnection classes.// TODO(deadbeef): Move this to pc/; this is part of the implementation.//// Example usage://// class TestInterface : public rtc::RefCountInterface &#123;// public:// std::string FooA() = 0;// std::string FooB(bool arg1) const = 0;// std::string FooC(bool arg1) = 0;// &#125;;//// Note that return types can not be a const reference.//// class Test : public TestInterface &#123;// ... implementation of the interface.// &#125;;//// BEGIN_PROXY_MAP(Test)// PROXY_SIGNALING_THREAD_DESTRUCTOR()// PROXY_METHOD0(std::string, FooA)// PROXY_CONSTMETHOD1(std::string, FooB, arg1)// PROXY_WORKER_METHOD1(std::string, FooC, arg1)// END_PROXY_MAP()//// Where the destructor and first two methods are invoked on the signaling// thread, and the third is invoked on the worker thread.//// The proxy can be created using//// TestProxy::Create(Thread* signaling_thread, Thread* worker_thread,// TestInterface*).//// The variant defined with BEGIN_SIGNALING_PROXY_MAP is unaware of// the worker thread, and invokes all methods on the signaling thread.//// The variant defined with BEGIN_OWNED_PROXY_MAP does not use// refcounting, and instead just takes ownership of the object being proxied. rtcerror.h/ccrtcerror_unittest.ccrtpparameters.hrtpreceiverinterface.hrtpsender.hrtpsenderinterface.hstatstypes.h/ccstreamcollection.humametrics.hvideosourceproxy.hvideotracksource.hwebrtcsdp.haudio/audio_mixer.h AudioMixer:This class is under development and is not yet intended for for use outside of WebRtc/Libjingle. audio_codecs/audio_decoder.h/cc AudioDecoder audio_codecs/audio_decoder_factory.h AudioDecoderFactory audio_codecs/audio_encoder.h/cc-AudioEncoder: his is the interface class for encoders in AudioCoding module. Each codec type must have an implementation of this class. audio_codecs/audio_encoder_factory.h AudioEncoderFactory audio_codecs/audio_format.h/ccaudio_codecs/builtin_audio_encoder_factory.h/ccaudio_codecs/builtin_audio_decoder_factory.h/cccall/audio_sink.hcall/transport.hortc/mediadescription.h/ccortc/mediadescription_unittest.ccortc/ortcfactoryinterface.hortc/ortcrtpreceiverinterface.hortc/ortcrtpsenderinterface.hortc/packettransportinterface.hortc/rtptransportcontrollerinterface.hortc/rtptransportinterface.hortc/sessiondecription.h/ccortc/sessiondescription_unittest.ccortc/srtptransportinerface.hortc/udptransportinterface.h]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之base]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-base%2F</url>
    <content type="text"><![CDATA[src/webrtc/base是webrtc基础平台库，包括线程、锁、socket,智能指针等. 智能指针refcount.h定义了rtc::RefCountInterface: 123456789101112131415#include &quot;webrtc/base/refcountedobject.h&quot;namespace rtc &#123;// Reference count interface.class RefCountInterface &#123; public: virtual int AddRef() const = 0; virtual int Release() const = 0; protected: virtual ~RefCountInterface() &#123;&#125;&#125;;&#125; // namespace rtc refcountedobject.h下定义了RefCountedObject: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;utility&gt;#include &quot;webrtc/base/atomicops.h&quot;namespace rtc &#123;template &lt;class T&gt;class RefCountedObject : public T &#123; public: RefCountedObject() &#123;&#125; template &lt;class P0&gt; explicit RefCountedObject(P0&amp;&amp; p0) : T(std::forward&lt;P0&gt;(p0)) &#123;&#125; template &lt;class P0, class P1, class... Args&gt; RefCountedObject(P0&amp;&amp; p0, P1&amp;&amp; p1, Args&amp;&amp;... args) : T(std::forward&lt;P0&gt;(p0), std::forward&lt;P1&gt;(p1), std::forward&lt;Args&gt;(args)...) &#123;&#125; virtual int AddRef() const &#123; return AtomicOps::Increment(&amp;ref_count_); &#125; virtual int Release() const &#123; int count = AtomicOps::Decrement(&amp;ref_count_); if (!count) &#123; delete this; &#125; return count; &#125; // Return whether the reference count is one. If the reference count is used // in the conventional way, a reference count of 1 implies that the current // thread owns the reference and no other thread shares it. This call // performs the test for a reference count of one, and performs the memory // barrier needed for the owning thread to act on the object, knowing that it // has exclusive access to the object. virtual bool HasOneRef() const &#123; return AtomicOps::AcquireLoad(&amp;ref_count_) == 1; &#125; protected: virtual ~RefCountedObject() &#123;&#125; mutable volatile int ref_count_ = 0;&#125;;&#125; // namespace rtc 线程Thread网络Socket]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之sdp协议]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-sdp%2F</url>
    <content type="text"><![CDATA[Session Description Protocol(会话描述协议)RFC定义SDP的协议有两个: RFC3264: An Offer/Answer Model with the session Description Protocol(SDP),用来概述一个请求/响应模型 RFC2327: SDP:Session Description Protocol,描述数据格式. 1.RFC23271.1.概述SDP 完全是一种会话描述格式 ― 它不属于传输协议 ― 它只使用不同的适当的传输协议，包括会话通知协议（SAP）、会话初始协议（SIP）、实时流协议（RTSP）、MIME 扩展协议的电子邮件以及超文本传输协议（HTTP）。SDP协议是也是基于文本的协议，这样就能保证协议的可扩展性比较强，这样就使其具有广泛的应用范围。SDP 不支持会话内容或媒体编码的协商，所以在流媒体中只用来描述媒体信息。媒体协商这一块要用RTSP来实现． SDP包括以下一些方面： 会话的名称和目的 会话存活时间 包含在会话中的媒体信息，包括： 媒体类型(video, audio, etc) 传输协议(RTP/UDP/IP, H.320, etc) 媒体格式(H.261 video, MPEG video, etc) 多播或远端（单播）地址和端口 为接收媒体而需的信息(addresses, ports, formats and so on) 使用的带宽信息 可信赖的接洽信息（Contact information） 1.2.SDP协议格式SDP描述由许多文本行组成，文本行的格式为&lt;类型&gt;=&lt;值&gt;，&lt;类型&gt;是一个字母，&lt;值&gt;是结构化的文本串，其格式依&lt;类型&gt;而定。 ＜type＞=[CRLF] 1.2.1.fields分类 Seeesion Description v(Protocol Version),mnd,The current protocol version.Always “0” using RFC4566 o(Origin),Mnd,The session originator’s name and session identifiers. s(Session Name), Mnd,The textural session Name i(Session Information), opt,Textural information about the session u(Uri),opt, A pointer to supplemental session Information e(Email Address), opt, Email contract information for the person responsible. P(phone Address),opt,Phone contract information for the person responsible c(Connection Data),C,The connection type and Address b(Bandwidth),opt,Proposed bandwidth limits. z(Time Zones), opt, Accounts for daylight saving information k(Encryption Keys),opt,A simple mechanism for exchanging keys, Rarely used. Timing Description t(Timing),mnd, start and end times. r(Repeat Times),opt, Specified the duration and intervals for any session repeats. Media Description m(Media Description),mnd, Media definitions including media type(e.g.”audio”),transport details and formats. i(Session Information),opt c(Connection Data),c b(Bandwidth):opt k( Encryption keys),opt a(Attributes),opt 1.2.2.典型格式1234567891011121314151617181920212223242526Session description v= (protocol version) o= (owner/creator and session identifier) s= (session name) i=* (session information) u=* (URI of description) e=* (email address) p=* (phone number) c=* (connection information - not required if included in all media) b=* (zero or more bandwidth information lines) One or more time descriptions (&quot;t=&quot; and &quot;r=&quot; lines, see below) z=* (time zone adjustments) k=* (encryption key) a=* (zero or more session attribute lines) Zero or more media descriptionsTime description t= (time the session is active) r=* (zero or more repeat times)Media description, if present m= (media name and transport address) i=* (media title) c=* (connection information - optional if included at session-level) b=* (zero or more bandwidth information lines) k=* (encryption key) a=* (zero or more media attribute lines) 带&quot;*&quot;号的是可选的,其余的是必须的。一般顺序也按照上面的顺序来排列。 1.2.3.各type对应值的结构化文本串 v= 其中：nettype是IN,代表internet,addrtype是IP4或IP6。unicast-address任务创建计算机的地址。 整个这个属性，是唯一表示一个任务。 e=123@126.com 或 p=+1 616 555-6011 对于一个任务只能两者之中的一个，表示会议控制者的联系方式。邮件地址可以是[email]j.doe@example.com[/email] (Jane Doe)形式，括号里面的是描述联系人的名称，或者Jane Doe &lt;[email]j.doe@example.com[/email]&gt;，前面的是联系人的名称。 c= 这个连接数据，可以是传话级别的连接数据，或者是单独一个媒体数据的连接数据。在是多播时，connection-address就该是一个多播组地址，当是单播时，connection-address就该是一个单播地址。对于addrtype是IP4的情况下，connection-address不仅包含IP地址，并且还要包含a time to live value(TTL 0-255)，如：c=IN IP4 224.2.36.42/128，IP6没有这个TTL值。还允许象这样的[/]/格式的connection-address。如：c=IN IP4 224.2.1.1/127/3等同于包含c=IN IP4 224.2.1.1/127, c=IN IP4 224.2.1.2/127, c=IN IP4 224.2.1.3/127三行内容。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 r= 重复次数在时间表示里面可以如下表示： d - days (86400 seconds) h - hours (3600 seconds) m - minutes (60 seconds) s - seconds (allowed for completeness) z=&lt;adjustment time&gt; &lt;offset&gt; &lt;adjustment time&gt; &lt;offset&gt; .... k=&lt;method&gt; k=&lt;method&gt;:&lt;encryption key&gt; a=&lt;attribute&gt; a=&lt;attribute&gt;:&lt;value&gt; m=&lt;media&gt; &lt;port&gt; &lt;proto&gt; &lt;fmt&gt; ... m=&lt;media&gt; &lt;port&gt;/&lt;number of ports&gt; &lt;proto&gt; &lt;fmt&gt; ... a=cat:分类，根据分类接收者隔离相应的会话 a=keywds:关键字，根据关键字隔离相应的会话 a=tool:创建任务描述的工具的名称及版本号 a=ptime:在一个包里面的以毫秒为单位的媒体长度 a=maxptime:以毫秒为单位，能够压缩进一个包的媒体量。 a=rtpmap: / [/] a=recvonly a=sendrecv a=sendonly a=inactive， a=orient:其可能的值，”portrait”, “landscape” and “seascape” 。 a=type:,建议值是，”broadcast”, “meeting”, “moderated”, “test” and “H332”。 a=charset: a=sdplang:指定会话或者是媒体级别使用的语言 a=framerate:设置最大视频帧速率 a=quality:值是0-10 a=fmtp: 在SIP协议的包含的内容是SDP时，应该把Content-Type设置成application/sdp。1.3.SDP协议例子1.3.1.helix流媒体服务器的RTSP协议中的SDP协议:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0 //SDP version// o field定义的源的一些信息。其格式为：o=&lt;username&gt; &lt;sess-id&gt; &lt;sess-version&gt; &lt;nettype&gt; &lt;addrtype&gt; &lt;unicast-address&gt;o=- 1271659412 1271659412 IN IP4 10.56.136.37 s=&lt;No title&gt;i=&lt;No author&gt; &lt;No copyright&gt; //session的信息c=IN IP4 0.0.0.0 //connect 的信息，分别描述了：网络协议，地址的类型，连接地址。c=IN IP4 0.0.0.0t=0 0 //时间信息，分别表示开始的时间和结束的时间，一般在流媒体的直播的时移中见的比较多。a=SdpplinVersion:1610641560 //描述性的信息a=StreamCount:integer;2 //用来描述媒体流的信息，表示有两个媒体流。integer表示信息的格式为整数。a=control:*a=DefaultLicenseValue:integer;0 //License信息a=FileType:string;&quot;MPEG4&quot; ////用来描述媒体流的信息说明当前协商的文件是mpeg4格式的文件a=LicenseKey:string;&quot;license.Summary.Datatypes.RealMPEG4.Enabled&quot;a=range:npt=0-72.080000 //用来表示媒体流的长度m=audio 0 RTP/AVP 96 //做为媒体描述信息的重要组成部分描述了媒体信息的详细内容：表示session的audio是通过RTP来格式传送的，其payload值为96传送的端口还没有定。b=as:24 //audio 的bitrateb=RR:1800b=RS:600a=control:streamid=1 //通过媒体流1来发送音频a=range:npt=0-72.080000 //说明媒体流的长度。a=length:npt=72.080000a=rtpmap:96 MPEG4-GENERIC/32000/2 //rtpmap的信息，表示音频为AAC的其sample为32000a=fmtp:96 profile-level-id=15;mode=AAC-hbr;sizelength=13;indexlength=3;indexdeltalength=3;config=1210 //config为AAC的详细格式信息a=mimetype:string;&quot;audio/MPEG4-GENERIC&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;48000a=HasOutOfOrderTS:integer;1a=MaxBitRate:integer;48000a=Preroll:integer;1000a=OpaqueData:buffer;&quot;A4CAgCIAAAAEgICAFEAVABgAAAC7gAAAu4AFgICAAhKIBoCAgAEC&quot;a=StreamName:string;&quot;Audio Track&quot;下面是video的信息基本和audio的信息相对称，这里就不再说了。m=video 0 RTP/AVP 97b=as:150b=RR:11250b=RS:3750a=control:streamid=2a=range:npt=0-72.080000a=length:npt=72.080000a=rtpmap:97 MP4V-ES/2500a=fmtp:97 profile-level-id=1;a=mimetype:string;&quot;video/MP4V-ES&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;300000a=HasOutOfOrderTS:integer;1a=Height:integer;240 //影片的长度a=MaxBitRate:integer;300000a=MaxPacketSize:integer;1400a=Preroll:integer;1000a=Width:integer;320 //影片的宽度a=OpaqueData:buffer;&quot;AzcAAB8ELyARAbd0AAST4AAEk+AFIAAAAbDzAAABtQ7gQMDPAAABAAAAASAAhED6KFAg8KIfBgEC&quot;a=StreamName:string;&quot;Video Track&quot; 1.3.2.Webrtc SDP示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0o=- 0 0 IN IP4 127.0.0.1s=WX-RTC-SERVERt=0 0a=group:BUNDLE audio videoa=msid-semantic: WMS ryODEhTpFzm=audio 1 UDP/TLS/RTP/SAVPF 0 126c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-levela=mid:audioa=rtcp-muxa=rtpmap:0 PCMU/8000a=rtpmap:126 telephone-event/8000m=video 1 UDP/TLS/RTP/SAVPF 124 125 96c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=extmap:2 urn:ietf:params:rtp-hdrext:toffseta=extmap:3 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-timea=extmap:4 urn:3gpp:video-orientationa=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/playout-delaya=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=mid:videoa=rtcp-muxa=rtpmap:124 H264/90000a=rtcp-fb:124 ccm fira=rtcp-fb:124 nacka=rtcp-fb:124 nack plia=rtcp-fb:124 goog-remba=fmtp:124 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:125 H264/90000a=rtcp-fb:125 ccm fira=rtcp-fb:125 nacka=rtcp-fb:125 nack plia=rtcp-fb:125 goog-remba=fmtp:125 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:96 VP8/90000a=rtcp-fb:96 ccm fira=rtcp-fb:96 nacka=rtcp-fb:96 nack plia=rtcp-fb:96 goog-remb 2.RFC3264An Offer/Answer Model with the Session Description Protocol (SDP) 2.1情态动词定义在RFC2119: “MUST”，必须、一定要； “MUST NOT”，禁止； “REQUIRED”，需要； “SHALL”、”SHOULD”，应该； “SHALL NOT”、”SHOULD NOT”，不应该； “RECOMMENDED”，推荐； “MAY”，可以2.2术语 媒体流（Media Stream），或称为媒体类型（Media Type），即我们通常所说的音频流、视频流等，所有通信实体要进行媒体交互之前都必须进行媒体注的协商 媒体格式（Media Format），每种媒体流都有不同的编码格式，像音频有G711、G712编码，视频有H261、H264等，像现在所谓的高清视频采用是720P、1070P等。 单一会话（Unitcast Session） 多会话（Multicast Sessions） 单一媒体流（Unitcast Streams） 多媒体流（Multicast Streams）2.3offer/answerrfc3264协议[1]主要概述一个请求/响应模型（offer/answer，以下叙述采用英文），包括请求/响应的实体和不同阶段的操作行为，如初始协商过程和重协商过程，并简单介绍消息中各种参数的含义。具体各个参数的详细说明见rfc2327协议[2]2.3.1.实体,消息Offer/Answer模型包括两个实体，一个是请求主体Offerer，另外一个是响应实体Answerer，两个实体只是在逻辑上进行区分，在一定条件可以转换。例如，手机A发起媒体协商请求，那么A就是Offerer，反之如果A为接收请求则为Offerer。 Offerer发给Answerer的请求消息称为请求offer，内容包括媒体流类型、各个媒体流使用的编码集，以及将要用于接收媒体流的IP和端口。 Answerer收到offer之后，回复给Offerer的消息称为响应，内容包括要使用的媒体编码，是否接收该媒体流以及告诉Offerer其用于接收媒体流的IP和端口。2.3.2.SDP各个参数简单介绍下面示例摘自3264协议[1] v=0 o=carol 28908764872 28908764872 IN IP4 100.3.6.6 //会话ID号和版本 s=- //用于传递会话主题 t=0 0 //会话时间，一般由其它信令消息控制，因此填0 c=IN IP4 192.0.2.4 //描述本端将用于传输媒体流的IP m=audio 0 RTP/AVP 0 1 3 //媒体类型 端口号 本端媒体使用的编码标识（Payload）集 a=rtpmap:0 PCMU/8000 //rtpmap映射表，各种编码详细描述参数，包括使用带宽（bandwidth） a=rtpmap:1 1016/8000 a=rtpmap:3 GSM/8000 a=sendonly //说明本端媒体流的方向，取值包括sendonly/recvonly/sendrecv/inactive a=ptime:20 //说明媒体流打包时长 m=video 0 RTP/AVP 31 34 a=rtpmap:31 H261/90000 a=rtpmap:34 H263/900002.3.3.实体行为、操作过程2.3.3.1.初始协商的Offer请求实体A &lt;-&gt; 实体B，实体首先发起Offer请求，内容如2节所示，对于作何一个媒体流/媒体通道，这时实体A必须： 如果媒体流方向标为recvonly/sendrecv，即a=recvonly或a=sendrecv，则A必须（MUST）准备好在这个IP和端口上接收实体B发来的媒体流； 如果媒体流方向标为sendonly/inactive，即a=recvonly或a=sendrecv，则A不需要进行准备。2.3.3.1.Answer响应实体B收到A的请求offer后，根据自身支持的媒体类型和编码策略，回复响应。 如果实体B回复的响应中的媒体流数量和顺序必须（MUST）和请求offer一致，以便实体A进行甄别和决策。即m行的数量和顺序必须一致，B不能（MUST NOT）擅自增加或删除媒体流。如果B不支持某个媒体流，可以在对应的端口置0，但不能不带这个m行描述。 对于某种媒体，实体B必须（MUST）从请求offer中选出A支持且自己也支持的该媒体的编码标识集，并且可以（MAY）附带自己支持的其它类型编码。 对于响应消息中各个媒体的方向： 如果请求某媒体流的方向为sendonly，那么响应中对应媒体的方向必须为recvonly； 如果请求某媒体流的方向为recvonly，那么响应中对应媒体的方向必须为sendonly； 如果请求某媒体流的方向为sendrecv，那么响应中对应媒体的方向可以为sendrecv/sendonly/recvonly/inactive中的一种； 如果请求某媒体流的方向为inactive，那么响应中对应媒体的方向必须为inactive； 响应answer里提供IP和端口，指示Offerer本端期望用于接收媒体流的IP和端口，一旦响应发出之后，Offerer必须（MUST）准备好在这个IP和端口上接收实体A发来的媒体流。 如果请求offer中带了ptime（媒体流打包间隔）的a行或带宽的a行，则响应answer也应该（SHOULD）相应的携带。 实体B Offerer应该（SHOULD）使用实体A比较期望的编码生成媒体流发送。一般来说对于m行，如m=video 0 RTP/AVP 31 34，排充越靠前的编码表示该实体越希望以这个编码作为载体，这里示例31(H261)，34（H263）中H261为A更期望使用的编码类型。同理，当实体A收到响应answer后也是这样理解的。2.3.3.2.实体收到响应后的处理当实体A收到B回复的响应后，可以（MAY）开始发送媒体流，如果媒体流方向为sendonly/sendrecv， 必须（MUST）使用answer列举的媒体类型/编码生成媒体发送； 应该（SHOULD）使用answer中的ptime和bandwidth来打包发送媒体流； 可以（MAY）立即停止监听端口，该端口为offer支持answer不支持的媒体所使用的端口。 2.3.4.修改媒体流（会话）修改媒体流的offer-answer操作必须基于之前协商的媒体形式（音频、视频等），不能（MUST NOT）对已有媒体流进行删减。 2.3.4.1.删除媒体流如果实体认定新的会话不支持之前媒商的某个媒体，新的offer只须对这种媒体所在m行的端口置0，但不能不描述这种媒体，即不带对应m行。当answerer收到响应之后，处理同初始协商一样。 2.3.4.2.增加媒体流如果实体打算新增媒体流，在offer里只须加上描述即可或者占用之前端口被置0的媒体流，即用新的媒体描述m行替换旧的。当answerer收到offer请求后，发现有新增媒体描述，或者过于端口被置0的媒体行被新的媒体描述替换，即知道当前为新增媒体流，处理同初始协商。 2.3.4.3.修改媒体流修改媒体注主要是针对初始协商结果，如果有变更即进入修改流程处理，可能的变更包括IP地址、端口，媒体格式（编码），媒体类型（音、视频），媒体属性（ptime，bandwidth，媒体流方向变更等）。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之入门]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-introduce%2F</url>
    <content type="text"><![CDATA[webrtc developersThe WebRTC APIsThree main tasks Acquiring audio and video Communicating audio and video Communicating arbitrary data Three main JavaScript APIs MediaStream(aka getUserMedia) RTCPeerConnection RTCDataChannel MediaStream(Acquiring audio and video) MediaStream Pepresent a stream of audio and/or video Can contain multiple ‘tracks’ Obtain a MediaStream with navigator.getUserMedia() Constraints Controls the contents of the MediaStream Media type, resolution, frame rateRTCPeerConnection(Audio and video communication between peers)RTCPeerConnection does a lot Signal processing Codec handling Peer to peer communication Security Bandwidth managementWebRTC architecture RTCDataChannel(Bidirectional communication of arbitrary data between peers) RTCDataChannel Same API as WebSockets Ultra-low latency Unreliable or reliable Secure Servers and Protocols(Peer to peer — but we need servers :) Abstract Signaling Need to exchange ‘session description’ objects: What formats I support, what I want to send Network information for peer-to-peer setup Can use any messaging mechanism Can use any messaging protocol STUN and TRUN(P2P in the age of firewalls and NATs) An ideal world The real world STUN Tell me what my public IP address is Simple server, cheap to run Data flows peer-to-peer TURN Provide a cloud fallback if peer-to-peer communication fails Data is sent through server, uses server bandwidth Ensures the call works in almost all environments ICE ICE: a framework for connecting peers Tries to find the best path for each call Vast majority of calls can use STUN (webrtcstats.com): Deploying STUN/TURN stun.l.google.com:19302 WebRTC stunserver, turnserver rfc5766-turn-server restund SecuritySecurity throughout WebRTC Mandatory encryption for media and data Secure UI, explicit opt-in Sandboxed, no plugins WebRTC Security Architecture ArchitecturesPeer to Peer : one-to-one callclientA &lt;——–&gt; clientB Mesh: small N-way call123456clientA &lt;-------------&gt; clientB /|\ \ / /|\ | \ / | | / \ | \|/ / \|/clientC &lt;--------------&gt; clientD Star: medium N-way call123clientA &lt;---------&gt; clientBclientA &lt;---------&gt; clientCclientA &lt;---------&gt; clientD MCU: large N-way call1234567MCU &lt;--------------&gt;clientAMCU &lt;--------------&gt;clientBMCU &lt;--------------&gt;clientCMCU &lt;--------------&gt;clientDMCU &lt;--------------&gt;clientEMCU &lt;--------------&gt;clientFMCU &lt;--------------&gt;clientG]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之源码管理工具gclient]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-gclient%2F</url>
    <content type="text"><![CDATA[google的chromium项目是用gclient来管理源码的checkout, update等。 gclient是google专门为这种多源项目编写的脚本，它可以将多个源码管理系统中的代码放在一起管理。甚至包括将Git和svn代码放在一起。 webrtc也是使用gclient管理代码. gclient的sync，update等命令密切相关的两类文件.gclient和DEPS。 .gclient文件是gclient的控制文件，该文件放在工作目录的最上层(webrtc环境下与src统计目录)。”.gclient”文件是一个Python的脚本，定义了一组”solutions”，格式类似如下 1234567891011solutions = [ &#123; &quot;name&quot; : &quot;src&quot;, &quot;url&quot; : &quot;svn://svnserver/component/trunk/src&quot;, &quot;custom_deps&quot; : &#123; # To use the trunk of a component instead of what&apos;s in DEPS: #&quot;component&quot;: &quot;https://svnserver/component/trunk/&quot;, # To exclude a component from your working copy: #&quot;data/really_large_component&quot;: None, &#125; &#125;, ] name:checkout出源码的名字 url:源码所在的目录,gclient希望checkout出的源码中包括一个DEPS的文件,这个文件包含了必须checkout到工作目录的源码信息; deps_file:这是一个文件名(不包括路径),指在工程目录中包含依赖列表的文件,该项可选,默认值为”DEPS” custom_deps:这是一个可选的字典对象,会覆盖工程的”DEPS”文件定义的条目.一般它用作本地目录中,那些不用checkout的代码,或者让本地目录从不同位置checkout一个新的代码出来,或者checkout不同的分支,版本等.也可以用于增加在DEPS中不存在的新的项目.如: 12345678&quot;custom_deps&quot;: &#123; &quot;src/content/test/data/layout_tests/LayoutTests&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome_frame/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_linux&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_mac&quot;: None, &quot;src/third_party/hunspell_dictionaries&quot;: None, &#125;, target_os:这个可选的条目可以指出特殊的平台,根据平台类checkout出不同代码,如: 1target_os = [&apos;android&apos;] 如果target_os_only值为True的话,那么,仅仅checkout出对应的代码,如: 12target_os = [ &quot;ios&quot; ] target_os_only = True 在每个checkout出的工程中，gclient期望发现一个DEPS文件（由deps_file来给定），它定义了工程不同部分都是如何checkout出来。 “DEPS”也是一个python脚本，最简单的，如下： 12345deps = &#123; &quot;src/outside&quot; : &quot;http://outside-server/trunk@1234&quot;, &quot;src/component&quot; : &quot;svn://svnserver/component/trunk/src@77829&quot;, &quot;src/relative&quot; : &quot;/trunk/src@77829&quot;, &#125; deps的每个条目都包含一个key-value对，key是被checkout的本地目录，而value就是对应的远程URL。如果路径是以’/‘开头的，那么它是一个相对URL，相对与.gclient中URL地址。 URL通常包含一个版本号，以便锁定源码在特定版本上。当然，这是可选的。如果没有，那么它将获取指定分支上最新的版本。 DEPS还可以包含其他类型的数据，如vars, 12345678910111213vars = &#123; &apos;pymox&apos;: &apos;http://pymox.googlecode.com/svn&apos;, &apos;sfntly&apos;: &apos;http://sfntly.googlecode.com/svn&apos;, &apos;eyes-free&apos;: &apos;http://eyes-free.googlecode.com/svn&apos;, &apos;rlz&apos;: &apos;http://rlz.googlecode.com/svn&apos;, &apos;smhasher&apos;: &apos;http://smhasher.googlecode.com/svn&apos;,...&#125; vars定义了一组变量，在后面，可以通过Var(xxx)来访问。Var(xxx)返回一个字符串，故此，也可以进行操作，如 1234&apos;src/third_party/cros_dbus_cplusplus/source&apos;:Var(&quot;git.chromium.org&quot;) + &apos;/chromiumos/third_party/dbus-cplusplus.git@5e8f6d9db5c2abfb91d91f751184f25bb5cd0900&apos;,&apos;src/third_party/WebKit&apos;:Var(&quot;webkit_trunk&quot;)[:-6] + &apos;/branches/chromium/1548@153044&apos;, 第二个自立，Var(“webkit_trunk”)[:-6]是一个python表达式，表示取得”webkit_trunk”表示的字符串的最后6个 Hooks：DEPS包含可选的内容 hooks，也有重要的作用，它表示在sync, update或者recert后，执行一个hook操作。 如果使用 –nohooks选项（hook默认执行），那么在gclient sync或者其他操作后，不会执行hook。你可以通过gclient runhooks来单独执行； 如果有 gclient sync –force，那么，无论sync是否成功，都会执行hook。 hook在DEPS中的写法，一般是： 1234567hooks = [ &#123; &quot;pattern&quot;: &quot;\\.(gif|jpe?g|pr0n|png)$&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;image_indexer.py&quot;, &quot;--all&quot;]&#125;, &#123; &quot;pattern&quot;: &quot;.&quot;, &quot;name&quot;: &quot;gyp&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;src/build/gyp_chromium&quot;]&#125;,] hooks包含一组hook，每个hook有几个重要项: pattern 是一个正则表达式，用来匹配工程目录下的文件，一旦匹配成功，action项就会执行 action 描述一个根据特定参数运行的命令行。这个命令在每次gclient时，无论多少文件匹配，至多运行一次。这个命令和.gclient在同一目录下运行。如果第一个参数是”python”，那么，当前的python解释器将被使用。如果包含字符串 “$matching_files”，它将该字符串扩展为匹配出的文件列表。 name 可选，标记出hook所属的组，可以被用来覆盖和重新组织。 deps_os： DEPS中定义不同平台依赖关系的项目，如 1234567891011121314151617181920212223deps_os = &#123; &quot;win&quot;: &#123; &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: &quot;/trunk/deps/reference_builds/chrome_win@197743&quot;, &quot;src/third_party/cygwin&quot;: &quot;/trunk/deps/third_party/cygwin@133786&quot;,..... &#125;, &quot;ios&quot;: &#123; &quot;src/third_party/GTM&quot;: (Var(&quot;googlecode_url&quot;) % &quot;google-toolbox-for-mac&quot;) + &quot;/trunk@&quot; + Var(&quot;gtm_revision&quot;), &quot;src/third_party/nss&quot;: &quot;/trunk/deps/third_party/nss@&quot; + Var(&quot;nss_revision&quot;),.... &#125;,...&#125; deps_os指定不同平台的依赖，它可以包含多种平台，和.gclient中的target_os对应。这种对应关系如下： 12345678910111213DEPS_OS_CHOICES = &#123; &quot;win32&quot;: &quot;win&quot;, &quot;win&quot;: &quot;win&quot;, &quot;cygwin&quot;: &quot;win&quot;, &quot;darwin&quot;: &quot;mac&quot;, &quot;mac&quot;: &quot;mac&quot;, &quot;unix&quot;: &quot;unix&quot;, &quot;linux&quot;: &quot;unix&quot;, &quot;linux2&quot;: &quot;unix&quot;, &quot;linux3&quot;: &quot;unix&quot;, &quot;android&quot;: &quot;android&quot;,&#125; 下载webrtc android代码的.gclient文件(与src同级目录): 12345678910solutions = [ &#123; &quot;url&quot;: &quot;https://chromium.googlesource.com/external/webrtc.git&quot;, &quot;managed&quot;: False, &quot;name&quot;: &quot;src&quot;, &quot;deps_file&quot;: &quot;DEPS&quot;, &quot;custom_deps&quot;: &#123;&#125;, &#125;,]target_os = [&quot;android&quot;, &quot;unix&quot;] src同级目录下.gclient_entries定义了各模块及对应地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344entries = &#123; &apos;src&apos;: &apos;https://chromium.googlesource.com/external/webrtc.git&apos;, &apos;src/base&apos;: &apos;https://chromium.googlesource.com/chromium/src/base@413df39df4640665d7ee1e8c198be1e91cedb4d9&apos;, &apos;src/build&apos;: &apos;https://chromium.googlesource.com/chromium/src/build@98f2769027214c848094d0d58156474eada3bc1b&apos;, &apos;src/buildtools&apos;: &apos;https://chromium.googlesource.com/chromium/buildtools.git@98f00fa10dbad2cdbb2e297a66c3d6d5bc3994f3&apos;, &apos;src/testing&apos;: &apos;https://chromium.googlesource.com/chromium/src/testing@3eab1a4b0951ac1fcb2be8bf9cb24143b509ea52&apos;, &apos;src/testing/gmock&apos;: &apos;https://chromium.googlesource.com/external/googlemock.git@0421b6f358139f02e102c9c332ce19a33faf75be&apos;, &apos;src/testing/gtest&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/googletest.git@6f8a66431cb592dad629028a50b3dd418a408c87&apos;, &apos;src/third_party&apos;: &apos;https://chromium.googlesource.com/chromium/src/third_party@939f3a2eae486dd7cf3b31eae38642d2bc243737&apos;, &apos;src/third_party/android_tools&apos;: &apos;https://chromium.googlesource.com/android_tools.git@b65c4776dac2cf1b80e969b3b2d4e081b9c84f29&apos;, &apos;src/third_party/boringssl/src&apos;: &apos;https://boringssl.googlesource.com/boringssl.git@777fdd6443d5f01420b67137118febdf56a1c8e4&apos;, &apos;src/third_party/catapult&apos;: &apos;https://chromium.googlesource.com/external/github.com/catapult-project/catapult.git@6939b1db033bf35f4adf1ee55824b6edb3e324d6&apos;, &apos;src/third_party/ced/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/compact_enc_det.git@e21eb6aed10b9f6e2727f136c52420033214d458&apos;, &apos;src/third_party/colorama/src&apos;: &apos;https://chromium.googlesource.com/external/colorama.git@799604a1041e9b3bc5d2789ecbd7e8db2e18e6b8&apos;, &apos;src/third_party/ffmpeg&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ffmpeg.git@28a5cdde5c32bcf66715343c10f74e85713f7aaf&apos;, &apos;src/third_party/gflags&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/gflags@892576179b45861b53e04a112996a738309cf364&apos;, &apos;src/third_party/gflags/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/gflags/gflags@03bebcb065c83beff83d50ae025a55a4bf94dfca&apos;, &apos;src/third_party/gtest-parallel&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/gtest-parallel@7eb02a6415979ea59e765c34fe9da6c792f53e26&apos;, &apos;src/third_party/icu&apos;: &apos;https://chromium.googlesource.com/chromium/deps/icu.git@b34251f8b762f8e2112a89c587855ca4297fed96&apos;, &apos;src/third_party/jsoncpp/source&apos;: &apos;https://chromium.googlesource.com/external/github.com/open-source-parsers/jsoncpp.git@f572e8e42e22cfcf5ab0aea26574f408943edfa4&apos;, &apos;src/third_party/jsr-305/src&apos;: &apos;https://chromium.googlesource.com/external/jsr-305.git@642c508235471f7220af6d5df2d3210e3bfc0919&apos;, &apos;src/third_party/junit/src&apos;: &apos;https://chromium.googlesource.com/external/junit.git@64155f8a9babcfcf4263cf4d08253a1556e75481&apos;, &apos;src/third_party/libFuzzer/src&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer.git@16f5f743c188c836d32cdaf349d5d3effb8a3518&apos;, &apos;src/third_party/libjpeg_turbo&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libjpeg_turbo.git@7260e4d8b8e1e40b17f03fafdf1cd83296900f76&apos;, &apos;src/third_party/libsrtp&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libsrtp.git@ccf84786f8ef803cb9c75e919e5a3976b9f5a672&apos;, &apos;src/third_party/libvpx/source/libvpx&apos;: &apos;https://chromium.googlesource.com/webm/libvpx.git@f22b828d685adee4c7a561990302e2d21b5e0047&apos;, &apos;src/third_party/libyuv&apos;: &apos;https://chromium.googlesource.com/libyuv/libyuv.git@fc02cc3806a394a6b887979ba74aa49955f3199b&apos;, &apos;src/third_party/lss&apos;: &apos;https://chromium.googlesource.com/linux-syscall-support.git@63f24c8221a229f677d26ebe8f3d1528a9d787ac&apos;, &apos;src/third_party/mockito/src&apos;: &apos;https://chromium.googlesource.com/external/mockito/mockito.git@de83ad4598ad4cf5ea53c69a8a8053780b04b850&apos;, &apos;src/third_party/openh264/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/cisco/openh264@0fd88df93c5dcaf858c57eb7892bd27763f0f0ac&apos;, &apos;src/third_party/openmax_dl&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/openmax.git@7acede9c039ea5d14cf326f44aad1245b9e674a7&apos;, &apos;src/third_party/requests/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/kennethreitz/requests.git@f172b30356d821d180fa4ecfa3e71c7274a32de4&apos;, &apos;src/third_party/robolectric/robolectric&apos;: &apos;https://chromium.googlesource.com/external/robolectric.git@2a0b6ba221c14f3371813a676ce06143353e448d&apos;, &apos;src/third_party/ub-uiautomator/lib&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ub-uiautomator.git@00270549ce3161ae72ceb24712618ea28b4f9434&apos;, &apos;src/third_party/usrsctp/usrsctplib&apos;: &apos;https://chromium.googlesource.com/external/github.com/sctplab/usrsctp@8679f2b0bf063ac894dc473debefd61dbbebf622&apos;, &apos;src/third_party/yasm/source/patched-yasm&apos;: &apos;https://chromium.googlesource.com/chromium/deps/yasm/patched-yasm.git@7da28c6c7c6a1387217352ce02b31754deb54d2a&apos;, &apos;src/tools&apos;: &apos;https://chromium.googlesource.com/chromium/src/tools@4718dd2b6d53fb68819b3fd23676b40935f4f31e&apos;, &apos;src/tools/gyp&apos;: &apos;https://chromium.googlesource.com/external/gyp.git@eb296f67da078ec01f5e3a9ea9cdc6d26d680161&apos;, &apos;src/tools/swarming_client&apos;: &apos;https://chromium.googlesource.com/external/swarming.client.git@11e31afa5d330756ff87aa12064bb5d032896cb5&apos;, &apos;src/buildtools/clang_format/script&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/cfe/tools/clang-format.git@c09c8deeac31f05bd801995c475e7c8070f9ecda&apos;, &apos;src/buildtools/third_party/libc++/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxx.git@b1ece9c037d879843b0b0f5a2802e1e9d443b75a&apos;, &apos;src/buildtools/third_party/libc++abi/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxxabi.git@0edb61e2e581758fc4cd4cd09fc588b3fc91a653&apos;, &apos;src/third_party/android_tools/ndk&apos;: &apos;https://chromium.googlesource.com/android_ndk.git@26d93ec07f3ce2ec2cdfeae1b21ee6f12ff868d8&apos;,&#125;]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之信令交互流程]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-signalling%2F</url>
    <content type="text"><![CDATA[无论是使用前端JS的WebRTC API接口，还是在WebRTC源码上构建自己的对聊框架，都需要遵循以下执行流程： 上述序列中，WebRTC并不提供Stun服务器和Signal服务器，服务器端需要自己实现。Stun服务器可以用google提供的实现stun协议的测试服务器（stun:stun.l.google.com:19302），Signal服务器则完全需要自己实现了，它需要在ClientA和ClientB之间传送彼此的SDP信息和candidate信息，ClientA和ClientB通过这些信息建立P2P连接来传送音视频数据。 stun/turn、relay服务器的实现在WebRTC源码中都有示例。 上述序列中，标注的场景是ClientA向ClientB发起对聊请求，调用描述如下： ClientA首先创建PeerConnection对象，然后打开本地音视频设备，将音视频数据封装成MediaStream添加到PeerConnection中。 ClientA调用PeerConnection的CreateOffer方法创建一个用于offer的SDP对象，SDP对象中保存当前音视频的相关参数。ClientA通过PeerConnection的SetLocalDescription方法将该SDP对象保存起来，并通过Signal服务器发送给ClientB。 ClientB接收到ClientA发送过的offer SDP对象，通过PeerConnection的SetRemoteDescription方法将其保存起来，并调用PeerConnection的CreateAnswer方法创建一个应答的SDP对象，通过PeerConnection的SetLocalDescription的方法保存该应答SDP对象并将它通过Signal服务器发送给ClientA。 ClientA接收到ClientB发送过来的应答SDP对象，将其通过PeerConnection的SetRemoteDescription方法保存起来。 在SDP信息的offer/answer流程中，ClientA和ClientB已经根据SDP信息创建好相应的音频Channel和视频Channel并开启Candidate数据的收集，Candidate数据可以简单地理解成Client端的IP地址信息（本地IP地址、公网IP地址、Relay服务端分配的地址）。 当ClientA收集到Candidate信息后，PeerConnection会通过OnIceCandidate接口给ClientA发送通知，ClientA将收到的Candidate信息通过Signal服务器发送给ClientB，ClientB通过PeerConnection的AddIceCandidate方法保存起来。同样的操作ClientB对ClientA再来一次。 这样ClientA和ClientB就已经建立了音视频传输的P2P通道，ClientB接收到ClientA传送过来的音视频流，会通过PeerConnection的OnAddStream回调接口返回一个标识ClientA端音视频流的MediaStream对象，在ClientB端渲染出来即可。同样操作也适应ClientB到ClientA的音视频流的传输。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git服务搭建]]></title>
    <url>%2F2017%2F04%2F25%2Fserver-git%2F</url>
    <content type="text"><![CDATA[纯git server软件安装环境:ubuntu16.0.4 安装Git-Core:sudo apt-get install python-setuptools 安装openssh-server和openssh-client:sudo apt-get install openssh-server openssh-client 安装python tool:sudo apt-get install python-setuptools 安装gitosis:12345git clone https://github.com/res0nat0r/gitosis.gitcd gitosis/sudo python setup.py install 添加管理账号12345678sudo adduser \ --system \ --shell /bin/sh \ --gecos &apos;git version control&apos; \ --group \ --disabled-password \ --home /home/git \ git 如果已有git账户,可以替换成gitmanager 创建链接映射由于gitosis默认状态下会将仓库放在用户的repositories目录下，例如gitmanager用户的仓库地址默认在 /home/gitmanager/repositories/目录下，这里我们需要创建一个链接映射。让他指向我们前面创建的专门用于存放项目的仓库目录/home/gitrepository。 1sudo ln -s /home/gitrepository /home/gitmanager/repositories 初始化管理用户 拷贝管理用户公钥到/tmp/下,如: 1scp ~/.ssh/id_rsa.pub gitmanager@192.168.0.68:/tmp/ 使用拷贝来的公钥初始化gitosis: 12sudo -H -u gitmanager gitosis-init &lt; /tmp/id_ras.pubsudo chmod 755 /home/gitmanager/repositories/gitosis-admin.git/hooks/post-update 配置账号 验证ssh1234ssh gitmanager@192.168.0.68TY allocation request failed on channel 0ERROR:gitosis.serve.main:Need SSH_ORIGINAL_COMMAND in environment. Connection to gitserver closed. 说明 Gitosis 认出了该用户的身份，但由于没有运行任何 Git 命令，所以它切断了连接。 克隆gitosis管理仓库:1git clone gitmanager@192.168.0.68:gitosis-admin.git 这会得到一个名为 gitosis-admin 的工作目录，主要由两部分组成： 12./gitosis.conf./keydir gitosis.conf 文件是用来设置用户、仓库和权限的控制文件。keydir 目录则是保存所有具有访问权限用户公钥的地方— 每人一个。在 keydir 里的文件名（比如上面的 qingkouwei.pub） 会自动从使用 gitosis-init 脚本导入的公钥尾部的描述中获取该名字。 看一下 gitosis.conf 文件的内容，它应该只包含与刚刚克隆的 gitosis-admin 相关的信息： 12345[gitosis][group gitosis-admin]members = qingkouweiwritable = gitosis-admin 要创建项目demo,在里面加入: 123[group demo]members = qingkouweiwritable = demo 要为demo项目添加用户user1: 123[group demo]members = qingkouwei user1writable = demo 并将用户user1的公钥计入到keydir,并且公钥名.pub和members里面的名字对应. 要添加对demo项目只读的用户: 1234567[group demo]members = qingkouwei user1writable = demo[group demo]members = user2readonly = demo 修改完配置文件和keydir,使用git push到gitosis-admin服务器.即可直接git add remote add suervename gitmanager@192.168.0.68:demo.git,然后直接将本地目录推送到demo仓库,不需要再服务器手动创建demo仓库,gitosis会帮忙自动创建. 常见问题 ERROR:gitosis.serve.main:Repository read access denied 原因: gitosis.conf中的members与keydir中的用户名不一致，如gitosis中的members = foo@bar，但keydir中的公密名却叫foo.pub 解决方法: 使keydir的名称与gitosis中members所指的名称一致。 改为members = foo 或 公密名称改为foo@bar.pub clone时报does not appear to be a git repository 原因: clone时不能用绝对路径，直接写gitosis-admin.git即可. 参考:https://git-scm.com/book/zh/v1/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84-Git-Gitosis gitlab服务搭建]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware中Bridged,NAT,host-only三种网络连接模式的原理和区别]]></title>
    <url>%2F2017%2F04%2F22%2Fvmware-network-mode%2F</url>
    <content type="text"><![CDATA[不同虚拟交换机应用在不同的联网模式Bridged、NAT、host-only、custom四种模式，下面分别介绍其具体分配： VMnet0：这是VMware用于虚拟桥接网络下的虚拟交换机； VMnet1：这是VMware用于虚拟Host-Only网络下的虚拟交换机； VMnet8：这是VMware用于虚拟NAT网络下的虚拟交换机； VMnet2~VMnet7及VMnet9：是VMware用于虚拟自定义custom网络下的虚拟交换机； VMware Network Adapter VMnet1：这是宿主机用于与Host-Only虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet8：这是宿主机用于与NAT虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet1与VMware Network Adapter VMnet8可以在宿主机网络连接中看到. 1.Bridged桥接模式VMware在桥接模式下，虚拟机使用VMware为该虚拟机分配的虚拟网卡，宿主机使用自身的物理网卡（有线或无线都行），并且默认使用虚拟交换机VMnet0来连接虚拟机的虚拟网卡和宿主机的物理网卡。在此模式下没有局域网动态地址分配DHCP服务器，也没有网络地址转换ＮＡＴ服务器，虚拟交换机没有连接DHCP服务器和ＮＡＴ服务器。宿主机的网口（插网线的那个口）与宿主机物理网卡相连，同时也就和虚拟机的虚拟网卡相连，也就是和虚拟交换机相连，所以虚拟机相当于在宿主机所在局域网内的一个单独的主机，他的行为和宿主机是同等地位的，没有依存关系。所有桥接下的网卡与网卡都是交换模式的，相互可以访问而不干扰。在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关与DNS需要与主机网卡一致原理图如下： 配置虚拟机网卡,编辑/etc/sysconfig/network-scripts/ifcfg-eth0: 1234567891011DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=noneIPADDR=192.168.31.128 #设置虚拟机ip地址,与主机ip地址在同一网段NETMASK=255.255.255.0 #设置子网掩码GATEWAY=192.168.31.1#设置虚拟网关,与主机相同DNS1=192.168.31.1 #设置虚拟机DNS,与主机相同 执行/etc/init.d/network restart重启虚拟机网卡,ping内网与外网测试. 2.NAT网络地址转换模式： 注意：红色的方框是nat服务器，nat服务器有两个网卡一个是虚拟内网网卡，一个是宿主机的物理网卡。禁用VmNet8，虚拟机仍然可以上网，ping通主机，但是主机ping不通虚拟机的网卡。在NAT模式中，主机网卡直接与虚拟NAT设备相连，然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上，这样就实现了虚拟机联网。那么我们会觉得很奇怪，为什么需要虚拟网卡VMware Network Adapter VMnet8呢？原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。弥补了NAT协议中外网不能访问局域网的缺点。 具体配置: 123456789101112DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=dhcp #动态获取ip地址,如果此处设置为静态,则下面手动配置ip需要在DHCP地址范围内#NAT模式也可以设置静态ip,但需要在DHCP地址范围内IPADDR=192.168.31.128NETMASK=255.255.255.0GATEWAY=192.168.31.1DNS1=192.168.31.1 3.Host-Only方式 注意：上图中的VmNet8应该为VmNet1。其实跟nat模式的图片是类似的，只是少了nat服务。 所以host-only上不了外网，只能实现主机的VmNet1网卡和虚拟机的虚拟网卡通信。 NAT介绍NAT（Network Address Translation，网络地址转换）是1994年提出的。当在专用网内部的一些主机本来已经分配到了本地IP地址（即仅在本专用网内使用的专用地址），但现在又想和因特网上的主机通信（并不需要加密）时，可使用NAT方法。 这种方法需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球IP地址。这样，所有使用本地地址的主机在和外界通信时，都要在NAT路由器上将其本地地址转换成全球IP地址，才能和因特网连接。 另外，这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用的IP地址空间的枯竭。 功能NAT不仅能解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。 宽带分享：这是 NAT 主机的最大功能。 安全防护：NAT 之内的 PC 联机到 Internet 上面时，他所显示的 IP 是 NAT 主机的公共 IP，所以 Client 端的 PC 当然就具有一定程度的安全了，外界在进行 portscan（端口扫描） 的时候，就侦测不到源Client 端的 PC 。 实现方式NAT的实现方式有三种，即静态转换Static Nat、动态转换Dynamic Nat和端口多路复用OverLoad。 静态转换是指将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一成不变的，某个私有IP地址只转换为某个公有IP地址。借助于静态转换，可以实现外部网络对内部网络中某些特定设备（如服务器）的访问。 动态转换是指将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定的，是随机的，所有被授权访问上Internet的私有IP地址可随机转换为任何指定的合法IP地址。也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态转换。动态转换可以使用多个合法外部地址集。当ISP提供的合法IP地址略少于网络内部的计算机数量时。可以采用动态转换的方式。 端口多路复用（Port address Translation,PAT)是指改变外出数据包的源端口并进行端口转换，即端口地址转换（PAT，Port Address Translation).采用端口多路复用方式。内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，从而可以最大限度地节约IP地址资源。同时，又可隐藏网络内部的所有主机，有效避免来自internet的攻击。因此，目前网络中应用最多的就是端口多路复用方式。 ALG（Application Level Gateway），即应用程序级网关技术：传统的NAT技术只对IP层和传输层头部进行转换处理，但是一些应用层协议，在协议数据报文中包含了地址信息。为了使得这些应用也能透明地完成NAT转换，NAT使用一种称作ALG的技术，它能对这些应用程序在通信时所包含的地址信息也进行相应的NAT转换。例如：对于FTP协议的PORT/PASV命令、DNS协议的 “A” 和 “PTR” queries命令和部分ICMP消息类型等都需要相应的ALG来支持。 如果协议数据报文中不包含地址信息，则很容易利用传统的NAT技术来完成透明的地址转换功能，通常我们使用的如下应用就可以直接利用传统的NAT技术：HTTP、TELNET、FINGER、NTP、NFS、ARCHIE、RLOGIN、RSH、RCP等。 工作原理借助于NAT，私有（保留）地址的”内部”网络通过路由器发送数据包时，私有地址被转换成合法的IP地址，一个局域网只需使用少量IP地址（甚至是1个）即可实现私有地址网络内所有计算机与Internet的通信需求。 NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。 NAPTNAPT（Network Address Port Translation），即网络端口地址转换，可将多个内部地址映射为一个合法公网地址，但以不同的协议端口号与不同的内部地址相对应，也就是&lt;内部地址+内部端口&gt;与&lt;外部地址+外部端口&gt;之间的转换。NAPT普遍用于接入设备中，它可以将中小型的网络隐藏在一个合法的IP地址后面。NAPT也被称为“多对一”的NAT，或者叫PAT（Port Address Translations，端口地址转换）、地址超载（address overloading）。 NAPT与动态地址NAT不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的TCP端口号。NAPT算得上是一种较流行的NAT变体，通过转换TCP或UDP协议端口号以及地址来提供并发性。除了一对源和目的IP地址以外，这个表还包括一对源和目的协议端口号，以及NAT盒使用的一个协议端口号。 NAPT的主要优势在于，能够使用一个全球有效IP地址获得通用性。主要缺点在于其通信仅限于TCP或UDP。当所有通信都采用TCP或UDP，NAPT允许一台内部计算机访问多台外部计算机，并允许多台内部主机访问同一台外部计算机，相互之间不会发生冲突。 NAT穿透方法目前常用的针对UDP的NAT 穿透（NAT Traversal）方法主要有：STUN、TURN、ICE、uPnP等。其中ICE方式由于其结合了STUN和TURN的特点，所以使用最为广泛。针对TCP的NAT穿透技术目前仍为难点。实用的技术仍然不多。 配置在配置NAT(网络地址转换)之前，首先需要了解内部本地地址和内部全局地址的分配情况。根据不同的需求，执行以下不同的配置任务。 内部源地址NAT配置 内部源地址NAPT配置 重叠地址NAT配置 TCP负载均衡]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网卡配置]]></title>
    <url>%2F2017%2F04%2F22%2Flinux-networkcard%2F</url>
    <content type="text"><![CDATA[linux网卡可以通过命令和配置文件配置,如果是桌面环境还可以通过图形化界面配置. 1.ifconfig(interfaces config)命令方式通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置(用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在)。 1.1命令格式1ifconfig [网络设备] [参数] 1.2命令功能ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 1.3命令参数 up 启动指定网络设备/网卡。 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。 arp 设置指定网卡是否支持ARP协议。 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 1.4使用实例1.4.1显示网络设备信息（激活状态的）命令:ifcofig 输出: 12345678910111213141516[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 说明 eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 1.4.2启动关闭指定网卡命令： ifconfig eth0 up ifconfig eth0 down 输出： 说明： ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.3为网卡配置和删除IPv6地址命令： ifconfig eth0 add 33ffe:3240:800:1005::2/64 ifconfig eth0 del 33ffe:3240:800:1005::2/64 输出： 说明： ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址； ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址； 练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.4用ifconfig修改MAC地址命令： ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 down //关闭网卡[root@localhost ~]# ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE //修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:AA:BB:CC:DD:EE inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB)[root@localhost ~]# ifconfig eth0 hw ether 00:50:56:BF:26:20 //关闭网卡并修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 1.4.5配置IP地址输出: 123[root@localhost ~]# ifconfig eth0 192.168.120.56[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 说明: ifconfig eth0 192.168.120.56 给eth0网卡配置IP地：192.168.120.56 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 /给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255 1.4.6启用和关闭ARP协议命令： ifconfig eth0 arp ifconfig eth0 -arp 输出： 12[root@localhost ~]# ifconfig eth0 arp[root@localhost ~]# ifconfig eth0 -arp 说明 ifconfig eth0 arp 开启网卡eth0 的arp协议； ifconfig eth0 -arp 关闭网卡eth0 的arp协议； 1.4.7 设置最大传输单元命令： ifconfig eth0 mtu 1500 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 mtu 1480[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1480 Metric:1 RX packets:8712395 errors:0 dropped:0 overruns:0 frame:0 TX packets:36631 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597062089 (569.4 MiB) TX bytes:2643973 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# ifconfig eth0 mtu 1500[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8712548 errors:0 dropped:0 overruns:0 frame:0 TX packets:36685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597072333 (569.4 MiB) TX bytes:2650581 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# 说明: 设置能通过的最大数据包大小为1500bytes 2.配置文件方式ubuntu配置文件:/etc/network/interfaces 1234567auto loiface lo inet loopbackauto eth0 #配置静态ipiface eth0 inet staticaddress 192.168.1.100netmask 255.255.255.0gateway 192.168.1.1 centos配置文件:/etc/sysconfig/network-scripts/ifcfg-eth0 123456789101112DEVICE=eth0(默认)HWADDR=00:0C:29:2E:36:16(默认)TYPE=Ethernet(默认)UUID=XXXXXXX(默认)ONBOOT=yes(默认为no,修改为yes意为每次reboot后 ifup eth0)MM_CONTROLLED=yes(默认)#BOOTPROTO=dhcp(dhcp为自动分配ip地址,我们把他注释了，在下面另外加)BOOTPROTO=static(新添加)IPV6INIT=no(新添加)USERCTL=no(新添加)IPADDR=192.168.164.100(新添加)NETMASK=255.255.255.0(新添加) service network restart重启网卡服务 3.图形界面方式添加虚拟网卡一台服务器需要设置多个ip,但又不想添加多块网卡,那就需要设置虚拟网卡.这里介绍几种方式在linux服务器上添加虚拟网卡. 比如向eth0中添加一块虚拟网卡: 1.快速创建删除虚拟网卡sudo ifconfig eth0: 192.168.10.10 up 以上的命令就可以在eth0网卡上创建一个叫eth0:0的虚拟网卡,他的地址是:192.168.1.63 如果不想要这个虚拟网卡了,可以使用如下命令删除: 1sudo ifconfig eth0:0 down 重启服务器或者网络后,虚拟网卡就没有了. 2.修改网卡配置文件在ubuntu下,网卡的配置文件是/etc/network/interfaces,所以我们修改它: sudo vim /etc/network/interfaces 在这个文件中增加如下内容并保存: 123456auto eth0:0iface eth0:0 inet staticaddress 192.168.10.10netmask 255.255.255.0#network 192.168.10.1#broadcast 192.168.1.255 保存后,我们需要重启网卡(重新加载配置文件)才会生效,使用如下命令重启:sudo /etc/init.d/networking restart 他的优点是重启服务器或者网卡配置不会丢失。 3.创建tag前两种方法都有一个特点，创建的网卡可有不同的ip地址，但是Mac地址相同。无法用来创建虚拟机。 添加虚拟网卡tap 1tunctl -b 其他配置命令: 显示网桥信息:brctl show 添加网桥:brctl addbr virbr0 激活网桥:ip link set virbr0 up 添加虚拟网卡tap:tunctl -b tap0 ——-&gt; 执行上面使命就会生成一个tap,后缀从0，1，2依次递增激活创建的tap:ip link set tap0 up 将tap0虚拟网卡添加到指定网桥上:brctl addif br0 tap0给网桥配制ip地址:ifconfig virbr1 169.254.251.4 up 将virbr1网桥上绑定的网卡eth5解除: brctl delif virb1 eth5 给virbr1网桥添加网卡eth6:brctl addif virbr1 eth6]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android声音播放与录制]]></title>
    <url>%2F2017%2F04%2F19%2Fissues-android-audio%2F</url>
    <content type="text"><![CDATA[AudioTrackAudioTrack类说明:123456789101112131415161718192021222324252627282930313233343536373839/** * The AudioTrack class manages and plays a single audio resource for Java applications. * It allows streaming of PCM audio buffers to the audio sink for playback. This is * achieved by &quot;pushing&quot; the data to the AudioTrack object using one of the * &#123;@link #write(byte[], int, int)&#125;, &#123;@link #write(short[], int, int)&#125;, * and &#123;@link #write(float[], int, int, int)&#125; methods. * * &lt;p&gt;An AudioTrack instance can operate under two modes: static or streaming.&lt;br&gt; * In Streaming mode, the application writes a continuous stream of data to the AudioTrack, using * one of the &#123;@code write()&#125; methods. These are blocking and return when the data has been * transferred from the Java layer to the native layer and queued for playback. The streaming * mode is most useful when playing blocks of audio data that for instance are: * * &lt;ul&gt; * &lt;li&gt;too big to fit in memory because of the duration of the sound to play,&lt;/li&gt; * &lt;li&gt;too big to fit in memory because of the characteristics of the audio data * (high sampling rate, bits per sample ...)&lt;/li&gt; * &lt;li&gt;received or generated while previously queued audio is playing.&lt;/li&gt; * &lt;/ul&gt; * * The static mode should be chosen when dealing with short sounds that fit in memory and * that need to be played with the smallest latency possible. The static mode will * therefore be preferred for UI and game sounds that are played often, and with the * smallest overhead possible. * * &lt;p&gt;Upon creation, an AudioTrack object initializes its associated audio buffer. * The size of this buffer, specified during the construction, determines how long an AudioTrack * can play before running out of data.&lt;br&gt; * For an AudioTrack using the static mode, this size is the maximum size of the sound that can * be played from it.&lt;br&gt; * For the streaming mode, data will be written to the audio sink in chunks of * sizes less than or equal to the total buffer size. * * AudioTrack is not final and thus permits subclasses, but such use is not recommended. */public class AudioTrack extends PlayerBase implements AudioRouting&#123; &#125; 构造方法说明1234567891011121314151617//根据采样率，采样精度，单双声道来得到frame的大小。int bufsize = AudioTrack.getMinBufferSize(8000,//每秒8K个点 AudioFormat.CHANNEL_CONFIGURATION_STEREO,//双声道AudioFormat.ENCODING_PCM_16BIT);//一个采样点16比特-2个字节//注意，按照数字音频的知识，这个算出来的是一秒钟buffer的大小。//创建AudioTrackAudioTrack trackplayer = new AudioTrack(AudioManager.STREAM_MUSIC, 8000, AudioFormat.CHANNEL_CONFIGURATION_ STEREO, AudioFormat.ENCODING_PCM_16BIT, bufsize,AudioTrack.MODE_STREAM);// trackplayer.play() ;//开始trackplayer.write(bytes_pkg, 0, bytes_pkg.length) ;//往track中写数据….trackplayer.stop();//停止播放trackplayer.release();//释放底层资源。 参数说明1. AudioTrack.MODE_STREAM的意思：AudioTrack中有MODE_STATIC和MODE_STREAM两种分类。 STREAM的意思是由用户在应用程序通过write方式把数据一次一次得写到audiotrack中。这个和我们在socket中发送数据一样，应用层从某个地方获取数据，例如通过编解码得到PCM数据，然后write到audiotrack。这种方式的坏处就是总是在JAVA层和Native层交互，效率损失较大。 而STATIC的意思是一开始创建的时候，就把音频数据放到一个固定的buffer，然后直接传给audiotrack，后续就不用一次次得write了。AudioTrack会自己播放这个buffer中的数据。 这种方法对于铃声等内存占用较小，延时要求较高的声音来说很适用。 2. StreamType这个在构造AudioTrack的第一个参数中使用。这个参数和Android中的AudioManager有关系，涉及到手机上的音频管理策略。 Android将系统的声音分为以下几类常见的（定义在AudioManager)： 1234567891011121314151617181920/** The audio stream for phone calls */public static final int STREAM_VOICE_CALL = AudioSystem.STREAM_VOICE_CALL;/** The audio stream for system sounds */public static final int STREAM_SYSTEM = AudioSystem.STREAM_SYSTEM;/** The audio stream for the phone ring */public static final int STREAM_RING = AudioSystem.STREAM_RING;/** The audio stream for music playback */public static final int STREAM_MUSIC = AudioSystem.STREAM_MUSIC;/** The audio stream for alarms */public static final int STREAM_ALARM = AudioSystem.STREAM_ALARM;/** The audio stream for notifications */public static final int STREAM_NOTIFICATION = AudioSystem.STREAM_NOTIFICATION;/** @hide The audio stream for phone calls when connected to bluetooth */public static final int STREAM_BLUETOOTH_SCO = AudioSystem.STREAM_BLUETOOTH_SCO;/** @hide The audio stream for enforced system sounds in certain countries (e.g camera in Japan) */public static final int STREAM_SYSTEM_ENFORCED = AudioSystem.STREAM_SYSTEM_ENFORCED;/** The audio stream for DTMF Tones */public static final int STREAM_DTMF = AudioSystem.STREAM_DTMF;/** @hide The audio stream for text to speech (TTS) */public static final int STREAM_TTS = AudioSystem.STREAM_TTS; 常用说明: STREAM_ALARM：警告声 STREAM_MUSCI：音乐声，例如music等 STREAM_RING：铃声 STREAM_SYSTEM：系统声音 STREAM_VOCIE_CALL：电话声音 为什么要分这么多呢？以前在台式机上开发的时候很少知道有这么多的声音类型，不过仔细思考下，发现这样做是有道理的。例如你在听music的时候接到电话，这个时候music播放肯定会停止，此时你只能听到电话，如果你调节音量的话，这个调节肯定只对电话起作用。当电话打完了，再回到music，你肯定不用再调节音量了。 其实系统将这几种声音的数据分开管理，所以，这个参数对AudioTrack来说，它的含义就是告诉系统，我现在想使用的是哪种类型的声音，这样系统就可以对应管理他们了。 AudioRecordAudioRecord说明The AudioRecord class manages the audio resources for Java applications to record audio from the audio input hardware of the platform. This is achieved by “pulling” (reading) the data from the AudioRecord object. The application is responsible for polling the AudioRecord object in time using one of the following three methods: read(byte[], int, int), read(short[], int, int) or read(ByteBuffer, int). The choice of which method to use will be based on the audio data storage format that is the most convenient for the user of AudioRecord. Upon creation, an AudioRecord object initializes its associated audio buffer that it will fill with the new audio data. The size of this buffer, specified during the construction, determines how long an AudioRecord can record before “over-running” data that has not been read yet. Data should be read from the audio hardware in chunks of sizes inferior to the total recording buffer size. audiosource类型定义在MediaRecorder中 1234567891011121314151617181920212223242526272829/** Default audio source **/ public static final int DEFAULT = 0; /** Microphone audio source */ public static final int MIC = 1; /** Voice call uplink (Tx) audio source */ public static final int VOICE_UPLINK = 2; /** Voice call downlink (Rx) audio source */ public static final int VOICE_DOWNLINK = 3; /** Voice call uplink + downlink audio source */ public static final int VOICE_CALL = 4; /** Microphone audio source with same orientation as camera if available, the main * device microphone otherwise */ public static final int CAMCORDER = 5; /** Microphone audio source tuned for voice recognition if available, behaves like * &#123;@link #DEFAULT&#125; otherwise. */ public static final int VOICE_RECOGNITION = 6; /** Microphone audio source tuned for voice communications such as VoIP. It * will for instance take advantage of echo cancellation or automatic gain control * if available. It otherwise behaves like &#123;@link #DEFAULT&#125; if no voice processing * is applied. */ public static final int VOICE_COMMUNICATION = 7; AudioManager获取系统音量代码 1234567891011121314151617181920212223242526272829//初始化AudioManager:AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE);//通话音量int max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_VOICE_CALL );int current = mAudioManager.getStreamVolume( AudioManager.STREAM_VOICE_CALL );Log.d(“VIOCE_CALL”, “max : ” + max + ” current : ” + current);//系统音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_SYSTEM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_SYSTEM );Log.d(“SYSTEM”, “max : ” + max + ” current : ” + current);//铃声音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_RING );current = mAudioManager.getStreamVolume( AudioManager.STREAM_RING );Log.d(“RING”, “max : ” + max + ” current : ” + current);//音乐音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_MUSIC );current = mAudioManager.getStreamVolume( AudioManager.STREAM_MUSIC );Log.d(“MUSIC”, “max : ” + max + ” current : ” + current);//提示声音音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_ALARM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_ALARM );Log.d(“ALARM”, “max : ” + max + ” current : ” + current); ps： 游戏过程中只允许调整多媒体音量，而不允许调整通话音量。 1setVolumeControlStream(AudioManager.STREAM_MUSIC); 控制音量AudioManager提供了设置音量的方法： 1public void setStreamVolume(intstreamType,intindex,intflags) 其中streamType有内置的常量，去文档里面就可以看到。 使用示例: 12345678910111213141516171819202122232425//音量控制,初始化定义 AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE); //最大音量 int maxVolume = mAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC); //当前音量 int currentVolume = mAudioManager.getStreamVolume(AudioManager.STREAM_MUSIC);//直接控制音量if(isSilent)&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0); &#125;else&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, tempVolume, 0); //tempVolume:音量绝对值 &#125; //以一步步长控制音量的增减，并弹出系统默认音量控制条：//降低音量，调出系统音量控制 if(flag == 0)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_LOWER, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; //增加音量，调出系统音量控制 else if(flag == 1)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_RAISE, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; 监听按键手动控制音量 123456789101112131415161718192021AudioManager audio = (AudioManager) getSystemService(Service.AUDIO_SERVICE);@Overridepublic boolean onKeyDown(int keyCode, KeyEvent event) &#123; switch (keyCode) &#123; case KeyEvent.KEYCODE_VOLUME_UP: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_RAISE, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; case KeyEvent.KEYCODE_VOLUME_DOWN: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_LOWER, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; default: break; &#125; return super.onKeyDown(keyCode, event); 插入耳机状态仍使用扬声器外放音乐插入耳机的时候也可以选择使用扬声器播放音乐，来电铃声就是这么用的。但是只能用MediaPlayer，播放音频文件。 使用AudioTrack.write播放是行不通的(有待验证)。按理说AudioRecord、AudioTrack类相对于MediaRecorder mediaPlayer来说，更加接近底层，应该也行得通的。 插入耳机，选择外放的代码如下(兼容性验证)： 123456789AudioManager audioManager = (AudioManager) this.getSystemService(Context.AUDIO_SERVICE); audioManager.setMicrophoneMute(false); audioManager.setSpeakerphoneOn(true);//使用扬声器外放，即使已经插入耳机 setVolumeControlStream(AudioManager.STREAM_MUSIC);//控制声音的大小 audioManager.setMode(AudioManager.STREAM_MUSIC); //播放一段声音，查看效果 MediaPlayer playerSound = MediaPlayer.create(this, Uri.parse(&quot;file:///system/media/audio/ui/camera_click.ogg&quot;)); playerSound.start(); 使用STREAM_VOCIE_CALL播放声音与耳机冲突使用STREAM_VOCIE_CALL播放声音在某些手机,比如魅蓝等上面会导致声音仍外放,耳机没声音现象. WebRtc使用STREAM_VOCIE_CALL播放声音,导致某些手机声音低,没法使用音量键调节,插入耳机声音仍外放等问题.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>issue</tag>
        <tag>Audio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown中嵌入LaTex]]></title>
    <url>%2F2017%2F04%2F16%2Flatex%2F</url>
    <content type="text"><![CDATA[MarkDown中使用标识符$$和$$$$即可引入LaTeX语法,前者使用时不换行,即在所使用位置使用LaTeX的格式,后者会换行后居中 部分希腊字母 命令 显示 命令 显示 \alpha α A A \beta β B B \gamma γ \Gamma \varGamma Γ Γ delta δ \Delta \varDelta Δ Δ \epsilon ϵ E E \eta η H H \theta θ \Theta \varTheta Θ Θ \kappa κ K K \lambda λ \Lambda \varLambda Λ Λ \mu μ M M \nu ν N N \pi π \Pi \varPi Π Π \rho ρ P P \sigma σ \Sigma \varSigma Σ Σ \tau τ T T \phi \varphi ϕ φ \Phi \varPhi Φ Φ \omega ω \Omega \varOmega Ω Ω 全部24个字母: 名称 大写 Tex 小写 Tex alpha A A α \alpha beta B B β\ beta gamma Γ \Gamma γ \gamma delta Δ \Delta δ \delta epsilon E E ϵ \epsilon zeta Z Z ζ \zeta eta H H η \eta theta Θ \Theta θ \theta iota I I ι \iota kappa K K κ \kappa lambda Λ \Lambda λ \lambda mu M M μ \mu nu N N ν \nu xi Ξ \Xi ξ \xi omicron O O ο \omicron pi Π \Pi π \pi rho P P ρ \rho sigma Σ \Sigma σ \sigma tau T T τ \tau upsilon Υ \Upsilon υ \upsilon phi Φ \Phi ϕ \phi chi X X χ \chi psi Ψ \Psi ψ \psi omega Ω \Omega ω \omega 部分运算符 命令 显示 命令 显示 \pm ± \mp ∓ \times × \div ÷ \circ ∘ \bullet ∙ \cdot ⋅ \cup ∪ \cap ∩ \subset ⊂ \supset ⊃ \subseteq ⊆ \supseteq ⊇ \leq ≤ \geq ≥ \propto ∝ 其他符号 命令 显示 命令 显示 \cdotp ⋅ \cdots ⋯ \ddots ⋱ \infty ∞ \partial ∂ \bot ⊥ \hat{a} â \tilde{a} ã \bar{a} a¯ \vec{a} a⃗ \dot{a} a˙ \sqrt{a} a‾‾√ \sqrt[3]{2} a‾‾√3 a^{3} a3 \frac{1}{a} 1a \lim_{x \to 0} lima→0 集合关系符号 说明 命令 集合的大括号 { … }\ 集合中的竖线$\mid$ \mid 属于 \in 不属于 \not\in A包含于B A\subset B A真包含于B A\subsetneqq B A包含B A\supset B A真包含B A\supsetneqq B A不包含于B A\not\subset B A交B A\cap B A并B A\cup B A的闭包 \overline{A} A减去B A\setminus B 实数集合 \mathbb{R} 空集 \emptyset 表格中竖线用&amp;#124; 括号总结 功能 语法 显示 不好看 ( \frac{1}{2} ) $(\frac{1}{2})$ 好一点 \left( \frac{1}{2} \right) $\left ( \frac{1}{2} \right )$ 可以使用\left和\right来显示不同的括号： 功能 语法 显示 圆括号，小括号 \left( \frac{a}{b} \right) $\left( \frac{a}{b} \right)$ 方括号，中括号 \left[ \frac{a}{b} \right] $\left[ \frac{a}{b} \right]$ 花括号，大括号 \left\{ \frac{a}{b} \right\} $ \left{ \frac{a}{b} \right}$ 角括号 \left \langle \frac{a}{b} \right \rangle $\left\langle \frac{a}{b} \right \rangle$ 单竖线，绝对值 \left 竖线 \frac{a}{b} \right 竖线 双竖线，范 \left \ 竖线 \frac{a}{b} \right \ 竖线 取整函数 （Floor function） \left \lfloor \frac{a}{b} \right \rfloor $ \left \lfloor \frac{a}{b} \right \rfloor$ 取顶函数 （Ceiling function) \left \lceil \frac{c}{d} \right \rceil $ \left \lceil \frac{c}{d} \right \rceil$ 斜线与反斜线 \left / \frac{a}{b} \right \backslash $ \left / \frac{a}{b} \right \backslash$ 上下箭头 \left \uparrow \frac{a}{b} \right \downarrow \left \Uparrow \frac{a}{b} \right \Downarrow \left \updownarrow \frac{a}{b} \right \Updownarrow $\left \uparrow \frac{a}{b} \right \downarrow$ $\left \Uparrow \frac{a}{b} \right \Downarrow$ $\left \updownarrow \frac{a}{b} \right \Updownarrow$ 混合括号 \left [ 0,1 \right ) \left \langle \psi ) $\left [ 0,1 \right )$ $ \left \langle \psi \right)$ 单左括号 \left \{ \frac{a}{b} \right . $\left { \frac{a}{b} \right .$ 单右括号 \left . \frac{a}{b} \right \} $\left . \frac{a}{b} \right }$ 备注： 可以使用\big, \Big, \bigg, \Bigg控制括号的大小，比如代码\Bigg ( \bigg [ \Big \{ \big \langle \left | \| \frac{a}{b} \| \right | \big \rangle \Big \} \bigg ] \Bigg )显示 $$\Bigg ( \bigg [ \Big { \big \langle \left | | x | \right | \big \rangle \Big } \bigg ] \Bigg )$$ 矩阵基本用法使用$$\begin{matrix}…\end{matrix}$$这样的形式来表示矩阵，在\begin与\end之间加入矩阵中的元素即可。矩阵的行之间使用\\分隔，列之间使用&amp;分隔。 1234567$$ \begin&#123;matrix&#125; 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \end&#123;matrix&#125;$$ $$ \begin{matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \ \end{matrix} $$ 加括号如果要对矩阵加括号，可以像上文中提到的一样，使用\left与\right配合表示括号符号。也可以使用特殊的matrix。即替换\begin{matrix}…\end{matrix}中的matrix为pmatrix，bmatrix，Bmatrix，vmatrix,Vmatrix. 省略元素可以使用\cdots ⋯ \ddots ⋱ \vdots ⋮ 来省略矩阵中的元素 增广矩阵增广矩阵需要使用前面的array来实现 1234567$$ \left[ \begin&#123;array&#125;&#123;cc|c&#125; 1&amp;2&amp;3\\ 4&amp;5&amp;6 \end&#123;array&#125; \right]$$ $$ \left[ \begin{array}{cc|c} 1&amp;2&amp;3\ 4&amp;5&amp;6 \end{array} \right] $$ 表格使用$$\begin{array}{列样式}…\end{array}$$这样的形式来创建表格，列样式可以是clr表示居中，左，右对齐，还可以使用|表示一条竖线。表格中 各行使用\\分隔，各列使用&amp;分隔。使用\hline在本行前加入一条直线。 例如， 123456789$$\begin&#123;array&#125;&#123;c|lcr&#125;n &amp; \text&#123;Left&#125; &amp; \text&#123;Center&#125; &amp; \text&#123;Right&#125; \\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i \\\end&#123;array&#125;$$ 上标与下标上标和下标分别使用^与_，例如x_i^2：$x_i^2$ 。默认情况下，上下标符号仅仅对下一个组起作用。一个组即单个字符或者使用{..}包裹起来的内容。也就是说，如果使用10^10，会得到$10^10$ ，而10^{10}才是$10^{10}$ 。同时，大括号还能消除二义性，如x^5^6将得到一个错误，必须使用大括号来界定^的结合性，如{x^5}^6：${x^5}^6$ 或者 x^{5^6}：$x^{5^6}$ 。 对齐的公式分类表达式定义函数的时候经常需要分情况给出表达式，可使用\begin{cases}…\end{cases}。其中，使用\来分类，使用&amp;指示需要对齐的位置。如： 多重积分连分数方程组颜色公式标记与引用求和与积分分式与根式特殊函数与符号空间顶部符号 参考 http://mlworks.cn/posts/introduction-to-mathjax-and-latex-expression/]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高数1.函数与极限]]></title>
    <url>%2F2017%2F04%2F13%2Fam-function-and-limitaion%2F</url>
    <content type="text"><![CDATA[1.映射与函数1.1 集合1.1.1 集合的概念集合(集)是指具有某种特定性质的事物的总体,组成这个集合的事物成为该集合的元素(简称元) 表示:用大写拉丁字母A,B,C…表示集合,小写拉丁字母表示集合的元素 分类: 有限集 无限集 表示数集的字母的右上角标*表示该数集内排除0的集,标上+来表示数集内排除0和负数的集 常用表示 N={0, 1, 2, 3…};全体非负整数即自然数的集合 N+={1,2,3,…n,….};全体正整数的集合 Z={…,-n,…-3, -2,-1, 0, 1, 2, 3,…,n…};全体整数的集合 $Q=\lbrace \frac{p}{q}|p \in Z,q \in N^{+} \rbrace$;全体有理数集 全体实数记做R,R*为排除0的实数集,R+为全体正实数集. 子集概念: 子集 真子集 集合相等:互为子集 空集 $\emptyset$1.1.2 集合的运算 1.1.3 区间和领域]]></content>
      <categories>
        <category>高数</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android线程使用总结]]></title>
    <url>%2F2017%2F04%2F10%2Ftips-android-thread%2F</url>
    <content type="text"><![CDATA[1. Threading Performance在程序开发的实践当中，为了让程序表现得更加流畅，我们肯定会需要使用到多线程来提升程序的并发执行性能。但是编写多线程并发的代码一直以来都是一个相对棘手的问题，所以想要获得更佳的程序性能，我们非常有必要掌握多线程并发编程的基础技能。 众所周知，Android 程序的大多数代码操作都必须执行在主线程，例如系统事件(例如设备屏幕发生旋转)，输入事件(例如用户点击滑动等)，程序回调服务，UI 绘制以及闹钟事件等等。那么我们在上述事件或者方法中插入的代码也将执行在主线程。 一旦我们在主线程里面添加了操作复杂的代码，这些代码就很可能阻碍主线程去响应点击/滑动事件，阻碍主线程的 UI 绘制等等。我们知道，为了让屏幕的刷新帧率达到 60fps，我们需要确保 16ms 内完成单次刷新的操作。一旦我们在主线程里面执行的任务过于繁重就可能导致接收到刷新信号的时候因为资源被占用而无法完成这次刷新操作，这样就会产生掉帧的现象，刷新帧率自然也就跟着下降了(一旦刷新帧率降到 20fps 左右，用户就可以明显感知到卡顿不流畅了)。 为了避免上面提到的掉帧问题，我们需要使用多线程的技术方案，把那些操作复杂的任务移动到其他线程当中执行，这样就不容易阻塞主线程的操作，也就减小了出现掉帧的可能性。 为主线程减轻负的多线程方案有哪些呢？这些方案分别适合在什么场景下使用？Android 系统为我们提供了若干组工具类来帮助解决这个问题。 AsyncTask: 为 UI 线程与工作线程之间进行快速的切换提供一种简单便捷的机制。适用于当下立即需要启动，但是异步执行的生命周期短暂的使用场景。 HandlerThread: 为某些回调方法或者等待某些任务的执行设置一个专属的线程，并提供线程任务的调度机制。 ThreadPool: 把任务分解成不同的单元，分发到各个不同的线程上，进行同时并发处理。 IntentService: 适合于执行由 UI 触发的后台 Service 任务，并可以把后台任务执行的情况通过一定的机制反馈给 UI。 了解这些系统提供的多线程工具类分别适合在什么场景下，可以帮助我们选择合适的解决方案，避免出现不可预期的麻烦。虽然使用多线程可以提高程序的并发量，但是我们需要特别注意因为引入多线程而可能伴随而来的内存问题。举个例子，在 Activity 内部定义的一个 AsyncTask，它属于一个内部类，该类本身和外面的 Activity 是有引用关系的，如果 Activity 要销毁的时候，AsyncTask 还仍然在运行，这会导致 Activity 没有办法完全释放，从而引发内存泄漏。所以说，多线程是提升程序性能的有效手段之一，但是使用多线程却需要十分谨慎小心，如果不了解背后的执行机制以及使用的注意事项，很可能引起严重的问题。 2. Understanding Android Threading通常来说，一个线程需要经历三个生命阶段：开始，执行，结束。线程会在任务执行完毕之后结束，那么为了确保线程的存活，我们会在执行阶段给线程赋予不同的任务，然后在里面添加退出的条件从而确保任务能够执行完毕后退出。 在很多时候，线程不仅仅是线性执行一系列的任务就结束那么简单的，我们会需要增加一个任务队列，让线程不断的从任务队列中获取任务去进行执行，另外我们还可能在线程执行的任务过程中与其他的线程进行协作。如果这些细节都交给我们自己来处理，这将会是件极其繁琐又容易出错的事情。 所幸的是，Android 系统为我们提供了 Looper，Handler，MessageQueue 来帮助实现上面的线程任务模型： Looper: 能够确保线程持续存活并且可以不断的从任务队列中获取任务并进行执行。 Handler: 能够帮助实现队列任务的管理，不仅仅能够把任务插入到队列的头部，尾部，还可以按照一定的时间延迟来确保任务从队列中能够来得及被取消掉。 MessageQueue: 使用 Intent，Message，Runnable 作为任务的载体在不同的线程之间进行传递。 把上面三个组件打包到一起进行协作，这就是 HandlerThread 我们知道，当程序被启动，系统会帮忙创建进程以及相应的主线程，而这个主线程其实就是一个 HandlerThread。这个主线程会需要处理系统事件，输入事件，系统回调的任务，UI绘制等等任务，为了避免主线程任务过重，我们就会需要不断的开启新的工作线程来处理那些子任务。 3. Memory &amp; Threading增加并发的线程数会导致内存消耗的增加，平衡好这两者的关系是非常重要的。我们知道，多线程并发访问同一块内存区域有可能带来很多问题，例如读写的权限争夺问题，ABA 问题等等。为了解决这些问题，我们会需要引入锁的概念。 在 Android 系统中也无法避免因为多线程的引入而导致出现诸如上文提到的种种问题。Android UI 对象的创建，更新，销毁等等操作都默认是执行在主线程，但是如果我们在非主线程对UI对象进行操作，程序将可能出现异常甚至是崩溃。 另外，在非 UI 线程中直接持有 UI 对象的引用也很可能出现问题。例如Work线程中持有某个 UI 对象的引用，在 Work 线程执行完毕之前，UI 对象在主线程中被从 ViewHierarchy 中移除了，这个时候 UI 对象的任何属性都已经不再可用了，另外对这个 UI 对象的更新操作也都没有任何意义了，因为它已经从 ViewHierarchy 中被移除，不再绘制到画面上了。 不仅如此，View 对象本身对所属的 Activity 是有引用关系的，如果工作线程持续保有 View 的引用，这就可能导致 Activity 无法完全释放。除了直接显式的引用关系可能导致内存泄露之外，我们还需要特别留意隐式的引用关系也可能导致泄露。例如通常我们会看到在 Activity 里面定义的一个 AsyncTask，这种类型的 AsyncTask 与外部的 Activity 是存在隐式引用关系的，只要 Task 没有结束，引用关系就会一直存在，这很容易导致 Activity 的泄漏。更糟糕的情况是，它不仅仅发生了内存泄漏，还可能导致程序异常或者崩溃。 为了解决上面的问题，我们需要谨记的原则就是：不要在任何非 UI 线程里面去持有 UI 对象的引用。系统为了确保所有的 UI 对象都只会被 UI 线程所进行创建，更新，销毁的操作，特地设计了对应的工作机制(当 Activity 被销毁的时候，由该 Activity 所触发的非 UI 线程都将无法对UI对象进行操作，否者就会抛出程序执行异常的错误)来防止 UI 对象被错误的使用。 4. Good AsyncTask HuntingAsyncTask 是一个让人既爱又恨的组件，它提供了一种简便的异步处理机制，但是它又同时引入了一些令人厌恶的麻烦。一旦对 AsyncTask 使用不当，很可能对程序的性能带来负面影响，同时还可能导致内存泄露。 举个例子，常遇到的一个典型的使用场景：用户切换到某个界面，触发了界面上的图片的加载操作，因为图片的加载相对来说耗时比较长，我们需要在子线程中处理图片的加载，当图片在子线程中处理完成之后，再把处理好的图片返回给主线程，交给 UI 更新到画面上。 AsyncTask 的出现就是为了快速的实现上面的使用场景，AsyncTask 把在主线程里面的准备工作放到 onPreExecute()方法里面进行执行，doInBackground()方法执行在工作线程中，用来处理那些繁重的任务，一旦任务执行完毕，就会调用 onPostExecute()方法返回到主线程。 使用 AsyncTask 需要注意的问题有哪些呢？请关注以下几点： 首先，默认情况下，所有的 AsyncTask 任务都是被线性调度执行的，他们处在同一个任务队列当中，按顺序逐个执行。假设你按照顺序启动20个 AsyncTask，一旦其中的某个 AsyncTask 执行时间过长，队列中的其他剩余 AsyncTask 都处于阻塞状态，必须等到该任务执行完毕之后才能够有机会执行下一个任务。 为了解决上面提到的线性队列等待的问题，我们可以使用 AsyncTask.executeOnExecutor()强制指定 AsyncTask 使用线程池并发调度任务。 其次，如何才能够真正的取消一个 AsyncTask 的执行呢？我们知道 AsyncTaks 有提供 cancel()的方法，但是这个方法实际上做了什么事情呢？线程本身并不具备中止正在执行的代码的能力，为了能够让一个线程更早的被销毁，我们需要在 doInBackground()的代码中不断的添加程序是否被中止的判断逻辑. 一旦任务被成功中止，AsyncTask 就不会继续调用 onPostExecute()，而是通过调用 onCancelled()的回调方法反馈任务执行取消的结果。我们可以根据任务回调到哪个方法（是 onPostExecute 还是 onCancelled）来决定是对 UI 进行正常的更新还是把对应的任务所占用的内存进行销毁等。 最后，使用 AsyncTask 很容易导致内存泄漏，一旦把 AsyncTask 写成 Activity 的内部类的形式就很容易因为 AsyncTask 生命周期的不确定而导致 Activity 发生泄漏。 综上所述，AsyncTask 虽然提供了一种简单便捷的异步机制，但是我们还是很有必要特别关注到他的缺点，避免出现因为使用错误而导致的严重系统性能问题。 5. Getting a HandlerThread大多数情况下，AsyncTask 都能够满足多线程并发的场景需要（在工作线程执行任务并返回结果到主线程），但是它并不是万能的。例如打开相机之后的预览帧数据是通过 onPreviewFrame()的方法进行回调的，onPreviewFrame()和 open()相机的方法是执行在同一个线程的。 如果这个回调方法执行在 UI 线程，那么在 onPreviewFrame()里面将要执行的数据转换操作将和主线程的界面绘制，事件传递等操作争抢系统资源，这就有可能影响到主界面的表现性能。 我们需要确保 onPreviewFrame()执行在工作线程。如果使用 AsyncTask，会因为 AsyncTask 默认的线性执行的特性(即使换成并发执行)会导致因为无法把任务及时传递给工作线程而导致任务在主线程中被延迟，直到工作线程空闲，才可以把任务切换到工作线程中进行执行。 所以我们需要的是一个执行在工作线程，同时又能够处理队列中的复杂任务的功能，而 HandlerThread 的出现就是为了实现这个功能的，它组合了 Handler，MessageQueue，Looper 实现了一个长时间运行的线程，不断的从队列中获取任务进行执行的功能。 回到刚才的处理相机回调数据的例子，使用 HandlerThread 我们可以把 open()操作与 onPreviewFrame()的操作执行在同一个线程，同时还避免了 AsyncTask 的弊端。如果需要在 onPreviewFrame()里面更新 UI，只需要调用 runOnUiThread()方法把任务回调给主线程就够了。 HandlerThread 比较合适处理那些在工作线程执行，需要花费时间偏长的任务。我们只需要把任务发送给 HandlerThread，然后就只需要等待任务执行结束的时候通知返回到主线程就好了。 另外很重要的一点是，一旦我们使用了 HandlerThread，需要特别注意给 HandlerThread 设置不同的线程优先级，CPU 会根据设置的不同线程优先级对所有的线程进行调度优化。 掌握 HandlerThread 与 AsyncTask 之间的优缺点，可以帮助我们选择合适的方案。 6. Swimming in Threadpools线程池适合用在把任务进行分解，并发进行执行的场景。通常来说，系统里面会针对不同的任务设置一个单独的守护线程用来专门处理这项任务。例如使用 Networking Thread 用来专门处理网络请求的操作，使用 IO Thread 用来专门处理系统的 I\O 操作。针对那些场景，这样设计是没有问题的，因为对应的任务单次执行的时间并不长而且可以是顺序执行的。但是这种专属的单线程并不能满足所有的情况，例如我们需要一次性 decode 40张图片，每个线程需要执行 4ms 的时间，如果我们使用专属单线程的方案，所有图片执行完毕会需要花费 160ms(40*4)，但是如果我们创建10个线程，每个线程执行4个任务，那么我们就只需要16ms就能够把所有的图片处理完毕。 为了能够实现上面的线程池模型，系统为我们提供了 ThreadPoolExecutor 帮助类来简化实现，剩下需要做的就只是对任务进行分解就好了。 使用线程池需要特别注意同时并发线程数量的控制，理论上来说，我们可以设置任意你想要的并发数量，但是这样做非常的不好。因为 CPU 只能同时执行固定数量的线程数，一旦同时并发的线程数量超过 CPU 能够同时执行的阈值，CPU 就需要花费精力来判断到底哪些线程的优先级比较高，需要在不同的线程之间进行调度切换。 一旦同时并发的线程数量达到一定的量级，这个时候 CPU 在不同线程之间进行调度的时间就可能过长，反而导致性能严重下降。另外需要关注的一点是，每开一个新的线程，都会耗费至少 64K+ 的内存。为了能够方便的对线程数量进行控制，ThreadPoolExecutor 为我们提供了初始化的并发线程数量，以及最大的并发数量进行设置。 另外需要关注的一个问题是：Runtime.getRuntime().availableProcesser()方法并不可靠，他返回的值并不是真实的 CPU 核心数，因为 CPU 会在某些情况下选择对部分核心进行睡眠处理，在这种情况下，返回的数量就只能是激活的 CPU 核心数。 7. The Zen of IntentService默认的 Service 是执行在主线程的，可是通常情况下，这很容易影响到程序的绘制性能(抢占了主线程的资源)。除了前面介绍过的 AsyncTask 与 HandlerThread，我们还可以选择使用 IntentService 来实现异步操作。IntentService 继承自普通 Service 同时又在内部创建了一个 HandlerThread，在 onHandlerIntent()的回调里面处理扔到 IntentService 的任务。所以 IntentService 就不仅仅具备了异步线程的特性，还同时保留了 Service 不受主页面生命周期影响的特点。 如此一来，我们可以在 IntentService 里面通过设置闹钟间隔性的触发异步任务，例如刷新数据，更新缓存的图片或者是分析用户操作行为等等，当然处理这些任务需要小心谨慎。 使用 IntentService 需要特别留意以下几点： 首先，因为 IntentService 内置的是 HandlerThread 作为异步线程，所以每一个交给 IntentService 的任务都将以队列的方式逐个被执行到，一旦队列中有某个任务执行时间过长，那么就会导致后续的任务都会被延迟处理。 其次，通常使用到 IntentService 的时候，我们会结合使用 BroadcastReceiver 把工作线程的任务执行结果返回给主 UI 线程。使用广播容易引起性能问题，我们可以使用 LocalBroadcastManager 来发送只在程序内部传递的广播，从而提升广播的性能。我们也可以使用 runOnUiThread() 快速回调到主 UI 线程。 最后，包含正在运行的 IntentService 的程序相比起纯粹的后台程序更不容易被系统杀死，该程序的优先级是介于前台程序与纯后台程序之间的。 8. Threading and Loaders当启动工作线程的 Activity 被销毁的时候，我们应该做点什么呢？为了方便的控制工作线程的启动与结束，Android 为我们引入了 Loader 来解决这个问题。我们知道 Activity 有可能因为用户的主动切换而频繁的被创建与销毁，也有可能是因为类似屏幕发生旋转等被动原因而销毁再重建。在 Activity 不停的创建与销毁的过程当中，很有可能因为工作线程持有 Activity 的 View 而导致内存泄漏(因为工作线程很可能持有 View 的强引用，另外工作线程的生命周期还无法保证和 Activity 的生命周期一致，这样就容易发生内存泄漏了)。除了可能引起内存泄漏之外，在 Activity 被销毁之后，工作线程还继续更新视图是没有意义的，因为此时视图已经不在界面上显示了。 Loader 的出现就是为了确保工作线程能够和 Activity 的生命周期保持一致，同时避免出现前面提到的问题。 LoaderManager 会对查询的操作进行缓存，只要对应 Cursor 上的数据源没有发生变化，在配置信息发生改变的时候(例如屏幕的旋转)，Loader 可以直接把缓存的数据回调到 onLoadFinished()，从而避免重新查询数据。另外系统会在 Loader 不再需要使用到的时候(例如使用 Back 按钮退出当前页面)回调 onLoaderReset()方法，我们可以在这里做数据的清除等等操作。 在 Activity 或者 Fragment 中使用 Loader 可以方便的实现异步加载的框架，Loader 有诸多优点。但是实现 Loader 的这套代码还是稍微有点点复杂，Android 官方为我们提供了使用 Loader 的示例代码进行参考学习。 9. The Importance of Thread Priority理论上来说，我们的程序可以创建出非常多的子线程一起并发执行的，可是基于 CPU 时间片轮转调度的机制，不可能所有的线程都可以同时被调度执行，CPU 需要根据线程的优先级赋予不同的时间片。 Android 系统会根据当前运行的可见的程序和不可见的后台程序对线程进行归类，划分为 forground 的那部分线程会大致占用掉 CPU 的90%左右的时间片，background 的那部分线程就总共只能分享到5%-10%左右的时间片。之所以设计成这样是因为 forground 的程序本身的优先级就更高，理应得到更多的执行时间。 默认情况下，新创建的线程的优先级默认和创建它的母线程保持一致。如果主 UI 线程创建出了几十个工作线程，这些工作线程的优先级就默认和主线程保持一致了，为了不让新创建的工作线程和主线程抢占 CPU 资源，需要把这些线程的优先级进行降低处理，这样才能给帮组 CPU 识别主次，提高主线程所能得到的系统资源。 在 Android 系统里面，我们可以通过 android.os.Process.setThreadPriority(int) 设置线程的优先级，参数范围从-20到19，数值越小优先级越高。Android 系统还为我们提供了以下的一些预设值，我们可以通过给不同的工作线程设置不同数值的优先级来达到更细粒度的控制。 大多数情况下，新创建的线程优先级会被设置为默认的0，主线程设置为0的时候，新创建的线程还可以利用 THREAD_PRIORITY_LESS_FAVORABLE 或者 THREAD_PRIORITY_MORE_FAVORABLE 来控制线程的优先级。 Android 系统里面的 AsyncTask 与 IntentService已经默认帮助我们设置线程的优先级，但是对于那些非官方提供的多线程工具类，我们需要特别留意根据需要自己手动来设置线程的优先级。 10. Profile GPU Rendering : M Update从 Android M 系统开始，系统更新了 GPU Profiling 的工具来帮助我们定位 UI 的渲染性能问题。早期的 CPU Profiling 工具只能粗略的显示出 Process，Execute，Update 三大步骤的时间耗费情况。 但是仅仅显示三大步骤的时间耗费情况，还是不太能够清晰帮助我们定位具体的程序代码问题，所以在 Android M 版本开始，GPU Profiling 工具把渲染操作拆解成如下8个详细的步骤进行显示。 旧版本中提到的 Proces，Execute，Update 还是继续得到了保留，他们的对应关系如下： 接下去我们看下其他五个步骤分别代表了什么含义： Sync &amp; Upload：通常表示的是准备当前界面上有待绘制的图片所耗费的时间，为了减少该段区域的执行时间，我们可以减少屏幕上的图片数量或者是缩小图片本身的大小。 Measure &amp; Layout：这里表示的是布局的 onMeasure 与 onLayout 所花费的时间，一旦时间过长，就需要仔细检查自己的布局是不是存在严重的性能问题。 Animation：表示的是计算执行动画所需要花费的时间，包含的动画有 ObjectAnimator，ViewPropertyAnimator，Transition 等等。一旦这里的执行时间过长，就需要检查是不是使用了非官方的动画工具或者是检查动画执行的过程中是不是触发了读写操作等等。 Input Handling：表示的是系统处理输入事件所耗费的时间，粗略等于对于的事件处理方法所执行的时间。一旦执行时间过长，意味着在处理用户的输入事件的地方执行了复杂的操作。 Misc/Vsync Delay：如果稍加注意，我们可以在开发应用的 Log 日志里面看到这样一行提示：I/Choreographer(691): Skipped XXX frames! The application may be doing too much work on its main thread。这意味着我们在主线程执行了太多的任务，导致 UI 渲染跟不上 vSync 的信号而出现掉帧的情况。 上面八种不同的颜色区分了不同的操作所耗费的时间，为了便于我们迅速找出那些有问题的步骤，GPU Profiling 工具会显示 16ms 的阈值线，这样就很容易找出那些不合理的性能问题，再仔细看对应具体哪个步骤相对来说耗费时间比例更大，结合上面介绍的细化步骤，从而快速定位问题，修复问题。 http://bugly.qq.com/bbs/forum.php?mod=viewthread&amp;tid=1022]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MP4格式解析]]></title>
    <url>%2F2017%2F04%2F09%2Fm-f-mp4%2F</url>
    <content type="text"><![CDATA[目前MP4的概念被炒得很火，也很乱。最开始MP4指的是音频（MP3的升级版），即MPEG-2 AAC标准。随后MP4概念被转移到视频上，对应的是MPEG-4标准。而现在我们流行的叫法，多半是指能播放MPEG-4标准编码格式视频的播放器。但是这篇文章介绍的内容跟上面这些都无关，我们要讨论的是MP4文件封装格式，对应的标准为ISO/IEC 14496-12，即信息技术 视听对象编码的第12部分：ISO 基本媒体文件格式（Information technology Coding of audio-visual objects Part 12: ISO base media file format）。ISO/IEC组织指定的标准一般用数字表示，ISO/IEC 14496即MPEG-4标准。 MP4视频文件封装格式是基于QuickTime容器格式定义的，因此参考QuickTime的格式定义对理解MP4文件格式很有帮助。MP4文件格式是一个十分开放的容器，几乎可以用来描述所有的媒体结构，MP4文件中的媒体描述与媒体数据是分开的，并且媒体数据的组织也很自由，不一定要按照时间顺序排列，甚至媒体数据可以直接引用其他文件。同时，MP4也支持流媒体。MP4目前被广泛用于封装h.264视频和AAC音频，是高清视频的代表。MP4格式的官方文件后缀名是“.mp4”，还有其他的以mp4为基础进行的扩展或者是缩水版本的格式，包括：M4V, 3GP, F4V等。 1.概述MP4文件中的所有数据都装在box（QuickTime中为atom）中，也就是说MP4文件由若干个box组成，每个box有类型和长度，可以将box理解为一个数据对象块。box中可以包含另一个box，这种box称为container box。一个MP4文件首先会有且只有一个“ftyp”类型的box，作为MP4格式的标志并包含关于文件的一些信息；之后会有且只有一个“moov”类型的box（Movie Box），它是一种container box，子box包含了媒体的metadata信息；MP4文件的媒体数据包含在“mdat”类型的box（Midia Data Box）中，该类型的box也是container box，可以有多个，也可以没有（当媒体数据全部引用其他文件时），媒体数据的结构由metadata进行描述。 下面是一些概念： track 表示一些sample的集合，对于媒体数据来说，track表示一个视频或音频序列。 hint track 这个特殊的track并不包含媒体数据，而是包含了一些将其他数据track打包成流媒体的指示信息。 sample 对于非hint track来说，video sample即为一帧视频，或一组连续视频帧，audio sample即为一段连续的压缩音频，它们统称sample。对于hint track，sample定义一个或多个流媒体包的格式。 sample table 指明sampe时序和物理布局的表。 chunk 一个track的几个sample组成的单元。 不讨论涉及hint的内容，只关注包含媒体数据的本地MP4文件。下图为一个典型的MP4文件的结构树。 2.Boxbox中的字节序为网络字节序，也就是大端字节序（Big-Endian），简单的说，就是一个32位的4字节整数存储方式为高位字节在内存的低端。Box由header和body组成，其中header统一指明box的大小和类型，body根据类型有不同的意义和格式。 标准的box开头的4个字节（32位）为box size，该大小包括box header和box body整个box的大小，这样我们就可以在文件中定位各个box。如果size为1，则表示这个box的大小为large size，真正的size值要在largesize域上得到。（实际上只有“mdat”类型的box才有可能用到large size。）如果size为0，表示该box为文件的最后一个box，文件结尾即为该box结尾。（同样只存在于“mdat”类型的box中。）size后面紧跟的32位为box type，一般是4个字符，如“ftyp”、“moov”等，这些box type都是已经预定义好的，分别表示固定的意义。如果是“uuid”，表示该box为用户扩展类型。如果box type是未定义的，应该将其忽略。 3.File Type Box(ftyp)该box有且只有1个，并且只能被包含在文件层，而不能被其他box包含。该box应该被放在文件的最开始，指示该MP4文件应用的相关信息。 “ftyp” body依次包括1个32位的major brand（4个字符），1个32位的minor version（整数）和1个以32位（4个字符）为单位元素的数组compatible brands。这些都是用来指示文件应用级别的信息。该box的字节实例如下： 1200000000h: 00 00 00 18 66 74 79 70 6D 70 34 32 00 00 00 01 ; ....ftypmp42....00000010h: 6D 70 34 32 6D 70 34 31 00 00 5A EB 6D 6F 6F 76 ; mp42mp41..Zmoov 4.Movie Box(moov)该box包含了文件媒体的metadata信息，“moov”是一个container box，具体内容信息由子box诠释。同File Type Box一样，该box有且只有一个，且只被包含在文件层。一般情况下，“moov”会紧随“ftyp”出现。 一般情况下（限于篇幅，本文只讲解常见的MP4文件结构），“moov”中会包含1个“mvhd”和若干个“trak”。其中“mvhd”为header box，一般作为“moov”的第一个子box出现（对于其他container box来说，header box都应作为首个子box出现）。“trak”包含了一个track的相关信息，是一个container box。下图为部分“moov”的字节实例，其中红色部分为box header，绿色为“mvhd”，黄色为一部分“trak”。 4.1 Movie Header Box(mvhd)“mvhd”接口如下表: 字段 字节数 意义 box size 4 box大小 box type 4 box类型 version 1 box版本，0或1，一般为0。（以下字节数均按version=0） flags 3 creation time 4 创建时间（相对于UTC时间1904-01-01零点的秒数） modification time 4 修改时间 time scale 4 文件媒体在1秒时间内的刻度值，可以理解为1秒长度的时间单元数 duration 4 该track的时间长度，用duration和time scale值可以计算track时长，比如audio track的time scale = 8000, duration = 560128，时长为70.016，video track的time scale = 600, duration = 42000，时长为70 rate 4 推荐播放速率，高16位和低16位分别为小数点整数部分和小数部分，即[16.16] 格式，该值为1.0（0x00010000）表示正常前向播放 volume 2 与rate类似，[8.8] 格式，1.0（0x0100）表示最大音量 reserved 10 保留位 matrix 36 视频变换矩阵 pre-defined 24 next track id 4 下一个track使用的id号 4.2Track Box(trak)“trak”也是一个container box，其子box包含了该track的媒体数据引用和描述（hint track除外）。一个MP4文件中的媒体可以包含多个track，且至少有一个track，这些track之间彼此独立，有自己的时间和空间信息。“trak”必须包含一个“tkhd”和一个“mdia”，此外还有很多可选的box（略）。其中“tkhd”为track header box，“mdia”为media box，该box是一个包含一些track媒体数据信息box的container box。 box类型说明 ftypefile type,说明文件类型 moovmetadata container,存放媒体信息的地方 mvhdmovie header,文件的总体信息,如时长,创建时间等 mvhdmovie header,文件的总体信息,如时长,创建时间等 traktrack or stream container,存放视频/音频流的容器 tkhdtrack header,track的总体信息,如时长,宽高等 mediatrak media information container mdhdmedia header,定义TimeScale,trak需要通过TimeScale转换成真实时间 hdlrhandler,表明本trak类型,指明是video/audio/还是hint minfmedia information container,数据在子box中 stblsample table box,存放时间/偏移的映射关系表,数据在子box中 stsdsample descriptions stts(decoding)time-to-sample,”时戳-sample序号”的映射表 stscsample-to-chunk,sample和chunk的映射表,这里的算法比较巧妙 stszsample size,每个sample的大小 stz2sample size,另一种sample size的存储算法,更节省空间 stsssync sample table,可随机访问的sample列表(关键帧列表) stcochunk offset,每个chunk的偏移,sample的偏移可根据其他box推算出来 co6464-bit chunk offset mdatmedia data container,具体的媒体数据 Mdat Box引用 http://xhelmboyx.tripod.com/formats/mp4-layout.txt]]></content>
      <categories>
        <category>音视频封装</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>format</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android系列基础知识]]></title>
    <url>%2F2015%2F04%2F13%2Ftips-android-knowledge%2F</url>
    <content type="text"><![CDATA[四大组件ActivityActivity生命周期 不同场景下Activity生命周期的变化过程 启动Activity： onCreate()—&gt;onStart()—&gt;onResume()，Activity进入运行状态。 Activity退居后台： 当前Activity转到新的Activity界面或按Home键回到主屏： onPause()—&gt;onStop()，进入停滞状态。 Activity返回前台： onRestart()—&gt;onStart()—&gt;onResume()，再次回到运行状态。 Activity退居后台，且系统内存不足， 系统会杀死这个后台状态的Activity，若再次回到这个Activity,则会走onCreate()–&gt;onStart()—&gt;onResume() 锁定屏与解锁屏幕 只会调用onPause()，而不会调用onStop方法，开屏后则调用onResume() Activity 四中launchMode standard singleTop singleTask singleInstance 我们可以在AndroidManifest.xml配置的android:launchMode属性为以上四种之一。 standard standard模式是默认的启动模式，不用为配置android:launchMode属性即可，当然也可以指定值为standard。standard启动模式，不管有没有已存在的实例，都生成新的实例。 singleTop 我们在上面的基础上为指定属性android:launchMode=”singleTop”，系统就会按照singleTop启动模式处理跳转行为。跳转时系统会先在栈结构中寻找是否有一个Activity实例正位于栈顶，如果有则不再生成新的，而是直接使用。如果系统发现存在有Activity实例,但不是位于栈顶，重新生成一个实例。 这就是singleTop启动模式，如果发现有对应的Activity实例正位于栈顶，则重复利用，不再生成新的实例。 singleTask 如果发现有对应的Activity实例，则使此Activity实例之上的其他Activity实例统统出栈，使此Activity实例成为栈顶对象，显示到幕前。 singleInstance 这种启动模式比较特殊，因为它会启用一个新的栈结构，将Acitvity放置于这个新的栈结构中，并保证不再有其他Activity实例进入。 LaunchMode使用场景 singleTop适合接收通知启动的内容显示页面。例如，某个新闻客户端的新闻内容页面，如果收到10个新闻推送，每次都打开一个新闻内容页面是很烦人的。 singleTask适合作为程序入口点。例如浏览器的主界面。不管从多少个应用启动浏览器，只会启动主界面一次，其余情况都会走onNewIntent，并且会清空主界面上面的其他页面。 singleInstance应用场景：闹铃的响铃界面。 你以前设置了一个闹铃：上午6点。在上午5点58分，你启动了闹铃设置界面，并按 Home 键回桌面；在上午5点59分时，你在微信和朋友聊天；在6点时，闹铃响了，并且弹出了一个对话框形式的 Activity(名为 AlarmAlertActivity) 提示你到6点了(这个 Activity 就是以 SingleInstance 加载模式打开的)，你按返回键，回到的是微信的聊天界面，这是因为 AlarmAlertActivity 所在的 Task 的栈只有他一个元素， 因此退出之后这个 Task 的栈空了。如果是以 SingleTask 打开 AlarmAlertActivity，那么当闹铃响了的时候，按返回键应该进入闹铃设置界面。fragment 问题 若Activity已经销毁,此时AsynTask执行完并返回结果,会报异常么? 当一个App旋转时，整个Activity会被销毁和重建。当Activity重启时，AsyncTask中对该Activity的引用是无效的，因此onPostExecute()就不会起作用，若AsynTask正在执行，折会报 view not attached to window manager 异常.同样也是生命周期的问题，在 Activity 的onDestory()方法中调用Asyntask.cancal方法，让二者的生命周期同步 内存不足时,系统会杀死后台的Activity,如果需要进行一些临时状态的保存,在哪个方法进行:Activity的 onSaveInstanceState() 和 onRestoreInstanceState()并不是生命周期方法,不同于 onCreate()、onPause()等生命周期方法，它们并不一定会被触发。当应用遇到意外情况（如：内存不足、用户直接按Home键）由系统销毁一个Activity，onSaveInstanceState() 会被调用。但是当用户主动去销毁一个Activity时，例如在应用中按返回键，onSaveInstanceState()就不会被调用。除非该activity是被用户主动销毁的，通常onSaveInstanceState()只适合用于保存一些临时性的状态，而onPause()适合用于数据的持久化保存。 Android两个应用能在同一个任务栈吗？栈一般以包名命名，两个应用的签名和udid要相同 Service保证Service在后台不被kill的方法 Service设置成START_STICKY kill 后会被重启（等待5秒左右），重传Intent，保持与重启前一样 通过 startForeground将进程设置为前台进程， 做前台服务，优先级和前台应用一个级别​，除非在系统内存非常缺，否则此进程不会被 kill 双进程Service： 让2个进程互相保护**，其中一个Service被清理后，另外没被清理的进程可以立即重启进程 QQ黑科技: 在应用退到后台后，另起一个只有 1 像素的页面停留在桌面上，让自己保持前台状态，保护自己不被后台清理工具杀死 在已经root的设备下，修改相应的权限文件,将App伪装成系统级的应用 Android4.0系列的一个漏洞，已经确认可行 用C编写守护进程(即子进程) : Android系统中当前进程(Process)fork出来的子进程，被系统认为是两个不同的进程。当父进程被杀死的时候，子进程仍然可以存活，并不受影响。鉴于目前提到的在Android-&gt;- Service层做双守护都会失败，我们可以fork出c进程，多进程守护。死循环在那检查是否还存在，具体的思路如下（Android5.0以上的版本不可行） 用C编写守护进程(即子进程)，守护进程做的事情就是循环检查目标进程是否存在，不存在则启动它。 在NDK环境中将1中编写的C代码编译打包成可执行文件(BUILD_EXECUTABLE)。主进程启动时将守护进程放入私有目录下，赋予可执行权限，启动它即可。 联系厂商，加入白名单 Service进程优先级在AndroidManifest.xml文件中对于intent-filter可以通过android:priority = “1000”这个属性设置最高优先级，1000是最高值，如果数字越小则优先级越低，同时适用于广播。 IntentServicesIntentService是Service的子类，是一个异步的，会自动停止的服务，很好解决了传统的Service中处理完耗时操作忘记停止并销毁Service的问题 生成一个默认的且与线程相互独立的工作线程执行所有发送到onStartCommand()方法的Intent,可以在onHandleIntent()中处理. 串行队列,每次只运行一个任务,不存在线程安全问题,所有任务执行完后自动停止服务,不需要自己手动调用stopSelf()来停止. BroadcastReceiver\Android引入广播机制原因 从MVC的角度考虑(应用程序内) 其实回答这个问题的时候还可以这样问，android为什么要有那4大组件，现在的移动开发模型基本上也是照搬的web那一套MVC架构，只不过是改了点嫁妆而已。android的四大组件本质上就是为了实现移动或者说嵌入式设备上的MVC架构，它们之间有时候是一种相互依存的关系，有时候又是一种补充关系，引入广播机制可以方便几大组件的信息和数据交互。 程序间互通消息(例如在自己的应用程序内监听系统来电) 效率上(参考UDP的广播协议在局域网的方便性) 设计模式上(反转控制的一种应用，类似监听者模式) 注册广播的两种方法 静态注册:在清单文件中注册， 常见的有监听设备启动，常驻注册不会随程序生命周期改变 动态注册:在代码中注册，随着程序的结束，也就停止接受广播了 补充一点：有些广播只能通过动态方式注册，比如时间变化事件、屏幕亮灭事件、电量变更事件，因为这些事件触发频率通常很高，如果允许后台监听，会导致进程频繁创建和销毁，从而影响系统整体性能 两种广播类型普通广播为全局广播,LocalBroadcastManager是Android Support包提供了一个工具，是用来在同一个应用内的不同组件间发送Broadcast的。 使用LocalBroadcastManager有如下好处： 发送的广播只会在自己App内传播，不会泄露给其他App，确保隐私数据不会泄露 其他App也无法向你的App发送该广播，不用担心其他App会来搞破坏 比系统全局广播更加高效 和系统广播使用方式类似： 先通过LocalBroadcastManager lbm = LocalBroadcastManager.getInstance(this); 获取实例,然后通过函数 registerReceiver来注册监听器 ContentProvider实现数据共享当一个应用程序需要把自己的数据暴露给其他程序使用时，该就用程序就可通过提供ContentProvider来实现；其他应用程序就可通过ContentResolver来操作ContentProvider暴露的数据。 一旦某个应用程序通过ContentProvider暴露了自己的数据操作接口，那么不管该应用程序是否启动，其他应用程序都可以通过该接口来操作该应用程序的内部数据，包括增加数据、删除数据、修改数据、查询数据等。 ContentProvider以某种Uri的形式对外提供数据，允许其他应用访问或修改数据；其他应用程序使用ContentResolver根据Uri去访问操作指定数据。 步骤： 定义自己的ContentProvider类，该类需要继承Android提供的ContentProvider基类。 在AndroidManifest.xml文件中注册个ContentProvider，注册ContenProvider时需要为它绑定一个URL。 例： android:authorities=”com.myit.providers.MyProvider” /&gt; 说明：authorities就相当于为该ContentProvider指定URL。 注册后，其他应用程序就可以通过该Uri来访问MyProvider所暴露的数据了。 接下来，使用ContentResolver操作数据，Context提供了如下方法来获取ContentResolver对象。 一般来说，ContentProvider是单例模式，当多个应用程序通过ContentResolver来操作 ContentProvider提供的数据时，ContentResolver调用的数据操作将会委托给同一个ContentProvider处理。 使用ContentResolver操作数据只需两步： 1、调用Activity的ContentResolver获取ContentResolver对象。 2、根据需要调用ContentResolver的insert()、delete()、update()和query（）方法操作数据即可 ContentProvider的主要还是用于数据共享，其可以对Sqlite，SharePreferences，File等进行数据操作用来共享数据。而sql的可以理解为数据库的一门语言，可以使用它完成CRUD等一系列的操作 View与布局LinearLayout和RelativeLayout性能对比 RelativeLayout会让子View调用2次onMeasure，LinearLayout 在有weight时，也会调用子View2次onMeasure RelativeLayout的子View如果高度和RelativeLayout不同，则会引发效率问题，当子View很复杂时，这个问题会更加严重。如果可以，尽量使用padding代替margin。 在不影响层级深度的情况下,使用LinearLayout和FrameLayout而不是RelativeLayout。 最后再思考一下文章开头那个矛盾的问题，为什么Google给开发者默认新建了个RelativeLayout，而自己却在DecorView中用了个LinearLayout。因为DecorView的层级深度是已知而且固定的，上面一个标题栏，下面一个内容栏。采用RelativeLayout并不会降低层级深度，所以此时在根节点上用LinearLayout是效率最高的。而之所以给开发者默认新建了个RelativeLayout是希望开发者能采用尽量少的View层级来表达布局以实现性能最优，因为复杂的View嵌套对性能的影响会更大一些。 绘制自定义view的基本流程 明确需求，确定你想实现的效果 确定是使用组合控件的形式还是全新自定义的形式，组合控件即使用多个系统控件来合成一个新控件，你比如titilebar，这种形式相对简单，参考 如果是完全自定义一个view的话，你首先需要考虑继承哪个类，是View呢，还是ImageView等子类。 根据需要去复写View#onDraw、View#onMeasure、View#onLayout方法 根据需要去复写dispatchTouchEvent、onTouchEvent方法 根据需要为你的自定义view提供自定义属性，即编写attr.xml,然后在代码中通过TypedArray等类获取到自定义属性值 需要处理滑动冲突、像素转换等问题 View的绘制流程 measure()方法，layout()，draw()三个方法主要存放了一些标识符，来判断每个View是否需要再重新测量，布局或者绘制，主要的绘制过程还是在onMeasure，onLayout，onDraw这个三个方法中 onMesarue() 为整个View树计算实际的大小，即设置实际的高(对应属性:mMeasuredHeight)和宽(对应属性: mMeasureWidth)，每个View的控件的实际宽高都是由父视图和本身视图决定的。 onLayout() 为将整个根据子视图的大小以及布局参数将View树放到合适的位置上。 onDraw() 开始绘制图像，绘制的流程如下 首先绘制该View的背景 调用onDraw()方法绘制视图本身 (每个View都需要重载该方法，ViewGroup不需要实现该方法) 如果该View是ViewGroup，调用dispatchDraw ()方法绘制子视图 绘制滚动条 自定义View执行invalidate()方法,不会回调onDraw()可能的原因 自定义一个view时，重写onDraw。调用view.invalidate(),会触发onDraw和computeScroll()。前提是该view被附加在当前窗口. view.postInvalidate(); //是在非UI线程上调用的 自定义一个ViewGroup，重写onDraw。onDraw可能不会被调用，原因是需要先设置一个背景(颜色或图)。表示这个group有东西需要绘制了，才会触发draw，之后是onDraw。因此，一般直接重写dispatchDraw来绘制viewGroup.自定义一个ViewGroup,dispatchDraw会调用drawChild. 事件传递机制 事件从Activity.dispatchTouchEvent()开始传递，只要没有被停止或拦截，从最上层的View(ViewGroup)开始一直往下(子View)传递。子View可以通过onTouchEvent()对事件进行处理。 事件由父View(ViewGroup)传递给子View，ViewGroup可以通过onInterceptTouchEvent()对事件做拦截，停止其往下传递。 如果事件从上往下传递过程中一直没有被停止，且最底层子View没有消费事件，事件会反向往上传递，这时父View(ViewGroup)可以进行消费，如果还是没有被消费的话，最后会到Activity的onTouchEvent()函数。 如果View没有对ACTION_DOWN进行消费，之后的其他事件不会传递过来。 OnTouchListener优先于onTouchEvent()对事件进行消费。 上面的消费即表示相应函数返回值为true。 View中setOnTouchListener中的onTouch,onTouchEvent,onClick的执行顺序:onTouch优于onTouchEvent,onTouchEvent优于onClick Android下滑冲突的常见解决思路:相关的滑动组件 重写onInterceptTouchEvent，然后判断根据xy值，来决定是否要拦截当前操作 动画三种动画 逐帧动画(Drawable Animation)： 加载一系列Drawable资源来创建动画，简单来说就是播放一系列的图片来实现动画效果，可以自定义每张图片的持续时间 补间动画(Tween Animation)： Tween可以对View对象实现一系列简单的动画效果，比如位移，缩放，旋转，透明度等等。但是它并不会改变View属性的值，只是改变了View的绘制的位置，比如，一个按钮在动画过后，不在原来的位置，但是触发点击事件的仍然是原来的坐标。 属性动画(Property Animation)： 动画的对象除了传统的View对象，还可以是Object对象，动画结束后，Object对象的属性值被实实在在的改变了 动画原理Animation框架定义了透明度，旋转，缩放和位移几种常见的动画，而且控制的是整个View，实现原理是每次绘制视图时View所在的ViewGroup中的drawChild函数获取该View的Animation的Transformation值，然后调用canvas.concat(transformToApply.getMatrix())，通过矩阵运算完成动画帧，如果动画没有完成，继续调用invalidate()函数，启动下次绘制来驱动动画，动画过程中的帧之间间隙时间是绘制函数所消耗的时间，可能会导致动画消耗比较多的CPU资源，最重要的是，动画改变的只是显示，并不能相应事件 属性动画特性如果你的需求中只需要对View进行移动、缩放、旋转和淡入淡出操作，那么补间动画确实已经足够健全了。但是很显然，这些功能是不足以覆盖所有的场景的，一旦我们的需求超出了移动、缩放、旋转和淡入淡出这四种对View的操作，那么补间动画就不能再帮我们忙了，也就是说它在功能和可扩展方面都有相当大的局限性，那么下面我们就来看看补间动画所不能胜任的场景。 注意上面我在介绍补间动画的时候都有使用“对View进行操作”这样的描述，没错，补间动画是只能够作用在View上的。也就是说，我们可以对一个Button、TextView、甚至是LinearLayout、或者其它任何继承自View的组件进行动画操作，但是如果我们想要对一个非View的对象进行动画操作，抱歉，补间动画就帮不上忙了。可能有的朋友会感到不能理解，我怎么会需要对一个非View的对象进行动画操作呢？这里我举一个简单的例子，比如说我们有一个自定义的View，在这个View当中有一个Point对象用于管理坐标，然后在onDraw()方法当中就是根据这个Point对象的坐标值来进行绘制的。也就是说，如果我们可以对Point对象进行动画操作，那么整个自定义View的动画效果就有了。显然，补间动画是不具备这个功能的，这是它的第一个缺陷。 然后补间动画还有一个缺陷，就是它只能够实现移动、缩放、旋转和淡入淡出这四种动画操作，那如果我们希望可以对View的背景色进行动态地改变呢？很遗憾，我们只能靠自己去实现了。说白了，之前的补间动画机制就是使用硬编码的方式来完成的，功能限定死就是这些，基本上没有任何扩展性可言。 最后，补间动画还有一个致命的缺陷，就是它只是改变了View的显示效果而已，而不会真正去改变View的属性。什么意思呢？比如说，现在屏幕的左上角有一个按钮，然后我们通过补间动画将它移动到了屏幕的右下角，现在你可以去尝试点击一下这个按钮，点击事件是绝对不会触发的，因为实际上这个按钮还是停留在屏幕的左上角，只不过补间动画将这个按钮绘制到了屏幕的右下角而已。 优化布局优化 避免OverDraw过渡绘制 优化布局层级 避免嵌套过多无用布局 当我们在画布局的时候，如果能实现相同的功能，优先考虑相对布局，然后在考虑别的布局，不要用绝对布局。 使用标签把复杂的界面需要抽取出来 使用标签，因为它在优化UI结构时起到很重要的作用。目的是通过删减多余或者额外的层级，从而优化整个Android Layout的结构。核心功能就是减少冗余的层次从而达到优化UI的目的！ ViewStub 是一个隐藏的，不占用内存空间的视图对象，它可以在运行时延迟加载布局资源文件。ListView卡顿的原因以及优化策略 重用converView： 通过复用converview来减少不必要的view的创建，另外Infalte操作会把xml文件实例化成相应的View实例，属于IO操作，是耗时操作。 减少findViewById()操作： 将xml文件中的元素封装成viewholder静态类，通过converview的setTag和getTag方法将view与相应的holder对象绑定在一起，避免不必要的findviewbyid操作 避免在 getView 方法中做耗时的操作: 例如加载本地 Image 需要载入内存以及解析 Bitmap ，都是比较耗时的操作，如果用户快速滑动listview，会因为getview逻辑过于复杂耗时而造成滑动卡顿现象。用户滑动时候不要加载图片，待滑动完成再加载，可以使用这个第三方库glide Item的布局层次结构尽量简单，避免布局太深或者不必要的重绘 尽量能保证 Adapter 的 hasStableIds() 返回 true 这样在 notifyDataSetChanged() 的时候，如果item内容并没有变化，ListView 将不会重新绘制这个 View，达到优化的目的 在一些场景中，ScollView内会包含多个ListView，可以把listview的高度写死固定下来。 由于ScollView在快速滑动过程中需要大量计算每一个listview的高度，阻塞了UI线程导致卡顿现象出现，如果我们每一个item的高度都是均匀的，可以通过计算把listview的高度确定下来，避免卡顿现象出现 使用 RecycleView 代替listview： 每个item内容的变动，listview都需要去调用notifyDataSetChanged来更新全部的item，太浪费性能了。RecycleView可以实现当个item的局部刷新，并且引入了增加和删除的动态效果，在性能上和定制上都有很大的改善 ListView 中元素避免半透明： 半透明绘制需要大量乘法计算，在滑动时不停重绘会造成大量的计算，在比较差的机子上会比较卡。 在设计上能不半透明就不不半透明。实在要弄就把在滑动的时候把半透明设置成不透明，滑动完再重新设置成半透明。 尽量开启硬件加速： 硬件加速提升巨大，避免使用一些不支持的函数导致含泪关闭某个地方的硬件加速。当然这一条不只是对 ListView。 ViewHolder为什么要被声明成静态内部类 这个是考静态内部类和非静态内部类的主要区别之一。非静态内部类会隐式持有外部类的引用，就像大家经常将自定义的adapter在Activity类里，然后在adapter类里面是可以随意调用外部activity的方法的。当你将内部类定义为static时，你就调用不了外部类的实例方法了，因为这时候静态内部类是不持有外部类的引用的。声明ViewHolder静态内部类，可以将ViewHolder和外部类解引用。大家会说一般ViewHolder都很简单，不定义为static也没事吧。确实如此，但是如果你将它定义为static的，说明你懂这些含义。万一有一天你在这个ViewHolder加入一些复杂逻辑，做了一些耗时工作，那么如果ViewHolder是非静态内部类的话，就很容易出现内存泄露。如果是静态的话，你就不能直接引用外部类，迫使你关注如何避免相互引用。 所以将 ViewHolder内部类 定义为静态的，是一种好习惯 内存泄露问题 资源对象没有关闭造成,如查询数据库没有关闭游标 构造Adapter时,没有使用缓存ConvertView Bitmap对象在不使用时调用recycle()释放内存 context逃逸问题 注册没有取消,如动态注册广播在Activity销毁前没有unregisterReceiver 集合对象未清理,如无用时没有释放对象的引用 在Activity中使用非静态的内部类，并开启一个长时间运行的线程，因为内部类持有Activity的引用，会导致Activity本来可以被gc时却长期得不到回收 OOM发生情况 类的静态变量持有大数据对象 静态变量长期维持到大数据对象的引用，阻止垃圾回收。 非静态内部类存在静态实例 非静态内部类会维持一个到外部类实例的引用，如果非静态内部类的实例是静态的，就会间接长期维持着外部类的引用，阻止被回收掉。 资源对象未关闭 资源性对象比如（Cursor，File文件等）往往都用了一些缓冲，我们在不使用的时候，应该及时关闭它们， 以便它们的缓冲及时回收内存。它们的缓冲不仅存在于java虚拟机内，还存在于java虚拟机外。 如果我们仅仅是把它的引用设置为null,而不关闭它们，往往会造成内存泄露。 解决办法： 比如SQLiteCursor（在析构函数finalize（）,如果我们没有关闭它，它自己会调close()关闭）， 如果我们没有关闭它，系统在回收它时也会关闭它，但是这样的效率太低了。 因此对于资源性对象在不使用的时候，应该调用它的close()函数，将其关闭掉，然后才置为null. 在我们的程序退出时一定要确保我们的资源性对象已经关闭。 程序中经常会进行查询数据库的操作，但是经常会有使用完毕Cursor后没有关闭的情况。如果我们的查询结果集比较小， 对内存的消耗不容易被发现，只有在常时间大量操作的情况下才会复现内存问题，这样就会给以后的测试和问题排查带来困难和风险，记得try catch后，在finally方法中关闭连接 Handler内存泄漏 Handler作为内部类存在于Activity中，但是Handler生命周期与Activity生命周期往往并不是相同的，比如当Handler对象有Message在排队，则无法释放，进而导致本该释放的Acitivity也没有办法进行回收。 解决办法:声明handler为static类，这样内部类就不再持有外部类的引用了，就不会阻塞Activity的释放.如果内部类实在需要用到外部类的对象，可在其内部声明一个弱引用引用外部类 一些不良代码习惯 有些代码并不造成内存泄露，但是他们的资源没有得到重用，频繁的申请内存和销毁内存，消耗CPU资源的同时，也引起内存抖动 解决方案 如果需要频繁的申请内存对象和和释放对象，可以考虑使用对象池来增加对象的复用。 例如ListView便是采用这种思想，通过复用converview来避免频繁的GC 避免oom 使用更加轻量的数据结构 例如，我们可以考虑使用ArrayMap/SparseArray而不是HashMap等传统数据结构。通常的HashMap的实现方式更加消耗内存，因为它需要一个额外的实例对象来记录Mapping操作。另外，SparseArray更加高效，在于他们避免了对key与value的自动装箱（autoboxing），并且避免了装箱后的解箱。 避免在Android里面使用Enum Android官方培训课程提到过“Enums often require more than twice as much memory as static constants. You should strictly avoid using enums on Android.”，具体原理请参考《Android性能优化典范（三）》，所以请避免在Android里面使用到枚举。 减小Bitmap对象的内存占用 Bitmap是一个极容易消耗内存的大胖子，减小创建出来的Bitmap的内存占用可谓是重中之重，，通常来说有以下2个措施： inSampleSize：缩放比例，在把图片载入内存之前，我们需要先计算出一个合适的缩放比例，避免不必要的大图载入。 decode format：解码格式，选择ARGB_6666/RBG_545/ARGB_4444/ALPHA_6，存在很大差异 Bitmap对象的复用 缩小Bitmap的同时，也需要提高BitMap对象的复用率，避免频繁创建BitMap对象，复用的方法有以下2个措施 LRUCache : “最近最少使用算法”在Android中有极其普遍的应用。ListView与GridView等显示大量图片的控件里，就是使用LRU的机制来缓存处理好的Bitmap，把近期最少使用的数据从缓存中移除，保留使用最频繁的数据， inBitMap高级特性:利用inBitmap的高级特性提高Android系统在Bitmap分配与释放执行效率。使用inBitmap属性可以告知Bitmap解码器去尝试使用已经存在的内存区域，新解码的Bitmap会尝试去使用之前那张Bitmap在Heap中所占据的pixel data内存区域，而不是去问内存重新申请一块区域来存放Bitmap。利用这种特性，即使是上千张的图片，也只会仅仅只需要占用屏幕所能够显示的图片数量的内存大小 使用更小的图片 在涉及给到资源图片时，我们需要特别留意这张图片是否存在可以压缩的空间，是否可以使用更小的图片。尽量使用更小的图片不仅可以减少内存的使用，还能避免出现大量的InflationException。假设有一张很大的图片被XML文件直接引用，很有可能在初始化视图时会因为内存不足而发生InflationException，这个问题的根本原因其实是发生了OOM。 StringBuilder 在有些时候，代码中会需要使用到大量的字符串拼接的操作，这种时候有必要考虑使用StringBuilder来替代频繁的“+”。 避免在onDraw方法里面执行对象的创建 类似onDraw等频繁调用的方法，一定需要注意避免在这里做创建对象的操作，因为他会迅速增加内存的使用，而且很容易引起频繁的gc，甚至是内存抖动。 ANRANR全称Application Not Responding，意思就是程序未响应。如果一个应用无法响应用户的输入，系统就会弹出一个ANR对话框，用户可以自行选择继续等待亦或者是停止当前程序。一旦出现下面两种情况，则弹出ANR对话框 应用在5秒内未响应用户的输入事件（如按键或者触摸） BroadcastReceiver未在10秒内完成相关的处理 Service在特定的时间内无法处理完成 超时的原因一般有两种： (1)当前的事件没有机会得到处理（UI线程正在处理前一个事件没有及时完成或者looper被某种原因阻塞住） (2)当前的事件正在处理，但没有及时完成 UI线程尽量只做跟UI相关的工作，耗时的工作（数据库操作，I/O，连接网络或者其他可能阻碍UI线程的操作）放入单独的线程处理，尽量用Handler来处理UI thread和thread之间的交互。 UI线程主要包括如下： Activity:onCreate(), onResume(), onDestroy(), onKeyDown(), onClick() AsyncTask: onPreExecute(), onProgressUpdate(), onPostExecute(), onCancel() Mainthread handler: handleMessage(), post(runnable r) 如何定位ANR错误开发机器上,查看/data/anr/traces.text.最新的ANR信息在最开始部分. 如何避免ANR避免ANR最核心的一点就是在主线程减少耗时操作.通常需要从以下几个方案下手: 使用子线程处理耗时IO操作。 降低子线程优先级使用Thread或者HandlerThread时，调用Process.setThreadPriority(Process.THREAD_PRIORITY_BACKGROUND)设置优先级，否则仍然会降低程序响应，因为默认Thread的优先级和主线程相同。 使用Handler处理子线程结果，而不是使用Thread.wait()或者Thread.sleep()来阻塞主线程。 Activity的onCreate和onResume回调中尽量避免耗时的代码 BroadcastReceiver中onReceive代码也要尽量减少耗时操作建议使用IntentService处理。IntentService是一个异步的，会自动停止的服务，很好解决了传统的Service中处理完耗时操作忘记停止并销毁Service的问题 nativeDalvik,JVM,ART区别什么是Dalvik？Dalvik是Google公司自己设计用于Android平台的虚拟机。 Dalvik虚拟机是Google等厂商合作开发的Android移动设备平台的核心组成部分之一。 它可以支持已转换为**.dex格式**的Java应用程序的运行，.dex格式是专为Dalvik设计的一种压缩格式，适合内存和处理器速度有限的系统。 Dalvik 经过优化，允许在有限的内存中同时运行多个虚拟机的实例，并且每一个Dalvik 应用作为一个独立的Linux 进程执行。独立的进程可以防止在虚拟机崩溃的时候所有程序都被关闭。 很长时间以来，Dalvik虚拟机一直被用户指责为拖慢安卓系统运行速度不如IOS的根源。 2014年6月25日，Android L 正式亮相于召开的谷歌I/O大会，Android L 改动幅度较大，谷歌将直接删除Dalvik，代替它的是传闻已久的ART。 什么是ART？即Android Runtime ART 的机制与 Dalvik 不同。在Dalvik下，应用每次运行的时候，字节码都需要通过即时编译器（just in time ，JIT）转换为机器码，这会拖慢应用的运行效率，而在ART 环境中，应用在第一次安装的时候，字节码就会预先编译成机器码，使其成为真正的本地应用。这个过程叫做预编译（AOT,Ahead-Of-Time）。这样的话，应用的启动(首次)和执行都会变得更加快速。 ART优缺点 优点： 系统性能的显著提升。 用启动更快、运行更快、体验更流畅、触感反馈更及时。 更长的电池续航能力。 支持更低的硬件。 缺点： 机器码占用的存储空间更大，字节码变为机器码之后，可能会增加10%-20%（不过在应用包中，可执行的代码常常只是一部分。比如最新的 Google+ APK 是 28.3 MB，但是代码只有 6.9 MB。） 应用的安装时间会变长。 JVMJVM其核心目的，是为了构建一个真正跨OS平台，跨指令集的程序运行环境(VM)。DVM的目的是为了将android OS的本地资源和环境，以一种统一的界面提供给应用程序开发。严格来说，DVM不是真正的VM，它只是开发的时候提供了VM的环境，并不是在运行的时候提供真正的VM容器。这也是为什么JVM必须设计成stack-based的原因。 Dalvik和JVM有啥关系？主要区别： Dalvik是基于寄存器的，而JVM是基于栈的。 Dalvik运行dex文件，而JVM运行java字节码 自Android 2.2开始，Dalvik支持JIT（just-in-time，即时编译技术）。优化后的Dalvik较其他标准虚拟机存在一些不同特性: 占用更少空间 为简化翻译，常量池只使用32位索引 标准Java字节码实行8位堆栈指令,Dalvik使用16位指令集直接作用于局部变量。局部变量通常来自4位的“虚拟寄存器”区。这样减少了Dalvik的指令计数，提高了翻译速度。 当Android启动时，Dalvik VM 监视所有的程序（APK），并且创建依存关系树，为每个程序优化代码并存储在Dalvik缓存中。Dalvik第一次加载后会生成Cache文件，以提供下次快速加载，所以第一次会很慢。 Dalvik解释器采用预先算好的Goto地址，每个指令对内存的访问都在64字节边界上对齐。这样可以节省一个指令后进行查表的时间。为了强化功能, Dalvik还提供了快速翻译器（Fast Interpreter）。 一般来说,基于堆栈的机器必须使用指令才能从堆栈上的加载和操作数据,因此,相对基于寄存器的机器，它们需要更多的指令才能实现相同的性能。但是基于寄存器机器上的指令必须经过编码,因此,它们的指令往往更大。 Dalvik虚拟机既不支持Java SE 也不支持Java ME类库(如：Java类,AWT和Swing都不支持)。 相反,它使用自己建立的类库（Apache Harmony Java的一个子集）。 JVM：所有的jar程序，其运行环境完全是由JVM来提供，包括运行时，各类资源的调度，而JVM的架构，其设计为一个JVM里面可以运行多个java程序，JVM就像一个真正的“机器”，可以跑着多个程序。如果去看看一些企业级的JVM(例如tom cat，WAS)，从OS的进程管理中，一般你只能看见一个JVM的进程(当然，你也可以起多个JVM，但JVM架构就是OS-JVM-APP的3层运行时模式)，而看不见JVM里面运行的程序，而一个JVM里，可以跑多个java app。简单得说，JVM完全屏蔽了应用程序和OS之间的联系，而改用JVM充当了中间层，这也是一个真正跨平台运行时VM必须要做到的。只要是相同的 JDK，JVM为所有在其中运行的程序，提供了完全一致的运行环境，而不论你是什么样的底层OS和硬件条件。因此这也是我在其他一篇答案中提到，JVM的特点是取底层OS和硬件环境的交集，从而保障这种一致性。而所有应用程序和底层资源的互动，一定是依赖JVM的传递和转换来实现。JVM真正实现了一个 OS对应用程序运行时管理的所有功能。从开发环境角度和运行时角度，都是完全一致的真正VM DVM：而DVM的特点在于使用了Zygote，Zygote有几个非常有意思的特点。 一是Zygote采用预加载，由其首先判定安装的APK的需要以及相互依存树，以及OS及硬件环境的特点，在每次启动的时候进行预加载(现在你明白为什么 android的app在应用管理里你能轻易查到它都调用了那些重庆肛肠科关键性的本地资源的原因了吧?)，这就意味着，你安装的应用越多，Zygote的加载就越慢，一般来说你的手机启动就会越慢。另外来说，在不同的硬件环境里(例如有无GPS芯片)Zygote初始化的实例是不同的。也就是说，zygote并不提供一个统一的运行环境，具有更好的弹性，这种机制意味着DVM可以取底层资源的合集来提供上层应用使用，差别只是在程序安装或者启动的过程中，DVM可以提示程序需求资源，本地环境可能未能满足而导致无法运行。DVM的Zygote并不是提供一个运行时容器，它提供的只是一个用于共享的进程，所有的应用程序运行，都是独立的，OS级别的进程，直接受到OS层面的资源控制以及调度的影响，只是他们共享Zygote说预加载的类而已。这也就是我为什么说，DVM就像是给每个应用程序在底层加了个套子，而不是提供了一个真正的运行时的VM。也就是说，DVM在开发环境中说提供的VM平台，和运行时的环境是很有可能不一致的。开发环境中提供的VM平台，是一个各种运行时可能环境的合集。 从这点上来说，一般我们认为，JVM中的JAVA程序的崩溃，最多导致JVM的崩溃，而不会导致OS崩溃，但是apk的崩溃，可以直接导致OS崩溃，android手机会因为应用程序死机，大家应该是很常见了。但是大家一般是不会看到java程序导致死机吧?因为运行时中间隔着一个JVM。(当然，其实还是有些小门道可以用java程序让OS崩溃，因为这个，我和某些JAVA大拿打赌赢过饭局，呵呵，不过这是其他话题，不在这里展开了) 除此之外，在JVM的机制中，不同的程序，打包以后，他们都是在运行层级真正独立的程序(指程序应用重庆妇科医院他们相互之间的关系，而不是和JVM的关系)，即便他们在包里使用了同样的类，运行时都是单独加载，单独运行的(及加载多遍)。 DVM这种预加载-共享的机制，使得不同应用之间，在运行时，是共享相同的类的，一般来说，在系统资源消耗方面，拥有更高的效率。 最后，补充一点，byte code并不意味着就是解释执行，也能是加载编译，安装编译，预编译等等。实际上，不同的byte code的程序，不同的技术，不同的具体语言，其真正执行的情况挺复杂，难以一概而论的，好多都是混合技术的案例。 在智能手机大部分都可以让用户选择使用Dalvik还是ART模式。当然默认还是使用Dalvik模式。 用法：设置-辅助功能-开发者选项（开发人员工具）-选择运行环境（不同的手机设置的步骤可能不一样）。 问题整理1. 分析Java线程中断机制stop和interrupted的用法 当我们点击某个杀毒软件的取消按钮来停止查杀病毒时，当我们在控制台敲入quit命令以结束某个后台服务时……都需要通过一个线程去取消另一个线程正在执行的任务。Java没有提供一种安全直接的方法来停止某个线程，但是Java提供了中断机制。如果对Java中断没有一个全面的了解，可能会误以为被中断的线程将立马退出运行，但事实并非如此。中断机制是如何工作的？捕获或检测到中断后，是抛出InterruptedException还是重设中断状态以及在方法中吞掉中断状态会有什么后果？Thread.stop与中断相比又有哪些异同？什么情况下需要使用中断？本文将从以上几个方面进行描述。 中断的原理Java中断机制是一种协作机制，也就是说通过中断并不能直接终止另一个线程，而需要被中断的线程自己处理中断。这好比是家里的父母叮嘱在外的子女要注意身体，但子女是否注意身体，怎么注意身体则完全取决于自己。Java中断模型也是这么简单，每个线程对象里都有一个boolean类型的标识（不一定就要是Thread类的字段，实际上也的确不是，这几个方法最终都是通过native方法来完成的），代表着是否有中断请求（该请求可以来自所有线程，包括被中断的线程本身）。例如，当线程t1想中断线程t2，只需要在线程t1中将线程t2对象的中断标识置为true，然后线程2可以选择在合适的时候处理该中断请求，甚至可以不理会该请求，就像这个线程没有被中断一样。java.lang.Thread类提供了几个方法来操作这个中断状态，这些方法包括：public static boolean interrupted测试当前线程是否已经中断。线程的中断状态 由该方法清除。换句话说，如果连续两次调用该方法，则第二次调用将返回false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。public boolean isInterrupted()测试线程是否已经中断。线程的中断状态不受该方法的影响。public void interrupt()中断线程。其中，interrupt方法是唯一能将中断状态设置为true的方法。静态方法interrupted会将当前线程的中断状态清除，但这个方法的命名极不直观，很容易造成误解，需要特别注意。 上面的例子中，线程t1通过调用interrupt方法将线程t2的中断状态置为true，t2可以在合适的时候调用interrupted或isInterrupted来检测状态并做相应的处理。此外，类库中的有些类的方法也可能会调用中断，如FutureTask中的cancel方法，如果传入的参数为true，它将会在正在运行异步任务的线程上调用interrupt方法，如果正在执行的异步任务中的代码没有对中断做出响应，那么cancel方法中的参数将不会起到什么效果；又如ThreadPoolExecutor中的shutdownNow方法会遍历线程池中的工作线程并调用线程的interrupt方法来中断线程，所以如果工作线程中正在执行的任务没有对中断做出响应，任务将一直执行直到正常结束。 中断的处理既然Java中断机制只是设置被中断线程的中断状态，那么被中断线程该做些什么？显然，作为一种协作机制，不会强求被中断线程一定要在某个点进行处理。实际上，被中断线程只需在合适的时候处理即可，如果没有合适的时间点，甚至可以不处理，这时候在任务处理层面，就跟没有调用中断方法一样。“合适的时候”与线程正在处理的业务逻辑紧密相关，例如，每次迭代的时候，进入一个可能阻塞且无法中断的方法之前等，但多半不会出现在某个临界区更新另一个对象状态的时候，因为这可能会导致对象处于不一致状态。 处理时机决定着程序的效率与中断响应的灵敏性。频繁的检查中断状态可能会使程序执行效率下降，相反，检查的较少可能使中断请求得不到及时响应。如果发出中断请求之后，被中断的线程继续执行一段时间不会给系统带来灾难，那么就可以将中断处理放到方便检查中断，同时又能从一定程度上保证响应灵敏度的地方。当程序的性能指标比较关键时，可能需要建立一个测试模型来分析最佳的中断检测点，以平衡性能和响应灵敏性。中断状态的管理 一般说来，当可能阻塞的方法声明中有抛出InterruptedException则暗示该方法是可中断的，如BlockingQueue#put、BlockingQueue#take、Object#wait、Thread#sleep等，如果程序捕获到这些可中断的阻塞方法抛出的InterruptedException或检测到中断后，这些中断信息该如何处理？一般有以下两个通用原则：如果遇到的是可中断的阻塞方法抛出InterruptedException，可以继续向方法调用栈的上层抛出该异常，如果是检测到中断，则可清除中断状态并抛出InterruptedException，使当前方法也成为一个可中断的方法。 若有时候不太方便在方法上抛出InterruptedException，比如要实现的某个接口中的方法签名上没有throws InterruptedException，这时就可以捕获可中断方法的InterruptedException并通过Thread.currentThread.interrupt()来重新设置中断状态。如果是检测并清除了中断状态，亦是如此。 一般的代码中，尤其是作为一个基础类库时，绝不应当吞掉中断，即捕获到InterruptedException后在catch里什么也不做，清除中断状态后又不重设中断状态也不抛出InterruptedException等。因为吞掉中断状态会导致方法调用栈的上层得不到这些信息。当然，凡事总有例外的时候，当你完全清楚自己的方法会被谁调用，而调用者也不会因为中断被吞掉了而遇到麻烦，就可以这么做。总得来说，就是要让方法调用栈的上层获知中断的发生。假设你写了一个类库，类库里有个方法amethod，在amethod中检测并清除了中断状态，而没有抛出InterruptedException，作为amethod的用户来说，他并不知道里面的细节，如果用户在调用amethod后也要使用中断来做些事情，那么在调用amethod之后他将永远也检测不到中断了，因为中断信息已经被amethod清除掉了。如果作为用户，遇到这样有问题的类库，又不能修改代码，那该怎么处理？只好在自己的类里设置一个自己的中断状态，在调用interrupt方法的时候，同时设置该状态，这实在是无路可走时才使用的方法。 中断的响应 程序里发现中断后该怎么响应？这就得视实际情况而定了。有些程序可能一检测到中断就立马将线程终止，有些可能是退出当前执行的任务，继续执行下一个任务……作为一种协作机制，这要与中断方协商好，当调用interrupt会发生些什么都是事先知道的，如做一些事务回滚操作，一些清理工作，一些补偿操作等。若不确定调用某个线程的interrupt后该线程会做出什么样的响应，那就不应当中断该线程。 Thread.interrupt VS Thread.stopThread.stop方法已经不推荐使用了。而在某些方面Thread.stop与中断机制有着相似之处。如当线程在等待内置锁或IO时，stop跟interrupt一样，不会中止这些操作；当catch住stop导致的异常时，程序也可以继续执行，虽然stop本意是要停止线程，这么做会让程序行为变得更加混乱。那么它们的区别在哪里？最重要的就是中断需要程序自己去检测然后做相应的处理，而Thread.stop会直接在代码执行过程中抛出ThreadDeath错误，这是一个java.lang.Error的子类。123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.ticmy.interrupt; import java.util.Arrays; import java.util.Random; import java.util.concurrent.TimeUnit; public class TestStop &#123; private static final int[] array = new int[80000]; private static final Thread t = new Thread() &#123; public void run() &#123; try &#123; System.out.println(sort(array)); &#125; catch (Error err) &#123; err.printStackTrace(); &#125; System.out.println(&quot;in thread t&quot;); &#125; &#125;; static &#123; Random random = new Random(); for(int i = 0; i &lt; array.length; i++) &#123; array[i] = random.nextInt(i + 1); &#125; &#125; private static int sort(int[] array) &#123; for (int i = 0; i &lt; array.length-1; i++)&#123; for(int j = 0 ;j &lt; array.length - i - 1; j++)&#123; if(array[j] &lt; array[j + 1])&#123; int temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; &#125; &#125; &#125; return array[0]; &#125; public static void main(String[] args) throws Exception &#123; t.start(); TimeUnit.SECONDS.sleep(1); System.out.println(&quot;go to stop thread t&quot;); t.stop(); System.out.println(&quot;finish main&quot;); &#125; &#125; 这个例子很简单，线程t里面做了一个非常耗时的排序操作，排序方法中，只有简单的加、减、赋值、比较等操作，一个可能的执行结果如下： 123456go to stop thread t java.lang.ThreadDeath at java.lang.Thread.stop(Thread.java:758) at com.ticmy.interrupt.TestStop.main(TestStop.java:44) finish main in thread t 这里sort方法是个非常耗时的操作，也就是说主线程休眠一秒钟后调用stop的时候，线程t还在执行sort方法。就是这样一个简单的方法，也会抛出错误！换一句话说，调用stop后，大部分Java字节码都有可能抛出错误，哪怕是简单的加法！ 如果线程当前正持有锁，stop之后则会释放该锁。由于此错误可能出现在很多地方，那么这就让编程人员防不胜防，极易造成对象状态的不一致。例如，对象obj中存放着一个范围值：最小值low，最大值high，且low不得大于high，这种关系由锁lock保护，以避免并发时产生竞态条件而导致该关系失效。假设当前low值是5，high值是10，当线程t获取lock后，将low值更新为了15，此时被stop了，真是糟糕，如果没有捕获住stop导致的Error，low的值就为15，high还是10，这导致它们之间的小于关系得不到保证，也就是对象状态被破坏了！如果在给low赋值的时候catch住stop导致的Error则可能使后面high变量的赋值继续，但是谁也不知道Error会在哪条语句抛出，如果对象状态之间的关系更复杂呢？这种方式几乎是无法维护的，太复杂了！如果是中断操作，它决计不会在执行low赋值的时候抛出错误，这样程序对于对象状态一致性就是可控的。 正是因为可能导致对象状态不一致，stop才被禁用。 中断的使用通常，中断的使用场景有以下几个： 点击某个桌面应用中的取消按钮时； 某个操作超过了一定的执行时间限制需要中止时； 多个线程做相同的事情，只要一个线程成功其它线程都可以取消时； 一组线程中的一个或多个出现错误导致整组都无法继续时； 当一个应用或服务需要停止时。 下面来看一个具体的例子。这个例子里，本打算采用GUI形式，但考虑到GUI代码会使程序复杂化，就使用控制台来模拟下核心的逻辑。这里新建了一个磁盘文件扫描的任务，扫描某个目录下的所有文件并将文件路径打印到控制台，扫描的过程可能会很长。若需要中止该任务，只需在控制台键入quit并回车即可。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.ticmy.interrupt; import java.io.BufferedReader; import java.io.File; import java.io.InputStreamReader; public class FileScanner &#123; private static void listFile(File f) throws InterruptedException &#123; if(f == null) &#123; throw new IllegalArgumentException(); &#125; if(f.isFile()) &#123; System.out.println(f); return; &#125; File[] allFiles = f.listFiles(); if(Thread.interrupted()) &#123; throw new InterruptedException(&quot;文件扫描任务被中断&quot;); &#125; for(File file : allFiles) &#123; //还可以将中断检测放到这里 listFile(file); &#125; &#125; public static String readFromConsole() &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); try &#123; return reader.readLine(); &#125; catch (Exception e) &#123; e.printStackTrace(); return &quot;&quot;; &#125; &#125; public static void main(String[] args) throws Exception &#123; final Thread fileIteratorThread = new Thread() &#123; public void run() &#123; try &#123; listFile(new File(&quot;c:\\&quot;)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; new Thread() &#123; public void run() &#123; while(true) &#123; if(&quot;quit&quot;.equalsIgnoreCase(readFromConsole())) &#123; if(fileIteratorThread.isAlive()) &#123; fileIteratorThread.interrupt(); return; &#125; &#125; else &#123; System.out.println(&quot;输入quit退出文件扫描&quot;); &#125; &#125; &#125; &#125;.start(); fileIteratorThread.start(); &#125; &#125; 在扫描文件的过程中，对于中断的检测这里采用的策略是，如果碰到的是文件就不检测中断，是目录才检测中断，因为文件可能是非常多的，每次遇到文件都检测一次会降低程序执行效率。此外，在fileIteratorThread线程中，仅是捕获了InterruptedException，没有重设中断状态也没有继续抛出异常，因为我非常清楚它的使用环境，run方法的调用栈上层已经没有可能需要检测中断状态的方法了。 在这个程序中，输入quit完全可以执行System.exit(0)操作来退出程序，但正如前面提到的，这是个GUI程序核心逻辑的模拟，在GUI中，执行System.exit(0)会使得整个程序退出。 2. 线程状态 新建状态(New)： 当用new操作符创建一个线程时， 例如new Thread(r)，线程还没有开始运行，此时线程处在新建状态。 当一个线程处于新生状态时，程序还没有开始运行线程中的代码 就绪状态(Runnable) 一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的start()方法。当线程对象调用start()方法即启动了线程，start()方法创建线程运行的系统资源，并调度线程运行run()方法。当start()方法返回后，线程就处于就绪状态。 处于就绪状态的线程并不一定立即运行run()方法，线程还必须同其他线程竞争CPU时间，只有获得CPU时间才可以运行线程。因为在单CPU的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态。因此此时可能有多个线程处于就绪状态。对多个处于就绪状态的线程是由Java运行时系统的线程调度程序(thread scheduler)来调度的。 运行状态(Running) 当线程获得CPU时间后，它才进入运行状态，真正开始执行run()方法. 阻塞状态(Blocked) 线程运行过程中，可能由于各种原因进入阻塞状态: 1&gt;线程通过调用sleep方法进入睡眠状态； 2&gt;线程调用一个在I/O上被阻塞的操作，即该操作在输入输出操作完成之前不会返回到它的调用者； 3&gt;线程试图得到一个锁，而该锁正被其他线程持有； 4&gt;线程在等待某个触发条件；...... 所谓阻塞状态是正在运行的线程没有运行结束，暂时让出CPU，这时其他处于就绪状态的线程就可以获得CPU时间，进入运行状态。 死亡状态(Dead) 有两个原因会导致线程死亡： 1) run方法正常退出而自然死亡， 2) 一个未捕获的异常终止了run方法而使线程猝死。 为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用isAlive方法。如果是可运行或被阻塞，这个方法返回true； 如果线程仍旧是new状态且不是可运行的， 或者线程死亡了，则返回false. 3.View 的onDraw与dispatchDraw绘制VIew本身的内容，通过调用View.onDraw(canvas)函数实现 绘制自己的孩子通过dispatchDraw（canvas）实现 View组件的绘制会调用draw(Canvas canvas)方法，draw过程中主要是先画Drawable背景，对 drawable调用setBounds()然后是draw(Canvas c)方法.有点注意的是背景drawable的实际大小会影响view组件的大小，drawable的实际大小通过getIntrinsicWidth()和getIntrinsicHeight()获取，当背景比较大时view组件大小等于背景drawable的大小 画完背景后，draw过程会调用onDraw(Canvas canvas)方法，然后就是dispatchDraw(Canvas canvas)方法, dispatchDraw()主要是分发给子组件进行绘制，我们通常定制组件的时候重写的是onDraw()方法。值得注意的是ViewGroup容器组件的绘制，当它没有背景时直接调用的是dispatchDraw()方法, 而绕过了draw()方法，当它有背景的时候就调用draw()方法，而draw()方法里包含了dispatchDraw()方法的调用。因此要在ViewGroup上绘制东西的时候往往重写的是dispatchDraw()方法而不是onDraw()方法，或者自定制一个Drawable，重写它的draw(Canvas c)和 getIntrinsicWidth(), getIntrinsicHeight()方法，然后设为背景。 4.opengl可编程管线与固定区别1）、固定渲染管线 ——这是标准的几何&amp;光照(T&amp;L)管线，功能是固定的，它控制着世界、视、投影变换及固定光照控制和纹理混合。T&amp;L管线可以被渲染状态控制，矩阵，光照和采制参数。 2）、顶点着色器——图形开发人员可以对渲染管线中的顶点运算和像素运算分别进行编程处理了，而无须象以前那样套用一些固定函数，取代设置参数来控制管线，最早出现与DX8，包括PS和VS两部分。 5.光照6.深度测试像素归属测试：这一步骤由OpenGL ES内部进行，不由开发人员控制；测试确定帧缓冲区的位置的像素是否归属当前OpenGL ES所有，如不属于或被另一个窗口遮挡，从而完全不显示这些像素。 裁剪测试：判断像素是否在由 glScissor 定义的剪裁矩形内，不在该剪裁区域内的像素就会被剪裁掉； 模板和深度测试：测试输入片段的模板和深度值上进行，以确定片段是否应该被拒绝；深度测试比较下一个片段与帧缓冲区中的片段的深度，从而决定哪一个像素在前面，哪一个像素被遮挡； 混合：是将片段的颜色和帧缓冲区中已有的颜色值进行混合，并将混合所得的新值写入帧缓冲； 抖动：可用于最小化因为使用有限精度在帧缓冲区中保存颜色值而产生的伪像。 Framebuffer：这是流水线的最后一个阶段，Framebuffer 中存储这可以用于渲染到屏幕或纹理中的像素值，也可以从Framebuffer 中读回像素值，但不能读取其他值（如深度值，模版值等）。 7.Intent为什么可序列化的数据大家都知道进行Android开发的时候，无法将对象的引用传给Activities或者Fragments，我们需要将这些对象放到一个Intent或者Bundle里面，然后再传递 序列化的原因基本三种情况： 永久性保存对象，保存对象的字节序列到本地文件中； 对象在网络中传递； 对象在IPC间传递。8.SharedPreference之前为了解决应用的内存压力，在同一个应用中使用了多进程，但在程序自测的过程中发现不同进程之间的SharedPreferences数据不能共享，但应用内很多数据都是通过SharedPreferences来保存的，如果改成其它多进程通信的方式改动比较大。通过查看源码发现，在API Level&gt;=11即Android 3.0可以通过Context.MODE_MULTI_PROCESS属性来实现SharedPreferences多进程共享，具体使用方式如下：12345678910111213141516171819public class PreferencesUtils &#123; public static String PREFERENCE_NAME = &quot;SharedPreferencesDemo&quot;; private PreferencesUtils()&#123; &#125; public static boolean putString(Context context, String key, String value) &#123; SharedPreferences settings = context.getSharedPreferences(PREFERENCE_NAME, Context.MODE_MULTI_PROCESS); SharedPreferences.Editor editor = settings.edit(); editor.putString(key, value); return editor.commit(); &#125; public static String getString(Context context, String key, String defaultValue) &#123; SharedPreferences settings = context.getSharedPreferences(PREFERENCE_NAME, Context.MODE_MULTI_PROCESS); return settings.getString(key, defaultValue); &#125;&#125; 本来以为通过MODE_MULTI_PROCESS属性使用SharedPreferences就可以解决不同进程之间不能共享数据的问题了，但SQA总是反馈一些随机但出现频率比较大的bug，比如在使用过程中没有清除程序数据的前提下，会出现欢迎界面和操作指引，这是通过保存在SharedPreferences的标志来判断用户是否是第一次启动程序的，分析发现保存在SharedPreferences中的数据丢失了，但代码中并没有去清除这些数据，所以推测可能是不同进程同一时间对SharedPreferences操作导致的，经验证确实如此，去掉多进程就不会再出现这个问题了。 由于进程间是不能内存共享的，每个进程操作的SharedPreferences都是一个单独的实例，上述的问题并不能通过锁来解决，这导致了多进程间通过SharedPreferences来共享数据是不安全的，这个问题只能通过多进程间其它的通信方式或者是在确保不会同时操作SharedPreferences数据的前提下使用SharedPreferences来解决。 apply和commit都是提交保存，区别在于apply是异步执行的，不需要等待。不论删除，修改，增加都必须调用apply或者commit提交保存。 9.保存sd卡怎么加锁10.Handler中Queue的排序方式11.IOC 控制反转12.Android IPC13.OKHttp与httpclient区别]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
</search>