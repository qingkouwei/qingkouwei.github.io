<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tips-android-arch]]></title>
    <url>%2F2017%2F12%2F05%2Ftips-android-arch%2F</url>
    <content type="text"><![CDATA[Android官方架构组件介绍之LifeCycle,Android架构组件一共包括以下几个： LifeCycle ： 与Activity和Fragment的生命周期有关 LiveData ：异步可订阅数据，也是生命周期感知 ViewModel ：视图数据持有模型，也是生命周期感知 Room ：SQLite抽象层，用于简化SQLite数据存储 官网]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux批量操作文件]]></title>
    <url>%2F2017%2F11%2F30%2Ftips-linux-rename%2F</url>
    <content type="text"><![CDATA[一个批量将mp4文件转成gif文件的命令 1find . -name &quot;*.mp4&quot; |sed &apos;s/.mp4$//g&apos;|xargs -i ffmpeg -i &#123;&#125;.mp4 &#123;&#125;.gif sed &#39;s/.mp4$//g&#39;使用sed命令将mp4文件名的.mp4全部替换成空./g是全局替换.s是sed的替换命令,替换格式&#39;s/原文/要替换成的/&#39; 或者: 1for file in $(find . -name &quot;*.mp4&quot; -type f);do ffmpeg -i &quot;$file&quot; &quot;$&#123;file%.*&#125;.gif&quot;;done 找到所有.mp4文件进行循环,file是mp4文件全名,${file%.*}是剔除从右边最小匹配,即将.mp4去掉]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下Core Dump文件的行程与分析]]></title>
    <url>%2F2017%2F11%2F17%2Fenv-mac-debug-c%2F</url>
    <content type="text"><![CDATA[mac下生成core dump 使用ulimit -c查看ulimit设置,显示unlimited表示开启,显示0表示关闭,通过ulimit -c unlimited打开设置; 但是这个只在当前窗口有效果。如果需要变成系统全局设置。 就需要去改/etc/profile文件，打开，然后加上ulimit -c unlimited就可以了，这样当产生Crash的时候就会自动产生dump文件。 之后需要配置一下dump产生的规则和路径:sudo sysctl kern.corefile=/cores/core.%N.%P,其中%N表示进程名字，%P表示进程id。Linux还有%S,%T分别表示最后一个信号和时间，在MAC上没找到对应的。(mac默认生成的core dump在/cores/下). 最后如何用lldb来查看一个core dump文件lldb -c core.xxx. 在lldb命令下输入bt查看报错代码. 生成太多core文件会占用电脑磁盘,可以关闭全局的core dump生成配置: 永久关闭，则在/etc/sysctl.conf中加入一行（如果存在，则将其值修改为0），重启后生效：kern.coredump=0 零时关闭，当前生效，重启后失效：sudo sysctl -w kern.coredump=0]]></content>
      <categories>
        <category>env</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>language</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android兼容性]]></title>
    <url>%2F2017%2F11%2F14%2Ftips-android-compatibility%2F</url>
    <content type="text"><![CDATA[oppo r9s无法浮层无法显示问题oppo r9s,系统版本6.0.1,wmParams.type = WindowManager.LayoutParams.TYPE_TOAST;时无法正常弹出,改成wmParams.type = WindowManager.LayoutParams.TYPE_PHONE;可显示. 在activity中弹出浮层后马上将activity movetoback导致oppo r9s 浮层无法显示,moveTaskToBack后延迟一秒显示浮层可解决问题. 12345//moveTaskToBackval intent = Intent(Intent.ACTION_MAIN) intent.flags = Intent.FLAG_ACTIVITY_NEW_TASK// 注意 intent.addCategory(Intent.CATEGORY_HOME) aty.startActivity(intent)]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL查询案例]]></title>
    <url>%2F2017%2F11%2F08%2Fdb-sql-query%2F</url>
    <content type="text"><![CDATA[如下数据库表: 12345678910111213141516Student(S#,Sname,Sage,Ssex)学生表S#：学号Sname：学生姓名Sage：学生年龄Ssex：学生性别Course(C#,Cname,T#)课程表C#：课程编号Cname：课程名称T#：教师编号SC(S#,C#,score)成绩表S#：学号C#：课程编号score：成绩Teacher(T#,Tname)教师表T#：教师编号：Tname：教师名字 查询“001”课程比“002”课程成绩高的所有学生的学号 1select a.S# from (select S#,score from SC where C#=&apos;001&apos;)a, (select s#,score from SC where c#=&apos;002&apos;)b Where a.score&gt;b.score 查询平均成绩大于60分的同学的学号和平均成绩 1查询平均成绩大于60分的同学的学号和平均成绩 查询所有同学的学号、姓名、选课数、总成绩 1select student.S#, student.Sname, count(sc.C#), sum(score) from student left outer join SC on student.S# = SC.S# group by S 查询姓‘李’的老师的个数 123select count(distinct(Tname))from teacherwhere tname like &apos;李%&apos;; 查询没有学过“叶平”老师可的同学的学号、姓名： 1234select student.S#, student.Snamefrom Studentwhere S# not in (select distinct(SC.S#) from SC,Course,Teacherwhere sc.c#=course.c# AND teacher.T#=course.T# AND Teahcer.Tname =&apos;叶平&apos;); 查询学过“叶平”老师所教的所有课的同学的学号、姓名： 123456select S#,Sname from Student where S# in (select S# from SC ,Course ,Teacherwhere SC.C#=Course.C# and Teacher.T#=Course.T#and Teacher.Tname=&apos;叶平&apos; group by S#having count(SC.C#)=(select count(C#) from Course,Teacher where Teacher.T#=Course.T# and Tname=&apos;叶平&apos;)); 查询学过“011”并且也学过编号“002”课程的同学的学号、姓名： 1234select Student.S#,Student.Snamefrom Student,SC where Student.S#=SC.S#and SC.C#=&apos;001&apos;andexists( Select * from SC as SC_2 where SC_2.S#=SC.S# and SC_2.C#=&apos;002&apos;); 查询课程编号“002”的成绩比课程编号“001”课程低的所有同学的学号、姓名： 123456Select S#,Snamefrom (select Student.S#,Student.Sname,score ,(select score from SC SC_2 where SC_2.S#=Student.S# and SC_2.C#=&apos;002&apos;) score2 from Student,SCwhere Student.S#=SC.S# and C#=&apos;001&apos;) S_2where score2 &lt; score; 查询所有课程成绩小于60的同学的学号、姓名： 1234select S#, snamefrom studentwhere s# not in(select student.s# from student, sc where s.s# = sc.s# and score&gt;60); 查询没有学全所有课的同学的学号、姓名： 12345select student.s#, student.snamefrom student, scwhere student.s#=sc.s#group by student.s#, student.snamehaving count(c#)&lt;(select count(c#) from course); 查询至少有一门课与学号为“1001”同学所学相同的同学的学号和姓名： 1234select s#, Snamefrom Student, SCwhere student.s# = sc.s#and c# in (select c# from SC where s#=&apos;1001&apos;); 查询至少学过学号为“001”同学所有一门课的其他同学学号和姓名； 1234select distinct sc.s# , snamefrom student, scwhere student.s#=sc.s#and c# in (select C# from sc where s#=&apos;001&apos;); 把“SC”表中“叶平”老师教的课的成绩都更改为此课程的平均成绩： 123Update Sc Set Score=(Select Avg(s2_Score) From sc s2 Where s2.c#=sc.c#) Where c# IN(Select c# From sc cs INNER JOIN Teacher tc ON cs.t#=tc.t# WHERE tname =&apos;叶平&apos;) 查询和“1002”号的同学学习的课程完全相同的其他同学学号和姓名： 1234select s# from sc where c# in(select c# from sc where s#=&apos;1002&apos;)group by s# having count(*)=(select count(*) from sc where s#=&apos;1002&apos;); 删除学习“叶平”老师课的SC表记录： 12345delect scfrom course, Teacherwhere course.c#=sc.c#and course.t#=teacher.t#and tname=&apos;叶平&apos;; 向SC表中插入一些记录，这些记录要求符合以下条件：没有上过编号“003”课程的同学学号、002号课的平均成绩： 123Insert SC select S#,&apos;002&apos;,(Select avg(score) from SC where C#=&apos;002&apos;)from Student where S# not in (Select S# from SC where C#=&apos;002&apos;); 按平均成绩从高到低显示所有学生的“数据库”、“企业管理”、“英语”三门的课程成绩，按如下形式显示：学生ID，数据库，企业管理，英语，有效课程数，有效平均分： 12345678select s# as 学生ID,(select score from sc where sc.s#=t.s# and c#=&apos;004&apos;) as 数据库,(select score from sc where sc.s#=t.s# and c#=&apos;001&apos;) as 企业管理,(select score from sc where sc.s#=t.s# and c#=&apos;006&apos;) as 英语,count(*) as 有效课程数, avg(t.score) as 平局成绩from sc as tgroup by s#order by avg(t.score) 查询各科成绩最高和最低的分： 以如下的形式显示：课程ID，最高分，最低分 123456789101112select L.c# as 课程ID, L.score as 最高分,R.score as 最低分from sc L, sc Rwhere L.c# = R.c#and L.score = (select max(IL.score) from sc IL, student as IM where L.c#=IL.c# and IM.s#=IL.s# group by IL.c#)and R.score = (select min(IR.score) from sc as IR where R.c#=IR.c# group by IR.c#); 按各科平均成绩从低到高和及格率的百分数从高到低顺序： 12345678SELECT t.C# AS 课程号,max(course.Cname)AS 课程名,isnull(AVG(score),0) AS 平均成绩,100 * SUM(CASE WHEN isnull(score,0)&gt;=60 THEN 1 ELSE 0 END)/COUNT(*) AS 及格百分数 FROM SC T,Course where t.C#=course.C# GROUP BY t.C# ORDER BY 100 * SUM(CASE WHEN isnull(score,0)&gt;=60 THEN 1 ELSE 0 END)/COUNT(*) DESC 查询如下课程平均成绩和及格率的百分数(用”1行”显示): 企业管理（001），马克思（002），OO&amp;UML （003），数据库（004）： 查询不同老师所教不同课程平均分从高到低显示： 12345678SELECT max(Z.T#) AS 教师ID,MAX(Z.Tname) AS 教师姓名,C.C# AS 课程ID,AVG(Score) AS 平均成绩 FROM SC AS T,Course AS C ,Teacher AS Z where T.C#=C.C# and C.T#=Z.T# GROUP BY C.C# ORDER BY AVG(Score) DESC 查询如下课程成绩第3名到第6名的学生成绩单：企业管理(001)，马克思(002)，UML(003)，数据库(004)： 统计下列各科成绩，各分数段人数：课程ID，课程名称，[100-85],[85-70],[70-60],[ 小于60] ： 12345678SELECT SC.C# as 课程ID, Cname as 课程名称,SUM(CASE WHEN score BETWEEN 85 AND 100 THEN 1 ELSE 0 END) AS [100 - 85] ,SUM(CASE WHEN score BETWEEN 70 AND 85 THEN 1 ELSE 0 END) AS [85 - 70],SUM(CASE WHEN score BETWEEN 60 AND 70 THEN 1 ELSE 0 END) AS [70 - 60],SUM(CASE WHEN score &lt; 60 THEN 1 ELSE 0 END) AS [60 -] FROM SC,Course where SC.C#=Course.C# GROUP BY SC.C#,Cname; 查询学生平均成绩及其名次： 123456789SELECT 1+(SELECT COUNT( distinct 平均成绩) FROM (SELECT S#,AVG(score) AS 平均成绩 FROM SC GROUP BY S# ) AS T1 WHERE 平均成绩 &gt; T2.平均成绩) as 名次, S# as 学生学号,平均成绩 FROM (SELECT S#,AVG(score) 平均成绩 FROM SC GROUP BY S# ) AS T2 ORDER BY 平均成绩 desc; 查询各科成绩前三名的记录（不考虑成绩并列情况）： 123456789SELECT t1.S# as 学生ID,t1.C# as 课程ID,Score as 分数 FROM SC t1 WHERE score IN(SELECT TOP 3 score FROM SC WHERE t1.C#= C# ORDER BY score DESC)``` 26. 查询每门课程被选修的学生数： select c#, count(s#) from sc group by c#; 127. 查询出只选修一门课程的全部学生的学号和姓名： select sc.s#, student.sname, count(c#) as 选课数 from sc,student where sc.s# =student.s# group by sc.s#,Student.sname having count(c#)=1; 128. 查询男生、女生人数： select count(Ssex) as 男生人数 from student group by Ssex having Ssex=’男’； select count(Ssex) as 女生人数 from student group by Ssex having Ssex=’女’; 129. 查询姓“张”的学生名单： select sname from student where sname like ‘张%’; 130. 查询同名同姓的学生名单，并统计同名人数： select sanme,count() from student group by sname havang count()&gt;1; 131. 1981年出生的学生名单（注：student表中sage列的类型是datetime）: select sname, convert(char(11),DATEPART(year,sage)) as age from student where convert(char(11),DATEPART(year,Sage))=’1981’; 132. 查询平均成绩大于85的所有学生的学号、姓名和平均成绩： select Sname,SC.S# ,avg(score)from Student,SCwhere Student.S#=SC.S# group by SC.S#,Sname having avg(score)&gt;85; 133. 查询每门课程的平均成绩，结果按平均成绩升序排序，平均成绩相同时，按课程号降序排列： select C#, avg(score) from sc group by c# order by avg(score), c# desc; 134. 查询课程名称为“数据库”，且分数低于60的学生名字和分数： select sname, isnull(score,0) from student, sc ,course where sc.s#=student.s# and sc.c#=course.c# and course.cname=’数据库’ and score]]></content>
      <categories>
        <category>db</category>
      </categories>
      <tags>
        <tag>sql</tag>
        <tag>db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android-phone-compatibility]]></title>
    <url>%2F2017%2F11%2F02%2Fandroid-phone-compatibility%2F</url>
    <content type="text"><![CDATA[系统摄像视频文件格式一般手机使用摄像头录制视频格式为yuv420p,而小米5录制出的为yuvj420p.格式转换是yuvj420p当成yuv420p处理即可.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>compatibility</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ndk编译常见问题]]></title>
    <url>%2F2017%2F11%2F01%2Fissue-ndk-compile%2F</url>
    <content type="text"><![CDATA[depends on undefined modules问题: 12Users/shenjunwei/program/android-ndk-r14b/build/core/build-binary.mk:687: Android NDK: Module magicsdk_fmod depends on undefined modules: cutils/Users/shenjunwei/program/android-ndk-r14b/build/core/build-binary.mk:700: *** Android NDK: Aborting (set APP_ALLOW_MISSING_DEPS=true to allow missing dependencies) . Stop. 解决方案: Android.mk中增加APP_ALLOW_MISSING_DEPS=true shared library text segment is not shareable问题: 1234/Users/shenjunwei/program/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: warning: shared library text segment is not shareable/Users/shenjunwei/program/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: treating warnings as errorsclang++: error: linker command failed with exit code 1 (use -v to see invocation)make: *** [/Users/shenjunwei/Documents/repository/wonxing/normandy_android_app/modules-int/magicsdk_core/src/main/obj/local/armeabi-v7a/libmagicsdk_ex.so] Error 1 解决: 123456from Android NDK r11 you can useLOCAL_LDLIBS += -Wl,--no-warn-shared-textrelYou can also useLOCAL_DISABLE_FATAL_LINKER_WARNINGS := true shared library text segment is not shareable has text relocations问题: 12345678910/data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so: has text relocationsE/FileUtil: access inferno failed! /data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so java.lang.UnsatisfiedLinkError: dlopen failed: /data/app/com.wonxing.touchfa-2/lib/arm/libmagicsdk_ex.so: has text relocations at java.lang.Runtime.load0(Runtime.java:897) at java.lang.System.load(System.java:1505) at com.wonxing.magicsdk.core.util.FileUtil$EXLibUtil.load(FileUtil.java:465) at com.wonxing.magicsdk.core.MagicRecorder.loadEXLibrary(MagicRecorder.java:280) at com.wonxing.magicsdk.core.MagicRecorder.prepare(MagicRecorder.java:471) at com.wonxing.magicsdk.core.MagicRecorder.prepare(MagicRecorder.java:352) at com.wonxing.touchfa.ui.activity.VideoImportActivity.preparePlaySDK(VideoImportActivity.java:144) 解决: 方案一 This issue could be solved by checking the targetSDKVersion in the manifest file. Using “22” and not “23” as targetSDKVersion solved it. (See below) 123&lt;uses-sdk android:minSdkVersion=&quot;15&quot; android:targetSdkVersion=&quot;22&quot; /&gt; I also checked the build.gradle files for compile version and targetSDKversion: 1234567compileSdkVersion 22 buildToolsVersion &apos;22.0.1&apos; defaultConfig &#123; minSdkVersion 15 targetSdkVersion 22 &#125; 方案二 It was caused by the ffmpeg, and it could also be solved by patching the latest ffmpeg code12345libavcodec\arm\fft_fixed_neon.Slibavcodec\arm\fft_neon.Slibavcodec\arm\fft_vfp.Slibavcodec\arm\mlpdsp_armv5te.Slibutil\arm\asm.S I took the latest from https://github.com/FFmpeg/FFmpeg You will also need HAVE_SECTION_DATA_REL_RO declared somewhere in your build for the macro in asm.S to use the dynamic relocations option. 方案三(Further informations:) Previous versions of Android would warn if asked to load a shared library with text relocations: “libfoo.so has text relocations. This is wasting memory and prevents security hardening. Please fix.”. Despite this, the OS will load the library anyway. Marshmallow rejects library if your app’s target SDK version is &gt;= 23. System no longer logs this because it assumes that your app will log the dlopen(3) failure itself, and include the text from dlerror(3) which does explain the problem. Unfortunately, lots of apps seem to catch and hide the UnsatisfiedLinkError throw by System.loadLibrary in this case, often leaving no clue that the library failed to load until you try to invoke one of your native methods and the VM complains that it’s not present. You can use the command-line scanelf tool to check for text relocations. You can find advice on the subject on the internet; for example https://wiki.gentoo.org/wiki/Hardened/Textrels_Guide is a useful guide. And you can check if your shared lbirary has text relocations by doing this: 1readelf -a path/to/yourlib.so | grep TEXTREL If it has text relocations, it will show you something like this: 10x00000016 (TEXTREL) 0x0 If this is the case, you may recompile your shared library with the latest NDK version available: 1ndk-build -B -j 8 And if you check it again, the grep command will return nothing. Android Developers Blog Hardened/Textrels Guide]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>NDK</tag>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最近应用杀掉进程application不销毁问题探讨]]></title>
    <url>%2F2017%2F10%2F31%2Ftips-android-application-recent%2F</url>
    <content type="text"><![CDATA[建雨在芝士圈应用的application中使用了全局静态变量标志是否正在录制中,开启直播后将该变量设置为录制中,录制中一些操作将被屏蔽.但是对某些手机(如htc d816)当从”最近应用”杀掉进程后有时候application不被回收,该状态变量无法通过application的onCreate中重新初始化,同时通知栏也未消失.在Android 应用被杀后Notification不取消问题及应用深杀和浅杀时Service生命周期情况探讨中找到service的onTaskRemoved方法可以监听到应用被从最近应用中移除. 关于&lt;&gt;摘要: 目中有如下需求：后台service进行导入操作，要更新Notification。当运行系统清理使应用被杀时，Notification无法取消，仍然在通知栏显示。为解决这个问题进行了如下探索： 首先想到利用service的startForeground()来更新通知栏，这样当应用被杀掉时候Notification可以一起被去掉。但针对项目的需求：service可以同时导入多个文件，并且会对应显示多个通知。这种情况下用service.startForeground()更新通知栏时候，当应用被杀时候之后cancel掉最后一次调用startForeground对应id的Notification，而其他通知仍然不能被取消。 继续探索用其他方式取消通知栏：在进程被杀掉的时候，会调用service的哪些生命周期函数呢？service的onDestroy()方法只有在调用Context的stopService()或Service的stopSelf()后才会被调用，在应用被杀时候Service的onDestroy()不会被执行。 我们发现service的 onTaskRemoved()方法，该方法何时被调用呢？方法的注释说明是这么写的： 12345678910111213/*** This is called if the service is currently running and the user has* removed a task that comes from the service&apos;s application. If you have* set &#123;@linkandroid.content.pm.ServiceInfo#FLAG_STOP_WITH_TASK ServiceInfo.FLAG_STOP_WITH_TASK&#125;* then you will not receive this callback; instead, the service will simply* be stopped.**@paramrootIntentThe original root Intent that was used to launch* the task that is being removed.*/public void onTaskRemoved(Intent rootIntent) &#123;&#125; 注释表明onTaskRemoved()方法在当用户移除应用的一个Task栈时被调用。也就是当用户在最近任务界面把该应用的一个task划掉时，或者在最近任务界面进行清理时。这两种情况下onTaskRemoved()都会被调用，但在大多Android机型上，这两种情况有所不同：第一种情况即应用被浅杀(用户只划掉这一个Task)，该Task栈会被清理，但如果有后台service在运行，该应用的进程不会被杀掉，后台service仍然在运行。第二种即应用被深杀(用户在最近任务界面直接按清理按钮)，该应用的进程会被直接杀掉，后台的service当然也停止了。对于不同的手机品牌和机型在最近任务进行各种清理时过程可能不太一样，但应用浅杀和深杀对于所有Android手机都是有普遍意义的。 下面我们分析在应用被浅杀和被深杀以及先浅杀再深杀后的生命周期： 浅杀： 104-21 17:55:13.733 8264-8264/com.qintong.test D/qintong: vCardService onTaskRemoved. 深杀： 会出现两种情况： (a). 12304-26 16:20:00.349 32674-32674/? D/qintong: Service onTaskRemoved.04-26 16:21:01.621 2936-2936/? D/qintong: Service is being created.04-26 16:21:01.628 2936-2936/? D/qintong: Service onStartCommand. (b). 1204-21 17:59:58.397 8264-8264/com.qintong.test D/qintong: Service onCreate.04-21 17:59:58.404 8264-8264/com.qintong.test D/qintong: Service onTaskRemoved. 浅杀＋深杀 （service 的 onStartCommand 返回 STICKY）： 12304-21 18:05:12.717 8264-8264/com.qintong.test D/qintong: Service onTaskRemoved.04-21 18:05:29.214 9207-9207/com.qintong.test D/qintong: Service onCreate.04-21 18:05:29.223 9207-9207/com.qintong.test D/qintong: Service onStartCommand. 我们来分析这几种情况： (1).浅杀时:应用进程没被杀掉，service仍然在执行，service的onTaskRemoved()立即被调用。 (2).深杀时：有两种情况：第一种情况是深杀后直接调用onTaskRemoved()且service停止，过段时间后service重启调用其onCreate()和onStartCommand()。第二种是应用的进程被杀掉，过一会后service的onCreate()方法被调用，紧接着onTaskRemoved()被调用。由于被深杀后应用的进程立刻停止了，所以service的onTaskRemoved()无法被立即调用。而过若干秒后，service重启，onCreate()被调用，紧接着onTaskRemoved()被调用。而这里service的其他方法并没有被调用，即使onStartCommand()返回STICKY，service重启后onStartCommand()方法也没有被调用。 (3).浅杀+深杀时(service 的 onStartCommand 返回 STICKY)：onTaskRemoved()立刻被调用(浅杀后)，深杀后过段时间onCreate()和onStartCommand()相继被调用。执行浅杀Task被清理，应用的进程还在，onTaskRemoved()被调用，过程与(1)一样。再执行深杀：由于该应用的Task栈已经没有了，所有再深杀onTaskRemoved()不会再被调用，深杀后service停止。而由于实验时候onStartCommand()返回STICKY，所有service过段时间会被再次启动，执行了onCreate()方法和onStartCommand()方法。 所以综上所述，service的onTaskRemoved()在应用浅杀后会被立即调用而在service被深杀后，会直接调用onTaskRemoved或service会被重启并调用onTaskRemoved()。 回到我们的问题：应用被杀后，如何取消Notification： 我们先看最后的解决方案，在来分析为何能work。 service的代码如下： 12345678910111213141516171819202122@Overridepublic void onCreate() &#123; super.onCreate(); mBinder=newMyBinder(); if(DEBUG) Log.d(LOG_TAG,&quot;vCardService is being created.&quot;); mNotificationManager= ((NotificationManager)getSystemService(NOTIFICATION_SERVICE)); initExporterParams();&#125;@Overridepublic int onStartCommand(Intent intent, intflags, intid) &#123; if(DEBUG) Log.d(LOG_TAG,&quot;vCardService onStartCommand.&quot;); mNotificationManager.cancelAll(); return START_STICKY;&#125;@Overridepublic void onTaskRemoved(Intent rootIntent) &#123; if(DEBUG) Log.d(LOG_TAG,&quot;vCardService onTaskRemoved.&quot;); mNotificationManager.cancelAll(); super.onTaskRemoved(rootIntent);&#125; 如上代码，在浅杀时候：只执行onTaskRemoved()，通知被取消，但service仍然在运行，所以还会继续发通知，正常运行。 深杀时：第一种情况直接调用onTaskRemoved()且service停止，通知被取消。第二种情况，进程被杀掉，几秒后service重启，onCreate() -&gt; onTaskRemoved()，运行结果就是深杀后过几秒后Notification被取消。 浅杀+深杀时：浅杀后onTaskRemoved()被调用，service仍在运行，通知仍然在更新。深杀时，onCreate() -&gt; onStartCommand()，在onStartCommand()时候取消通知。 另外，mNotificationManager.cancelAll()会清除应用的所有通知，如果应用想保留和该service无关其他通知，可以调用mNotificationManager.cancel(String tag, int id)或cancel(int id)清除指定通知。 当然，还可以有另一种方式：浅杀时后就把service后台执行的任务停止，并清理notification，我们可以根据需求来选择。 补充： 疑问：1.为啥有时候深杀不立即调用onTaskRemoved()，而是在重启之后调用的呢？ stackoverflow上的答复:https://stackoverflow.com/questions/32224233/ontaskremoved-called-after-oncreate-in-started-service-on-swipe-out-from-recent/41506752 大意是service执行较重UI操作时候service不会立即停止，而新的service会启动。不太确定这个解释的正确性…… Calling onTaskRemoved of the running service(when app gets swiped out from recent apps) will be generally delayed if we are performing any heavy UI related stuff or broadcasting messages to receivers in service. E.g , Assume you are downloading the file of size 50MB from web server, so from web server everytime you are reading 1024bytes of stream data as buffer and that data you are writing to a file in device. Meanwhile you are updating the progress to the UI thread which means every KB you are updating to the UI thread, this will cause the application to freeze. So in between if you swipe-out from recent app list , then the system will try to stop the service but since the service is in-contact with the UI thread, the system will be unable to stop that service, but it will create new service eventhough the old service is not yet stopped. Once old service finishes the communication with the UI thread then onTaskRemoved() gets called and the old service will be stopped. The new service will be running in the background. 2.为何servive.startForeground()添加的Notification可以在service被杀死后去掉呢？我们分析源码：ActiveServices中killServicesLocked()-&gt;scheduleServiceRestartLocked()中调用了r.cancelNotification()，清除了notification: 1234567891011121314151617181920212223public void cancelNotification() &#123; if (foregroundId != 0) &#123; // Do asynchronous communication with notification manager to // avoid deadlocks. final String localPackageName = packageName; final int localForegroundId = foregroundId; ams.mHandler.post(new Runnable() &#123; public void run() &#123; INotificationManager inm = NotificationManager.getService(); if (inm == null) &#123; return; &#125; try &#123; inm.cancelNotificationWithTag(localPackageName, null, localForegroundId, userId); &#125; catch (RuntimeException e) &#123; Slog.w(TAG, &quot;Error canceling notification for service&quot;, e); &#125; catch (RemoteException e) &#123; &#125; &#125; &#125;); &#125; &#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kotlin语法]]></title>
    <url>%2F2017%2F10%2F31%2Fl-kotlin%2F</url>
    <content type="text"><![CDATA[字符串比较123var str1 = &quot;chaychan&quot;var str2 = &quot;chaychan&quot;println(str1 == str2) 比较两个字符串，如果两个字符串的内容一致，在Java中使用 str1 == str2 时，是比较两个字符串的地址值，很清楚两个字符串的地址不一样，返回false，但是在kotlin中，则不是如此，比较的只是字符串的内容，而===相当于Java中的==，用来比较引用对象, 上述代码返回的是true。 equal函数 equals(str:String) 方法中的参数是与之对比的字符串，默认不忽略大小写，即大小写敏感，比如： 123var str1 = &quot;chaychan&quot;var str2 = &quot;ChayChan&quot;println(str1.equals(str2)) 打印结果为false，因为不忽略大小写的话，两个字符串内容对比是不一致的，所以返回false。 equals(str:String,ignoreCase:Boolean) 方法中有两个参数，第一个参数是与之对比的字符串，第二个参数是布尔类型的值，是否忽略大小写，如：123var str1 = &quot;chaychan&quot;var str2 = &quot;ChayChan&quot;println(str1.equals(str2,true)) 返回结果为true。 源码优化分析源码 1.Lateinit在View声明阶段，都会需要使用lateinit来延迟声明变量。 12345class TaskActivity : AppCompatActivity()&#123; private val CURRENT_FILTERING_KEY = &quot;CURRENT_FILTERING_KEY&quot;; private lateinit var drawerLayout : DrawerLayout private lateinit var tasksPresenter:TasksPresenter&#125; kotlin中延迟声明还包括lazy的方式 12val name:String by lazy &#123;&quot;cangwang&quot;&#125;lateinit var drawLayout:drawLayout 区别在于: .lazy{}只能用再val类型,lateinit只能用在var类型 .lateinit不能用在可空的属性上和java的基本类型上lateinit var name:String会报错 .lateinit可以在任何位置初始化并且可以初始化多次,因为其衔接var变量.而lazy在第一次被调用时就被初始化,其衔接的是val常量,想要被改变只能重新定义 2.findViewByIdApi26前: 1234@Overridepublic View findViewById(@IdRes int id)&#123; return getDelegate().findViewById(id);&#125; Api26之后 12345@SuppressWarnings(&quot;TypeParameterUnusedInFormals&quot;)@Overridepublic &lt;T extends View&gt; T indViewById(@IdRes int id)&#123; return getDelegate().findViewById(id);&#125; 五个kotlin Standard.kt里面的函数:apply,with,let,run,also apply作用12345setSupportActionBar(findViewById&lt;Toolbar&gt;(R.id.toolbar))supportActionBar?.apply&#123; setDisplayHomeAsUpEnabled(true) setDisplayShowHomeEnabled(true)&#125; 在函数内可以通过this指代该对象,返回值为该对象自己 with函数 将某对象作为函数的参数,在函数内可以通过this指代该对象.返回值为函数块的最后一行或指定return表达式1234567891011121314override fun getView(i:Int,view:View?,viewGroup:ViewGroup):View&#123; val rowView=Vview?:LayoutInflater.from(viewGroup.context).inflate(R.layout.task_item,viewGroup,false) val task = getItem(i) with(rowView.findViewById&lt;TextView&gt;(R.id.title))&#123; text = task.titleForList &#125; with(rowView.findViewById&lt;CheckBox&gt;(R.id.complete))&#123; isChecked=task.isCompleted rowView.setBackgroundDrawable(...) setOnClickListener&#123; &#125; &#125;&#125; 3.lat函数12345private fun showMessage(message:String)&#123; view?.let&#123; Snackbar.make(it,message,Snackbar.LENGTH_LONG).show() &#125;&#125; 将对象作为函数参数,在函数块内可以通过it指代该对象.返回值为函数块的最后一行或指定return表达式 4. run函数其有两种表达式: 第一种无参数输入 第二种会将对象本身this给函数调用 返回值为函数块最后一行,或者指定return表达式 Object单例对象是使用Object申明 Kotlin没有静态属性和方法,需要使用单例对象来实现类似的功能. data相当于java中定义的数据bean类,其可以直接在属性之后编写get和set方法 @JvmOverloads]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tool-as3]]></title>
    <url>%2F2017%2F10%2F31%2Ftool-as3%2F</url>
    <content type="text"><![CDATA[AndroidStudio3.0新特性支持Java8语言由于AS3.0默认支持Java8语言，所以我们就可以移除build.gradle里面的jackOptions了 jackOptions { true } 然后可以在build.gradle配置为Java8 1234567android &#123; ... compileOptions &#123; sourceCompatibility JavaVersion.VERSION_1_8 targetCompatibility JavaVersion.VERSION_1_8 &#125;&#125; 如果对Java8的一些特性存在问题,我们也可以在gradle.properties里面禁用Java8 1android.enableDesugar=false 配置产品渠道AS3.0以前我们常用productFlavors配置不同的渠道包，比如 123456789productFlavors &#123; dev&#123; applicationIdSuffix &quot;.dev&quot; ... &#125; prod &#123; ... &#125; &#125; AS3.0得新增flavorDimensions的配置，主要有以下 12 个构建变体： 构建变体： 1[minApi24, minApi23, minApi21][Demo, Full][Debug, Release] 对应 APK： 1app-[minApi24, minApi23, minApi21]-[demo, full]-[debug, release].apk 比如这里创建一个构建方式 首先得在defaultConfig通过flavorDimensions配置构建变体，如下 1234defaultConfig &#123; ... flavorDimensions &quot;debug&quot;,&quot;release&quot; &#125; 然后productFlavors的配置就可以如下: 1234567891011productFlavors &#123; demo &#123; dimension &quot;debug&quot; applicationIdSuffix &quot;.demo&quot; ... &#125; prod &#123; dimension &quot;release&quot; ... &#125; &#125; 改进的Android插件 优化了多 module 的项目并行编译运行更详细Task的展示 构建变体的从属管理，比如上文的Flavors Dimensions配置新 api ，implementation依赖（替代compile ），compileOnly（替代provided）和runtimeOnly（替代 apk） 通过增量编译 优化多dex的app构建速度 优化了AAPT2增量资源化处理。如果要启用AAPT2,在gradle.properties文件添加代码：android.enableAapt2=true 支持java8语言 增加测试工具，可通过dependencies依赖使用1234dependencies&#123; androidTestUtil“com.linkedin.testbutler：测试管家应用：1.3.0@apk” ...&#125; 常见出错总结1Error:Cause: getMainOutputFile is no longer supported. Use getOutputFileName if you need to determine the file name of the output. 或 1Error:Not valid. 主要是AndResGuard1.2.3版本还没有兼容AS3.0 1Error:All flavors must now belong to a named flavor dimension. The flavor &apos;prod&apos; is not assigned to a flavor dimension. Learn more at https://d.android.com/r/tools/flavorDimensions-missing-error-message.html AS3.0需要通过flavorDimensions来配置产品渠道，详细看上文。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>AndroidStudio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/CPP中的编程技巧及其概念]]></title>
    <url>%2F2017%2F10%2F17%2Ftips-candcpp%2F</url>
    <content type="text"><![CDATA[C Languagesize_tsize_t的全称应该是size type，就是说“一种用来记录大小的数据类型”。属于C99标准，它所定义的变量可以进行加减乘除运算。因此函数中表示数据大小的变量，推荐使用这个类型！例如： 1int xxx(voidvoid *p, size_t len); 指针的指针（双重指针）的作用： 用来传递需要修改的指针参数到函数中； 用来动态生成多维数组； 多用于指针交换，可以避免数据复制，提升系统的性能，同时还可以让函数修改指针，例如扩充其大小，指向等一般指针的指针用作参数，大多用在需要函数改变指针(重新引用变量)而又不能通过返回值传递(例如返回值用于传递其他结果)时。 内联函数以空间换时间。 backtrace函数追踪函数调用堆栈以及定位段错误一般察看函数运行时堆栈的方法是使用GDB（bt命令）之类的外部调试器,但是,有些时候为了分析程序的BUG,(主要针对长时间运行程序的分析),在程序出错时打印出函数的调用堆栈是非常有用的 CPP显示限定数组实参的原始个数数组在作为函数参数传递时会退化为指针： A declaration of a parameter as “array of type” shall be adjusted to “qualified pointer to type”. 以及前面已经提到的： int x[3][5];Here x is a 3 × 5 array of integers. When x appears in an expression, it is converted to a pointer to (the first of three) five-membered arrays of integers. 这意味着数组作为参数传递时会丢失边界(C/C++的原生数组本来也就没有边界检查…)。 123void funcA(int x[10])&#123;&#125;// Equivalent tovoid funcB(int *x)&#123;&#125; 其对应的中间代码为： 123456789101112; Function Attrs: nounwind uwtabledefine void @_Z5funcAPi(i32*) #4 &#123; %2 = alloca i32*, align 8 store i32* %0, i32** %2, align 8 ret void&#125;; Function Attrs: nounwind uwtabledefine void @_Z5funcBPi(i32*) #4 &#123; %2 = alloca i32*, align 8 store i32* %0, i32** %2, align 8 ret void&#125; 如果数组边界的精确数值非常重要，并且希望函数只接收含有特定数量的元素的数组，可以使用引用形参： 1void funcC(int (&amp;x)[10])&#123;&#125; 其中间代码为： 123456; Function Attrs: nounwind uwtabledefine void @_Z5funcCRA10_i([10 x i32]* dereferenceable(40)) #4 &#123; %2 = alloca [10 x i32]*, align 8 store [10 x i32]* %0, [10 x i32]** %2, align 8 ret void&#125; 如果我们使用数组元素个数不等于10的数组传递给funcC,会导致编译错误： 123456789// note: candidate function not viable: no known conversion from &apos;int [11]&apos; to &apos;int (&amp;)[10]&apos; for 1st argument.void funcC(int (&amp;x)[10])&#123;&#125;int main(int argc,char* argv[])&#123; int x[11]=&#123;0,1,2,3,4,5,6,7,8,9,10&#125;; // error: no matching function for call to &apos;funcC&apos;. funcC(x); return 0;&#125; 也可以使用函数模板参数来指定函数接收参数的数组大小： 12template&lt;int arrSize&gt;void funcA(int x[arrSize])&#123;&#125; 使用时： 123int x[12]funcA&lt;12&gt;(x); // OKfuncA&lt;13&gt;(x); //ERROR 启用编译器的改变符号的隐式类型转换警告12345if((unsigned int)4&lt;(unsigned int)(int)-1)&#123; cout&lt;&lt;&quot;yes&quot;&lt;&lt;endl;&#125;else&#123; cout&lt;&lt;&quot;no&quot;&lt;&lt;endl;&#125; if中的那段表达式是为true的(输出yes)，而且编译时也不会发出警告。 虽然我们指定了(int)-1，但是当将unsigned int和int比较时会发生隐式转换。即： The usual arithmetic conversions are performed on operands of arithmetic or enumeration type. 1((unsigned int)4&lt;(unsigned)(int)-1)==true Warnings about conversions between signed and unsigned integers are disabled by default in C++ unless -Wsign-conversion is explicitly enabled. 通过启用-Wsign-conversion就可以看到警告了(建议开启)。 该参数的作用为： Warn for implicit conversions that may change the sign of an integer value, like assigning a signed integer expression to an unsigned integer variable. An explicit cast silences the warning. In C, this option is enabled also by -Wconversion. 断言(assert)assert Defined in header(c++)/(C) If NDEBUG is defined as a macro name at the point in the source code where is included, then assert does nothing. If NDEBUG is not defined, then assert checks if its argument (which must have scalar type) compares equal to zero. 12345#ifdef NDEBUG#define assert(condition) ((void)0)#else#define assert(condition) /*implementation defined*/#endif assert只在Debug模式中有效，使用release模assert什么都不做了。 因为在VC++里面，release会在全局定义NDEBUG 下面的代码在VS中使用debug和release模式分别编译并输入&gt;100的数，会有不一样的结果(release不会) 123456789101112131415#include &lt;iostream&gt;using namespace std;bool func(int x) &#123; if (x &gt; 100) &#123; return true; &#125; else &#123; return false; &#125;&#125;int main(void) &#123; int i; cin &gt;&gt; i; assert(func(i));&#125; 无效的引用通常情况下我们创建的引用就是有效的，但是也可以人为因素使坏… 123456char* ident(char *p) &#123; return p; &#125;int main(int argc,char* argv[])&#123; char&amp; r &#123;*ident(nullptr)&#125;; return 0;&#125; 这是UB的行为。 in particular, a null reference cannot exist in a well-defined program, because the only way to create such a reference would be to bind it to the “object” obtained by indirection through a null pointer,which causes undefined behavior. 数组的引用123456789void f(int(&amp;r)[4])&#123; cout&lt;&lt;sizeof(r)&lt;&lt;endl;&#125;void g(void)&#123; int a[]=&#123;1,2,3,4&#125;; f(a); // OK int b[]=&#123;1,2,3&#125;; f(b); // 错误，元素个数有误&#125; 对于数组引用类型的从参数来说，元素个数也是其类型的一部分。通常只有在模板中才会使用数组引用，此时数组的引用可以通过推断得到。 12345678910template&lt;class T,int N&gt;void f(T(&amp;r)[N])&#123; // ...&#125;int a1[10];double a2[100];void g()&#123; f(a1); // T是int，N是10 f(a2); // T是double，N是100&#125; 这么做的后果是调用f()所用的不同类型的数组有多少个，对应定义的函数有多少个。 忽略函数参数的顶层const为了与C语言兼容，在C++中会自动忽略参数类型的顶层const。 例如下面的函数在C++会报重定义错误，而不是重载： 12345// 类型是int(int)int f(int x)&#123;&#125;// error: redefinition of &apos;f&apos;// 类型是int(int)int f(const int x)&#123;&#125; 不论对于哪种情况，允许修改实参也好，不允许修改实参也好，它都只是函数调用者提供的实参的一个副本。因此调用过程不会破坏调用上下文的数据安全性。 char作为数组下标时当心unsigned/signed当char类型用作数组下标时，一定要先转unsigned char（因为char通常是有符号的(依赖实现定义)）。不能直接转int或unsigned int，会数组下标越界。 12345678#include &lt;stdio.h&gt;int main(void) &#123; char ch=-1; printf(&quot;%d %u %d&quot;, (int)ch, (unsigned)ch, (unsigned char)ch); return 0;&#125;// output// -1 4294967295 255 struct tag (*[5])(float)The type designated as struct tag (*[5])(float) has type ‘‘array of pointer to function returning struct tag’’. The array has length five and the function has a single parameter of type float. Its type category is array. new一个指针数组123int TEN=10;auto A=new (void(*[TEN])(void));delete[] A; 底层(Low-Level)const和顶层(Top-Level)const 底层const(Low-Level const):表示指针所指的对象是一个常量。 顶层const(Top-Level const):表示指针本身是个常量。顶层const可以表示任意的对象是常量，这对于任何数据类型都适用。123456int ival=0;int *const ivalp_1=&amp;ival; // 不能改变ivalp_1的值，这是一个顶层constconst int ci=42; // 不能改变ci的值，这是一个顶层constconst int *ivalp_2=&amp;ci;; // 允许改变ivalp_2的值，这是一个底层constconst int *const ivalp_3=ivalp_2; //靠右的是顶层const，靠左的是底层constconst int &amp;ref=ci; // 用于声明引用的const都是底层const 其实我有一个简单的区分的方法：看const修饰的右边是什么。 对于int const *x=std::nullput;，const修饰的是x，因为x是指针，我们就暂且把此处的x当做解引用来看，他就代表x所指向的对象，则它就是底层const。 反之亦然，int * const x=std::nullptr;，因为const修饰的是指针x，所以它就是顶层const。 在构造函数中传递this指针的危害如果我们在构造函数中将this指针传递给其它的函数，有可能会引发这样的问题： 123456struct C;void no_opt(C*);struct C &#123; int c; C() : c(0) &#123; no_opt(this); &#125;&#125;; 看起来上面的代码似乎没什么问题，但是我们构造一个const C的时候，有可能会出现这样的问题： 1234567const C cobj;void no_opt(C* cptr) &#123; int i = cobj.c * 100; // value of cobj.c is unspecified cout&lt;&lt;i&lt;&lt;endl; cout &lt;&lt; cobj.c * 100 // value of cobj.c is unspecified &lt;&lt; &apos;\n&apos;;&#125; 上面的代码会编译通过并可以在no_opt中修改常量对象cobj的成员i的值。 在一个常量对象构造的时候将其this指针传递给其他函数，这意味着我们可以修改该常量中的对象的值，这是不合乎标准的。 During the construction of a const object, if the value of the object or any of its subobjects is accessed through a glvalue that is not obtained, directly or indirectly, from the constructor’s this pointer, the value of the object or subobject thus obtained is unspecified. 所以还是不要在构造函数中写将this指针传递出类外的东西(最好还是只初始化数据成员吧)… 获取当前执行程序的绝对路径有两种方法： 1234#include &lt;direct.h&gt;char buffer[MAXPATH];getcwd(buffer, MAXPATH);cout&lt;&lt;buffer&lt;&lt;endl; 这种方法有一个弊端：如果将可执行程序添加至系统的PATH路径，则获取到的是在某个目录执行时该目录的路径。 另一种方法是通过Windows API来获取： 123456const string getTheProgramAbsPath(void)&#123; TCHAR exeFullPath[MAX_PATH]; // MAX_PATH在WINDEF.h中定义了，等于260 memset(exeFullPath,0,MAX_PATH); GetModuleFileName(NULL,exeFullPath,MAX_PATH); return &#123;exeFullPath&#125;;&#125; 在此种方式下不论是否将该程序添加至系统的PATH路径以及在何处执行，都会获取该可执行程序在系统中存放的绝对路径。 一个奇葩的using用法12345using foofunc=void(int);foofunc foo;int main()&#123; foo(1);&#125; 上面的代码里： 1foofunc foo; 是声明一个函数foo，可以看一下目标文件中的符号信息(省去无关细节)： 123456$ clang++ -c testusing.cc -o testusing.o -std=c++11$ llvm-nm testusing.o-------- U _Z3fooi-------- U __main-------- U atexit00000050 T main 通过gcc工具链中的c++filt可以还原目标文件中的符号： 12$ c++filt _Z3fooifoo(int) 但是并没有定义，直接链接会产生未定义错误。 右值引用12int x=123;int &amp;&amp;y=x+1; 其IR代码为： 1234567891011121314# 使用值123初始化x%2 = alloca i32, align 4store i32 123, i32* %2, align 4# y%3 = alloca i32*, align 8# 存放x+1产生的临时对象%4 = alloca i32, align 4# 计算x+1%5 = load i32, i32* %2, align 4%6 = add nsw i32 %5, 1# x+1 产生一个临时值，该临时值为%4store i32 %6, i32* %4, align 4# 将该临时值的地址绑定到%3(y)store i32* %4, i32** %3, align 8 从而实现非拷贝行为，其行为类似于将一个对象的地址赋值给一个指针。 其实右值引用的作用就是给临时对象续命——将引用绑定到一个临时对象，不会带来额外的拷贝操作。 实现同样续命行为的还有const T&amp;： 12int x=123;const int &amp;y=x+1; 和上面的示例在LLVM下会产生一模一样的IR代码。 一个数组名字例子1234int a[]=&#123;1,2,3,4,5&#125;;int *p=(int*)(&amp;a+1);printf(&quot;%d,%d\n&quot;,*(a+1),*(p-1));// output: 2,5 到底有几种传参方式大多数人都觉得在C++函数中有以下三种传参方式： 传值(by value)：形参的值是实参的拷； 传引用(by reference)：形参是实参的别名； 传指针(by pointer)：传递指向对象的指针给形参； 实际上，C++中只有两种传参方式：传值、传引用。 因为传指针(by pointer)也是传值的一种，形参的值也只是实参的一份拷贝，只是形参和实参都是指针而已。 在C++之父的著作：《The C++ Programming Language 4th》中写道： Unless a formal argument(parameter) is a reference, a copy of the actual argument is passed to the function. 传指针(by value)只是一种利用指针的性质来实现防止拷贝带来开销的一种技巧，而不是一种传参方式。 定义拷贝/赋值与析构函数的三大法则 如果一个类需要自定义的拷贝构造函数、拷贝赋值操作符、析构函数中的任何一个，那么他往往同时需要三者。 因为编译器生成的隐式定义的copy constructor和operator=语义是逐成员拷贝(memberwise)的，所以如果编译器生成的操作不能够满足类的拷贝需求(比如类成员是具有管理某种资源的句柄)，使用编译器的隐式定义会具有浅拷贝，导致两个对象进入某种共享状态。 12345678910111213141516struct A&#123; A():memory(nullptr)&#123;&#125; void getMemory(std::size_t memSize)&#123; memory=(char*)malloc(memSize); &#125; ~A()&#123; free(memory); &#125;private: char* memory;&#125;;int main()&#123; A x; x.getMemory(12); A y; y=x;&#125; 如果使用编译器生成的语义会使对象x和y内部共享一块内存，所以需要用户自己定义拷贝构造和拷贝赋值操作符，同样的原因，因为类成员持有某种资源，也需要用户自定义一个析构函数。 引用的实现C++标准中是这么解释引用的: [ISO/IEC 14882:2014 §8.3.2]A reference can be thought of as a name of an object. 但是标准中并没有要求应该如何实现引用这一行为(这一点标准中比比皆是)，不过多数编译器底层都是使用指针来实现的。 看下列代码： 123int a=123;int &amp;ra=a;int *pc=&amp;a; 然后将其编译为LLVM-IR来看编译器的实际行为： 123456%2 = alloca i32, align 4%3 = alloca i32*, align 8%4 = alloca i32*, align 8store i32 123, i32* %2, align 4store i32* %2, i32** %3, align 8store i32* %2, i32** %4, align 8 可以看到，指针和引用在经过编译器之后具有了完全相同的行为。 适当使用编译器生成操作在特殊成员函数的隐式声明及其标准行为中提到了编译器会隐式生成和定义六种特殊的成员函数的行为。 因为编译器生成的copy constructor和copy assigment operator均是具有memberwise行为的。所以当我们撰写的类使用浅拷贝可以满足的时候(值语义)，没必要自己费劲再写相关的操作了，因为编译器生成的和你手写的一样好，而且不容易出错。 1234567struct A&#123; A(int a=0,double b=0.0):x(a),y(b)&#123;&#125; A(const A&amp;)=default; A&amp; operator=(const A&amp;)=default; int x; double y;&#125;; 虽然当你没有显式定义一个copy constructor和copy assignment operator的时候编译器就会隐式定义，但是最好还是自己手动使用=delete指定。 编译器生成的和下面这样手写的一样： 1234567891011121314struct A&#123; A(int a=0,double b=0.0):x(a),y(b)&#123;&#125; A(const A&amp; r)&#123; x=r.x; y=r.y; &#125; A&amp; operator=(const A&amp; r)&#123; x=r.x; y=r.y; return *this; &#125; int x; double y;&#125;; 显然自己手写容易出错，这样的行为可以放心地交给编译器来做。 STL容器中压缩容量和真正地删除元素摘取自《C++编程规范：101条规则/准则与最佳实践》第82条。 压缩容器容量：swap魔术1234vector&lt;int&gt; x&#123;1,2,3,4,5,6,7&#125;;// ...vector&lt;int&gt;(x).swap(x); // 压缩到合适容量vector&lt;int&gt;().swap(x); // 删除所有元素 真正地删除元素：std::remove并不执行删除操作STL中的std::remove算法并不真正地从容器中删除元素。因为std::remove属于algorithm，只操作迭代器范围，不掉用容器的成员函数，所以是不可能从容器中真正删除元素的。 来看一下SGISTL中的实现(SGISTL的实现太老，没有用到std::move)： 12345678910111213141516171819202122template &lt;class _InputIter, class _Tp&gt;inline _InputIter find(_InputIter __first, _InputIter __last, const _Tp&amp; __val)&#123; while (__first != __last &amp;&amp; !(*__first == __val)) ++__first; return __first;&#125;template &lt;class _InputIter, class _OutputIter, class _Tp&gt;_OutputIter remove_copy(_InputIter __first, _InputIter __last, _OutputIter __result, const _Tp&amp; __value) &#123; for ( ; __first != __last; ++__first) if (!(*__first == __value)) &#123; *__result = *__first; ++__result; &#125; return __result;&#125;template &lt;class _ForwardIter, class _Tp&gt;_ForwardIter remove(_ForwardIter __first, _ForwardIter __last, const _Tp&amp; __value) &#123; __first = find(__first, __last, __value); _ForwardIter __i = __first; return __first == __last ? __first : remove_copy(++__i, __last, __first, __value);&#125; 可以看到它们只是移动元素的位置，并非真正地把元素删除，只是将不该删除的元素移动到容器的首部，然后返回新的结束位置迭代器。 等于是把删除的部分移动到了元素的尾部，所以要真正地删除容器中所有匹配的元素，需要用erase-remove惯用法： 1c.erase(std::remove(c.begin(),c.end(),value),c.end()); // 删除std::remove之后容器尾部的元素 谨防隐藏基类中的重载函数如果基类中具有一个虚函数func但是其又重载了几个非虚函数： 12345678910111213141516struct A&#123; virtual void func()&#123; cout&lt;&lt;&quot;A::func()&quot;&lt;&lt;endl; &#125; void func(int)&#123; cout&lt;&lt;&quot;A::func(int)&quot;&lt;&lt;endl; &#125; void func(double)&#123; cout&lt;&lt;&quot;A::func(double)&quot;&lt;&lt;endl; &#125;&#125;;struct B:public A&#123; virtual void func()&#123; cout&lt;&lt;&quot;B::func()&quot;&lt;&lt;endl; &#125;&#125;; 如果我们想要在B对象中使用非虚版本的func函数： 123B x;// error: too many arguments to function call, expected 0, have 1x.func(123); 这是由于派生类在覆盖基类虚函数的时候会隐藏其他的重载函数，需要在B中显式引入： 1234567struct B:public A&#123; virtual void func()&#123; cout&lt;&lt;&quot;B::func()&quot;&lt;&lt;endl; &#125; // 将A::func的重载函数引入作用域 using A::func;&#125;; 宏的替代宏在预处理阶段被替换，此时C++的语法和语义规则还没有生效，宏能做的只是简单的文本替换，是极其生硬的工具。 C++中几乎从不需要宏。可以用const和enum定义易于理解的常量。用inline来避免函数调用的开销，用template指定函数系列和类型系列，用namespace避免名字冲突。 除非在条件编译时使用，其他任何时候都没有在C++中使用宏的正当理由。 类内内存分配函数C++中类内的内存分配函数都是static成员函数: Any allocation function for a class T is a static member (even if not explicitly declared static). 这意味着operator new/operator delete以及operator new[]/operator delete[]都被隐式声明为static成员函数。 异常安全 析构函数、operator new、operator delete不能抛出异常 swap操作不要抛出异常 首先做任何可能抛出异常的事情(但不会改变对象重要的状态)，然后以不会抛出异常的操作结束。 当一个被抛出的异常从throw表达式奔向catch子句时，所经之路任何一个部分执行的函数比从执行堆栈上移除其激活记录之前，都必须清理他所控制的任何资源。 不要在代码中插入可能会提前返回的代码、调用可能会抛出异常的函数、或者插入其他一些东西从而使得函数末尾的资源释放得不到执行。 指向类成员函数指针的cv版本如果我们具有一个类A，其中具有重载的成员函数func，而他们的区别只是该成员函数是否为const，那么在定义一个指向成员函数的指针时如何分别？ 12345678struct A&#123; void func()const&#123; std::cout&lt;&lt;&quot;void func()const&quot;&lt;&lt;std::endl; &#125; void func()&#123; std::cout&lt;&lt;&quot;void func()&quot;&lt;&lt;std::endl; &#125;&#125;; 如果我们只是创建一个A::func的指针，指向的只是non-const版本。 1void(A::*funcP)()=&amp;A::func; 想要指定const的版本，就需要在声明时指定const: 1void(A::*funcConstP)()const=&amp;A::func; 对于const的A对象要使用const的版本，对于non-const的A对象要使用non-const的版本，不能混用。 123456const A x;(x.*funcP)(); // ERROR!(x.*funcConstP)(); // OKA y;(y.*funcConstP)(); // ERROR!(y.*funcP)(); // OK STL中的compare操作实现不同于C语言中的宏，使用C++中的模板(template)和谓词(Predicates)可以很轻易的写出泛型的比较操作。 在宏定义中还要注意参数的副作用，因为宏只是简单的替换，比如： 1234#define MAX(a,b) a&gt;=b?a:b;MAX(--a,++b);// 被替换为--a&gt;=++b?--a:++b; 但是这个宏的实际操作这并不是我们所期待的行为。 幸运的是，在C++中我们可以使用模板来避免这种丑陋的宏定义，而且也可以传递一个自定义的谓词来实现我们的判断行为： 1234567891011struct Compare&#123; template&lt;typename T&gt; bool operator()(const T&amp; a,const T&amp; b)&#123; return a&lt;b?false:true; &#125;&#125;;template&lt;class T, class Compare&gt;const T&amp; max(const T&amp; a, const T&amp; b, Compare comp)&#123; return (comp(a, b)) ? b : a;&#125; 计算性构造函数在某些情况下，可以通过创建构造函数的方式来提高成员函数的执行效率。 123456789101112struct String&#123; String(const char* init); const String operator+(const String&amp; l,const String&amp; r)&#123; return String(l.s_,r.s_); &#125;private: String(const char* a,const char* b)&#123; s_=new char[strlen(a)+strlen(b)+1]; strcat(strcpy(s_,a),b); &#125; char *s_;&#125;; 自身类型的using成员怎么定义一个类的成员中能够获取到当前类类型的成员呢？ 可以用下面这种写法： 123456template&lt;typename T&gt;struct base&#123; using selfType=T;&#125;;template&lt;typename T&gt;struct foo:public base&lt;foo&lt;T&gt;&gt;&#123;&#125;; 虽然有种强行搞事的意思… std::vector的随机访问std::vector可以随机访问，因为其重载了[]操作符，以及有at成员函数，则通常有下面两种方式： 12345template&lt;typename T&gt;void f(std::vector&lt;T&gt;&amp; x)&#123; x[0]; x.at(0);&#125; 以上两种随机访问方式有什么区别？ 顺序容器的at(size_type)要求有范围检查。 [ISO/IEC 14882:2014]The member function at() provides bounds-checked access to container elements. at() throws out_of_range if n &gt;= a.size(). 而operator[]标准中则没有任何要求。 可以来看一下一些STL实现(SGISTL)的源码对std::vector的operator[size_type]和at(size_type)的实现： 首先是at(size_type)的实现 123456789101112// at(size_type)的实现#ifdef __STL_THROW_RANGE_ERRORSvoid _M_range_check(size_type __n) const &#123; if (__n &gt;= this-&gt;size()) __stl_throw_range_error(&quot;vector&quot;);&#125;reference at(size_type __n) &#123; _M_range_check(__n); return (*this)[__n]; &#125;const_reference at(size_type __n) const &#123; _M_range_check(__n); return (*this)[__n]; &#125;#endif /* __STL_THROW_RANGE_ERRORS */​` 再看一下operator[] (size_type)的实现： 123// operator[](size_type)的实现reference operator[](size_type __n) &#123; return *(begin() + __n); &#125;const_reference operator[](size_type __n) const &#123; return *(begin() + __n); &#125; 可以看到，operator[]的随机访问并没有范围检查。 即上面的问题： 12x[0];x.at(0); 这两个的区别在于，若x不为空，则行为相同，若x为空，x.at(0)则抛出一个std::out_of_range异常(C++标准规定)，而x[0]是未定义行为。 注意typedef和#define的区别12345678typedef int* INTPTR;#define INTPTR2 int*int main(int argc,char* argv[])&#123; INTPTR i1,i2; INTPTR2 i3,i4; return 0;&#125; 还是直接从IR代码来看吧： 1234%6 = alloca i32*, align 8%7 = alloca i32*, align 8%8 = alloca i32*, align 8%9 = alloca i32, align 4 注意%9不是i32*,它是一个i32的对象。 因为#define只是编译期的简单替换，所以在编译期展开的时候会变成这样： 1234#define INTPTR2 int*INTPTR2 i3,i4;// 编译期展开int* i3,i4; 即只有i3为int*，而i4则为int 为什么const object不是编译时常量？12const int x=10;int y[x]=&#123;0&#125;; 这里是可以的，在编译器优化下x会直接被替换为10 其中间代码如下: 12345%6 = alloca i32, align 4%7 = alloca [10 x i32], align 16store i32 10, i32* %6, align 4%8 = bitcast [10 x i32]* %7 to i8*call void @llvm.memset.p0i8.i64(i8* %8, i8 0, i64 40, i32 16, i1 false) 可以看到%7的分配时并没有使用%6，所以也并不依赖x这个对象，这个对象是编译期已知的。 但是，当我们这么写时，又如何编译期可知： 12345int x;cin&gt;&gt;x;const int y=x;// error: variable-sized object may not be initializedint z[y]=&#123;0&#125;; 这里是由于编译器扩展，所以C++也支持VLA。但是可以看到const是没办法为编译期常量的。 继承层次中的类查询在类的继承层次中，可能具有同一基类的几个不同的派生类，他们之间可能又互相继承派生出了几个继承层次，在这样的情况下如何判断某一个派生类的层次中是否继承自某一个类呢？ 可以使用dynamic_cast来实现我们的要求，关于C++类型转换的部分可以看我之前的一篇文章：详细分析下C++中的类型转换。下面先来看一下dynamic_cast在C++标准中的描述(ISO/IEC 14882:2014)： The result of the expression dynamic_cast(v) is the result of converting the expression v to type T. T shall be a pointer or reference to a complete class type, or “pointer to cv void.” The dynamic_cast operator shall not cast away constness (5.2.11). If C is the class type to which T points or refers, the run-time check logically executes as follows: If, in the most derived object pointed (referred) to by v, v points (refers) to a public base class subobject of a C object, and if only one object of type C is derived from the subobject pointed (referred) to by v the result points (refers) to that C object. Otherwise, if v points (refers) to a public base class subobject of the most derived object, and the type of the most derived object has a base class, of type C, that is unambiguous and public, the result points (refers) to the C subobject of the most derived object. Otherwise, the run-time check fails. The value of a failed cast to pointer type is the null pointer value of the required result type. A failed cast to reference type throws an exception (15.1) of a type that would match a handler (15.3) of type std::bad_cast (18.7.2). 所以我们可以对继承层次中的类指针执行dynamic_cast转换，检查是否转换成功，从而判断继承层次中是否具有某个类。 一个代码的例子如下： 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;using namespace std;struct Shape&#123; virtual void draw()=0; virtual ~Shape()&#123;&#125;&#125;;struct Roll&#123; virtual void roll()&#123;cout&lt;&lt;&quot;Roll:roll()&quot;&lt;&lt;endl;&#125; virtual ~Roll()&#123;&#125;&#125;;struct Circle:public Shape,public Roll&#123; void draw()&#123; cout&lt;&lt;&quot;Circle::draw&quot;&lt;&lt;endl; &#125; void roll()&#123; cout&lt;&lt;&quot;Circle::roll()&quot;&lt;&lt;endl; &#125; ~Circle()=default;&#125;;struct Square:public Shape&#123; void draw()&#123; cout&lt;&lt;&quot;Square::draw()&quot;&lt;&lt;endl; &#125; ~Square()=default;&#125;;int main(int argc,char* argv[])&#123; Shape *a=new Square; Roll *b=dynamic_cast&lt;Roll*&gt;(a); if(b!=NULL)&#123; cout&lt;&lt;&quot;yes&quot;&lt;&lt;endl; &#125;else&#123; cout&lt;&lt;&quot;no&quot;&lt;&lt;endl; &#125; delete a; return 0;&#125;// output: no 面的继承层次比较简单，但是当假设我们不知道Cricle和Square的具体继承层次时，那么如何判断Square中是否存在某一基类(如Roll)？ 解决的办法就是上面提到的dynamic_cast！通过dynamic_cast转换到转换到要检测的类类型的指针，如果转换成功，dynamic_cast会返回从源类型转换到目标类型的指针，如果失败会返回一个空指针(之所以不使用引用是因为要处理可能会抛出异常的潜在威胁)，这种转换并非是向上或者向下转型，而是横向转型。所以我们需要对dynamic_cast返回的对象(指针)作一个判断就可以得出检测目标的继承层次中是否存在要检测的类型。 但是，我觉得这种行为的适用场景十分狭窄，在良好的类设计下几乎不必要，如果你对自己所实现的类层次感到失控，那一定是糟糕的设计。 参考文献C/C++中的编程技巧及其概念]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[l-c-skill]]></title>
    <url>%2F2017%2F10%2F12%2Fl-c-skill%2F</url>
    <content type="text"><![CDATA[Segmentation fault段错误调试总结Segmetation fault也叫做段错误，引发的原因有好多，这里我们只说一下段错误发生时的调试方法。 方法1：加打印printf。这是最基本的往往也很有效的方法，在哪里Core掉就会在哪里停止打印–一目了然。同时这种方法也存在一个致命缺陷：如果恰巧Core掉的地方没加打印而程序代码又非常庞大又可能是多线程的，那查找问题等同于大海捞针。 方法2：gdb调试。加gdb调试往往能在Core dump时抓到，甚至能抓到哪一个文件哪个类哪个函数哪一行，甚是精确。要确保GDB能抓到可用信息要做一些准备： 加-g 参数，这样才会有调试信息。 我想是个程序员就应该知道吧。 在Makefile 中加上 -fstack-protector 和-fstack-protector-all 信息，确保函数调用栈不丢失，当然只能是一定程度的不丢失，要完成保留住是不太可能的，但起码可以得到栈顶函数。 有了上面两点对大多数的Segmentation fault都能抓住，但是函数调用栈彻底乱掉或者在动态库so中Core而这个库编译时没有加-g参数，这些情况就gdb就无能为力了。 方法3：手动获取函数调用栈。这种方法其实是借住两个系统函数backtrace和backtrace_symbol来获取函数调用栈的，把这两个函数放在信号处理函数中：当收到 SIGSEG时在信号处理函数中调用这两个函数打印函数调用栈，在没用GDB调试的时候这种方法可以代替gdb的一部分功能，这听起来是不是非常酷啊，来看一看实现吧： 12345678910111213141516171819202122232425262728293031323334#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;execinfo.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;static void SignalHandle(int sig)&#123; void *array[20]; size_t size; char **strings; int i; size = backtrace(array, 10); strings = backtrace_symbols(array, size); printf(&quot;SIGNAL ocurre %d, stack tarce:\n&quot;, sig); printf(&quot;obtained %d stack frames.\n&quot;, size); for (i = 0; i &lt; size; i++) printf(&quot;%s\n&quot;, strings); free(strings); printf(&quot;stack trace over!\n&quot;); exit(0);&#125;int main(int argc, char **argv)&#123; signal(SIGSEGV, SignalHandle); //...程序主体&#125; 当然这种方法在没有GDB时候会大显身手，经过实验就是有gdb的时候这种方法有时比gdb抓到调用栈要多一层；当然这种方法和用gdb调试一样要加-g和栈保护参数-fstack-protector 和 -fstack-protector-all。其缺点就是抓到的调用栈无效，这是什么意思呢？有时发生core dump,能定位到甚至哪一行，但是那一行根本没有明显的错误；或者追到没有调试信息的动态库里如glibc。当然这些情况大多数调试方法都无能为力，只能依靠程序员的经验了。 方法4：经验之谈。如果我们的程序是多线程的，发生core dump用以上方法均无效，除了仔细排查代码外，还有这么一方法让我们缩小范围。 c语言全局变量那些事 “C++的数组不支持多态”？ 代码执行的效率 深入理解C语言 对象的消息模型 读书笔记：对线程模型的批评 C语言的谜题 C语言函数实现的另类方法 谁说C语言很简单？ C语言下的错误处理的问题 C语言结构体里的成员数组和指针 C技巧：结构体参数转成不定参数]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arithmetic-kmp]]></title>
    <url>%2F2017%2F10%2F12%2Farithmetic-kmp%2F</url>
    <content type="text"><![CDATA[https://baike.baidu.com/item/kmp%E7%AE%97%E6%B3%95/10951804?fr=aladdin http://blog.csdn.net/yutianzuijin/article/details/11954939/]]></content>
  </entry>
  <entry>
    <title><![CDATA[(转)从头开始写项目makefile]]></title>
    <url>%2F2017%2F10%2F10%2Fcourse-makefile-project-practice%2F</url>
    <content type="text"><![CDATA[1. 基本规则一般一个稍大的linux项目会有很多个源文件组成，最终的可执行程序也是由这许多个源文件编译链接而成的。编译是把一个.c或.cpp文件编译成中间代码.o文件，链接是就使用这些中间代码文件生成可执行文件。比如在当前项目目录下有如下源文件： 123# ls common.h debug.c debug.h ipc.c ipc.h main.c tags timer.c timer.h tools.c tools.h # 以上源代码可以这样编译： 1# gcc -o target_bin main.c debug.c ipc.c timer.c tools.c 如果之后修改了其中某一个文件（如tools.c），再执行一下上一行代码即可，但如果有成千上万个源文件这样编译肯定是不够合理的。此时我们可以按下面步骤来编译： 123456# gcc -c debug.c # gcc -c ipc.c # gcc -c main.c # gcc -c timer.c # gcc -c tools.c # gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 如果其中tools.c修改了，只需要编译该文件，再执行最后生成可执行文件的操作，也就是做如下两步操作即可： 12# gcc -c tools.c # gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 这样做看上去应该很合理了。但是如果修改了多个文件，就很可能忘了编译某一文件，那么运行时就很有可能出错。如果是common.h文件修改了，那么包含该头文件的所有.c文件都需要重新编译，这样一来的话就更复杂更容易出错了。看来这种方法也不够好，手动处理很容易出错。那有没有一种自动化的处理方式呢？有的，那就是写一个Makefile来处理编译过程。 下面给一个简单的Makefile，在源代码目录下建一个名为Makefile的文件： 1234567891011121314151617target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o main.o: main.c common.h &gt;---gcc -c main.c debug.o: debug.c debug.h common.h &gt;---gcc -c debug.c ipc.o: ipc.c ipc.h common.h &gt;---gcc -c ipc.c timer.o: timer.c timer.h common.h &gt;---gcc -c timer.c tools.o: tools.c tools.h common.h &gt;---gcc -c tools.c 然后在命令行上执行命令： 1234567891011# make gcc -c main.c gcc -c debug.c gcc -c ipc.c gcc -c timer.c gcc -c tools.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # # ls common.h common.h~ debug.c debug.h debug.o ipc.c ipc.h ipc.o main.c main.o Makefile Makefile~ tags target_bin timer.c timer.h timer.o tools.c tools.h tools.o # 可见在该目录下生成了.o文件以及target_bin可执行文件。现在我们只需要执行一个make命令就可以完成所有编译工作，无需像之前一样手动执行所有动作，make命令会读取当前目录下的Makefile文件然后完成编译步骤。从编译过程输出到屏幕的内容看得到执行make命令之后所做的工作，其实就是我们之前手动执行的那些命令。现在来说一下什么是Makefile？ 所谓Makefile我的理解其实就是由一组组编译规则组成的文件，每条规则格式大致为： 123target ... : prerequisites ... &gt;---command ... 其中target是目标文件，可以为可执行文件、*.o文件或标签。Prerequisites是产生target所需要的源文件或*.o文件，可以是另一条规则的目标。commond是要产生该目标需要执行的操作系统命令，该命令必须以tab（文中以&gt;—标示tab字符）开头，不可用空格代替。 说白了就是要产生target，需要依赖后面的prerequisites文件，然后执行commond来产生来得到target。这和我们之前手动执行每条编译命令是一样的，其实就是定义好一个依赖关系，我们把产生每个文件的依赖文件写好，最终自动执行编译命令。 比如在我们给出的Makefile例子中target_bin main.o等就是target，main.o debug.o ipc.o timer.o tools.o是target_bin的prerequisites，gcc -o target_bin main.o debug.o ipc.o timer.o tools.o就是commond，把所有的目标文件编译为最终的可执行文件target，而main.c common.h是main.o的prerequisites，其gcc -c main.c命令生成target所需要的main.o文件。 在该例子中，Makefile工作过程如下： 首先查找第一条规则目标，第一条规则的目标称为缺省目标，只要缺省目标更新了就算完成任务了，其它工作都是为这个目的而做的。 该Makefile中第一条规则的目标target_bin，由于我们是第一次编译，target_bin文件还没生成，显然需要更新，但此时依赖文件main.o debug.o ipc.o timer.o tools.o都没有生成，所以需要先更新这些文件，然后才能更新target_bin。 所以make会进一步查找以这些依赖文件main.o debug.o ipc.o timer.o tools.o为目标的规则。首先找main.o，该目标也没有生成，该目标依赖文件为main.c common.h，文件存在，所以执行规则命令gcc -c main.c，生成main.o。其他target_bin所需要的依赖文件也同样操作。 最后执行gcc -o target_bin main.o debug.o ipc.o timer.o tools.o，更新target_bin。 在没有更改源代码的情况下，再次运行make： 123# make make: `target_bin&apos; is up to date. # 得到提示目标target_bin已经是最新的了。 如果修改文件main.c之后，再运行make： 12345# vim main.c # make gcc -c main.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # 此时make会自动选择受影响的目标重新编译： 首先更新缺省目标，先检查target_bin是否需要更新，这需要检查其依赖文件main.o debug.o ipc.o timer.o tools.o是否需要更新。 其次发现main.o需要更新，因为main.o目标的依赖文件main.c最后修改时间比main.o晚，所以需要执行生成目标main.o的命令：gcc -c main.c更新main.o。 最后发现目标target_bin的依赖文件main.o有更新过，所以执行相应命令gcc -o target_bin main.o debug.o ipc.o timer.o tools.o更新target_bin。 总结下，执行一条规则步骤如下： 先检查它的依赖文件，如果依赖文件需要更新，则执行以该文件为目标的的规则。如果没有该规则但找到文件，那么该依赖文件不需要更新。如果没有该规则也没有该文件，则报错退出。 再检查该文件的目标，如果目标不存在或者目标存在但依赖文件修改时间比他要晚或某依赖文件已更新，那么执行该规则的命令。 由此可见，Makefile可以自动发现更新过的文件，自动重新生成目标，使用Makefile比自己手动编译比起来，不仅效率高，还减少了出错的可能性。 Makefile中有很多目标，我们可以编译其中一个指定目标，只需要在make命令后面带上目标名称即可。如果不指定编译目标的话make会编译缺省的目标，也就是第一个目标，在本文给出的Makefile第一个目标为target_bin。如果只修改了tools.c文件的话，我们可能只想看看我们的更改的源代码是否有语法错误而又不想重新编译这个工程的话可以执行如下命令： 123# make tools.o gcc -c tools.c # 编译成功，这里又引出一个问题，如果继续执行同样的命令： 123# make tools.o make: `tools.o&apos; is up to date. # 我们先手动删掉tools.o文件再执行就可以了，怎么又是手动呢？我们要自动，要自动！！好吧，我们加一个目标来删除这些编译过程中产生的临时文件，该目标为clean。 我们在上面Makefile最后加上如下内容： 12clean: &gt;---rm *.o target_bin 当我们直接make命令时不会执行到该目标，因为没有被默认目标target_bin目标或以target_bin依赖文件为目标的目标包含在内。我们要执行该目标需要在make时指定目标即可。如下： 123# make clean rm *.o target_bin # 可见clean目标被执行到了，再执行make时make就会重新生成所有目标对应的文件，因为执行make clean时，那些文件被清除了。 clean目标应该存在与你的Makefile当中，它既可以方便你的二次编译，又可以保持的源文件的干净。该目标一般放在最后，不可放在最开头，否则会被当做缺省目标被执行，这很可能不是你的意愿。 最后总结一下，Makefile只是告诉了make命令如何来编译和链接程序，告诉make命令生成目标文件需要的文件，具体的编译链接工作是你的目标对应的命令在做。 给一个今天完整的makefile： 1234567891011121314151617181920target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o main.o: main.c common.h &gt;---gcc -c main.c debug.o: debug.c debug.h common.h &gt;---gcc -c debug.c ipc.o: ipc.c ipc.h common.h &gt;---gcc -c ipc.c timer.o: timer.c timer.h common.h &gt;---gcc -c timer.c tools.o: tools.c tools.h common.h &gt;---gcc -c tools.c clean: &gt;---rm *.o target_bin 2. 隐含规则自动推导上一节的Makefile勉强可用，但还写的比较繁琐，不够简洁。对每一个.c源文件，都需要写一个生成其对应的.o目标文件的规则，如果有几百个或上千个源文件，都手动来写，还不是很麻烦，这也不够自动化啊。 这样，我们把生成.o目标文件的规则全部删除掉，就是这样一个Makefile文件： 12345target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o clean: &gt;---rm *.o target_bin 这下简洁了不少，这样也能用吗？试试看吧先，make一下： 12345678# make cc -c -o main.o main.c cc -c -o debug.o debug.c cc -c -o ipc.o ipc.c cc -c -o timer.o timer.c cc -c -o tools.o tools.c gcc -o target_bin main.o debug.o ipc.o timer.o tools.o # 原来酱紫都可以啊！！target_bin后面那一群依赖文件怎么生成呢？不是没有生成*.o目标文件的规则了吗？再看屏幕编译输出内容： 12345cc -c -o main.o main.c cc -c -o debug.o debug.c cc -c -o ipc.o ipc.c cc -c -o timer.o timer.c cc -c -o tools.o tools.c 怎么长的和之前不太一样呢，尤其是前面那个cc是何物？ 其实make可以自动推导文件以及文件依赖关系后面的命令，于是我们就没必要去在每一个*.o文件后都写上类似的命令，因为，我们的 make 会自动推导依赖文件，并根据隐含规则自己推导命令。所以上面.o文件是由于make自动推导出的依赖文件以及命令来生成的。 下面来看看make是如何推导的。 命令make –p可以打印出很多默认变量和隐含规则。Makefile变量可以理解为C语言的宏，直接展开即可（后面会讲到）。取出我们关心的部分： 12345678910# default OUTPUT_OPTION = -o $@ # default CC = cc # default COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH) –c # Implicit Rules %.o: %.c # commands to execute (built-in): &gt;---$(COMPILE.c) $(OUTPUT_OPTION) $&lt; 其中cc是一个符号链接，指向gcc，这就可以解释为什么我们看到的编译输出为cc，其实还是使用gcc在编译。 123# ll /usr/bin/cc lrwxrwxrwx. 1 root root 3 Dec 3 2013 /usr/bin/cc -&gt; gcc # 变量$(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH)都为空。所以%.o: %.c规则命令展开为： 1cc -c -o $@ $&lt; 再看屏幕输出编译内容，摘取一条： 1cc -c -o main.o main.c 不是看出点什么？$@和main.o对应，$&lt;和main.c对应。其实$@和$&lt;是两个变量。$@为规则中的目标，$&lt;为规则中的第一个依赖文件。%.o:%.c是一种称为模式规则的特殊规则。因为main.o符合该模模式，再推导出依赖文件main.c，最终推导出整个规则为： 12main.o : main.c： &gt;--- cc -c -o main.o main.c 其余几个目标也同样推导。make自动推导的功能为我们减少了不少的Makefile代码，尤其是对源文件比较多的大型工程，我们的Makefile可以不用写得那么繁琐了。 最后，今天的Makefile相对于上一节进化成这个样子了： 12345target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o clean: &gt;---rm *.o target_bin 3. 变量的使用仔细研究我们的之前Makefile发现，我们还有改进的地方，就是此处： 12target_bin : main.o debug.o ipc.o timer.o tools.o &gt;---gcc -o target_bin main.o debug.o ipc.o timer.o tools.o 如果增加一个源文件xx.c的话，需要在两处或多处增加xx.o文件。我们可以使用变量来解决这个问题。之前说过，Makefile的变量就像C语言的宏一样，使用时在其位置上直接展开。变量在声明时赋予初值，在引用变量时需要给在变量名前加上“$”符号，但最好用小括号“（）”或是大括号“{}”把变量给包括起来。 默认目标target_bin也在多处出现了，该文件也可以使用变量代替。 修改我们的Makefile如下： 1234567SRC_OBJ = main.o debug.o ipc.o timer.o tools.o SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---gcc -o $(SRC_BIN) $(SRC_OBJ) clean: &gt;---rm $(SRC_OBJ) $(SRC_BIN) 这样每次有新增的文件是只需要在SRC_OBJ变量里面增加一个文件即可。要修改最终目标的名字是可以只修改变量SRC_BIN。 其实在之前还说过特殊变量： $@，表示规则中的目标。 $&lt;，表示规则中的第一个依赖文件。 $?，表示规则中所有比目标新的条件，组成一个列表，以空格分隔。 $^:，表示规则中的所有条件，组成一个列表，以空格分隔。 上一节我们看到make -p有很多自定义的变量，比如CC。其中很多变量我们可以直接使用或修改其变量值或增加值。我们的Makefile中可以使用CC（默认值为cc）、RM（默认值为rm -f）。 由此可见我们的Makefile还可以进一步修改： 123456SRC_OBJ = main.o debug.o ipc.o timer.o tools.o SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) 这样的Makefile编译也是可用的。 但是这样的Makefile还是需要我们手动添加文件，还是不够自动化，最好增删文件都要修改Makefile。伟大的人类真是太懒了！！于是乎，他们发明了一个函数wilcard（函数后面会讲到），它可以用来获取指定目录下的所有的.c文件列表。这样的话我们可以自动获取当前目录下所有.c源文件，然后通过其他方法再得到.o文件列表，这样的话就不需要在每次增删文件时去修改Makefile了。所谓其他方法这里给出两种： 使用patsubst函数。在$(patsubst %.c,%.o,$(dir) )中，patsubst把$(dir)中的变量符合后缀是.c的全部替换成.o。 变量值的替换。 我们可以替换变量中的共有的部分，其格式是“$(var:a=b)”或“${var:a=b}”，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。 修改后的Makefile如下： 1234567891011# SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC = $(wildcard *.c) SRC_OBJ = $(SRC:.c=.o) SRC_BIN = target_bin $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) 其中# 后面的内容为注释。 这样终于满足了那些懒人的想法了。可见在使用变量时，的确可以是编译变得更自动化。 其实变量的定义有三种运算符=、:=、?=、+=。 =运算符可以读取到后面定义的变量。比如：12345VAR = $(VAR2) VAR2 = hello_make all: &gt;---@echo =====$(VAR)===== 运行结果为： 123# =====hello_make===== # 但是这种定义可能会导致并非我们意愿的事发生，并不是很符合C语言的编程习惯。 :=运算符在遇到变量定义时立即展开。12345VAR := $(VAR2) VAR2 = hello_make all: &gt;---@echo =====$(VAR)===== 运行结果为： 123# ========== # ?=运算符在复制之前先做判断变量是否已经存在。例如var1 ?= $(var2)的意思是：如果var1没有定义过，那么?=相当于=，如果var1先前已经定义了，则什么也不做，不会给var重新赋值。 +=运算符是给变了追加值。如果变量还没有定义过就直接用+=赋值，那么+=相当于= 如何使用这几个运算符要看实际情况，有时一个大的工程可能有许多Makefile组成，变量可能在多个Makefile中都在使用，这时可能使用+=比较好。使用:=有时可能比要好。 有时在编译程序时，我们需要编译器给出警告，或加入调试信息，或告知编译器优化可执行文件。编译时C编译器的选项CFLAGS使用的较多，默认没有提供值，我们可以给该变量赋值。有时我们还需要使用链接器选项LFLAGS告诉链接器链接时需要的库文件。可能我们还需要给出包含头文件的路径，因为头文件很可能和源文件不再同一目录。所以，我们今天的Makefile加上部分注释又更新了： 1234567891011121314151617# A commonMakefile for c programs, version 1.0 # Copyright (C)2014 shallnew \at 163 \dot com CFLAGS += -g -Wall-Werror -O2 CPPFLAGS += -I.-I./inc LDFLAGS +=-lpthread # SRC_OBJ =$(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES =$(wildcard *.c) SRC_OBJ =$(SRC_FILES:.c=.o) SRC_BIN =target_bin $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_BIN) 编译： 12345678# make cc -g -Wall-Werror -O2 -I. -I./inc -c -o debug.odebug.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o ipc.oipc.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o main.omain.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o timer.otimer.c cc -g -Wall-Werror -O2 -I. -I./inc -c -o tools.otools.c cc -o target_bindebug.o ipc.o main.o timer.o tools.o -lpthread # 可见我们的预编译选项，编译选项都用到了，之前我们说过make的使用隐含规则自动推导： 1COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH) –c 其中变量CFLAGS 和 CPPFLAGS均是我们给出的，变量$(TARGET_ARCH)未给，所以在编译输出可以看到-c前面有2个空，最早未给变量是有四个空。 目前给出的Makefile基本上可以适用于那些源代码全部在同一目录下的简单项目，并且基本上在增删文件时不需要再去手动修改Makefile代码。在新的一个项目只需要把该Makefile拷贝到源代码目录下，再修改一下你需要编译的可执行文件名称以及你需要的编译连接选项即可。 后面章节将会讲到如何写多目录源代码工程下的Makefile。 最后，今天的最终Makefile是这样的： 1234567891011121314151617# A commonMakefile for c programs, version 1.0 # Copyright (C)2014 shallnew \at 163 \dot com CFLAGS += -g -Wall-Werror -O2 CPPFLAGS += -I.-I./inc LDFLAGS +=-lpthread # SRC_OBJ =$(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES =$(wildcard *.c) SRC_OBJ =$(SRC_FILES:.c=.o) SRC_BIN =target_bin $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_BIN) 3. 伪目标一般情况下，Makefile都会有一个clean目标，用于清除编译过程中产生的二进制文件。我们在第一节的Makefile就用到了这个 clean目标，该目标没有任何依赖文件，并且该目标对应的命令执行后不会生产clean文件。 像这种特点目标，它的规则所定义的命令不是去创建文件，而仅仅通过make指定目标来执行一些特定系统命令或其依赖为目标的规则（如all），称为伪目标。 一个Makefile一般都不会只有一个伪目标，如果按Makefile的“潜规则”以及其约定俗成的名字来说的话，在较大的项目的Makefile中比较常用的为目标有这些： all：执行主要的编译工作，通常用作缺省目标，放在最前面。 Install：执行编译后的安装工作，把可执行文件、配置文件、文档等分别拷到不同的安装目录。 clean：删除编译生成的二进制文件。 distclean：删除除源文件之外的所有中间生成文件，如配置文件，文档等。 tags：为vim等编辑器生成tags文件。 help：打印当前Makefile的帮助信息，比如有哪些目标可以有make指定去执行。 等。 make处理Makefile时，首先读取所有规则，建立关系依赖图。然后从缺省目标（第一个目标）或指定的目标开始执行。像clean，tags这样的目标一般不会作为缺省目标，也不会跟缺省目标有任何依赖关系，所以 make 无法生成它的依赖关系和决定它是否要执行。所以要执行这样的目标时，必须要显示的指定make该目标。就像前面我们清楚便已产生的中间二进制文件一样，需要显示执行命令：make clean。 伪目标也可以作为默认目标（如all），并且可以为其指定依赖文件。 我们先将version 1.0的Makefile完善下，我们可以加入帮助信息，tags等功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344# A common Makefile for c programs, version 1.1 # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc LDFLAGS += -lpthread # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard *.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefile for cprograms==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163 \dotcom&quot; &gt;---@echo &quot;The following targets are support:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, without link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vim editor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make [target]&apos;&quot; &gt;---@echo &quot;========================= Version 1.1=======================&quot; # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags *~ make会把执行的命令打印在屏幕上，如果我们不想把命令打印在屏幕上，只显示命令结果时，直接在命令前面加上符号“@”就可以实现。如上面help目标一样，只显示命令结果。一般我们会在make时都会输出“Compiling xxx.c…”,不输出编译时的命令。我们在后面写Makefile时可以模仿。 如果当前目录下存在一个和伪目标同名的文件时（如clean），此时如果执行命令make clean后出现如下结果： 1234# touch clean # make clean make: `clean&apos; is up to date. # 这是因为clean文件没有依赖文件，make认为目标clean是最新的不会去执行规则对应的命令。为了解决这个问题，我们可以明确地将该目标声明为伪目标。将一个目标声明为伪目标需要将它作为特殊目标.PHONY”的依赖。如下： 1.PHONY : clean 这条规则写在clean:规则的后面也行，也能起到声明clean是伪目标的作用 这样修改一下之前Makefile，将所有伪目标都作为.PHONY的依赖： 1.PHONY : all obj tag help clean disclean 这样在当前目录下存在文件clean时执行: 123# make clean rm -f debug.o ipc.o main.o timer.o tools.o target_bin target_bin.exe # 发现问题解决。 最后，给出今天最终的Makefile： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# A common Makefile for c programs, version 1.1 # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc LDFLAGS += -lpthread # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard *.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) tag: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefile for cprograms==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163 \dotcom&quot; &gt;---@echo &quot;The following targets are support:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, without link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and other information&quot; &gt;---@echo &quot; tags - create ctags for vim editor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make [target]&apos;&quot; &gt;---@echo &quot;========================= Version 1.1=======================&quot; # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags *~ .PHONY : all obj tag help clean disclean 5. 嵌套执行在大一些的项目里面，所有源代码不会只放在同一个目录，一般各个功能模块的源代码都是分开的，各自放在各自目录下，并且头文件和.c源文件也会有各自的目录，这样便于项目代码的维护。这样我们可以在每个功能模块目录下都写一个Makefile，各自Makefile处理各自功能的编译链接工作，这样我们就不必把所有功能的编译链接都放在同一个Makefile里面，这可使得我们的Makefile变得更加简洁，并且编译的时候可选择编译哪一个模块，这对分块编译有很大的好处。 现在我所处于工程目录树如下： 123456789101112131415161718192021222324252627282930313233. ├── include │ ├── common.h │ ├── ipc │ │ └── ipc.h │ └── tools │ ├── base64.h │ ├── md5.h │ └── tools.h ├── Makefile ├── src │ ├── ipc │ │ ├── inc │ │ ├── Makefile │ │ └── src │ │ └── ipc.c │ ├── main │ │ ├── inc │ │ ├── Makefile │ │ └── src │ │ ├── main.c │ │ └── main.c~ │ └── tools │ ├── inc │ ├── Makefile │ └── src │ ├── base64.c │ ├── md5.c │ └── tools.c └── tags 13 directories, 16 files 这样组织项目源码要比之前合理一些，那这样怎么来写Makefile呢？我们可以在每个目录下写一个Makefile，通过最顶层的Makefile一层一层的向下嵌套执行各层Makefile。那么我们最顶层的Makefile简单点的话可以这样写： 123456789101112# top Makefile for xxx all : &gt;---$(MAKE) -C src tags: &gt;---ctags -R clean : &gt;---$(MAKE) -C src clean .PHONY : all clean tags 命令： 1&gt;---$(MAKE) -C src 就是进入src目录继续执行该目录下的Makefile。然后src目录下的Makefile在使用同样的方法进入下一级目录tools、main、ipc，再执行该目录下的Makefile。其实这样有些麻烦，我们可以直接从顶层目录进入最后的目录执行make。再加入一些伪目标完善下，我们的顶层Makefile就出来了： 12345678910111213141516171819202122232425262728293031323334353637383940414243# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com all : &gt;---$(MAKE) -C src/ipc &gt;---$(MAKE) -C src/tools &gt;---$(MAKE) -C src/main tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, withoutlink&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.0 =======================&quot; obj: &gt;---$(MAKE) -C src/ipc obj &gt;---$(MAKE) -C src/tools obj &gt;---$(MAKE) -C src/main obj clean : &gt;---$(MAKE) -C src/ipc clean &gt;---$(MAKE) -C src/tools clean &gt;---$(MAKE) -C src/main clean distclean: &gt;---$(MAKE) -C src/ipc distclean &gt;---$(MAKE) -C src/tools distclean &gt;---$(MAKE) -C src/main distclean .PHONY : all clean distclean tags help 当我们这样组织源代码时，最下面层次的Makefile怎么写呢？肯定不可以将我们上一节的Makefile（version 1.1）直接拷贝到功能模块目录下，需要稍作修改。不能所有的模块都最终生成各自的可执行文件吧，我们目前是一个工程，所以最后只会生成一个可执行程序。我们这样做，让主模块目录生成可执行文件，其他模块目录生成静态库文件，主模块链接时要用其他模块编译产生的库文件来生成最终的程序。将上一节Makefile稍作修改得出编译库文件Makefile和编译可执行文件Makefile分别如下： 12345678910111213141516171819202122232425262728# A Makefile to generate archive file # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc -I../../include # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_LIB = libtools.a all : $(SRC_LIB) $(SRC_LIB) : $(SRC_OBJ) &gt;---$(AR) rcs $@ $^ &gt;---cp $@ ../../libs obj : $(SRC_OBJ) # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) tags *~ .PHONY : all obj clean disclean ==================== 12345678910111213141516171819202122232425262728# A Makefile to generate executive file # Copyright (C) 2014 shallnew \at 163 \dot com CFLAGS += -g -Wall -Werror -O2 CPPFLAGS += -I. -I./inc -I../../include LDFLAGS += -lpthread -L../../libs -ltools -lipc # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_BIN = target_bin all : $(SRC_BIN) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) obj : $(SRC_OBJ) # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_BIN) $(SRC_BIN).exe tags*~ .PHONY : all obj clean disclean 最后在顶层执行： 1234567891011121314151617181920212223242526272829303132333435# make clean make -C src/ipc clean make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; rm -f src/ipc.o libipc.a make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; make -C src/tools clean make[1]: Entering directory `/home/Myprojects/example_make/version-3.0/src/tools&apos; rm -f src/base64.o src/md5.o src/tools.o libtools.a make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; make -C src/main clean make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/main&apos; rm -f src/main.o target_bin target_bin.exe make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/main&apos; # make make -C src/ipc make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/ipc&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/ipc.osrc/ipc.c ar rcs libipc.a src/ipc.o cp libipc.a ../../libs make[1]: Leaving directory `/home/Myprojects/example_make/version-3.0/src/ipc&apos; make -C src/tools make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/base64.osrc/base64.c cc -g -Wall -Werror -O2 -I. -I./inc -I../../include -c -o src/md5.o src/md5.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/tools.osrc/tools.c ar rcs libtools.a src/base64.o src/md5.o src/tools.o cp libtools.a ../../libs make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/tools&apos; make -C src/main make[1]: Entering directory`/home/Myprojects/example_make/version-3.0/src/main&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/main.osrc/main.c cc -o target_bin src/main.o -lpthread -L../../libs -ltools-lipc make[1]: Leaving directory`/home/Myprojects/example_make/version-3.0/src/main&apos; # 最后生成了可执行程序文件。这样的话一个工程的各个模块就变得独立出来了，不但源码分开了，而且各自有各自的Makefile，并且各个功能模块是可独立编译的。 我们发现顶层Makefile还有可以改进的地方，就是在进入下一层目录是要重复写多次，如下： 123&gt;---$(MAKE) -C src/ipc &gt;---$(MAKE) -C src/tools &gt;---$(MAKE) -C src/main 每增加一个目录都要在多个伪目标里面加入一行，这样不够自动化啊，于是我们想到shell的循环语 句，我们可以在每条规则的命令处使用for循环。如下： 1234567DIR = src SUBDIRS = $(shell ls $(DIR)) all : &gt;---@for subdir in $(SUBDIRS); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir; \ &gt;---done 这样懒人有可以高兴很久了。不过还有问题： 上面for循环会依次进入系统命令ls列出的目录，但我们对每个目录的make顺序可能有要求，在该项目当中，main目录下的Makefile必须最后执行，因为最终的链接需要其他目录编译生成的库文件，否则会执行失败。并且在当前的Makefile中，当子目录执行make出现错误时，make不会退出。在最终执行失败的情况下，我们很难根据错误的提示定位出具体是是那个目录下的Makefile出现错误。这给问题定位造成了很大的困难。为了避免这样的问题，在命令执行错误后make退出。 所以将刚才的Makefile修改为如下 1234567DIR = src SUBDIRS = $(shell ls $(DIR)) all : &gt;---@for subdir in $(SUBDIRS); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir || exit 1; \ &gt;---done 这样在执行出错时立马退出，但这样还是没有解决问题，编译错误还是会出现。那怎么解决呢？ 我们可以通过增加规则来限制make执行顺序，这样就要用到伪目标，对每一个模块我们都为他写一条规则，每个模块名称是目标，最后需要执行的模块目标又是其他模块的目标，这样就限制了make顺序。在执行到最后需要执行的目标时，发现存在依赖，于是先更新依赖的目标，这样就不会出错了。并且这样的话，我们还可以对指定模块进行编译，比如我只修改了tools模块，我只想看看我修改的这个模块代码是否可以编译通过，我可以在编译时这样： 12345678910# make tools make -C src/tools make[1]: Entering directory`/home/Myprojects/example_make/version-2.1/src/tools&apos; cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/base64.o src/base64.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/md5.osrc/md5.c cc -g -Wall -Werror -O2 -I. -I./inc-I../../include -c -o src/tools.osrc/tools.c ar rcs libtools.a src/base64.o src/md5.o src/tools.o cp libtools.a ../../libs make[1]: Leaving directory`/home/Myprojects/example_make/version-2.1/src/tools&apos; # 还有另外一种方法也可以解决此问题，就是手动列出需要进入执行的模块名称（这里就是目录了），把最后需要执行的模块放在最后，这样for循环执行时最后需要编译链接的模块就放在最后了，不会像我们之前那样make是按照使用系统命令ls列出模块目录的顺序来执行。ls列出目录是按照每个目录的名称来排序的，我们总不能要求写代码的时候最后执行的模块的名称必须是以z开头的吧，总之不现实。 我们的顶层Makefile又进化了，也是这一节最终Makefile： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com DIR = src MODULES = $(shell ls $(DIR)) # MODULES = ipc main tools all : $(MODULES) $(MODULES): &gt;---$(MAKE) -C $(DIR)/$@ main:tools ipc obj: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done clean : &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done distclean: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; obj - just compile, withoutlink&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.0 =======================&quot; .PHONY : all clean distclean tags help 6.参数传递、条件判断、include 在多个Makefile嵌套调用时，有时我们需要传递一些参数给下一层Makefile。比如我们在顶层Makefile里面定义的打开调试信息变量DEBUG_SYMBOLS，我们希望在进入子目录执行子Makefile时该变量仍然有效，这是需要将该变量传递给子Makefile，那怎么传递呢？这里有两种方法： 在上层Makefile中使用”export”关键字对需要传递的变量进行声明。比如： 12DEBUG_SYMBOLS = TRUE export DEBUG_SYMBOLS 当不希望将一个变量传递给子 make 时，可以使用指示符 “unexport”来声明这个变量。 export一般用法是在定义变量的同时对它进行声明。如下： 1export DEBUG_SYMBOLS = TRUE 在命令行上指定变量。比如：1$(MAKE) -C xxx DEBUG_SYMBOLS = TRUE 这样在进入子目录xxx执行make时该变量也有效。 像编程语言一样，Makefile也有自己的条件语句。条件语句可以根据一个变量值来控制make的执行逻辑。比较常用的条件语句是ifeq –else-endif、ifneq-else-endif、ifdef-else-endif。 ifeq关键字用来判断参数是否相等。 比如判断是否生成调试信息可以这么用： 12345ifeq ($(DEBUG_SYMBOLS), TRUE) &gt;---CFLAGS += -g -Wall -Werror -O0 else &gt;---CFLAGS += -Wall -Werror -O2 endif Ifneq和ifeq作用相反，此关键字是用来判断参数是否不相等。 ifdef关键字用来判断一个变量是否已经定义。 后两个关键字用法和ifeq类似。 现在我们继续改进我们上一节的Makefile，上一节的Makefile完成Makefile的嵌套调用，每一个模块都有自己的Makefile。其实每个模块的Makefile都大同小异，只需要改改最后编译成生成的目标名称或者编译链接选项，规则都差不多，那么我们是否可以考虑将规则部分提取出来，每个模块只需修改各自变量即可。这样是可行的，我们将规则单独提取出来，写一个Makefile.rule，将他放在顶层Makefile同目录下，其他模块内部的Makefile只需要include该Makefile就可以了。如下： 1include $(SRC_BASE)/Makefile.rule include类似于C语言的头文件包含，你把它理解为为本替换就什么都明白了。 这样以后规则有修改的话我们直接修改该Makefile就可以了，就不用进入每一个模块去修改，这样也便于维护。 这样我们今天顶层Makefile稍作修改： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Top Makefile for C program # Copyright (C) 2014 shallnew \at 163 \dot com export DEBUG_SYMBOLS = TRUE DIR = src MODULES = $(shell ls $(DIR)) # MODULES = ipc main tools all : $(MODULES) $(MODULES): &gt;---$(MAKE) -C $(DIR)/$@ main:tools ipc clean : &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done distclean: &gt;---@for subdir in $(MODULES); \ &gt;---do $(MAKE) -C $(DIR)/$$subdir $@; \ &gt;---done tags: &gt;---ctags -R help: &gt;---@echo &quot;===============A common Makefilefor c programs==============&quot; &gt;---@echo &quot;Copyright (C) 2014 liuy0711 \at 163\dot com&quot; &gt;---@echo &quot;The following targets aresupport:&quot; &gt;---@echo &gt;---@echo &quot; all - (==make) compile and link&quot; &gt;---@echo &quot; clean - clean target&quot; &gt;---@echo &quot; distclean - clean target and otherinformation&quot; &gt;---@echo &quot; tags - create ctags for vimeditor&quot; &gt;---@echo &quot; help - print help information&quot; &gt;---@echo &gt;---@echo &quot;To make a target, do &apos;make[target]&apos;&quot; &gt;---@echo &quot;========================= Version2.2 =======================&quot; .PHONY : all clean distclean tags help 目前我们顶层目录下的目录树为： 123456789101112131415161718192021222324252627282930313233. ├── include │ ├── common.h │ ├── ipc │ │ └── ipc.h │ └── tools │ ├── base64.h │ ├── md5.h │ └── tools.h ├── libs ├── Makefile ├── Makefile.rule └── src ├── ipc │ ├──inc │ ├──Makefile │ └──src │ └── ipc.c ├── main │ ├──inc │ ├──Makefile │ └──src │ ├── main.c │ └── main.c~ └── tools ├── inc ├── Makefile └── src ├── base64.c ├── md5.c └── tools.c 14 directories, 16 files 每个子模块下的Makefile删除规则后修改为如下： 1234567891011SRC_BASE = ../.. CFLAGS += CPPFLAGS += -I. -I./inc -I$(SRC_BASE)/include # SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c)) SRC_FILES = $(wildcard src/*.c) SRC_OBJ = $(SRC_FILES:.c=.o) SRC_LIB = libtools.a include $(SRC_BASE)/Makefile.rule 而处于顶层目录下的Makefile.rule专门处理各模块编译链接时需要的规则。内容如下： 123456789101112131415161718192021222324252627282930# Copyright (C) 2014 shallnew \at 163 \dot com ifeq ($(DEBUG_SYMBOLS), TRUE) &gt;---CFLAGS += -g -Wall -Werror -O0 else &gt;---CFLAGS += -Wall -Werror -O2 endif all : $(SRC_BIN) $(SRC_LIB) ifneq ($(SRC_BIN),) $(SRC_BIN) : $(SRC_OBJ) &gt;---$(CC) -o $@ $^ $(LDFLAGS) endif ifneq ($(SRC_LIB),) $(SRC_LIB) : $(SRC_OBJ) &gt;---$(AR) rcs $@ $^ &gt;---cp $@ $(SRC_BASE)/libs endif # clean target clean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) $(SRC_BIN)$(SRC_BIN).exe distclean: &gt;---$(RM) $(SRC_OBJ) $(SRC_LIB) $(SRC_BIN)$(SRC_BIN).exe $(SRC_BASE)/libs/* $(SRC_BASE)/tags *~ .PHONY : all clean disclean ~ 我们将Makefile.rule放在顶层有可能会一不小心在命令行上面执行了该Makefile，如下： 123# make -f Makefile.rule make: Nothing tobe done for `all&apos;. # 由于我们没有定义变量$(SRC_BIN)和$(SRC_LIB)，伪目标all没有任何依赖，所以编译是无法成功的。这里我们我们应该禁止直接执行该Makefile。 在make里面有这样一个变量：MAKELEVEL，它在多级调用的 make 执行过程中。变量代表了调用的深度。在 make 一级级的执行过程中变量MAKELEVEL的值不断的发生变化，通过它的值我们可以了解当前make 递归调用的深度。顶层的MAKELEVEL的值为“0” 、下一级时为“1” 、再下一级为“2”…….，所以我们希望一个子目录的Makefile必须被上层 make 调用才可以执行，而不允许直接执行，我们可以判断变量MAKELEVEL来控制。所以我们这一节最终的Makefile.rule为： 123456789101112131415161718192021222324252627282930313233343536# Copyright (C)2014 shallnew \at 163 \dot com ifeq ($(DEBUG_SYMBOLS),TRUE) &gt;---CFLAGS +=-g -Wall -Werror -O0 else &gt;---CFLAGS +=-Wall -Werror -O2 endif ifeq($(MAKELEVEL), 0) all : msg else all : $(SRC_BIN)$(SRC_LIB) endif ifneq ($(SRC_BIN),) $(SRC_BIN) :$(SRC_OBJ) &gt;---$(CC) -o $@$^ $(LDFLAGS) endif ifneq($(SRC_LIB),) $(SRC_LIB) :$(SRC_OBJ) &gt;---$(AR) rcs$@ $^ &gt;---cp $@$(SRC_BASE)/libs endif msg: &gt;---@echo&quot;You cannot directily execute this Makefile! This Makefile should calledby toplevel Makefile.&quot; # clean target clean: &gt;---$(RM)$(SRC_OBJ) $(SRC_LIB) $(SRC_BIN) $(SRC_BIN).exe distclean: &gt;---$(RM)$(SRC_OBJ) $(SRC_LIB) $(SRC_BIN) $(SRC_BIN).exe $(SRC_BASE)/libs/*$(SRC_BASE)/tags *~ .PHONY : all cleandisclean 此时再直接执行该Makefile： 123# make -f Makefile.rule You cannot directily execute this Makefile! This Makefile should called by toplevel Makefile. # 7. 统一目标输出目录上一节我们把规则单独提取出来，方便了Makefile的维护，每个模块只需要给出关于自己的一些变量，然后再使用统一的规则Makefile。这一节我们继续改进我们的Makefile，到目前为止我们的Makefile编译链接输出的目标都在源文件同目录下或模块Makefile同一目录下，当一个项目大了之后，这样会显得很乱，寻找编译输出的文件也比较困难。既然Makefile本身就是按照我们的的规则来编译链接程序，那么我们就可以指定其编译链接目标的目录，这样，我们可以清楚输出文件的地方，并且在清除已编译的目标时直接删除指定目录即可，不需要一层一层的进入源代码目录进行删除，这样又提高了效率。 既然要统一目标输出目录，那么该目录就需要存在，所以我们可以增加一条规则来创建这些目录，包括创建可执行文件的目录、链接库文件的目录以及.o文件的目录。并且目录还可以通过条件判断根据是否产生调试信息来区分开相应的目标文件。一般一个工程的顶层目录下都会有一个build目录来存放编译的目标文件结果，目前我的工程目录下通过Makefile创建的目录build的目录树如下： 1234567891011121314151617181920build/ //build根目录 ├── unix //unix平台项目下不带调试信息输出目录 │ ├── bin //存放可执行文件目录 │ ├── lib //存放可文件目录 │ └── obj //存放.o文件目录，该目录下将每个模块生成的.o文件各自的目录下面 │ ├── ipc │ ├── main │ └── tools └── unix_dbg ////unix平台项目下带调试信息输出目录 ├── bin ├── lib └── obj ├── ipc ├── main └── tools 14 directories, 0 files``` 以上目录中bin和lib目录在顶层Makefile中创建，obj及其下面模块子目录在各模块的Makefile里面创建。顶层Makefile创建目录如下： ifeq ($(DEBUG_SYMBOLS), TRUE) —BUILDDIR = ./build/$(PLATFORM)_dbgelse—BUILDDIR = ./build/$(PLATFORM)endif all : $(BUILDDIR) $(MODULES) $(BUILDDIR): —@echo “ Create directory $@ …”—mkdir -p $(BUILDDIR)/bin $(BUILDDIR)/lib123我们在all目标里面增加了其依赖目标BUILDDIR，该目标对应的规则为创建bin目录和lib目录。这样每次编译之前都会创建目录。各模块内部Makefile创建生成.O文件的目录，如上目录树所示。类似于顶层Makefile，各模块内部Makefile需要根据平台、编译调试信息、以及模块名称来生成需要的目录名称，然后再增加创建该目录的规则。因为每个模块都会做这些处理，所以我们将这部分写在规则Makefile(Makefile.rule)里面，如下： …… define a root build directory base on the platformif without a SRC_BASE defined, just use local src directoryifeq ($(SRC_BASE),) —BUILDDIR = $(MOD_SRC_DIR)—OBJDIR = $(MOD_SRC_DIR)—LIBDIR = $(MOD_SRC_DIR)—BINDIR = $(MOD_SRC_DIR)else—ifeq ($(DEBUG_SYMBOLS), TRUE)—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)_dbg—else—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)—endif—OBJDIR = $(BUILDDIR)/obj/$(MODULE)—LIBDIR = $(BUILDDIR)/lib—BINDIR = $(BUILDDIR)/binendif……ifeq ($(MAKELEVEL), 0)all : msgelseall : lib binendif lib : $(OBJDIR) $(SRC_LIB) bin : $(OBJDIR) $(SRC_BIN) $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@……1此时我们编译一下后查看build目录： build/└── unix_dbg ├── bin ├── lib └── obj ├── ipc ├── main └── tools 7 directories, 0 files123456由于我们是开启了调试信息，所以创建了unix_dbg目录，并且该目录下创建了bin、lib、obj目录及其模块目录，但我们没有发现有文件存放在里面。到目前为止，这一节仅仅讲述如何创建统一的目标文件存放目录，但是要想将编译生成的目标文件自动生成到这些目录还没有完成。其实我们只需要给目标加上路径即可，但还是有一些详细的地方需要处理，具体的我们会在下一节中讲到，这一节暂不给出最后的Makefile。### 8. 模式规则上一节讲到目录创建成功，目标文件没有生产到对应目录下，这里我们先给目标文件加上对应目录，这样的话产生对应的目标文件会直接生成到对应目录。我们先给库文件目标和可执行文件目标加上路径，如下： lib : $(OBJDIR) $(LIBDIR)/$(SRC_LIB) bin : $(OBJDIR) $(BINDIR)/$(SRC_BIN) $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —$(AR) rcs $@ $^—cp $@ $(SRC_BASE)/libsendif1此时再执行make，完成后查看build目录树： build/└── unix_dbg ├── bin │ └── target_bin ├── lib │ ├── libipc.a │ └── libtools.a └── obj ├── ipc ├── main └── tools1可以看到，生成的目标是在对应目录下。我们乘胜追击，把.o文件也将其修改了。我们之前的每个模块Makefile大致是这样写的： SRC_BASE = ../.. CFLAGS +=CPPFLAGS += -I. -I./inc -I$(SRC_BASE)/include SRC_OBJ = $(patsubst %.c, %.o, $(wildcard *.c))SRC_FILES = $(wildcard src/*.c)SRC_OBJ = $(SRC_FILES:.c=.o)SRC_LIB = xx.a include $(SRC_BASE)/Makefile.rule1其中SRC_OBJ在此处给出，然后再在Makefile.rule中使用，此处的.o文件会在.c文件相同目录下生成，所以我们现在需要将.o文件加上路径，由于取得路径是在Makefile.rule里面，所以我们可以统一在Makefile.rule里面给变量SRC_OBJ赋值，大致如下： SRC_OBJ = $(patsubst %.c, $(OBJDIR)/%.o, $(notdir $(SRC_FILES)))12这里用到函数patsubst、notdir，关于函数会在后面讲到。这样.o文件作为目标生成之后就会生成到相应目录里面了。此时再编译： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make target../../build/unix_dbg/obj/ipc/ipc.o’, needed by ../../build/unix_dbg/lib/libipc.a&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2 12发现出错了，并且是在生成目标文件ipc.o时没有成功，查看build目录树也没有生成.o文件。为什么会生成失败呢？我们没有给出生成.o目标的规则，之前可以生成是因为make有通过隐含规则来自动推导的能力（这个之前有讲到，链接过去）。在我们没有修改之前，生成.o通过隐含规则来完成： %.o: %.c commands to execute (built-in): —$(COMPILE.c) $(OUTPUT_OPTION) $&lt;1该模式规则中目标文件是$(OBJDIR)/%.o，那么现在有了符合生成我们需要的.o文件的规则了，编译一下： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make target../../build/unix_dbg/obj/ipc/ipc.o’, needed by ../../build/unix_dbg/lib/libipc.a&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2# 123456发现还是不对，不是已经增加了模式规则了吗，为何还是没有生成.o文件。我们这里先说说静态模式规则：一个规则中可以有多个目标，规则所定义的命令对所有的目标有效。一个具有多目标的规则相当于多个规则。 规则的命令对不同的目标的执行效果不同， 因为在规则的命令中可能使用了自动化变量 `“$@”` 。 多目标规则意味着所有的目标具有相同的依赖文件。多目标通常用在以下两种情况：虽然在多目标的规则中， 可以根据不同的目标使用不同的命令 （在命令行中使用自动化变量 `“$@”` ）。但是， 多目标的规则并不能做到根据目标文件自动改变依赖文件 （像上边例子中使用自动化变量“$@”改变规则的命令一样） 。需要实现这个目的是，要用到make的静态模式。静态模式规则是这样一个规则：规则存在多个目标， 并且不同的目标可以根据目标文件的名字来自动构造出依赖文件。静态模式规则比多目标规则更通用， 它不需要多个目标具有相同的依赖。但是静态模式规则中的依赖文件必须是相类似的而不是完全相同的。静态模式规则语法如下： : : ….1比如下面是一个静态模式规则： objects = foo.o bar.o all: $(objects) $(objects): %.o: %.c$(CC) -c $(CFLAGS) $&lt; -o $@ 1该规则描述了所有的.o文件的依赖文件为对应的.c文件，对于目标“foo.o” ，取其茎“foo”替代对应的依赖模式“%.c”中的模式字符“%”之后可得到目标的依赖文件“foo.c”。这就是目标“foo.o”的依赖关系“foo.o: foo.c”，规则的命令行描述了如何完成由“foo.c”编译生成目标“foo.o” 。命令行中“$&lt;”和“$@”是自动化变量，“$&lt;” 表示规则中的第一个依赖文件， “$@” 表示规则中的目标文件。上边的这个规则描述了以下两个具体的规则： foo.o : foo.c —$(CC) -c $(CFLAGS) foo.c -o foo.obar.o : bar.c—$(CC) -c $(CFLAGS) bar.c -o bar.o123456789注：该示例与其相关描述摘抄于互联网，描述很不错，估计比我讲的详细）那静态模式规则和普通的模式规则（非静态模式规则）有什么去区别呢？两者都是用目标模式和依赖模式来构建目标的规则中的文件依赖关系，两者不同的地方是 make 在执行时使用它们的时机。静态模式规则只能用在规则中明确指出的那些文件的重建过程中。不能用在除此之外的任何文件的重建过程中，并且它对指定的每一个目标来说是唯一的。如果一个目标存在于两个规则，并且这两个规则都定义了命令， make 执行时就会提示错误。非静态模式规则可被用在任何和它相匹配的目标上，当一个目标文件同时符合多个目标模式时，make将会把第一个目标匹配的模式规则作为重建它的规则。那有没有想过如果我们指定了模式规则后，那还有隐含规则呢，那怎么选择执行哪一个模式规则呢？Makefile中明确指定的模式规则会覆盖隐含模式规则。就是说如果在Makefile中出现了一个对目标文件合适可用的模式规则，那么make就不会再为这个目标文件寻找其它隐含规则，而直接使用在Makefile中出现的这个规则。在使用时，明确规则永远优先于隐含规则。我们继续说之前的那个问题，我们定义了模式规则后还是没有生成.o文件，我们现在将其改为静态规则再试试就看，如下： $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@1执行后： makemake[1]: Entering directory /home/Myprojects/example_make/version-2.9/src/ipc&#39; make[1]: *** No rule to make targetipc.c’, needed by ../../build/unix_dbg/obj/ipc/ipc.o&#39;. Stop. make[1]: Leaving directory/home/Myprojects/example_make/version-2.9/src/ipc’make: * [ipc] Error 2# 123456789发现提示没有文件ipc.c，这说明没有生成.o的原因是没有.c文件，我很好奇的是为何使用非静态模式为何不提示呢？（还没搞懂，再研究研究，知道的可以给个提示哈~~）缺少依赖文件，为何没有*.c文件，仔细想想我们的.o文件没有和.c文件在同一目录。在我们工程中，将源代码和二进制文件（.o 文件和可执行文件）安排在不同的目录来进行区分管理。这种情况下，我们可以使用 make 提供的目录搜索依赖文件功能。该功能在下一节讲述，这一节说的够多了，有点累了。可惜最终还是没有给出一个可用的Makefile，在下一节将会给出。### 9. 目标搜索在一个较大的工程中，一般会将源代码和二进制文件（.o 文件和可执行文件）安排在不同的目录来进行区分管理。这种情况下，我们可以使用 make 提供的目录搜索依赖文件功能（在指定的若干个目录下自动搜索依赖文件）。在Makefile中，使用依赖文件的目录搜索功能。当工程的目录结构发生变化后，就可以做到不更改 Makefile的规则，只更改依赖文件的搜索目录。在我们上一节出现的问题当中，我们将.c文件统一放在src目录下，没有和Makefile目录在同一目录下，因此没有办法寻找到.o文件的依赖文件。make程序有一个特殊的变量VPATH，该变量可以指定依赖文件的搜索路径，当规则的依赖文件在当前目录不存在时，make 会在此变量所指定的目录下去寻找这些依赖文件。通常我们都是用此变量来指定规则的依赖文件的搜索路径。定义变量 “VPATH”时，使用空格或者冒号（:）将多个需要搜索的目录分开。make搜索目录的顺序是按照变量“VPATH”定义中的目录顺序进行的，当前目录永远是第一搜索目录。例如如下定义 VPATH += ./src123指定了依赖搜索目录为当前目录下的src目录，我们可以在Makefile.rules里面添加给VPATH变量赋值，而在包含该Makefile.rules之前给出当前模块.c文件所在目录。其实我们也可以直接指定依赖文件的路径，这样也是可以的，如下： $(SRC_OBJ) : $(OBJDIR)/%.o : $(MOD_SRC_DIR)/%.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@123456789101112但是这样在我们更改了工程目录结构之后，对应的依赖文件没有在同一目录下，又变得麻烦了，所以还不如直接给VPATH变量赋值，我们只需要指定源码所在的目录即可。其实我们还有另外一种搜索文件路径方法：使用vpath关键字（注意不是VPATH变量）， 它和VPATH类似，但是它可以为不同类型的文件（由文件名区分）指定不同的搜索目录。使用方法有三种：1. vpath PATTERN DIRECTORIES为所有符合模式“PATTERN”的文件指定搜索目录“DIRECTORIES” 。多个目录使用空格或者冒号（：）分开。2. vpath PATTERN清除之前为符合模式“PATTERN”的文件设置的搜索路径。3. vpath清除所有已被设置的文件搜索路径。vapth 使用方法中的“PATTERN”需要包含模式字符“%”；例如上面的定义： VPATH += ./src1可以写为： vpath %.c ./src1现在给一个我们的Makefile.rules： Copyright (C) 2014 shallnew \at 163 \dot comif without a platform defined, give value “unknow” to PLATFORMifndef PLATFORM —PLATFORM = unknowendif define a root build directory base on the platformif without a SRC_BASE defined, just use local src directoryifeq ($(SRC_BASE),) —BUILDDIR = $(MOD_SRC_DIR)—OBJDIR = $(MOD_SRC_DIR)—LIBDIR = $(MOD_SRC_DIR)—BINDIR = $(MOD_SRC_DIR)else—ifeq ($(DEBUG_SYMBOLS), TRUE)—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)_dbg—else—&gt;—BUILDDIR = $(SRC_BASE)/build/$(PLATFORM)—endif—OBJDIR = $(BUILDDIR)/obj/$(MODULE)—LIBDIR = $(BUILDDIR)/lib—BINDIR = $(BUILDDIR)/binendif update compilation flags base on “DEBUG_SYMBOLS”ifeq ($(DEBUG_SYMBOLS), TRUE) —CFLAGS += -g -Wall -Werror -O0else—CFLAGS += -Wall -Werror -O2endif VPATH += $(MOD_SRC_DIR) SRC_OBJ = $(patsubst %.c, $(OBJDIR)/%.o, $(notdir $(SRC_FILES))) ifeq ($(MAKELEVEL), 0)all : msgelseall : lib binendif lib : $(OBJDIR) $(LIBDIR)/$(SRC_LIB) bin : $(OBJDIR) $(BINDIR)/$(SRC_BIN) $(OBJDIR) : —mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —$(AR) rcs $@ $^—cp $@ $(SRC_BASE)/libsendif $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@ msg: —@echo “You cannot directily execute this Makefile! This Makefile should called by toplevel Makefile.” clean targetclean:ifneq ($(SRC_LIB),) —&gt;—$(RM) $(SRC_OBJ) $(LIBDIR)/$(SRC_LIB)endififneq ($(SRC_BIN),)—&gt;—$(RM) $(SRC_OBJ) $(BINDIR)/$(SRC_BIN)endif .PHONY : all clean12345678910111213### 10. make内嵌函数及make命令显示这一节我们讲一下make的函数，在之前的章节已经讲到了几个函数：wildcard、patsubst、notdir、shell等。一般函数的调用格式如下：`$(funcname arguments)`或`$(funcname arguments)`其中funcname是需要调用函数的函数名称，应该是make内嵌函数；arguments是函数参数，参数和函数名之间使用空格分割，如果存在多个参数时，参数之间使用逗号“,”分开。函数调用以“$”开头，使用成对的圆括号或花括号把函数名和参数括起，一般使用圆括号。下面来看一下常用的一些函数：1. 获取匹配模式文件名函数—wildcard 。用法：`$(wildcard PATTERN)`该函数会列出当前目录下所有符合模式“PATTERN”格式的文件名。返回空格分割的、存在当前目录下的所有符合模式“PATTERN”的文件名。例如： SRC_FILES = $(wildcard src/*.c)12345678返回src目录下所有.c文件列表。2. 字符串替换函数—subst。用法：`$(subst FROM,TO,TEXT)`该函数把字串“TEXT”中的“FROM”字符替换为“TO”，返回替换后的新字符串。3. 模式替换函数—patsubst。用法：`$(patsubst PATTERN,REPLACEMENT,TEXT)`该函数搜索“TEXT”中以空格分开的单词，将符合模式“TATTERN”替换为“REPLACEMENT” 。参数“PATTERN”中可以使用模式通配符“%”，来代表一个单词中的若干字符。如果参数“REPLACEMENT”中也包含一个“%” ，那么“REPLACEMENT”中的“%”将是“TATTERN”中的那个“%”所代表的字符串。例如： SRC_OBJ = $(patsubst %.c, %.o, $(SRC_FILES)) 12345将SRC_FILES中所有.c文件替换为.o返回给变量SRC_OBJ。此函数功能类似之前讲过的变量替换，http://blog.csdn.net/shallnet/article/details/37529935变量替换格式是“$(var:a=b)”或“$&#123;var:a=b&#125;”，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。例如我们存在一个代表所有.c 文件的变量。定义为“src_files = a.c b.c c.c” 。为了得到这些.c文件所对应的.o源文件。如下两种使用可以得到同一种结果： $(objects:.c=.o)$(patsubst %.c,%.o,$( src_files)) 123456789101112131415161718192021224. 过滤函数—filter。用法：$(filter PATTERN…,TEXT)该函数过滤掉字串“TEXT”中所有不符合模式“PATTERN”的单词，保留所有符合此模式的单词。可以使用多个模式。模式中一般需要包含模式字符“%” 。存在多个模式时，模式表达式之间使用空格分割。返回空格分割的“TEXT”字串中所有符合模式“PATTERN”的字串。5. 反过滤函数—filter-out。用法：`$(filter-out PATTERN...,TEXT)`和“filter”函数实现的功能相反。过滤掉字串“TEXT”中所有符合模式“PATTERN” 的单词， 保留所有不符合此模式的单词。 可以有多个模式。存在多个模式时，模式表达式之间使用空格分割。6. 取目录函数—dir。用法：`$(dir NAMES…)`从文件名序列“NAMES…”中取出各个文件名的目录部分。文件名的目录部分就是包含在文件名中的最后一个斜线`（ “/” ）` （包括斜线）之前的部分。返回空格分割的文件名序列“NAMES…”中每一个文件的目录部分。如果文件名中没有斜线，认为此文件为当前目录`（ “./” ）`下的文件。7. 取文件名函数——notdir。用法：`$(notdir NAMES…)`从文件名序列“NAMES…”中取出非目录部分。目录部分是指最后一个斜线`（ “/” ）` （包括斜线）之前的部分。删除所有文件名中的目录部分，只保留非目录部分。文件名序列“NAMES…”中每一个文件的非目录部分。8. 取后缀函数—suffix。用法：`$(suffix NAMES…) `函数从文件名序列“NAMES…”中取出各个文件名的后缀。后缀是文件名中最后一个以点“.”开始的（包含点号）部分，如果文件名中不包含一个点号，则为空。 返回以空格分割的文件名序列“NAMES…”中每一个文件的后缀序列。9. 取前缀函数—basename。用法：`$(basename NAMES…)`从文件名序列“NAMES…”中取出各个文件名的前缀部分（点号之后的部分） 。前缀部分指的是文件名中最后一个点号之前的部分。 返回空格分割的文件名序列“NAMES…”中各个文件的前缀序列。如果文件没有前缀，则返回空字串。这里仅仅讲到一些常用的函数，还有一些函数没有讲到，用到的时候可以去翻翻makefile手册。通常情况下make在编译时会打印出当前正在执行的命令，当编译链接选项很长时，会输出很多东西在屏幕上，如果我 不想再屏幕上看到很多东西，我们可以在命令前面加上@，这样命令就不会输出到屏幕了。我们这样尝试修改下： makemake[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/ipc&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/ipc’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/tools&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/tools’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/main&#39; make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/main’ 123发现只有进入目录和退出目录的显示，这样很难知道目前编译过程。其实我们可以在规则命令处加入一行类似打印：`@echo &quot;do something......&quot;`这样可以输出目前正在做的事，又不会输出正在执行命令。现在将规则修改下如下： $(OBJDIR) : —@echo “ MKDIR $(notdir $@)…”—@mkdir -p $@ ifneq ($(SRC_BIN),)$(BINDIR)/$(SRC_BIN) : $(SRC_OBJ) —@echo “ LINK $(notdir $@)…”—@$(CC) -o $@ $^ $(LDFLAGS)endif ifneq ($(SRC_LIB),)$(LIBDIR)/$(SRC_LIB) : $(SRC_OBJ) —@echo “ ARCHIVE $(notdir $@)…”—@$(AR) rcs $@ $^—@echo “ COPY $@ to $(SRC_BASE)/libs”—@cp $@ $(SRC_BASE)/libsendif $(SRC_OBJ) : $(OBJDIR)/%.o : %.c —@echo “ COMPILE $(notdir $&lt;)…”—@$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@1编译输出如下： makemake[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/ipc&#39; COMPILE ipc.c... ARCHIVE libipc.a... COPY ../../build/unix_dbg/lib/libipc.a to ../../libs make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/ipc’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/tools&#39; COMPILE base64.c... COMPILE md5.c... COMPILE tools.c... ARCHIVE libtools.a... COPY ../../build/unix_dbg/lib/libtools.a to ../../libs make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/tools’make[1]: Entering directory /home/Myprojects/example_make/version-3.1/src/main&#39; COMPILE main.c... LINK target_bin... make[1]: Leaving directory/home/Myprojects/example_make/version-3.1/src/main’ 12其中目录切换的输出仍然很多，我们可以将其关闭，这需要使用到make的参数，在make -C是指定--no-print-directory参数。我们将顶层目录下Makefile规则修改如下： $(BUILDDIR): —@echo “ Create directory $@ …”—mkdir -p $(BUILDDIR)/bin $(BUILDDIR)/lib $(MODULES): —@$(MAKE) -C $(DIR)/$@ MODULE=$@ –no-print-directory main:tools ipc clean : —@for subdir in $(MODULES); \—do $(MAKE) -C $(DIR)/$$subdir MODULE=$$subdir $@ –no-print-directory; \—done编译输出： makeCOMPILE ipc.c... ARCHIVE libipc.a... COPY ../../build/unix_dbg/lib/libipc.a to ../../libs COMPILE base64.c... COMPILE md5.c... COMPILE tools.c... ARCHIVE libtools.a... COPY ../../build/unix_dbg/lib/libtools.a to ../../libs COMPILE main.c... LINK target_bin… make cleanrm -f ../../build/unix_dbg/obj/ipc/ipc.o ../../build/unix_dbg/lib/libipc.arm -f ../../build/unix_dbg/obj/main/main.o ../../build/unix_dbg/bin/target_binrm -f ../../build/unix_dbg/obj/tools/base64.o ../../build/unix_dbg/obj/tools/md5.o../../build/unix_dbg/obj/tools/tools.o ../../build/unix_dbg/lib/libtools.a # ``` 这样看上去输出清爽多了。其实我们也可以使用make -s 来全面禁止命令的显示。 【版权声明：转载请保留出处：http://blog.csdn.net/shallnet/article/details/37358655】]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Makefile经典教程]]></title>
    <url>%2F2017%2F09%2F30%2Fcourse-makefile%2F</url>
    <content type="text"><![CDATA[什么是makefile？或许很多Winodws的程序员都不知道这个东西，因为那些Windows的IDE都为你做了这个工作，但我觉得要作一个好的和professional的程序员，makefile还是要懂。这就好像现在有这么多的HTML的编辑器，但如果你想成为一个专业人士，你还是要了解HTML的标识的含义。特别在Unix下的软件编译，你就不能不自己写makefile了，会不会写makefile，从一个侧面说明了一个人是否具备完成大型工程的能力。因为，makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。 现在讲述如何写makefile的文章比较少，这是我想写这篇文章的原因。当然，不同产商的make各不相同，也有不同的语法，但其本质都是在“文件依赖性”上做文章，这里，我仅对GNU的make进行讲述，我的环境是RedHat Linux 8.0，make的版本是3.80。必竟，这个make是应用最为广泛的，也是用得最多的。而且其还是最遵循于IEEE 1003.2-1992 标准的（POSIX.2）。 在这篇文档中，将以C/C++的源码作为我们基础，所以必然涉及一些关于C/C++的编译的知识，相关于这方面的内容，还请各位查看相关的编译器的文档。这里所默认的编译器是UNIX下的GCC和CC。 关于程序的编译和链接 在此，我想多说关于程序编译的一些规范和方法，一般来说，无论是C、C++、还是pas，首先要把源文件编译成中间代码文件，在Windows下也就是 .obj 文件，UNIX下是 .o 文件，即 Object File，这个动作叫做编译（compile）。然后再把大量的Object File合成执行文件，这个动作叫作链接（link）。 编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（O文件或是OBJ文件）。 链接时，主要是链接函数和全局变量，所以，我们可以使用这些中间目标文件（O文件或是OBJ文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。 总结一下，源文件首先会生成中间目标文件，再由中间目标文件生成执行文件。在编译时，编译器只检测程序语法，和函数、变量是否被声明。如果函数未被声明，编译器会给出一个警告，但可以生成Object File。而在链接程序时，链接器会在所有的Object File中找寻函数的实现，如果找不到，那到就会报链接错误码（Linker Error），在VC下，这种错误一般是：Link 2001错误，意思说是说，链接器未能找到函数的实现。你需要指定函数的ObjectFile. 1 Makefile 介绍make命令执行时，需要一个 Makefile 文件，以告诉make命令需要怎么样的去编译和链接程序。 首先，我们用一个示例来说明Makefile的书写规则。以便给大家一个感兴认识。这个示例来源于GNU的make使用手册，在这个示例中，我们的工程有8个C文件，和3个头文件，我们要写一个Makefile来告诉make命令如何编译和链接这几个文件。我们的规则是： 如果这个工程没有编译过，那么我们的所有C文件都要编译并被链接。 如果这个工程的某几个C文件被修改，那么我们只编译被修改的C文件，并链接目标程序。 如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的C文件，并链接目标程序。 只要我们的Makefile写得够好，所有的这一切，我们只用一个make命令就可以完成，make命令会自动智能地根据当前的文件修改的情况来确定哪些文件需要重编译，从而自己编译所需要的文件和链接目标程序。 1.1 Makefile的规则在讲述这个Makefile之前，还是让我们先来粗略地看一看Makefile的规则。 12345target... : prerequisites ... command ... ... ------------------------------------------------------------------------------- target也就是一个目标文件，可以是Object File，也可以是执行文件。还可以是一个标签（Label），对于标签这种特性，在后续的“伪目标”章节中会有叙述。 prerequisites就是，要生成那个target所需要的文件或是目标。 command也就是make需要执行的命令。（任意的Shell命令） 这是一个文件的依赖关系，也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。说白一点就是说，prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。这就是Makefile的规则。也就是Makefile中最核心的内容。 说到底，Makefile的东西就是这样一点，好像我的这篇文档也该结束了。还不尽然，这是Makefile的主线和核心，但要写好一个Makefile还不够，我会以后面一点一点地结合我的工作经验给你慢慢到来。内容还多着呢。：） 1.2 一个示例正如前面所说的，如果一个工程有3个头文件，和8个C文件，我们为了完成前面所述的那三个规则，我们的Makefile应该是下面的这个样子的。 1234567891011121314151617181920212223edit : main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.omain.o : main.c defs.h cc -c main.ckbd.o : kbd.c defs.h command.h cc -c kbd.ccommand.o : command.c defs.h command.h cc -c command.cdisplay.o : display.c defs.h buffer.h cc -c display.cinsert.o : insert.c defs.h buffer.h cc -c insert.csearch.o : search.c defs.h buffer.h cc -c search.cfiles.o : files.c defs.h buffer.h command.h cc -c files.cutils.o : utils.c defs.h cc -c utils.cclean : rm edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 反斜杠（\）是换行符的意思。这样比较便于Makefile的易读。我们可以把这个内容保存在文件为“Makefile”或“makefile”的文件中，然后在该目录下直接输入命令“make”就可以生成执行文件edit。如果要删除执行文件和所有的中间目标文件，那么，只要简单地执行一下make clean就可以了。 在这个makefile中，目标文件（target）包含：执行文件edit和中间目标文件（*.o），依赖文件（prerequisites）就是冒号后面的那些 .c 文件和 .h文件。每一个 .o 文件都有一组依赖文件，而这些 .o 文件又是执行文件 edit 的依赖文件。依赖关系的实质上就是说明了目标文件是由哪些文件生成的，换言之，目标文件是哪些文件更新的。 在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统命令，一定要以一个Tab键作为开头。记住，make并不管命令是怎么工作的，他只管执行所定义的命令。make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，那么，make就会执行后续定义的命令。 这里要说明一点的是，clean不是一个文件，它只不过是一个动作名字，有点像C语言中的lable一样，其冒号后什么也没有，那么，make就不会自动去找文件的依赖性，也就不会自动执行其后所定义的命令。要执行其后的命令，就要在make命令后明显得指出这个lable的名字。这样的方法非常有用，我们可以在一个makefile中定义不用的编译或是和编译无关的命令，比如程序的打包，程序的备份，等等。 1.3 make是如何工作的在默认的方式下，也就是我们只输入make命令。那么， make会在当前目录下找名字叫“Makefile”或“makefile”的文件。 如果找到，它会找文件中的第一个目标文件（target），在上面的例子中，他会找到“edit”这个文件，并把这个文件作为最终的目标文件。 如果edit文件不存在，或是edit所依赖的后面的 .o 文件的文件修改时间要比edit这个文件新，那么，他就会执行后面所定义的命令来生成edit这个文件。 如果edit所依赖的.o文件也存在，那么make会在当前文件中找目标为.o文件的依赖性，如果找到则再根据那一个规则生成.o文件。（这有点像一个堆栈的过程） 当然，你的C文件和H文件是存在的啦，于是make会生成 .o 文件，然后再用 .o 文件声明make的终极任务，也就是执行文件edit了。 这就是整个make的依赖性，make会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件。在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么make就会直接退出，并报错，而对于所定义的命令的错误，或是编译不成功，make根本不理。make只管文件的依赖性，即，如果在我找了依赖关系之后，冒号后面的文件还是不在，那么对不起，我就不工作啦。 通过上述分析，我们知道，像clean这种，没有被第一个目标文件直接或间接关联，那么它后面所定义的命令将不会被自动执行，不过，我们可以显示要make执行。即命令——make clean，以此来清除所有的目标文件，以便重编译。 于是在我们编程中，如果这个工程已被编译过了，当我们修改了其中一个源文件，比如file.c，那么根据我们的依赖性，我们的目标file.o会被重编译（也就是在这个依性关系后面所定义的命令），于是file.o的文件也是最新的啦，于是file.o的文件修改时间要比edit要新，所以edit也会被重新链接了（详见edit目标文件后定义的命令）。而如果我们改变了“command.h”，那么，kdb.o、command.o和files.o都会被重编译，并且，edit会被重链接。 1.4 makefile中使用变量在上面的例子中，先让我们看看edit的规则： 1234edit : main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 我们可以看到[.o]文件的字符串被重复了两次，如果我们的工程需要加入一个新的[.o]文件，那么我们需要在两个地方加（应该是三个地方，还有一个地方在clean中）。当然，我们的makefile并不复杂，所以在两个地方加也不累，但如果makefile变得复杂，那么我们就有可能会忘掉一个需要加入的地方，而导致编译失败。所以，为了makefile的易维护，在makefile中我们可以使用变量。makefile的变量也就是一个字符串，理解成C语言中的宏可能会更好。 比如，我们声明一个变量，叫objects, OBJECTS, objs, OBJS, obj, 或是 OBJ，反正不管什么啦，只要能够表示obj文件就行了。我们在makefile一开始就这样定义： 12objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.o 于是，我们就可以很方便地在我们的makefile中以“$(objects)”的方式来使用这个变量了，于是我们的改良版makefile就变成下面这个样子： 12345678910111213141516171819202122objects = main.o kbd.o command.o display.o \ insert.osearch.o files.o utils.oedit : $(objects) cc -o edit $(objects)main.o : main.c defs.h cc -c main.ckbd.o : kbd.c defs.h command.h cc -c kbd.ccommand.o : command.c defs.h command.h cc -c command.cdisplay.o : display.c defs.h buffer.h cc -c display.cinsert.o : insert.c defs.h buffer.h cc -c insert.csearch.o : search.c defs.h buffer.h cc -c search.cfiles.o : files.c defs.h buffer.h command.h cc -c files.cutils.o : utils.c defs.h cc -c utils.cclean : rm edit $(objects) 于是如果有新的 .o 文件加入，我们只需简单地修改一下 objects 变量就可以了。 关于变量更多的话题，我会在后续给你一一道来。 1.5 让make自动推导GNU的make很强大，它可以自动推导文件以及文件依赖关系后面的命令，于是我们就没必要去在每一个[.o]文件后都写上类似的命令，因为，我们的make会自动识别，并自己推导命令。 只要make看到一个[.o]文件，它就会自动的把[.c]文件加在依赖关系中，如果make找到一个whatever.o，那么whatever.c，就会是whatever.o的依赖文件。并且 cc -c whatever.c 也会被推导出来，于是，我们的makefile再也不用写得这么复杂。我们的是新的makefile又出炉了。 123456789101112131415161718objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.oedit : $(objects) cc -o edit $(objects)main.o : defs.hkbd.o : defs.h command.hcommand.o : defs.h command.hdisplay.o : defs.h buffer.hinsert.o : defs.h buffer.hsearch.o : defs.h buffer.hfiles.o : defs.h buffer.h command.hutils.o : defs.h.PHONY : cleanclean : rm edit $(objects) 这种方法，也就是make的“隐晦规则”。上面文件内容中，“.PHONY”表示，clean是个伪目标文件。 关于更为详细的“隐晦规则”和“伪目标文件”，我会在后续给你一一道来。 1.6 另类风格的makefile即然我们的make可以自动推导命令，那么我看到那堆[.o]和[.h]的依赖就有点不爽，那么多的重复的[.h]，能不能把其收拢起来，好吧，没有问题，这个对于make来说很容易，谁叫它提供了自动推导命令和文件的功能呢？来看看最新风格的makefile吧。 12345678910111213objects = main.o kbd.o command.o display.o \ insert.o search.o files.o utils.oedit : $(objects) cc -o edit $(objects)$(objects) : defs.hkbd.o command.o files.o : command.hdisplay.o insert.o search.o files.o : buffer.h.PHONY : cleanclean : rm edit $(objects) 这种风格，让我们的makefile变得很简单，但我们的文件依赖关系就显得有点凌乱了。鱼和熊掌不可兼得。还看你的喜好了。我是不喜欢这种风格的，一是文件的依赖关系看不清楚，二是如果文件一多，要加入几个新的.o文件，那就理不清楚了。 1.7 清空目标文件的规则每个Makefile中都应该写一个清空目标文件（.o和执行文件）的规则，这不仅便于重编译，也很利于保持文件的清洁。这是一个“修养”（呵呵，还记得我的《编程修养》吗）。一般的风格都是： 12clean: rm edit $(objects) 更为稳健的做法是： 123.PHONY : cleanclean : -rm edit $(objects) 前面说过，.PHONY意思表示clean是一个“伪目标”，。而在rm命令前面加了一个小减号的意思就是，也许某些文件出现问题，但不要管，继续做后面的事。当然，clean的规则不要放在文件的开头，不然，这就会变成make的默认目标，相信谁也不愿意这样。不成文的规矩是——“clean从来都是放在文件的最后”。 上面就是一个makefile的概貌，也是makefile的基础，下面还有很多makefile的相关细节，准备好了吗？准备好了就来。 2 Makefile 总述2.1 Makefile里有什么？Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。 显式规则。显式规则说明了，如何生成一个或多的的目标文件。这是由Makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。 隐晦规则。由于我们的make有自动推导的功能，所以隐晦的规则可以让我们比较粗糙地简略地书写Makefile，这是由make所支持的。 变量的定义。在Makefile中我们要定义一系列的变量，变量一般都是字符串，这个有点你C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。 文件指示。其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样；另一个是指根据某些情况指定Makefile中的有效部分，就像C语言中的预编译#if一样；还有就是定义一个多行的命令。有关这一部分的内容，我会在后续的部分中讲述。 注释。Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用“#”字符，这个就像C/C++中的“//”一样。如果你要在你的Makefile中使用“#”字符，可以用反斜框进行转义，如：\#。 最后，还值得一提的是，在Makefile中的命令，必须要以[Tab]键开始。 2.2Makefile的文件名默认的情况下，make命令会在当前目录下按顺序找寻文件名为“GNUmakefile”、“makefile”、“Makefile”的文件，找到了解释这个文件。在这三个文件名中，最好使用“Makefile”这个文件名，因为，这个文件名第一个字符为大写，这样有一种显目的感觉。最好不要用“GNUmakefile”，这个文件是GNU的make识别的。有另外一些make只对全小写的“makefile”文件名敏感，但是基本上来说，大多数的make都支持“makefile”和“Makefile”这两种默认文件名。 当然，你可以使用别的文件名来书写Makefile，比如：“Make.Linux”，“Make.Solaris”，“Make.AIX”等，如果要指定特定的Makefile，你可以使用make的“-f”和“–file”参数，如：make -f Make.Linux或make --file Make.AIX。 2.3 引用其它的Makefile在Makefile使用include关键字可以把别的Makefile包含进来，这很像C语言的#include，被包含的文件会原模原样的放在当前文件的包含位置。include的语法是： 1include&lt;filename&gt;filename可以是当前操作系统Shell的文件模式（可以保含路径和通配符） 在include前面可以有一些空字符，但是绝不能是[Tab]键开始。include和可以用一个或多个空格隔开。举个例子，你有这样几个Makefile：a.mk、b.mk、c.mk，还有一个文件叫foo.make，以及一个变量$(bar)，其包含了e.mk和f.mk，那么，下面的语句： 1include foo.make *.mk $(bar) 等价于： 1include foo.make a.mk b.mk c.mk e.mk f.mk make命令开始时，会把找寻include所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的#include指令一样。如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找： 如果make执行时，有“-I”或“–include-dir”参数，那么make就会在这个参数所指定的目录下去寻找。 如果目录/include（一般是：/usr/local/bin或/usr/include）存在的话，make也会去找。 如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如： -include 其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。 2.4 环境变量 MAKEFILES如果你的当前环境中定义了环境变量MAKEFILES，那么，make会把这个变量中的值做一个类似于include的动作。这个变量中的值是其它的Makefile，用空格分隔。只是，它和include不同的是，从这个环境变中引入的Makefile的“目标”不会起作用，如果环境变量中定义的文件发现错误，make也会不理。 但是在这里我还是建议不要使用这个环境变量，因为只要这个变量一被定义，那么当你使用make时，所有的Makefile都会受到它的影响，这绝不是你想看到的。在这里提这个事，只是为了告诉大家，也许有时候你的Makefile出现了怪事，那么你可以看看当前环境中有没有定义这个变量。 2.5 make的工作方式GNU的make工作时的执行步骤入下：（想来其它的make也是类似） 读入所有的Makefile。 读入被include的其它Makefile。 初始化文件中的变量。 推导隐晦规则，并分析所有规则。 为所有的目标文件创建依赖关系链。 根据依赖关系，决定哪些目标要重新生成。 执行生成命令。 1-5步为第一个阶段，6-7为第二个阶段。第一个阶段中，如果定义的变量被使用了，那么，make会把其展开在使用的位置。但make并不会完全马上展开，make使用的是拖延战术，如果变量出现在依赖关系的规则中，那么仅当这条依赖被决定要使用了，变量才会在其内部展开。 当然，这个工作方式你不一定要清楚，但是知道这个方式你也会对make更为熟悉。有了这个基础，后续部分也就容易看懂了。 3 Makefile书写规则规则包含两个部分，一个是依赖关系，一个是生成目标的方法。 在Makefile中，规则的顺序是很重要的，因为，Makefile中只应该有一个最终目标，其它的目标都是被这个目标所连带出来的，所以一定要让make知道你的最终目标是什么。一般来说，定义在Makefile中的目标可能会有很多，但是第一条规则中的目标将被确立为最终的目标。如果第一条规则中的目标有很多个，那么，第一个目标会成为最终的目标。make所完成的也就是这个目标。 好了，还是让我们来看一看如何书写规则。 3.1 规则举例12foo.o: foo.c defs.h # foo模块 cc -c -g foo.c 看到这个例子，各位应该不是很陌生了，前面也已说过，foo.o是我们的目标，foo.c和defs.h是目标所依赖的源文件，而只有一个命令“cc -c -g foo.c”（以Tab键开头）。这个规则告诉我们两件事： 文件的依赖关系，foo.o依赖于foo.c和defs.h的文件，如果foo.c和defs.h的文件日期要比foo.o文件日期要新，或是foo.o不存在，那么依赖关系发生。 如果生成（或更新）foo.o文件。也就是那个cc命令，其说明了，如何生成foo.o这个文件。（当然foo.c文件include了defs.h文件） 3.2 规则的语法123targets : prerequisites command ... 或是这样： 123targets : prerequisites ; command command ... targets是文件名，以空格分开，可以使用通配符。一般来说，我们的目标基本上是一个文件，但也有可能是多个文件。 command是命令行，如果其不与“target:prerequisites”在一行，那么，必须以[Tab键]开头，如果和prerequisites在一行，那么可以用分号做为分隔。（见上） prerequisites也就是目标所依赖的文件（或依赖目标）。如果其中的某个文件要比目标文件要新，那么，目标就被认为是“过时的”，被认为是需要重生成的。这个在前面已经讲过了。 如果命令太长，你可以使用反斜框\作为换行符。make对一行上有多少个字符没有限制。规则告诉make两件事，文件的依赖关系和如何成成目标文件。 一般来说，make会以UNIX的标准Shell，也就是/bin/sh来执行命令。 3.3 在规则中使用通配符如果我们想定义一系列比较类似的文件，我们很自然地就想起使用通配符。make支持三各通配符：*，?和[...]。这是和Unix的B-Shell是相同的。 ~ :波浪号（~）字符在文件名中也有比较特殊的用途。如果是“~/test”，这就表示当前用户的$HOME目录下的test目录。而“~hchen/test”则表示用户hchen的宿主目录下的test目录。（这些都是Unix下的小知识了，make也支持）而在Windows或是MS-DOS下，用户没有宿主目录，那么波浪号所指的目录则根据环境变量“HOME”而定。 *:通配符代替了你一系列的文件，如*.c表示所以后缀为c的文件。一个需要我们注意的是，如果我们的文件名中有通配符，如：*，那么可以用转义字符\，如\*来表示真实的*字符，而不是任意长度的字符串。 好吧，还是先来看几个例子吧：12clean: rm -f *.o 上面这个例子我不不多说了，这是操作系统Shell所支持的通配符。这是在命令中的通配符。 123print: *.c lpr -p $? touch print 上面这个例子说明了通配符也可以在我们的规则中，目标print依赖于所有的[.c]文件。其中的“$?”是一个自动化变量，我会在后面给你讲述。 1objects = *.o 上面这个例子，表示了，通符同样可以用在变量中。并不是说[*.o]会展开，不！objects的值就是*.o。Makefile中的变量其实就是C/C++中的宏。如果你要让通配符在变量中展开，也就是让objects的值是所有[.o]的文件名的集合，那么，你可以这样： 1objects := $(wildcard *.o) 这种用法由关键字“wildcard”指出，关于Makefile的关键字，我们将在后面讨论。 3.4 文件搜寻在一些大的工程中，有大量的源文件，我们通常的做法是把这许多的源文件分类，并存放在不同的目录中。所以，当make需要去找寻文件的依赖关系时，你可以在文件前加上路径，但最好的方法是把一个路径告诉make，让make在自动去找。 Makefile文件中的特殊变量VPATH就是完成这个功能的，如果没有指明这个变量，make只会在当前的目录中去找寻依赖文件和目标文件。如果定义了这个变量，那么，make就会在当当前目录找不到的情况下，到所指定的目录中去找寻文件了。 1VPATH = src:../headers 上面的的定义指定两个目录，src和../headers，make会按照这个顺序进行搜索。目录由“冒号”分隔。（当然，当前目录永远是最高优先搜索的地方） 另一个设置文件搜索路径的方法是使用make的vpath关键字（注意，它是全小写的），这不是变量，这是一个make的关键字，这和上面提到的那个VPATH变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。这是一个很灵活的功能。它的使用方法有三种： vpath &lt; pattern&gt; &lt; directories&gt; 为符合模式&lt; pattern&gt;的文件指定搜索目录。 vpath &lt; pattern&gt; 清除符合模式&lt; pattern&gt;的文件的搜索目录。 vpath 清除所有已被设置好了的文件搜索目录。 vapth使用方法中的&lt; pattern&gt;需要包含“%”字符。“%”的意思是匹配零或若干字符，例如，“%.h”表示所有以“.h”结尾的文件。&lt; pattern&gt;指定了要搜索的文件集，而&lt; directories&gt;则指定了的文件集的搜索的目录。例如：1vpath %.h ../headers 该语句表示，要求make在“../headers”目录下搜索所有以“.h”结尾的文件。（如果某文件在当前目录没有找到的话） 我们可以连续地使用vpath语句，以指定不同搜索策略。如果连续的vpath语句中出现了相同的&lt; pattern&gt;，或是被重复了的&lt; pattern&gt;，那么，make会按照vpath语句的先后顺序来执行搜索。如： 123vpath %.c foovpath % blishvpath %.c bar 其表示“.c”结尾的文件，先在“foo”目录，然后是“blish”，最后是“bar”目录。 12vpath %.c foo:barvpath % blish 而上面的语句则表示“.c”结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录。 3.5 伪目标最早先的一个例子中，我们提到过一个“clean”的目标，这是一个“伪目标”， 12clean: rm *.o temp 正像我们前面例子中的“clean”一样，即然我们生成了许多文件编译文件，我们也应该提供一个清除它们的“目标”以备完整地重编译而用。 （以“make clean”来使用该目标） 因为，我们并不生成“clean”这个文件。“伪目标”并不是一个文件，只是一个标签，由于“伪目标”不是文件，所以make无法生成它的依赖关系和决定它是否要执行。我们只有通过显示地指明这个“目标”才能让其生效。当然，“伪目标”的取名不能和文件名重名，不然其就失去了“伪目标”的意义了。 当然，为了避免和文件重名的这种情况，我们可以使用一个特殊的标记.PHONY来显示地指明一个目标是“伪目标”，向make说明，不管是否有这个文件，这个目标就是“伪目标”。 1.PHONY : clean 只要有这个声明，不管是否有“clean”文件，要运行“clean”这个目标，只有“make clean”这样。于是整个过程可以这样写： 123.PHONY: cleanclean: rm *.o temp 伪目标一般没有依赖的文件。但是，我们也可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个。一个示例就是，如果你的Makefile需要一口气生成若干个可执行文件，但你只想简单地敲一个make完事，并且，所有的目标文件都写在一个Makefile中，那么你可以使用“伪目标”这个特性： 1234567891011all : prog1 prog2 prog3.PHONY : allprog1 : prog1.o utils.o cc -o prog1 prog1.o utils.oprog2 : prog2.o cc -o prog2 prog2.oprog3 : prog3.o sort.o utils.o cc -o prog3 prog3.o sort.o utils.o 我们知道，Makefile中的第一个目标会被作为其默认目标。我们声明了一个“all”的伪目标，其依赖于其它三个目标。由于伪目标的特性是，总是被执行的，所以其依赖的那三个目标就总是不如“all”这个目标新。所以，其它三个目标的规则总是会被决议。也就达到了我们一口气生成多个目标的目的。“.PHONY : all”声明了“all”这个目标为“伪目标”。 随便提一句，从上面的例子我们可以看出，目标也可以成为依赖。所以，伪目标同样也可成为依赖。看下面的例子： 12345678910.PHONY: cleanall cleanobj cleandiffcleanall : cleanobj cleandiff rm programcleanobj : rm *.ocleandiff : rm *.diff “makeclean”将清除所有要被清除的文件。“cleanobj”和“cleandiff”这两个伪目标有点像“子程序”的意思。我们可以输入“makecleanall”和“make cleanobj”和“makecleandiff”命令来达到清除不同种类文件的目的 3.6 多目标Makefile的规则中的目标可以不止一个，其支持多目标，有可能我们的多个目标同时依赖于一个文件，并且其生成的命令大体类似。于是我们就能把其合并起来。当然，多个目标的生成规则的执行命令是同一个，这可能会可我们带来麻烦，不过好在我们的可以使用一个自动化变量“$@”（关于自动化变量，将在后面讲述），这个变量表示着目前规则中所有的目标的集合，这样说可能很抽象，还是看一个例子吧。 12bigoutput littleoutput : text.g generate text.g -$(subst output,,$@) &gt; $@ 上述规则等价于： 1234bigoutput : text.g generate text.g -big &gt; bigoutputlittleoutput : text.g generate text.g -little &gt; littleoutput 其中，-$(subst output,,$@)中的“$”表示执行一个Makefile的函数，函数名为subst，后面的为参数。关于函数，将在后面讲述。这里的这个函数是截取字符串的意思，“$@”表示目标的集合，就像一个数组，“$@”依次取出目标，并执于命令。 3.7 静态模式静态模式可以更加容易地定义多目标的规则，可以让我们的规则变得更加的有弹性和灵活。我们还是先来看一下语法： 123&lt;targets...&gt;: &lt;target-pattern&gt;: &lt;prereq-patterns ...&gt; &lt;commands&gt;... targets定义了一系列的目标文件，可以有通配符。是目标的一个集合。 target-parrtern是指明了targets的模式，也就是的目标集模式。 prereq-parrterns是目标的依赖模式，它对target-parrtern形成的模式再进行一次依赖目标的定义。 这样描述这三个东西，可能还是没有说清楚，还是举个例子来说明一下吧。如果我们的定义成“%.o”，意思是我们的集合中都是以“.o”结尾的，而如果我们的定义成“%.c”，意思是对所形成的目标集进行二次定义，其计算方法是，取模式中的“%”（也就是去掉了[.o]这个结尾），并为其加上[.c]这个结尾，形成的新集合。 所以，我们的“目标模式”或是“依赖模式”中都应该有“%”这个字符，如果你的文件名中有“%”那么你可以使用反斜杠\进行转义，来标明真实的“%”字符。 看一个例子： 123456objects = foo.o bar.oall: $(objects)$(objects): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@ 上面的例子中，指明了我们的目标从$object中获取，“%.o”表明要所有以“.o”结尾的目标，也就是“foo.o bar.o”，也就是变量$object集合的模式，而依赖模式“%.c”则取模式“%.o”的“%”，也就是“foobar”，并为其加下“.c”的后缀，于是，我们的依赖目标就是“foo.cbar.c”。而命令中的“$&lt;”和“$@”则是自动化变量，“$&lt;”表示所有的依赖目标集（也就是“foo.c bar.c”），“$@”表示目标集（也就是oo.o bar.o”）。于是，上面的规则展开后等价于下面的规则： 1234foo.o : foo.c $(CC) -c $(CFLAGS) foo.c -o foo.obar.o : bar.c $(CC) -c $(CFLAGS) bar.c -o bar.o 试想，如果我们的“%.o”有几百个，那种我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会一个很强大的功能。再看一个例子： 123456files = foo.elc bar.o lose.o$(filter %.o,$(files)): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@$(filter %.elc,$(files)): %.elc: %.el emacs -f batch-byte-compile $&lt; $(filter%.o,$(files))表示调用Makefile的filter函数，过滤“$filter”集，只要其中模式为“%.o”的内容。其的它内容，我就不用多说了吧。这个例字展示了Makefile中更大的弹性。 3.8 自动生成依赖性在Makefile中，我们的依赖关系可能会需要包含一系列的头文件，比如，如果我们的main.c中有一句“#include “defs.h””，那么我们的依赖关系应该是： 1main.o : main.c defs.h 但是，如果是一个比较大型的工程，你必需清楚哪些C文件包含了哪些头文件，并且，你在加入或删除头文件时，也需要小心地修改Makefile，这是一个很没有维护性的工作。为了避免这种繁重而又容易出错的事情，我们可以使用C/C++编译的一个功能。大多数的C/C++编译器都支持一个“-M”的选项，即自动找寻源文件中包含的头文件，并生成一个依赖关系。例如，如果我们执行下面的命令： 1cc -M main.c 其输出是： 1main.o : main.c defs.h 于是由编译器自动生成的依赖关系，这样一来，你就不必再手动书写若干文件的依赖关系，而由编译器自动生成了。需要提醒一句的是，如果你使用GNU的C/C++编译器，你得用-MM参数，不然，-M参数会把一些标准库的头文件也包含进来。 gcc-M main.c的输出是： 123456789main.o: main.c defs.h /usr/include/stdio.h /usr/include/features.h \ /usr/include/sys/cdefs.h /usr/include/gnu/stubs.h \ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stddef.h \ /usr/include/bits/types.h /usr/include/bits/pthreadtypes.h \ /usr/include/bits/sched.h /usr/include/libio.h \ /usr/include/_G_config.h /usr/include/wchar.h \ /usr/include/bits/wchar.h /usr/include/gconv.h \ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stdarg.h \ /usr/include/bits/stdio_lim.h gcc-MM main.c的输出则是： 1main.o: main.c defs.h 那么，编译器的这个功能如何与我们的Makefile联系在一起呢。因为这样一来，我们的Makefile也要根据这些源文件重新生成，让Makefile自已依赖于源文件？这个功能并不现实，不过我们可以有其它手段来迂回地实现这一功能。GNU组织建议把编译器为每一个源文件的自动生成的依赖关系放到一个文件中，为每一个“name.c”的文件都生成一个“name.d”的Makefile文件，[.d]文件中就存放对应[.c]文件的依赖关系。 于是，我们可以写出[.c]文件和[.d]文件的依赖关系，并让make自动更新或自成[.d]文件，并把其包含在我们的主Makefile中，这样，我们就可以自动化地生成每个文件的依赖关系了。 这里，我们给出了一个模式规则来产生[.d]文件： 1234567%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.; \ sed &apos;s,$∗\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.&gt; $@; \ rm -f $@. 这个规则的意思是，所有的[.d]文件依赖于[.c]文件，rm-f $@的意思是删除所有的目标，也就是[.d]文件，第二行的意思是，为每个依赖文件“$&#x201d;&#65292;&#x4e5f;&#23601;&#x662f;&#91;&#x2e;&#99;&#x5d;&#x6587;&#20214;&#x751f;&#x6210;&#20381;&#36182;&#25991;&#20214;&#65292;&#x201c;&#36;&#64;&#8221;&#34920;&#31034;&#x6a21;&#x5f0f;&#8220;&#37;&#46;&#x64;&#x201d;&#25991;&#x4ef6;&#xff0c;&#x5982;&#x679c;&#26377;&#19968;&#x4e2a;&#67;&#x6587;&#x4ef6;&#x662f;&#110;&#97;&#109;&#x65;&#x2e;&#x63;&#65292;&#x90a3;&#x4e48;&#8220;&#x25;&#x201d;&#x5c31;&#x662f;&#x201c;&#x6e;&#x61;&#x6d;&#x65;&#8221;&#65292;&#8220;&#xa;&#x201d;&#x610f;&#x4e3a;&#x4e00;&#x4e2a;&#x968f;&#x673a;&#x7f16;&#21495;&#xff0c;&#x7b2c;&#x4e8c;&#34892;&#29983;&#25104;&#30340;&#25991;&#20214;&#x6709;&#x53ef;&#33021;&#26159;&#8220;&#110;&#97;&#109;&#x65;&#46;&#100;&#x2e;&#49;&#50;&#51;&#52;&#x35;&#8221;&#65292;&#x7b2c;&#19977;&#x884c;&#x4f7f;&#x7528;&#x73;&#x65;&#100;&#21629;&#20196;&#20570;&#20102;&#19968;&#20010;&#26367;&#25442;&#xff0c;&#20851;&#20110;&#x73;&#101;&#x64;&#21629;&#20196;&#30340;&#x7528;&#27861;&#35831;&#x53c2;&#x770b;&#x76f8;&#20851;&#x7684;&#x4f7f;&#29992;&#x6587;&#x6863;&#x3002;&#x7b2c;&#x56db;&#34892;&#23601;&#26159;&#21024;&#x9664;&#x4e34;&#x65f6;&#25991;&#20214;&#12290;&#10;&#x603b;&#32780;&#x8a00;&#x4e4b;&#65292;&#x8fd9;&#20010;&#x6a21;&#24335;&#x8981;&#20570;&#x7684;&#x4e8b;&#x5c31;&#x662f;&#22312;&#x7f16;&#35793;&#x5668;&#29983;&#x6210;&#30340;&#x4f9d;&#36182;&#x5173;&#31995;&#20013;&#21152;&#20837;&#91;&#x2e;&#100;&#93;&#x6587;&#x4ef6;&#30340;&#20381;&#36182;&#65292;&#21363;&#x628a;&#20381;&#x8d56;&#20851;&#31995;&#65306;&#xa;&#x3c;&#x21;&#x2d;&#45;&#65532;&#x34;&#x30;&#45;&#45; 转成： 1main.o main.d : main.c defs.h 于是，我们的[.d]文件也会自动更新了，并会自动生成了，当然，你还可以在这个[.d]文件中加入的不只是依赖关系，包括生成的命令也可一并加入，让每个[.d]文件都包含一个完赖的规则。一旦我们完成这个工作，接下来，我们就要把这些自动生成的规则放进我们的主Makefile中。我们可以使用Makefile的“include”命令，来引入别的Makefile文件（前面讲过），例如： 123sources = foo.c bar.cinclude $(sources:.c=.d) 上述语句中的“$(sources:.c=.d)”中的“.c=.d”的意思是做一个替换，把变量$(sources)所有[.c]的字串都替换成[.d]，关于这个“替换”的内容，在后面我会有更为详细的讲述。当然，你得注意次序，因为include是按次来载入文件，最先载入的[.d]文件中的目标会成为默认目标 4 Makefile 书写命令每条规则中的命令和操作系统Shell的命令行是一致的。make会一按顺序一条一条的执行命令，每条命令的开头必须以[Tab]键开头，除非，命令是紧跟在依赖规则后面的分号后的。在命令行之间中的空格或是空行会被忽略，但是如果该空格或空行是以Tab键开头的，那么make会认为其是一个空命令。 我们在UNIX下可能会使用不同的Shell，但是make的命令默认是被“/bin/sh”——UNIX的标准Shell解释执行的。除非你特别指定一个其它的Shell。Makefile中，“#”是注释符，很像C/C++中的“//”，其后的本行字符都被注释。 4.1 显示命令通常，make会把其要执行的命令行在命令执行前输出到屏幕上。当我们用“@”字符在命令行前，那么，这个命令将不被make显示出来，最具代表性的例子是，我们用这个功能来像屏幕显示一些信息。如： 1@echo 正在编译XXX模块...... 当make执行时，会输出“正在编译XXX模块……”字串，但不会输出命令，如果没有“@”，那么，make将输出： 12echo 正在编译XXX模块......正在编译XXX模块...... 如果make执行时，带入make参数-n或--just-print，那么其只是显示命令，但不会执行命令，这个功能很有利于我们调试我们的Makefile，看看我们书写的命令是执行起来是什么样子的或是什么顺序的。 而make参数-s或--slient则是全面禁止命令的显示。 4.2 命令执行当依赖目标新于目标时，也就是当规则的目标需要被更新时，make会一条一条的执行其后的命令。需要注意的是，如果你要让上一条命令的结果应用在下一条命令时，你应该使用分号分隔这两条命令。比如你的第一条命令是cd命令，你希望第二条命令得在cd之后的基础上运行，那么你就不能把这两条命令写在两行上，而应该把这两条命令写在一行上，用分号分隔。如： 示例一： 123exec: cd /home/hchen pwd 示例二： 12exec: cd /home/hchen; pwd 当我们执行“make exec”时，第一个例子中的cd没有作用，pwd会打印出当前的Makefile目录，而第二个例子中，cd就起作用了，pwd会打印出“/home/hchen”。 make一般是使用环境变量SHELL中所定义的系统Shell来执行命令，默认情况下使用UNIX的标准Shell——/bin/sh来执行命令。但在MS-DOS下有点特殊，因为MS-DOS下没有SHELL环境变量，当然你也可以指定。如果你指定了UNIX风格的目录形式，首先，make会在SHELL所指定的路径中找寻命令解释器，如果找不到，其会在当前盘符中的当前目录中寻找，如果再找不到，其会在PATH环境变量中所定义的所有路径中寻找。MS-DOS中，如果你定义的命令解释器没有找到，其会给你的命令解释器加上诸如“.exe”、“.com”、“.bat”、“.sh”等后缀。 4.3 命令出错每当命令运行完后，make会检测每个命令的返回码，如果命令返回成功，那么make会执行下一条命令，当规则中所有的命令成功返回后，这个规则就算是成功完成了。如果一个规则中的某个命令出错了（命令退出码非零），那么make就会终止执行当前规则，这将有可能终止所有规则的执行。 有些时候，命令的出错并不表示就是错误的。例如mkdir命令，我们一定需要建立一个目录，如果目录不存在，那么mkdir就成功执行，万事大吉，如果目录存在，那么就出错了。我们之所以使用mkdir的意思就是一定要有这样的一个目录，于是我们就不希望mkdir出错而终止规则的运行。 为了做到这一点，忽略命令的出错，我们可以在Makefile的命令行前加一个减号“-”（在Tab键之后），标记为不管命令出不出错都认为是成功的。如： 12clean: -rm -f *.o 还有一个全局的办法是，给make加上-i或是--ignore-errors参数，那么，Makefile中所有命令都会忽略错误。而如果一个规则是以“.IGNORE”作为目标的，那么这个规则中的所有命令将会忽略错误。这些是不同级别的防止命令出错的方法，你可以根据你的不同喜欢设置。 还有一个要提一下的make的参数的是-k或是--keep-going，这个参数的意思是，如果某规则中的命令出错了，那么就终目该规则的执行，但继续执行其它规则。 4.4 嵌套执行make在一些大的工程中，我们会把我们不同模块或是不同功能的源文件放在不同的目录中，我们可以在每个目录中都书写一个该目录的Makefile，这有利于让我们的Makefile变得更加地简洁，而不至于把所有的东西全部写在一个Makefile中，这样会很难维护我们的Makefile，这个技术对于我们模块编译和分段编译有着非常大的好处。 例如，我们有一个子目录叫subdir，这个目录下有个Makefile文件，来指明了这个目录下文件的编译规则。那么我们总控的Makefile可以这样书写： 12subsystem: cd subdir &amp;&amp; $(MAKE) 其等价于： 12subsystem: $(MAKE) -C subdir 定义$(MAKE)宏变量的意思是，也许我们的make需要一些参数，所以定义成一个变量比较利于维护。这两个例子的意思都是先进入“subdir”目录，然后执行make命令。 我们把这个Makefile叫做 总控Makefile，总控Makefile的变量可以传递到下级的Makefile中（如果你显示的声明），但是不会覆盖下层的Makefile中所定义的变量，除非指定了“-e”参数。 如果你要传递变量到下级Makefile中，那么你可以使用这样的声明： 1export&lt;variable ...&gt; 如果你不想让某些变量传递到下级Makefile中，那么你可以这样声明： 1unexport&lt;variable ...&gt; 如： 示例一： 1export variable = value 其等价于： 12variable = valueexport variable 其等价于： 1export variable := value 其等价于： 12variable := valueexport variable 示例二： 1export variable += value 其等价于： 12variable += valueexport variable 如果你要传递所有的变量，那么，只要一个export就行了。后面什么也不用跟，表示传递所有的变量。 需要注意的是，有两个变量，一个是SHELL，一个是MAKEFLAGS，这两个变量不管你是否export，其总是要传递到下层Makefile中，特别是MAKEFILES变量，其中包含了make的参数信息，如果我们执行“总控Makefile”时有make参数或是在上层Makefile中定义了这个变量，那么MAKEFILES变量将会是这些参数，并会传递到下层Makefile中，这是一个系统级的环境变量。 但是make命令中的有几个参数并不往下传递，它们是“-C”,“-f”,“-h”“-o”和“-W”（有关Makefile参数的细节将在后面说明），如果你不想往下层传递参数，那么，你可以这样来： 12subsystem: cd subdir &amp;&amp; $(MAKE) MAKEFLAGS= 如果你定义了环境变量MAKEFLAGS，那么你得确信其中的选项是大家都会用到的，如果其中有“-t”,“-n”,和“-q”参数，那么将会有让你意想不到的结果，或许会让你异常地恐慌。 还有一个在“嵌套执行”中比较有用的参数，“-w”或是“–print-directory”会在make的过程中输出一些信息，让你看到目前的工作目录。比如，如果我们的下级make目录是“/home/hchen/gnu/make”，如果我们使用“make -w”来执行，那么当进入该目录时，我们会看到： 1make: Entering directory `/home/hchen/gnu/make&apos;. 而在完成下层make后离开目录时，我们会看到：1make: Leaving directory `/home/hchen/gnu/make&apos; 当你使用“-C”参数来指定make下层Makefile时，“-w”会被自动打开的。如果参数中有“-s”（“–slient”）或是“–no-print-directory”，那么，“-w”总是失效的。 4.5 定义命令包如果Makefile中出现一些相同命令序列，那么我们可以为这些相同的命令序列定义一个变量。定义这种命令序列的语法以“define”开始，以“endef”结束，如： 1234define run-yaccyacc $(firstword $^)mv y.tab.c $@endef 这里，“run-yacc”是这个命令包的名字，其不要和Makefile中的变量重名。在“define”和“endef”中的两行就是命令序列。这个命令包中的第一个命令是运行Yacc程序，因为Yacc程序总是生成“y.tab.c”的文件，所以第二行的命令就是把这个文件改改名字。还是把这个命令包放到一个示例中来看看吧。 12foo.c : foo.y $(run-yacc) 我们可以看见，要使用这个命令包，我们就好像使用变量一样。在这个命令包的使用中，命令包“run-yacc”中的“$^”就是“foo.y”，“$@”就是“foo.c”（有关这种以“$”开头的特殊变量，我们会在后面介绍），make在执行命令包时，命令包中的每个命令会被依次独立执行。 5.使用变量在 Makefile中的定义的变量，就像是C/C++语言中的宏一样，他代表了一个文本字串，在Makefile中执行的时候其会自动原模原样地展开在所使用的地方。其与C/C++所不同的是，你可以在Makefile中改变其值。在Makefile中，变量可以使用在“目标”，“依赖目标”，“命令”或是 Makefile的其它部分中。变量的命名字可以包含字符、数字，下划线（可以是数字开头），但不应该含有“:”、“#”、“=”或是空字符（空格、回车等）。变量是大小写敏感的，“foo”、“Foo”和“FOO”是三个不同的变量名。传统的Makefile的变量名是全大写的命名方式，但我推荐使用大小写搭配的变量名，如：MakeFlags。这样可以避免和系统的变量冲突，而发生意外的事情。有一些变量是很奇怪字串，如“$&lt;”、“$@”等，这些是自动化变量，我会在后面介绍。 5.1变量的基础变量在声明时需要给予初值，而在使用时，需要给在变量名前加上“$”符号，但最好用小括号“（）”或是大括号“{}”把变量给包括起来。如果你要使用真实的“$”字符，那么你需要用$$来表示。变量可以使用在许多地方，如规则中的“目标”、“依赖”、“命令”以及新的变量中。 先看一个例子： 12345objects = program.o foo.o utils.oprogram : $(objects)cc -o program $(objects)$(objects) : defs.h 变量会在使用它的地方精确地展开，就像C/C++中的宏一样，例如： 123foo = cprog.o : prog.$(foo)$(foo)$(foo) -$(foo) prog.$(foo) 展开后得到： 12prog.o : prog.ccc -c prog.c 当然，千万不要在你的Makefile中这样干，这里只是举个例子来表明Makefile中的变量在使用处展开的真实样子。可见其就是一个“替代”的原理。另外，给变量加上括号完全是为了更加安全地使用这个变量，在上面的例子中，如果你不想给变量加上括号，那也可以，但我还是强烈建议你给变量加上括号。 5.2变量中的变量在定义变量的值时，我们可以使用其它变量来构造变量的值，在Makefile中有两种方式来在用变量定义变量的值。 先看第一种方式，也就是简单的使用“=”号，在“=”左侧是变量，右侧是变量的值，右侧变量的值可以定义在文件的任何一处，也就是说，右侧中的变量不一定非要是已定义好 的值，其也可以使用后面定义的值。如： 1234567foo = $(bar)bar = $(ugh)ugh = Huh?all:echo $(foo) 我们执行“make all”将会打出变量$(foo)的值是“Huh?”（ $(foo)的值是$(bar)，$(bar)的值是$(ugh)，$(ugh)的值是“Huh?”）可见，变量是可以使用后面的变量来定义的。 这个功能有好的地方，也有不好的地方，好的地方是，我们可以把变量的真实值推到后面来定义，如： 12CFLAGS = $(include_dirs) -Oinclude_dirs = -Ifoo -Ibar 当“CFLAGS”在命令中被展开时，会是“-Ifoo -Ibar -O”。但这种形式也有不好的地方 ，那就是递归定义，如： 1CFLAGS = $(CFLAGS) -O 或： 12A = $(B)B = $(A) 这会让make陷入无限的变量展开过程中去，当然，我们的make是有能力检测这样的定义，并会报错。还有就是如果在变量中使用函数，那么，这种方式会让我们的make运行时非常慢，更糟糕的是，他会使用得两个make的函数“wildcard”和“shell”发生不可预知的错误。因为你不会知道这两个函数会被调用多少次。 为了避免上面的这种方法，我们可以使用make中的另一种用变量来定义变量的方法。这种方法使用的是“:=”操作符，如： 123x := fooy := $(x) barx := later 其等价于： 12y := foo barx := later 值得一提的是，这种方法，前面的变量不能使用后面的变量，只能使用前面已定义好了的变量。如果是这样： 12y := $(x) barx := foo 那么，y的值是“bar”，而不是“foo bar”。 上面都是一些比较简单的变量使用了，让我们来看一个复杂的例子，其中包括了make的函数、条件表达式和一个系统变量“MAKELEVEL”的使用： 123456ifeq (0,$&#123;MAKELEVEL&#125;)cur-dir := $(shell pwd)whoami := $(shell whoami)host-type := $(shell arch)MAKE := $&#123;MAKE&#125; host-type=$&#123;host-type&#125; whoami=$&#123;whoami&#125;endif 关于条件表达式和函数，我们在后面再说，对于系统变量“MAKELEVEL”，其意思是，如果我们的make有一个嵌套执行的动作（参见前面的“嵌套使用make”），那么，这个变量会记录了我们的当前Makefile的调用层数。 下面再介绍两个定义变量时我们需要知道的，请先看一个例子，如果我们要定义一个变量，其值是一个空格，那么我们可以这样来： 12nullstring :=space := $(nullstring) # end of the line nullstring 是一个Empty变量，其中什么也没有，而我们的space的值是一个空格。因为在操作符的右边是很难描述一个空格的，这里采用的技术很管用，先用一个 Empty变量来标明变量的值开始了，而后面采用“#”注释符来表示变量定义的终止，这样，我们可以定义出其值是一个空格的变量。请注意这里关于“#”的使用，注释符“#”的这种特性值得我们注意，如果我们这样定义一个变量： 1dir := /foo/bar # directory to put the frobs in dir这个变量的值是“/foo/bar”，后面还跟了4个空格，如果我们这样使用这样变量来指定别的目录——“$(dir)/file”那么就完蛋了。 还有一个比较有用的操作符是“?=”，先看示例： 1FOO ?= bar 其含义是，如果FOO没有被定义过，那么变量FOO的值就是“bar”，如果FOO先前被定义过，那么这条语将什么也不做，其等价于： 123ifeq ($(origin FOO), undefined)FOO = barendif 5.3变量高级用法这里介绍两种变量的高级使用方法 第一种是变量值的替换。 我们可以替换变量中的共有的部分，其格式是$(var:a=b)或是${var:a=b}，其意思是，把变量“var”中所有以“a”字串“结尾”的“a”替换成“b”字串。这里的“结尾”意思是“空格”或是“结束符”。 还是看一个示例吧： 12foo := a.o b.o c.obar := $(foo:.o=.c) 这个示例中，我们先定义了一个“$(foo)”变量，而第二行的意思是把“$(foo)”中所有以“.o”字串“结尾”全部替换成“.c”，所以我们的“$(bar)”的值就是“a.c b.c c.c”。 另外一种变量替换的技术是以“静态模式”（参见前面章节）定义的，如： 12foo := a.o b.o c.obar := $(foo:%.o=%.c) 这依赖于被替换字串中的有相同的模式，模式中必须包含一个“%”字符，这个例子同样让$(bar)变量的值为“a.c b.c c.c”。 第二种高级用法是——“把变量的值再当成变量”。先看一个例子： 123x = yy = za := $($(x)) 在这个例子中，$(x)的值是“y”，所以$($(x))就是$(y)，于是$(a)的值就是“z”。（注意，是“x=y”，而不是“x=$(y)”） 我们还可以使用更多的层次： 1234x = yy = zz = ua := $($($(x))) 这里的$(a)的值是“u”，相关的推导留给读者自己去做吧。 让我们再复杂一点，使用上“在变量定义中使用变量”的第一个方式，来看一个例子： 1234x = $(y)y = zz = Helloa := $($(x)) 这里的$($(x))被替换成了$($(y))，因为$(y)值是“z”，所以，最终结果是：a:=$(z)，也就是“Hello”。 再复杂一点，我们再加上函数： 12345x = variable1variable2 := Helloy = $(subst 1,2,$(x))z = ya := $($($(z))) 这个例子中，“$($($(z)))”扩展为“$($(y))”，而其再次被扩展为“$($(subst 1,2,$(x)))”。$(x)的值是“variable1”，subst函数把“variable1”中的所有“1”字串替换成“2”字串，于是，“variable1”变成“variable2”，再取其值，所以，最终，$(a)的值就是$(variable2)的值—— “Hello”。（喔，好不容易） 在这种方式中，或要可以使用多个变量来组成一个变量的名字，然后再取其值： 1234first_second = Helloa = firstb = secondall = $($a_$b) 这里的“$a_$b”组成了“first_second”，于是，$(all)的值就是“Hello”。 再来看看结合第一种技术的例子： 1234a_objects := a.o b.o c.o1_objects := 1.o 2.o 3.osources := $($(a1)_objects:.o=.c) 这个例子中，如果$(a1)的值是“a”的话，那么，$(sources)的值就是“a.c b.c c.c”；如果$(a1)的值是“1”，那么$(sources)的值是“1.c 2.c 3.c”。 再来看一个这种技术和“函数”与“条件语句”一同使用的例子： 123456789ifdef do_sortfunc := sortelsefunc := stripendifbar := a d b g q cfoo := $($(func) $(bar)) 这个示例中，如果定义了“do_sort”，那么：foo := $(sort a d b g q c)，于是$(foo)的值就是“a b c d g q”，而如果没有定义“do_sort”，那么：foo := $(sort a d bg q c)，调用的就是strip函数。 当然，“把变量的值再当成变量”这种技术，同样可以用在操作符的左边： 12345dir = foo$(dir)_sources := $(wildcard $(dir)/*.c)define $(dir)_printlpr $($(dir)_sources)endef 这个例子中定义了三个变量：“dir”，“foo_sources”和“foo_print”。 5.4追加变量值我们可以使用“+=”操作符给变量追加值，如： 12objects = main.o foo.o bar.o utils.oobjects += another.o 于是，我们的$(objects)值变成：“main.o foo.o bar.o utils.o another.o”（another.o被追加进去了） 使用“+=”操作符，可以模拟为下面的这种例子： 12objects = main.o foo.o bar.o utils.oobjects := $(objects) another.o 所不同的是，用“+=”更为简洁。 如果变量之前没有定义过，那么，“+=”会自动变成“=”，如果前面有变量定义，那么“+=”会继承于前次操作的赋值符。如果前一次的是“:=”，那么“+=”会以“:=”作为其赋值符，如： 12variable := valuevariable += more 等价于： 12variable := valuevariable := $(variable) more 但如果是这种情况： 12variable = valuevariable += more 由于前次的赋值符是“=”，所以“+=”也会以“=”来做为赋值，那么岂不会发生变量的递补归定义，这是很不好的，所以make会自动为我们解决这个问题，我们不必担心这个问题。 5.5override 指示符如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略。如果你想在Makefile中设置这类参数的值，那么，你可以使用“override”指示符。其语法是： 12override &lt;variable&gt; = &lt;value&gt;override &lt;variable&gt; := &lt;value&gt; 当然，你还可以追加： 1override &lt;variable&gt; += &lt;more text&gt; 对于多行的变量定义，我们用define指示符，在define指示符前，也同样可以使用ovveride指示符，如： 123override define foobarendef 5.6多行变量还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令（前面我们讲过“命令包”的技术就是利用这个关键字）。 define 指示符后面跟的是变量的名字，而重起一行定义变量的值，定义是以endef关键字结束。其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以[Tab]键开头，那么make就不会把其认为是命令。 下面的这个示例展示了define的用法： 1234define two-linesecho fooecho $(bar)endef 5.7环境变量make 运行时的系统环境变量可以在make开始运行时被载入到Makefile文件中，但是如果Makefile中已定义了这个变量，或是这个变量由make命令行带入，那么系统的环境变量的值将被覆盖。（如果make指定了“-e”参数，那么，系统环境变量将覆盖Makefile中定义的变量） 因此，如果我们在环境变量中设置了“CFLAGS”环境变量，那么我们就可以在所有的Makefile中使用这个变量了。这对于我们使用统一的编译参数有比较大的好处。如果Makefile中定义了CFLAGS，那么则会使用Makefile中的这个变量，如果没有定义则使用系统环境变量的值，一个共性和个性的统一，很像“全局变量”和“局部变量”的特性。 当make嵌套调用时（参见前面的“嵌套调用”章节），上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile中。当然，默认情况下，只有通过命令行设置的变量会被传递。而定义在文件中的变量，如果要向下层 Makefile传递，则需要使用exprot关键字来声明。（参见前面章节） 当然，我并不推荐把许多的变量都定义在系统环境中，这样，在我们执行不用的Makefile时，拥有的是同一套系统变量，这可能会带来更多的麻烦。 5.8目标变量前面我们所讲的在Makefile中定义的变量都是“全局变量”，在整个文件，我们都可以访问这些变量。当然，“自动化变量”除外，如“$&lt;”等这种类量的自动化变量就属于“规则型变量”，这种变量的值依赖于规则的目标和依赖目标的定义。 当然，我样同样可以为某个目标设置局部变量，这种变量被称为“Target-specific Variable”，它可以和“全局变量”同名，因为它的作用范围只在这条规则以及连带规则中，所以其值也只在作用范围内有效。而不会影响规则链以外的全局变量的值。 其语法是： 12345&lt;target ...&gt; : &lt;variable-assignment&gt;&lt;target ...&gt; : overide &lt;variable-assignment&gt;` 可以是前面讲过的各种赋值表达式，如“=”、“:=”、“+=”或是“？=”。第二个语法是针对于make命令行带入的变量，或是系统环境变量。 这个特性非常的有用，当我们设置了这样一个变量，这个变量会作用到由这个目标所引发的所有的规则中去。如： 123456789101112131415prog : CFLAGS = -gprog : prog.o foo.o bar.o$(CC) $(CFLAGS) prog.o foo.o bar.oprog.o : prog.c$(CC) $(CFLAGS) prog.cfoo.o : foo.c$(CC) $(CFLAGS) foo.cbar.o : bar.c$(CC) $(CFLAGS) bar.c 在这个示例中，不管全局的$(CFLAGS)的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则），$(CFLAGS)的值都是“-g” 5.9模式变量在GNU的make中，还支持模式变量（Pattern-specific Variable），通过上面的目标变量中，我们知道，变量可以定义在某个目标上。模式变量的好处就是，我们可以给定一种“模式”，可以把变量定义在符合这种模式的所有目标上。 我们知道，make的“模式”一般是至少含有一个“%”的，所以，我们可以以如下方式给所有以[.o]结尾的目标定义目标变量： 1%.o : CFLAGS = -O 同样，模式变量的语法和“目标变量”一样： 1234&lt;pattern ...&gt; : &lt;variable-assignment&gt;&lt;pattern ...&gt; : override &lt;variable-assignment&gt; override同样是针对于系统环境传入的变量，或是make命令行指定的变量。 6. 使用条件判断使用条件判断，可以让make根据运行时的不同情况选择不同的执行分支。条件表达式可以是比较变量的值，或是比较变量和常量的值。 6.1 示例下面的例子，判断$(CC)变量是否“gcc”，如果是的话，则使用GNU函数编译目标。 12345678910libs_for_gcc = -lgnunormal_libs =foo: $(objects)ifeq ($(CC),gcc)$(CC) -o foo $(objects) $(libs_for_gcc)else$(CC) -o foo $(objects) $(normal_libs)endif 可见，在上面示例的这个规则中，目标“foo”可以根据变量“$(CC)”值来选取不同的函数库来编译程序。 我们可以从上面的示例中看到三个关键字：ifeq、else和endif。ifeq的意思表示条件语句的开始，并指定一个条件表达式，表达式包含两个参数，以逗号分隔，表达式以圆括号括起。else表示条件表达式为假的情况。endif表示一个条件语句的结束，任何一个条件表达式都应该以endif结束。 当我们的变量$(CC)值是“gcc”时，目标foo的规则是： 12foo: $(objects)$(CC) -o foo $(objects) $(libs_for_gcc) 而当我们的变量$(CC)值不是“gcc”时（比如“cc”），目标foo的规则是： 12foo: $(objects)$(CC) -o foo $(objects) $(normal_libs) 当然，我们还可以把上面的那个例子写得更简洁一些： 12345678910111213libs_for_gcc = -lgnunormal_libs =ifeq ($(CC),gcc)libs=$(libs_for_gcc)elselibs=$(normal_libs)endiffoo: $(objects)$(CC) -o foo $(objects) $(libs) 6.2 语法条件表达式的语法为： 123&lt;conditional-directive&gt;&lt;text-if-true&gt;endif 以及： 12345&lt;conditional-directive&gt;&lt;text-if-true&gt;else&lt;text-if-false&gt;endif 其中表示条件关键字，如“ifeq”。这个关键字有四个。 第一个是我们前面所见过的“ifeq” 12345ifeq (&lt;arg1&gt;, &lt;arg2&gt; )ifeq &apos;&lt;arg1&gt;&apos; &apos;&lt;arg2&gt;&apos;ifeq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;ifeq &quot;&lt;arg1&gt;&quot; &apos;&lt;arg2&gt;&apos;ifeq &apos;&lt;arg1&gt;&apos; &quot;&lt;arg2&gt;&quot; 比较参数“arg1”和“arg2”的值是否相同。当然，参数中我们还可以使用make的函数。如： 123ifeq ($(strip $(foo)),)&lt;text-if-empty&gt;endif 这个示例中使用了“strip”函数，如果这个函数的返回值是空（Empty），那么就生效。 第二个条件关键字是“ifneq”。语法是： 12345ifneq (&lt;arg1&gt;, &lt;arg2&gt; )ifneq &apos;&lt;arg1&gt;&apos; &apos;&lt;arg2&gt;&apos;ifneq &quot;&lt;arg1&gt;&quot; &quot;&lt;arg2&gt;&quot;ifneq &quot;&lt;arg1&gt;&quot; &apos;&lt;arg2&gt;&apos;ifneq &apos;&lt;arg1&gt;&apos; &quot;&lt;arg2&gt;&quot; 其比较参数“arg1”和“arg2”的值是否相同，如果不同，则为真。和“ifeq”类似。 第三个条件关键字是“ifdef”。语法是： 1ifdef &lt;variable-name&gt; 如果变量的值非空，那到表达式为真。否则，表达式为假。当然，同样可以是一个函数的返回值。注意，ifdef只是测试一个变量是否有值，其并不会把变量扩展到当前位置。还是来看两个例子： 示例一： 1234567bar =foo = $(bar)ifdef foofrobozz = yeselsefrobozz = noendif 示例二： 123456foo =ifdef foofrobozz = yeselsefrobozz = noendif 第一个例子中，“$(frobozz)”值是“yes”，第二个则是“no”。 第四个条件关键字是“ifndef”。其语法是： 1ifndef &lt;variable-name&gt; 这个我就不多说了，和“ifdef”是相反的意思。 在这一行上，多余的空格是被允许的，但是不能以[Tab]键做为开始（不然就被认为是命令）。而注释符“#”同样也是安全的。“else”和“endif”也 一样，只要不是以[Tab]键开始就行了。 特别注意的是，make是在读取Makefile时就计算条件表达式的值，并根据条件表达式的值来选择语句，所以，你最好不要把自动化变量（如“$@”等）放入条件表达式中，因为自动化变量是在运行时才有的。 而且，为了避免混乱，make不允许把整个条件语句分成两部分放在不同的文件中。 7. 使用函数在Makefile中可以使用函数来处理变量，从而让我们的命令或是规则更为的灵活和具有智能。make所支持的函数也不算很多，不过已经足够我们的操作了。函数调用后，函数的返回值可以当做变量来使用。 7.1函数的调用语法函数调用，很像变量的使用，也是以“$”来标识的，其语法如下： 1$(&lt;function&gt; &lt;arguments&gt; ) 或是 1$&#123;&lt;function&gt; &lt;arguments&gt;&#125; 这里，就是函数名，make支持的函数不多。是函数的参数，参数间以逗号“,”分隔，而函数名和参数之间以“空格”分隔。函数调用以“$”开头，以圆括号或花括号把函数名和参数括起。感觉很像一个变量，是不是？函数中的参数可以使用变量，为了风格的统一，函数和变量的括号最好一样，如使用“$(subst a,b,$(x))”这样的形式，而不是“$(subst a,b,${x})”的形式。因为统一会更清楚，也会减少一些不必要的麻烦。 还是来看一个示例： 12345comma:= ,empty:=space:= $(empty) $(empty)foo:= a b cbar:= $(subst $(space),$(comma),$(foo)) 在这个示例中，$(comma)的值是一个逗号。$(space)使用了$(empty)定义了一个空格，$(foo)的值是“a b c”，$(bar)的定义用，调用了函数“subst”，这是一个替换函数，这个函数有三个参数，第一个参数是被替换字串，第二个参数是替换字串，第三个参数是替换操作作用的字串。这个函数也就是把$(foo)中的空格替换成逗号，所以$(bar)的值是“ a,b,c”。 7.2 字符串处理函数1$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt; ) 名称：字符串替换函数——subst。 功能：把字串中的字符串替换成。 返回：函数返回被替换过后的字符串。 示例： 1$(subst ee,EE,feet on the street)， 把“feet on the street”中的“ee”替换成“EE”，返回结果是“fEEt on the strEEt ”。 12$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,&lt;text&gt; ) 名称：模式字符串替换函数——patsubst。 功能：查找中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式，如果匹配的话，则以替换。这里，可以包括通配符“%”，表示任意长度的字串。如果中也包含“%”，那么，中的这个“%”将是中的那个“%”所代表的字串。（可以用“\”来转义，以“\%”来表示真实含义的“%”字符）返回：函数返回被替换过后的字符串。 示例： 1$(patsubst %.c,%.o,x.c.c bar.c) 把字串“x.c.c bar.c”符合模式[%.c]的单词替换成[%.o]，返回结果是“x.c.o bar.o” 备注： 这和我们前面“变量章节”说过的相关知识有点相似。如： 1“$(var:&lt;pattern&gt;=&lt;replacement&gt; )” 相当于 1“$(patsubst &lt;pattern&gt;,&lt;replacement&gt;,$(var))”， 而“$(var: = )” 则相当于 “$(patsubst %,%,$(var))”。 例如有：objects = foo.o bar.o baz.o， 那么，“$(objects:.o=.c)”和“$(patsubst %.o,%.c,$(objects))”是一样的。 1$(strip &lt;string&gt; ) 名称：去空格函数——strip。 功能：去掉字串中开头和结尾的空字符。 返回：返回被去掉空格的字符串值。 示例： 1$(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。 1$(findstring &lt;find&gt;,&lt;in&gt; ) 名称：查找字符串函数——findstring。 功能：在字串中查找字串。 返回：如果找到，那么返回，否则返回空字符串。 示例： 12$(findstring a,a b c)$(findstring a,b c) 第一个函数返回“a”字符串，第二个返回“”字符串（空字符串） 1$(filter &lt;pattern...&gt;,&lt;text&gt; ) 名称：过滤函数——filter。 功能：以模式过滤字符串中的单词，保留符合模式的单词。可 以有多个模式。 返回：返回符合模式的字串。 示例： 123sources := foo.c bar.c baz.s ugh.hfoo: $(sources)cc $(filter %.c %.s,$(sources)) -o foo $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。 1$(filter-out &lt;pattern...&gt;,&lt;text&gt; ) 名称：反过滤函数——filter-out。 功能：以模式过滤字符串中的单词，去除符合模式的单词。可 以有多个模式。 返回：返回不符合模式的字串。 示例： 12objects=main1.o foo.o main2.o bar.omains=main1.o main2.o $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”。 1$(sort &lt;list&gt; ) 名称：排序函数——sort。 功能：给字符串中的单词排序（升序）。 返回：返回排序后的字符串。 示例：$(sort foo bar lose)返回“bar foo lose” 。 备注：sort函数会去掉中相同的单词。 1$(word &lt;n&gt;,&lt;text&gt; ) 名称：取单词函数——word。 功能：取字符串中第个单词。（从一开始） 返回：返回字符串中第个单词。如果比中的单词数要大，那么返回空 字符串。 示例：$(word 2, foo bar baz)返回值是“bar”。 1$(wordlist &lt;s&gt;,&lt;e&gt;,&lt;text&gt; ) 名称：取单词串函数——wordlist。 功能：从字符串中取从开始到的单词串。和是一个数字。 返回：返回字符串中从到的单词字串。如果比中的单词数要大，那 么返回空字符串。如果大于的单词数，那么返回从开始，到结束的单 词串。 示例： $(wordlist 2, 3, foo bar baz)返回值是“bar baz”。 1$(words &lt;text&gt; ) 名称：单词个数统计函数——words。 功能：统计中字符串中的单词个数。 返回：返回中的单词数。 示例：$(words, foo bar baz)返回值是“3”。 备注：如果我们要取中最后的一个单词，我们可以这样：$(word $(words ), )。 1$(firstword &lt;text&gt; ) 名称：首单词函数——firstword。 功能：取字符串中的第一个单词。 返回：返回字符串的第一个单词。 示例：$(firstword foo bar)返回值是“foo”。 备注：这个函数可以用word函数来实现：$(word 1, )。 以上，是所有的字符串操作函数，如果搭配混合使用，可以完成比较复杂的功能。这里， 举一个现实中应用的例子。我们知道，make使用“VPATH”变量来指定“依赖文件”的搜索 路径。于是，我们可以利用这个搜索路径来指定编译器对头文件的搜索路径参数CFLAGS， 如： override CFLAGS += $(patsubst %,-I%,$(subst :, ,$(VPATH))) 如果我们的“$(VPATH)”值是“src:../headers”，那么“$(patsubst %,-I%,$(subst : , ,$(VPATH)))”将返回“-Isrc -I../headers”，这正是cc或gcc搜索头文件路径的参数 7.3文件名操作函数下面我们要介绍的函数主要是处理文件名的。每个函数的参数字符串都会被当做一个或是 一系列的文件名来对待。 1$(dir &lt;names...&gt; ) 名称：取目录函数——dir。 功能：从文件名序列中取出目录部分。目录部分是指最后一个反斜杠（“/”）之 前的部分。如果没有反斜杠，那么返回“./”。 返回：返回文件名序列的目录部分。 示例： $(dir src/foo.c hacks)返回值是“src/ ./”。 1$(notdir &lt;names...&gt; ) 名称：取文件函数——notdir。 功能：从文件名序列中取出非目录部分。非目录部分是指最后一个反斜杠（“/” ）之后的部分。 返回：返回文件名序列的非目录部分。 示例： $(notdir src/foo.c hacks)返回值是“foo.c hacks”。 1$(suffix &lt;names...&gt; ) 名称：取后缀函数——suffix。 功能：从文件名序列中取出各个文件名的后缀。 返回：返回文件名序列的后缀序列，如果文件没有后缀，则返回空字串。 示例：$(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c”。 1$(basename &lt;names...&gt; ) 名称：取前缀函数——basename。 功能：从文件名序列中取出各个文件名的前缀部分。 返回：返回文件名序列的前缀序列，如果文件没有前缀，则返回空字串。 示例：$(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar h acks”。 1$(addsuffix &lt;suffix&gt;,&lt;names...&gt; ) 名称：加后缀函数——addsuffix。 功能：把后缀加到中的每个单词后面。 返回：返回加过后缀的文件名序列。 示例：$(addsuffix .c,foo bar)返回值是“foo.c bar.c”。 1$(addprefix &lt;prefix&gt;,&lt;names...&gt; ) 名称：加前缀函数——addprefix。 功能：把前缀加到中的每个单词后面。 返回：返回加过前缀的文件名序列。 示例：$(addprefix src/,foo bar)返回值是“src/foo src/bar”。 1$(join &lt;list1&gt;,&lt;list2&gt; ) 名称：连接函数——join。 功能：把中的单词对应地加到的单词后面。如果的单词个数要比&lt; list2&gt;的多，那么，中的多出来的单词将保持原样。如果的单词个数要比 多，那么，多出来的单词将被复制到中。 返回：返回连接过后的字符串。 示例：$(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”。 7.4 foreach 函数foreach 函数和别的函数非常的不一样。因为这个函数是用来做循环用的，Makefile中的 foreach函数几乎是仿照于Unix标准Shell（/bin /sh）中的for语句，或是C-Shell（/bin /csh）中的foreach语句而构建的。它的语法是： 1$(foreach &lt;var&gt;,&lt;list&gt;,&lt;text&gt; ) 这个函数的意思是，把参数中的单词逐一取出放到参数所指定的变量中，然后再执行所包含的表达式。每一次会返回一个字符串，循环过程中，的所返回的每个字符串会以空格分隔，最后当整个循环结束时，所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。 所以，最好是一个变量名，可以是一个表达式，而中一般会使用 这个参数来依次枚举中的单词。举个例子： 1234names := a b c dfiles := $(foreach n,$(names),$(n).o) 上面的例子中，$(name)中的单词会被挨个取出，并存到变量“n”中，“$(n).o”每次根据“$(n)”计算出一个值，这些值以空格分隔，最后作为foreach函数的返回，所以，$(f iles)的值是“a.o b.o c.o d.o”。 注意，foreach中的参数是一个临时的局部变量，foreach函数执行完后，参数的变量将不在作用，其作用域只在foreach函数当中。 7.5 if 函数if函数很像GNU的make所支持的条件语句——ifeq（参见前面所述的章节），if函数的语法是： 1$(if &lt;condition&gt;,&lt;then-part&gt; ) 或是 1$(if &lt;condition&gt;,&lt;then-part&gt;,&lt;else-part&gt; ) 可见，if函数可以包含“else”部分，或是不含。即if函数的参数可以是两个，也可以是三个。参数是if的表达式，如果其返回的为非空字符串，那么这个表达式就相当于返回真，于是，会被计算，否则 会被计算。 而if函数的返回值是，如果为真（非空字符串），那个会是整个函数的返回值，如果为假（空字符串），那么会是整个函数的返回值，此时如果没有被定义，那么，整个函数返回空字串。 所以，和只会有一个被计算。 7.6 call函数call函数是唯一一个可以用来创建新的参数化的函数。你可以写一个非常复杂的表达式，这个表达式中，你可以定义许多参数，然后你可以用call函数来向这个表达式传递参数。其语法是： 1$(call &lt;expression&gt;,&lt;parm1&gt;,&lt;parm2&gt;,&lt;parm3&gt;...) 当 make执行这个函数时，参数中的变量，如$(1)，$(2)，$(3)等，会被参数，，依次取代。而的返回值就是 call函数的返回值。例如： 123reverse = $(1) $(2)foo = $(call reverse,a,b) 那么，foo的值就是“a b”。当然，参数的次序是可以自定义的，不一定是顺序的，如： 12reverse = $(2) $(1)foo = $(call reverse,a,b) 此时的foo的值就是“b a”。 7.7origin函数origin函数不像其它的函数，他并不操作变量的值，他只是告诉你你的这个变量是哪里来的？其语法是： 1$(origin &lt;variable&gt; ) 注意，是变量的名字，不应该是引用。所以你最好不要在中使用“$”字符。Origin函数会以其返回值来告诉你这个变量的“出生情况”，下面，是origin函 数的返回值: “undefined” 如果从来没有定义过，origin函数返回这个值“undefined”。 “default” 如果是一个默认的定义，比如“CC”这个变量，这种变量我们将在后面讲述。 “environment” 如果是一个环境变量，并且当Makefile被执行时，“-e”参数没有被打开。 “file” 如果这个变量被定义在Makefile中。 “command line” 如果这个变量是被命令行定义的。 “override” 如果是被override指示符重新定义的。 “automatic” 如果是一个命令运行中的自动化变量。关于自动化变量将在后面讲述。 这些信息对于我们编写Makefile是非常有用的，例如，假设我们有一个Makefile其包了一个定义文件Make.def，在Make.def中定义了一个变量“bletch”，而我们的环境中也有一 个环境变量“bletch”，此时，我们想判断一下，如果变量来源于环境，那么我们就把之重定义了，如果来源于Make.def或是命令行等非环境的，那么我们就不重新定义它。于是 ，在我们的Makefile中，我们可以这样写： 1234567891011ifdef bletchifeq &quot;$(origin bletch)&quot; &quot;environment&quot;bletch = barf, gag, etc.endifendif 当然，你也许会说，使用override关键字不就可以重新定义环境中的变量了吗？为什么需要使用这样的步骤？是的，我们用override是可以达到这样的效果，可是override过于粗 暴，它同时会把从命令行定义的变量也覆盖了，而我们只想重新定义环境传来的，而不想重新定义命令行传来的。 7.8 shell函数shell 函数也不像其它的函数。顾名思义，它的参数应该就是操作系统Shell的命令。它和反引号 是相同的功能。这就是说，shell函数把执行操作系统命令后的输出作为函数 返回。于是，我们可以用操作系统命令以及字符串处理命令awk，sed等等命令来生成一个变量，如： 12contents := $(shell cat foo)files := $(shell echo *.c) 注意，这个函数会新生成一个Shell程序来执行命令，所以你要注意其运行性能，如果你的Makefile中有一些比较复杂的规则，并大量使用了这个函数，那么对于你的系统性能是有害的。特别是Makefile的隐晦的规则可能会让你的shell函数执行的次数比你想像的多得多。 7.9 控制make的函数make提供了一些函数来控制make的运行。通常，你需要检测一些运行Makefile时的运行时信息，并且根据这些信息来决定，你是让make继续执行，还是停止。 1$(error &lt;text ...&gt; ) 产生一个致命的错误，是错误信息。注意，error函数不会在一被使用就会产生错误信息，所以如果你把其定义在某个变量中，并在后续的脚本中使用这个变量，那么也 是可以的。例如： 示例一： 123ifdef ERROR_001$(error error is $(ERROR_001))endif 示例二： 123ERR = $(error found an error!).PHONY: errerr: ; $(ERR) 示例一会在变量ERROR_001定义了后执行时产生error调用，而示例二则在目录err被执行时才发生error调用。 1$(warning &lt;text ...&gt; ) 这个函数很像error函数，只是它并不会让make退出，只是输出一段警告信息，而make继续执行。 8. make 的运行一般来说，最简单的就是直接在命令行下输入make命令，make命令会找当前目录的makefile来执行，一切都是自动的。但也有时你也许只想让 make重编译某些文件，而不是整个工程，而又有的时候你有几套编译规则，你想在不同的时候使用不同的编译规则，等等。本章节就是讲述如何使用make命令的。 8.1 make的退出码make命令执行后有三个退出码： 0 —— 表示成功执行。 1 —— 如果make运行时出现任何错误，其返回1。 2 —— 如果你使用了make的“-q”选项，并且make使得一些目标不需要更新，那么返回2。 Make的相关参数我们会在后续章节中讲述。 8.2 指定Makefile前面我们说过，GNU make找寻默认的Makefile的规则是在当前目录下依次找三个文件——“GNUmakefile”、“makefile”和“Makefile”。其按顺序找这三个文件，一旦找到，就 开始读取这个文件并执行。 当前，我们也可以给make命令指定一个特殊名字的Makefile。要达到这个功能，我们要使用make的“-f”或是“–file”参数（“– makefile”参数也行）。例如，我们有个mak efile的名字是“hchen.mk”，那么，我们可以这样来让make来执行这个文件： 1make –f hchen.mk 如果在make的命令行是，你不只一次地使用了“-f”参数，那么，所有指定的makefile将会被连在一起传递给make执行。 8.3 指定目标一般来说，make的最终目标是makefile中的第一个目标，而其它目标一般是由这个目标连带出来的。这是make的默认行为。当然，一般来说，你的 makefile中的第一个目标是由许多个目标组成，你可以指示make，让其完成你所指定的目标。要达到这一目的很简单，需在make命令后直接跟目标的名字就可以完成（如前面提到的“make clean”形式）任何在makefile中的目标都可以被指定成终极目标，但是除了以“- ”打头，或是包含了“=”的目标，因为有这些字符的目标，会被解析成命令行参数或是变量。甚至没有被我们明确写出来的目标也可以成为make的终极目标，也就是说，只要make可以找到其隐含规则推导规则，那么这个隐含目标同样可以被指定成终极目标。 有一个make的环境变量叫“MAKECMDGOALS”，这个变量中会存放你所指定的终极目标的列表，如果在命令行上，你没有指定目标，那么，这个变量是空值。这个变量可以让你使用在一些比较特殊的情形下。比如下面的例子： 1234sources = foo.c bar.cifneq ( $(MAKECMDGOALS),clean)include $(sources:.c=.d)endif 基于上面的这个例子，只要我们输入的命令不是“make clean”，那么makefile会自动包含“foo.d”和“bar.d”这两个makefile。 使用指定终极目标的方法可以很方便地让我们编译我们的程序，例如下面这个例子： 12.PHONY: allall: prog1 prog2 prog3 prog4 从这个例子中，我们可以看到，这个makefile中有四个需要编译的程序——“prog1”， “prog2”， “prog3”和 “prog4”，我们可以使用“make all”命令来编译所有的目标 （如果把all置成第一个目标，那么只需执行“make”），我们也可以使用“make prog2”来单独编译目标“prog2”。 即然make可以指定所有makefile中的目标，那么也包括“伪目标”，于是我们可以根据这种性质来让我们的makefile根据指定的不同的目标来完成不同的事。在Unix世界中，软件 发布时，特别是GNU这种开源软件的发布时，其 makefile都包含了编译、安装、打包等功能。我们可以参照这种规则来书写我们的makefile中的目标。 “all” 这个伪目标是所有目标的目标，其功能一般是编译所有的目标。 “clean” 这个伪目标功能是删除所有被make创建的文件。 “install” 这个伪目标功能是安装已编译好的程序，其实就是把目标执行文件拷贝到指定的目标中去。 “print” 这个伪目标的功能是例出改变过的源文件。 “tar” 这个伪目标功能是把源程序打包备份。也就是一个tar文件。 “dist” 这个伪目标功能是创建一个压缩文件，一般是把tar文件压成Z文件。或是gz文件。 “TAGS” 这个伪目标功能是更新所有的目标，以备完整地重编译使用。 “check”和“test” 这两个伪目标一般用来测试makefile的流程。 当然一个项目的makefile中也不一定要书写这样的目标，这些东西都是GNU的东西，但是我想，GNU搞出这些东西一定有其可取之处（等你的UNIX下的程序文件一多时你就会发现这些功能很有用了），这里只不过是说明了，如果你要书写这种功能，最好使用这种名字命名你的目标，这样规范一些，规范的好处就是——不用解释，大家都明白。而且如果你的makefile中有这些功能，一是很实用，二是可以显得你的makefile很专业（不是那种初学者的作品）。 8.4 检查规则有时候，我们不想让我们的makefile中的规则执行起来，我们只想检查一下我们的命令，或是执行的序列。于是我们可以使用make命令的下述参数： “-n” “–just-print” “–dry-run” “–recon” 不执行参数，这些参数只是打印命令，不管目标是否更新，把规则和连带规则下的命令打印出来，但不执行，这些参数对于我们调试makefile很有用处。 “-t” “–touch” 这个参数的意思就是把目标文件的时间更新，但不更改目标文件。也就是说，make假装编译目标，但不是真正的编译目标，只是把目标变成已编译过的状态。 “-q” “–question” 这个参数的行为是找目标的意思，也就是说，如果目标存在，那么其什么也不会输出，当然也不会执行编译，如果目标不存在，其会打印出一条出错信息。 “-W ” “–what-if=” “–assume-new=” “–new-file=” 这个参数需要指定一个文件。一般是是源文件（或依赖文件），Make会根据规则推导来运行依赖于这个文件的命令，一般来说，可以和“-n”参数一同使用，来查看这个依赖文件 所发生的规则命令。 另外一个很有意思的用法是结合“-p”和“-v”来输出makefile被执行时的信息（这个将在后面讲述）。 8.5 make的参数下面列举了所有GNU make 3.80版的参数定义。其它版本和产商的make大同小异，不过其它产商的make的具体参数还是请参考各自的产品文档。 “-b” “-m” 这两个参数的作用是忽略和其它版本make的兼容性。 “-B” “–always-make” 认为所有的目标都需要更新（重编译）。 “-C ” “–directory=” 指定读取makefile的目录。如果有多个“-C”参数，make的解释是后面的路径以前面的作为相对路径，并以最后的目录作为被指定目录。如：“make –C ~hchen/test –C prog” 等价于“make –C ~hchen/test/prog”。 “—debug[=]” 输出make的调试信息。它有几种不同的级别可供选择，如果没有参数，那就是输出最简单的调试信息。下面是的取值： a —— 也就是all，输出所有的调试信息。（会非常的多） b —— 也就是basic，只输出简单的调试信息。即输出不需要重编译的目标。 v —— 也就是verbose，在b选项的级别之上。输出的信息包括哪个makefile被解析，不需要被重编译的依赖文件（或是依赖目标）等。 i —— 也就是implicit，输出所以的隐含规则。 j —— 也就是jobs，输出执行规则中命令的详细信息，如命令的PID、返回码等。 m —— 也就是makefile，输出make读取makefile，更新makefile，执行makefile的信息。 “-d” 相当于“–debug=a”。 “-e” “–environment-overrides” 指明环境变量的值覆盖makefile中定义的变量的值。 “-f=” “–file=” “–makefile=” 指定需要执行的makefile。 “-h” “–help” 显示帮助信息。 “-i” “–ignore-errors” 在执行时忽略所有的错误。 “-I ” “–include-dir=” 指定一个被包含makefile的搜索目标。可以使用多个“-I”参数来指定多个目录。 “-j []” “–jobs[=]” 指同时运行命令的个数。如果没有这个参数，make运行命令时能运行多少就运行多少。如果有一个以上的“-j”参数，那么仅最后一个“-j”才是有效的。（注意这个参数在MS-D OS中是无用的） “-k” “–keep-going” 出错也不停止运行。如果生成一个目标失败了，那么依赖于其上的目标就不会被执行了。 “-l ” “–load-average[=&lt;load]” “—max-load[=]” 指定make运行命令的负载。 “-n” “–just-print” “–dry-run” “–recon” 仅输出执行过程中的命令序列，但并不执行。 “-o ” “–old-file=” “–assume-old=” 不重新生成的指定的，即使这个目标的依赖文件新于它。 “-p” “–print-data-base” 输出makefile中的所有数据，包括所有的规则和变量。这个参数会让一个简单的makefile都会输出一堆信息。如果你只是想输出信息而不想执行 makefile，你可以使用“make -q p”命令。如果你想查看执行makefile前的预设变量和规则，你可以使用“make –p –f /dev/null”。这个参数输出的信息会包含着你的makefile文件的文件名和行号，所以，用 这个参数来调试你的makefile会是很有用的，特别是当你的环境变量很复杂的时候。 “-q” “–question” 不运行命令，也不输出。仅仅是检查所指定的目标是否需要更新。如果是0则说明要更新，如果是2则说明有错误发生。 “-r” “–no-builtin-rules” 禁止make使用任何隐含规则。 “-R” “–no-builtin-variabes” 禁止make使用任何作用于变量上的隐含规则。 “-s” “–silent” “–quiet” 在命令运行时不输出命令的输出。 “-S” “–no-keep-going” “–stop” 取消“-k”选项的作用。因为有些时候，make的选项是从环境变量“MAKEFLAGS”中继承下来的。所以你可以在命令行中使用这个参数来让环境变量中的“-k”选项失效。 “-t” “–touch” 相当于UNIX的touch命令，只是把目标的修改日期变成最新的，也就是阻止生成目标的命令运行。 “-v” “–version” 输出make程序的版本、版权等关于make的信息。 “-w” “–print-directory” 输出运行makefile之前和之后的信息。这个参数对于跟踪嵌套式调用make时很有用。 “–no-print-directory” 禁止“-w”选项。 “-W ” “–what-if=” “–new-file=” “–assume-file=” 假定目标需要更新，如果和“-n”选项使用，那么这个参数会输出该目标更新时的运行动作。如果没有“-n”那么就像运行UNIX的“touch”命令一样，使得的修改时 间为当前时间。 “–warn-undefined-variables” 只要make发现有未定义的变量，那么就输出警告信息。 9. 隐含规则在我们使用Makefile时，有一些我们会经常使用，而且使用频率非常高的东西，比如，我们编译C/C++的源程序为中间目标文件（Unix下是[.o] 文件，Windows下是[.obj]文件）。本章讲述的就是一些在Makefile中的“隐含的”，早先约定了的，不需要我们再写出来的规则。 “隐含规则”也就是一种惯例，make会按照这种“惯例”心照不喧地来运行，那怕我们的Makefile中没有书写这样的规则。例如，把[.c]文件编译成[.o]文件这一规则，你根本就 不用写出来，make会自动推导出这种规则，并生成我们需要的[.o]文件。 “隐含规则”会使用一些我们系统变量，我们可以改变这些系统变量的值来定制隐含规则的运行时的参数。如系统变量“CFLAGS”可以控制编译时的编译器参数。 我们还可以通过“模式规则”的方式写下自己的隐含规则。用“后缀规则”来定义隐含规则会有许多的限制。使用“模式规则”会更回得智能和清楚，但“后缀规则”可以用来保 证我们Makefile的兼容性。 我们了解了“隐含规则”，可以让其为我们更好的服务，也会让我们知道一些“约定俗成”了的东西，而不至于使得我们在运行Makefile时出现一些我们觉得莫名其妙的东西。当 然，任何事物都是矛盾的，水能载舟，亦可覆舟，所以，有时候“隐含规则”也会给我们造成不小的麻烦。只有了解了它，我们才能更好地使用它。 9.1 使用隐含规则如果要使用隐含规则生成你需要的目标，你所需要做的就是不要写出这个目标的规则。那么，make会试图去自动推导产生这个目标的规则和命令，如果make可以自动推导生成这个目标的规则和命令，那么这个行为就是隐含规则的自动推导。当然，隐含规则是make事先约定好的一些东西。例如，我们有下面的一个Makefile： 12foo : foo.o bar.occ –o foo foo.o bar.o $(CFLAGS) $(LDFLAGS) 我们可以注意到，这个Makefile中并没有写下如何生成foo.o和bar.o这两目标的规则和命令。因为make的“隐含规则”功能会自动为我们自动去推导这两个目标的依赖目标和生成 命令。 make 会在自己的“隐含规则”库中寻找可以用的规则，如果找到，那么就会使用。如果找不到，那么就会报错。在上面的那个例子中，make调用的隐含规则是，把 [.o]的目标的依赖文件置成[.c]，并使用C的编译命令“cc –c $(CFLAGS) [.c]”来生成[.o]的目标。也就是说，我们完全没有必要写下下面的两条规则： 1234foo.o : foo.ccc –c foo.c $(CFLAGS)bar.o : bar.ccc –c bar.c $(CFLAGS) 因为，这已经是“约定”好了的事了，make和我们约定好了用C编译器“cc”生成[.o]文件的规则，这就是隐含规则。 当然，如果我们为[.o]文件书写了自己的规则，那么make就不会自动推导并调用隐含规则，它会按照我们写好的规则忠实地执行。 还有，在make的“隐含规则库”中，每一条隐含规则都在库中有其顺序，越靠前的则是越被经常使用的，所以，这会导致我们有些时候即使我们显示地指定了目标依赖，make也不会管。如下面这条规则（没有命令）： 1foo.o : foo.p 依赖文件“foo.p”（Pascal程序的源文件）有可能变得没有意义。如果目录下存在了“foo.c”文件，那么我们的隐含规则一样会生效，并会通过 “foo.c”调用C的编译器生成f oo.o文件。因为，在隐含规则中，Pascal的规则出现在C的规则之后，所以，make找到可以生成foo.o的 C的规则就不再寻找下一条规则了。如果你确实不希望任何隐含规则推导，那么，你就不要只写出“依赖规则”，而不写命令。 9.2隐含规则一览这里我们将讲述所有预先设置（也就是make内建）的隐含规则，如果我们不明确地写下规则，那么，make就会在这些规则中寻找所需要规则和命令。当然，我们也可以使用make的参数“-r”或“–no-builtin-rules”选项来取消所有的预设置的隐含规则。 当然，即使是我们指定了“-r”参数，某些隐含规则还是会生效，因为有许多的隐含规则都是使用了“后缀规则”来定义的，所以，只要隐含规则中有“后缀列表 ”（也就一系统 定义在目标.SUFFIXES的依赖目标），那么隐含规则就会生效。默认的后缀列表是：.out,.a, .ln, .o, .c, .cc, .C, .p, .f, .F, .r, .y, .l, .s, .S, .mod, .sym, .def, . h, .info, .dvi, .tex, .texinfo, .texi, .txinfo, .w, .ch .web, .sh, .elc, .el。具体的细节，我们会在后面讲述。 还是先来看一看常用的隐含规则吧。 编译C程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.c”，并且其生成命令是“$(CC) –c $(CPPFLAGS) $(CFLAGS)” 编译C++程序的隐含规则。 “.o” 的目标的依赖目标会自动推导为“.cc”或是“.C”，并且其生成命令是“$(CXX) –c $(CPPFLAGS) $(CFLAGS)”。（建议使用“.cc”作为C++源文件的后缀，而 不是“.C”） 编译Pascal程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.p”，并且其生成命令是“$(PC) –c $(PFLAGS)”。 编译Fortran/Ratfor程序的隐含规则。 “.o”的目标的依赖目标会自动推导为“.r”或“.F”或“.f”，并且其生成命令是: 123“.f” “$(FC) –c $(FFLAGS)”“.F” “$(FC) –c $(FFLAGS) $(CPPFLAGS)”“.f” “$(FC) –c $(FFLAGS) $(RFLAGS)” 预处理Fortran/Ratfor程序的隐含规则。 “.f”的目标的依赖目标会自动推导为“.r”或“.F”。这个规则只是转换Ratfor或有预处理的Fortran程序到一个标准的Fortran程序。其使用的命令是： 12“.F” “$(FC) –F $(CPPFLAGS) $(FFLAGS)”“.r” “$(FC) –F $(FFLAGS) $(RFLAGS)” 编译Modula-2程序的隐含规则。 “.sym” 的目标的依赖目标会自动推导为“.def”，并且其生成命令是：“$(M2C) $(M2FLAGS) $(DEFFLAGS)”。“&lt;n.o&gt;”的目标的依赖目标会自动推导为“.mod”， 并且其生成命令是：“$(M2C) $(M2FLAGS) $(MODFLAGS)”。 汇编和汇编预处理的隐含规则。 “.o” 的目标的依赖目标会自动推导为“.s”，默认使用编译品“as”，并且其生成命令是：“$(AS) $(ASFLAGS)”。“.s” 的目标的依赖目标会自动推导为“.S” ，默认使用C预编译器“cpp”，并且其生成命令是：“$(AS) $(ASFLAGS)”。 链接Object文件的隐含规则。 “” 目标依赖于“.o”，通过运行C的编译器来运行链接程序生成（一般是“ld”），其生成命令是：“$(CC) $(LDFLAGS) .o $(LOADLIBES) $(LDLIBS)”。这个规则对 于只有一个源文件的工程有效，同时也对多个Object文件（由不同的源文件生成）的也有效。例如如下规则：1x : y.o z.o 并且“x.c”、“y.c”和“z.c”都存在时，隐含规则将执行如下命令： 1234567cc -c x.c -o x.occ -c y.c -o y.occ -c z.c -o z.occ x.o y.o z.o -o xrm -f x.orm -f y.orm -f z.o 如果没有一个源文件（如上例中的x.c）和你的目标名字（如上例中的x）相关联，那么，你最好写出自己的生成规则，不然，隐含规则会报错的。 Yacc C程序时的隐含规则。 “.c”的依赖文件被自动推导为“n.y”（Yacc生成的文件），其生成命令是：“$(YACC) $(YFALGS)”。（“Yacc”是一个语法分析器，关于其细节请查看相关资料） Lex C程序时的隐含规则。 “.c”的依赖文件被自动推导为“n.l”（Lex生成的文件），其生成命令是：“$(LEX) $(LFALGS)”。（关于“Lex”的细节请查看相关资料） Lex Ratfor程序时的隐含规则。 “.r”的依赖文件被自动推导为“n.l”（Lex生成的文件），其生成命令是：“$(LEX ) $(LFALGS)”。 从C程序、Yacc文件或Lex文件创建Lint库的隐含规则。 “.ln” （lint生成的文件）的依赖文件被自动推导为“n.c”，其生成命令是：“$(LINT) $(LINTFALGS) $(CPPFLAGS) -i”。对于“.y”和“.l”也是同样的规则。 9.3隐含规则使用的变量在隐含规则中的命令中，基本上都是使用了一些预先设置的变量。你可以在你的makefile中改变这些变量的值，或是在make的命令行中传入这些值，或是在你的环境变量中设置这些值，无论怎么样，只要设置了这些特定的变量，那么其就会对隐含规则起作用。当然，你也可以利用make的“-R”或“–no– builtin-variables”参数来取消你所定义的变量 对隐含规则的作用。 例如，第一条隐含规则——编译C程序的隐含规则的命令是“$(CC) –c $(CFLAGS) $(CPPFLAGS)”。Make默认的编译命令是“cc”，如果你把变量“$(CC)”重定义成“gcc”，把 变量“$(CFLAGS)”重定义成 “-g”，那么，隐含规则中的命令全部会以“gcc –c -g $(CPPFLAGS)”的样子来执行了。 我们可以把隐含规则中使用的变量分成两种：一种是命令相关的，如“CC”；一种是参数 相的关，如“CFLAGS”。下面是所有隐含规则中会用到的变量： 关于命令的变量。 AR 函数库打包程序。默认命令是“ar”。 AS 汇编语言编译程序。默认命令是“as”。 CC C语言编译程序。默认命令是“cc”。 CXX C++语言编译程序。默认命令是“g++”。 CO 从 RCS文件中扩展文件程序。默认命令是“co”。 CPP C程序的预处理器（输出是标准输出设备）。默认命令是“$(CC) –E”。 FC Fortran 和 Ratfor 的编译器和预处理程序。默认命令是“f77”。 GET 从SCCS文件中扩展文件的程序。默认命令是“get”。 LEX Lex方法分析器程序（针对于C或Ratfor）。默认命令是“lex”。 PC Pascal语言编译程序。默认命令是“pc”。 YACC Yacc文法分析器（针对于C程序）。默认命令是“yacc”。 YACCR Yacc文法分析器（针对于Ratfor程序）。默认命令是“yacc –r”。 MAKEINFO 转换Texinfo源文件（.texi）到Info文件程序。默认命令是“makeinfo”。 TEX 从TeX源文件创建TeX DVI文件的程序。默认命令是“tex”。 TEXI2DVI 从Texinfo源文件创建军TeX DVI 文件的程序。默认命令是“texi2dvi”。 WEAVE 转换Web到TeX的程序。默认命令是“weave”。 CWEAVE 转换C Web 到 TeX的程序。默认命令是“cweave”。 TANGLE 转换Web到Pascal语言的程序。默认命令是“tangle”。 CTANGLE 转换C Web 到 C。默认命令是“ctangle”。 RM 删除文件命令。默认命令是“rm –f”。 关于命令参数的变量 下面的这些变量都是相关上面的命令的参数。如果没有指明其默认值，那么其默认值都是 空。 ARFLAGS 函数库打包程序AR命令的参数。默认值是“rv”。 ASFLAGS 汇编语言编译器参数。（当明显地调用“.s”或“.S”文件时）。 CFLAGS C语言编译器参数。 CXXFLAGS C++语言编译器参数。 COFLAGS RCS命令参数。 CPPFLAGS C预处理器参数。（ C 和 Fortran 编译器也会用到）。 FFLAGS Fortran语言编译器参数。 GFLAGS SCCS “get”程序参数。 LDFLAGS 链接器参数。（如：“ld”） LFLAGS Lex文法分析器参数。 PFLAGS Pascal语言编译器参数。 RFLAGS Ratfor 程序的Fortran 编译器参数。 YFLAGS Yacc文法分析器参数。 9.4 隐含规则链有些时候，一个目标可能被一系列的隐含规则所作用。例如，一个[.o]的文件生成，可能会是先被Yacc的[.y]文件先成[.c]，然后再被C的编译器生成。我们把这一系列的隐含规则 叫做“隐含规则链”。 在上面的例子中，如果文件[.c]存在，那么就直接调用C的编译器的隐含规则，如果没有[.c]文件，但有一个[.y]文件，那么Yacc的隐含规则会被调用，生成[.c]文件，然后，再调 用C编译的隐含规则最终由[.c]生成[.o]文件，达到目标。 我们把这种[.c]的文件（或是目标），叫做中间目标。不管怎么样，make会努力自动推导生成目标的一切方法，不管中间目标有多少，其都会执着地把所有的隐含规则和你书写的规则全部合起来分析，努力达到目标，所以，有些时候，可能会让你觉得奇怪，怎么我的目标会这样生成？怎么我的makefile发疯了？ 在默认情况下，对于中间目标，它和一般的目标有两个地方所不同：第一个不同是除非中间的目标不存在，才会引发中间规则。第二个不同的是，只要目标成功产生，那么，产生最终目标过程中，所产生的中间目标文件会被以“rm -f”删除。 通常，一个被makefile指定成目标或是依赖目标的文件不能被当作中介。然而，你可以明显地说明一个文件或是目标是中介目标，你可以使用伪目标“.INTERMEDIATE”来强制声明。（如：.INTERMEDIATE ： mid ） 你也可以阻止make自动删除中间目标，要做到这一点，你可以使用伪目标“.SECONDARY”来强制声明（如：.SECONDARY : sec）。你还可以把你的目标，以模式的方式来指定（如：%.o）成伪目标“.PRECIOUS”的依赖目标，以保存被隐含规则所生成的中间文件。 在“隐含规则链”中，禁止同一个目标出现两次或两次以上，这样一来，就可防止在make自动推导时出现无限递归的情况。 Make 会优化一些特殊的隐含规则，而不生成中间文件。如，从文件“foo.c”生成目标程序“foo”，按道理，make会编译生成中间文件“foo.o”，然后链接成“foo”，但在实际情况下，这一动作可以被一条“cc”的命令完成（cc –o foo foo.c），于是优化过的规 则就不会生成中间文件。 9.5定义模式规则你可以使用模式规则来定义一个隐含规则。一个模式规则就好像一个一般的规则，只是在规则中，目标的定义需要有”%”字符。”%”的意思是表示一个或多个任意字符。在依赖目标中同样可以使用”%”，只是依赖目标中的”%”的取值，取决于其目标。 有一点需要注意的是，”%”的展开发生在变量和函数的展开之后，变量和函数的展开发生在make载入Makefile时，而模式规则中的”%”则发生在运行时。 9.5.1 模式规则介绍模式规则中，至少在规则的目标定义中要包含”%”，否则，就是一般的规则。目标中的”%”定义表示对文件名的匹配，”%”表示长度任意的非空字符串。例如：”%.c”表示以”.c”结尾的文件名（文件名的长度至少为3），而”s.%.c”则表示以”s.”开头，”.c”结尾的文件名（文件名的长度至少为 5）。 如果”%”定义在目标中，那么，目标中的”%”的值决定了依赖目标中的”%”的值，也就是说，目标中的模式的”%”决定了依赖目标中”%”的样子。例如有一个模式规则如下： 1%.o : %.c ; &lt;command ......&gt; 其含义是，指出了怎么从所有的[.c]文件生成相应的[.o]文件的规则。如果要生成的目标是”a.o b.o”，那么”%c”就是”a.c b.c”。 一旦依赖目标中的”%”模式被确定，那么，make会被要求去匹配当前目录下所有的文件名，一旦找到，make就会规则下的命令，所以，在模式规则中，目标可能会是多个的，如果有模式匹配出多个目标，make就会产生所有的模式目标，此时，make关心的是依赖的文件名和生成目标的命令这两件事。 9.5.2 模式规则示例下面这个例子表示了,把所有的[.c]文件都编译成[.o]文件. 12%.o : %.c$(CC) -c $(CFLAGS) $(CPPFLAGS) $&lt; -o $@ 其中，&quot;$@&quot;表示所有的目标的挨个值，&quot;$&lt;&quot;表示了所有依赖目标的挨个值。这些奇怪的变 量我们叫”自动化变量”，后面会详细讲述。 下面的这个例子中有两个目标是模式的： 12%.tab.c %.tab.h: %.ybison -d $&lt; 这条规则告诉make把所有的[.y]文件都以”bison -d .y”执行，然后生成”.tab.c”和”.tab.h”文件。（其中，”“ 表示一个任意字符串）。如果我们的执行程序”foo”依 赖于文件”parse.tab.o”和”scan.o”，并且文件”scan.o”依赖于文件”parse.tab.h”，如果”parse.y”文件被更新了，那么根据上述的规则，”bison -d parse.y”就会被执行一次，于 是，”parse.tab.o”和”scan.o”的依赖文件就齐了。（假设，”parse.tab.o” 由”parse.tab.c”生成，和”scan.o”由”scan.c”生成，而”foo”由”parse.tab.o”和”scan.o”链接生成， 而且foo和其[.o]文件的依赖关系也写好，那么，所有的目标都会得到满足） 9.5.3 自动化变量在上述的模式规则中，目标和依赖文件都是一系例的文件，那么我们如何书写一个命令来完成从不同的依赖文件生成相应的目标？因为在每一次的对模式规则的解析时，都会是不同的目标和依赖文件。 自动化变量就是完成这个功能的。在前面，我们已经对自动化变量有所提涉，相信你看到这里已对它有一个感性认识了。所谓自动化变量，就是这种变量会把模式中所定义的一系列的文件自动地挨个取出，直至所有的符合模式的文件都取完了。这种自动化变量只应出现在规则的命令中。 下面是所有的自动化变量及其说明： $@:表示规则中的目标文件集。在模式规则中，如果有多个目标，那么，”$@”就是匹配于目标中模式定义的集合。 $%:仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是”foo.a(bar.o)”，那么，&quot;$%&quot;就是”bar.o”，”$@”就是”foo.a”。如果目标不是函数库文件（Unix下是[.a]，Windows下是[.lib]），那么，其值为空。 $&lt;:依赖目标中的第一个目标名字。如果依赖目标是以模式（即”%”）定义的，那么”$&lt;”将是符合模式的一系列的文件集。注意，其是一个一个取出来的。 $?: 所有比目标新的依赖目标的集合。以空格分隔。 $^: 所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那个这个变量会去除重复的依赖目标，只保留一份。 $+:这个变量很像”$^”，也是所有依赖目标的集合。只是它不去除重复的依赖目标。 $*:这个变量表示目标模式中”%”及其之前的部分。如果目标是”dir/a.foo.b”，并且目标的模式是”a.%.b”，那么，&quot;$*&quot;的值就是&quot;dir /a.foo“。这个变量对于构造有关联的文件名是比较有较。如果目标中没有模式的定义，那么&quot;$*“也就不能被推导出，但是，如果目标文件的后缀是 make所识别的，那么&quot;$*&quot;就是除了后缀的那一部分。例如：如果目标是”foo.c”，因为”.c”是make所能识别的后缀名，所以，&quot;$*&quot;的值就是”foo”。这个特性是GNU make的，很有可能不兼容于其它版本的make，所以，你应该尽量避免使用&quot;$*&quot;，除非是在隐含规则或是静态模式中。如果目标中的后缀是make所不能识别的，那么&quot;$*&quot;就是空值。当你希望只对更新过的依赖文件进行操作时，&quot;$?&quot;在显式规则中很有用，例如，假设有一个函数库文件叫”lib”，其由其它几个object文件更新。那么把object文件打包的比较有效率的Makefile规则是：lib : foo.o bar.o lose.o win.o ar r lib $? 在上述所列出来的自动量变量中。四个变量（$@、$&lt;、$%、$*）在扩展时只会有一个文件，而另三个的值是一个文件列表。这七个自动化变量还可以取得文件的目录名或是在当前目录下的符合模式的文件名，只需要搭配上”D”或”F”字样。这是GNU make中老版本的特性，在新版本中，我们使用函数”dir”或”notdir”就可以做到了。”D”的含义就是Directory，就是目录，”F”的含义就是File，就是文件。 下面是对于上面的七个变量分别加上”D”或是”F”的含义： $(@D):表示”$@”的目录部分（不以斜杠作为结尾），如果”$@”值是”dir/foo.o”，那么&quot;$(@D)&quot;就是”dir”，而如果”$@”中没有包含斜杠的话，其值就是”.”（当前目录）。 $(@F):表示”$@”的文件部分，如果”$@”值是”dir/foo.o”，那么&quot;$(@F)&quot;就是”foo.o”，&quot;$(@F)&quot;相当于函数”$(notdir $@)”。 &quot;$(*D)&quot; &quot;$(*F)&quot;:和上面所述的同理，也是取文件的目录部分和文件部分。对于上面的那个例子，&quot;$(*D)&quot;返回”dir”，而&quot;$(*F)&quot;返回”foo” &quot;$(%D)&quot; &quot;$(%F)&quot;:分别表示了函数包文件成员的目录部分和文件部分。这对于形同”archive(member)”形式的目标中的”member”中包含了不同的目录很有用。 &quot;$(&lt;D)&quot; &quot;$(&lt;F)&quot;:分别表示依赖文件的目录部分和文件部分。 &quot;$(^D)&quot; &quot;$(^F)&quot;:分别表示所有依赖文件的目录部分和文件部分。（无相同的） &quot;$(+D)&quot; &quot;$(+F)&quot;:分别表示所有依赖文件的目录部分和文件部分。（可以有相同的） &quot;$(?D)&quot; &quot;$(?F)&quot;:分别表示被更新的依赖文件的目录部分和文件部分。 最后想提醒一下的是，对于&quot;$&lt;&quot;，为了避免产生不必要的麻烦，我们最好给$后面的那个特定字符都加上圆括号，比如，&quot;$(&lt; )&quot;就要比&quot;$&lt;&quot;要好一些。 还得要注意的是，这些变量只使用在规则的命令中，而且一般都是”显式规则”和”静态模式规则”（参见前面”书写规则”一章）。其在隐含规则中并没有意义。 9.5.4 模式的匹配一般来说，一个目标的模式有一个有前缀或是后缀的”%”，或是没有前后缀，直接就是一个”%”。因为”%”代表一个或多个字符，所以在定义好了的模式中，我们把”%”所匹配的内容叫做”茎”，例如”%.c”所匹配的文件”test.c”中”test”就是”茎”。因为在目标和依赖目标中同时有”%”时，依赖目标的”茎”会传给目标，当做目标中的”茎”。 当一个模式匹配包含有斜杠（实际也不经常包含）的文件时，那么在进行模式匹配时，目录部分会首先被移开，然后进行匹配，成功后，再把目录加回去。在进行”茎”的传递时，我们需要知道这个步骤。例如有一个模式”e%t”，文件”src/eat” 匹配于该模式，于是”src/a”就是其”茎”，如果这个模式定义在依赖目标中，而被依赖于这个模式的目标中又有个模式”c%r”，那么，目标就是”src/car”。（”茎”被传递） 9.5.5 重载内建隐含规则你可以重载内建的隐含规则（或是定义一个全新的），例如你可以重新构造和内建隐含规则不同的命令，如： 12%.o : %.c$(CC) -c $(CPPFLAGS) $(CFLAGS) -D$(date) 你可以取消内建的隐含规则，只要不在后面写命令就行。如： 1%.o : %.s 同样，你也可以重新定义一个全新的隐含规则，其在隐含规则中的位置取决于你在哪里写下这个规则。朝前的位置就靠前。 9.6 老式风格的”后缀规则”后缀规则是一个比较老式的定义隐含规则的方法。后缀规则 会被 模式规则 逐步地取代。因为模式规则更强更清晰。为了和老版本的Makefile兼容，GNU make同样兼容于这些东西。后缀规则有两种方式：”双后缀”和”单后缀”。 双后缀规则定义了一对后缀：目标文件的后缀和依赖目标（源文件）的后缀。如”.c.o”相当于”%o : %c”。单后缀规则只定义一个后缀，也就是源文件的后缀。如”.c”相当于”% : %.c”。 后缀规则中所定义的后缀应该是make所认识的，如果一个后缀是make所认识的，那么这个规则就是单后缀规则，而如果两个连在一起的后缀都被make所认识，那就是双后缀规则。例如：”.c”和”.o”都是make所知道。因而，如果你定义了一个规则是”.c.o”那么其就是双后缀规则，意义就是”.c” 是源文件的后缀，”.o”是目标文件的后缀。如下示例： 12.c.o:$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 后缀规则不允许任何的依赖文件，如果有依赖文件的话，那就不是后缀规则，那些后缀统统被认为是文件名，如： 12.c.o: foo.h$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 这个例子，就是说，文件”.c.o”依赖于文件”foo.h”，而不是我们想要的这样： 12%.o: %.c foo.h$(CC) -c $(CFLAGS) $(CPPFLAGS) -o $@ $&lt; 后缀规则中，如果没有命令，那是毫无意义的。因为他也不会移去内建的隐含规则。 而要让make知道一些特定的后缀，我们可以使用伪目标&quot;.SUFFIXES&quot;来定义或是删除，如： 1.SUFFIXES: .hack .win 把后缀.hack和.win加入后缀列表中的末尾。 12.SUFFIXES: # 删除默认的后缀.SUFFIXES: .c .o .h # 定义自己的后缀 先清楚默认后缀，后定义自己的后缀列表。 make的参数”-r”或”-no-builtin-rules”也会使用得默认的后缀列表为空。而变量”SUFFIXE”被用来定义默认的后缀列表，你可以用”.SUFFIXES”来改变后缀列表，但请不要改变变量”SUFFIXE”的值。 9.7 隐含规则搜索算法比如我们有一个目标叫 T。下面是搜索目标T的规则的算法。请注意，在下面，我们没有提到后缀规则，原因是，所有的后缀规则在Makefile被载入内存时，会被转换成模式规则。如果目标是”archive(member)”的函数库文件模式，那么这个算法会被运行两次，第一次是找目标T，如果没有找到的话，那么进入第二次，第二次会把”member”当作T来搜索。 把T的目录部分分离出来。叫D，而剩余部分叫N。（如：如果T是”src/foo.o”，那么，D就是”src/“，N就是”foo.o”） 创建所有匹配于T或是N的模式规则列表。 如果在模式规则列表中有匹配所有文件的模式，如”%”，那么从列表中移除其它的模式。 移除列表中没有命令的规则。 对于第一个在列表中的模式规则： 推导其”茎”S，S应该是T或是N匹配于模式中”%”非空的部分。 计算依赖文件。把依赖文件中的”%”都替换成”茎”S。如果目标模式中没有包含斜框字符，而把D加在第一个依赖文件的开头。 测试是否所有的依赖文件都存在或是理当存在。（如果有一个文件被定义成另外一个规则的目标文件，或者是一个显式规则的依赖文件，那么这个文件就叫”理当存在”） 如果所有的依赖文件存在或是理当存在，或是就没有依赖文件。那么这条规则将被采用，退出该算法。 如果经过第5步，没有模式规则被找到，那么就做更进一步的搜索。对于存在于列表中的第一个模式规则： 如果规则是终止规则，那就忽略它，继续下一条模式规则。 计算依赖文件。（同第5步） 测试所有的依赖文件是否存在或是理当存在。 对于不存在的依赖文件，递归调用这个算法查找他是否可以被隐含规则找到。 如果所有的依赖文件存在或是理当存在，或是就根本没有依赖文件。那么这条规则被采用，退出该算法。 如果没有隐含规则可以使用，查看”.DEFAULT”规则，如果有，采用，把”.DEFAULT”的命令给T使用。 一旦规则被找到，就会执行其相当的命令，而此时，我们的自动化变量的值才会生成。 10. 使用make更新函数库文件函数库文件也就是对Object文件（程序编译的中间文件）的打包文件。在Unix下，一般是由命令”ar”来完成打包工作。 10.1 函数库文件的成员一个函数库文件由多个文件组成。你可以以如下格式指定函数库文件及其组成： 1archive(member) 这个不是一个命令，而一个目标和依赖的定义。一般来说，这种用法基本上就是为了”ar”命令来服务的。如： 12foolib(hack.o) : hack.oar cr foolib hack.o 如果要指定多个member，那就以空格分开，如： 1foolib(hack.o kludge.o) 其等价于： 1foolib(hack.o) foolib(kludge.o) 你还可以使用Shell的文件通配符来定义，如： 1foolib(*.o) 10.2 函数库成员的隐含规则当 make搜索一个目标的隐含规则时，一个特殊的特性是，如果这个目标是”a(m)”形式的，其会把目标变成”(m)”。于是，如果我们的成员是”%.o” 的模式定义，并且如果我们使用”make foo.a(bar.o)”的形式调用Makefile时，隐含规则会去找”bar.o”的规则，如果没有定义bar.o的规则，那么内建隐含规则生效，make会去找bar.c文件来生成bar.o，如果找得到的话，make执行的命令大致如下： 123cc -c bar.c -o bar.oar r foo.a bar.orm -f bar.o 还有一个变量要注意的是”$%”，这是专属函数库文件的自动化变量，有关其说明请参见”自动化变量”一节。 10.3 函数库文件的后缀规则你可以使用”后缀规则”和”隐含规则”来生成函数库打包文件，如： 1234.c.a:$(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o$(AR) r $@ $*.o$(RM) $*.o 其等效于： 1234(%.o) : %.c$(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $*.o$(AR) r $@ $*.o$(RM) $*.o 10.4 注意事项在进行函数库打包文件生成时，请小心使用make的并行机制（”-j”参数）。如果多个ar命令在同一时间运行在同一个函数库打包文件上，就很有可以损坏这个函数库文件。所以，在make未来的版本中，应该提供一种机制来避免并行操作发生在函数打包文件上。 但就目前而言，你还是应该不要尽量不要使用”-j”参数。 该篇文章为转载，是对原作者系列文章的总汇加上标注。 支持原创，请移步陈浩大神博客： http://blog.csdn.net/haoel/article/details/2886]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
        <tag>course</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile语法]]></title>
    <url>%2F2017%2F09%2F30%2Ftips-makefile%2F</url>
    <content type="text"><![CDATA[一个自定义模式规则示例1234567891011121314151617181920212223242526272829303132CC=gccSRCPATH=srcOUTPATH=objsSRCS_TEST_SORT=$(SRCPATH)/Common.c \ $(SRCPATH)/XSort.c\ $(SRCPATH)/Test_Sort.c#OBJS_TEST_SORT=$(SRCS_TEST_SORT:.c=.o)OBJS_TEST_SORT=$(patsubst src/%.c,$(OUTPATH)/%.o,$(SRCS_TEST_SORT))EXERC_TEST_SORT=TestSortSRCS_TEST_LIST=$(SRCPATH)/Common.c \ $(SRCPATH)/alist.c\ $(SRCPATH)/llist.c\ $(SRCPATH)/sllist.c\ $(SRCPATH)/linkedlist.c\ $(SRCPATH)/Test_List.c\ $(SRCPATH)/polynomial.c#OBJS_TEST_LIST=$(SRCS_TEST_LIST:.c=.o)OBJS_TEST_LIST=$(patsubst src/%.c,$(OUTPATH)/%.o,$(SRCS_TEST_LIST))EXERC_TEST_LIST=TestListstart:$(OBJS_TEST_SORT) $(OBJS_TEST_LIST) $(CC) -o $(EXERC_TEST_SORT) $(OBJS_TEST_SORT) $(CC) -o $(EXERC_TEST_LIST) $(OBJS_TEST_LIST) @echo ---------------SUCCESS----------------$(OUTPATH)/%.o:src/%.c $(CC) -g -fstack-protector -fstack-protector-all -o $@ -c $&lt;clean: rm -rf $(OBJS_TEST_SORT) $(EXERC_TEST_SORT) rm -rf $(OBJS_TEST_LIST) $(EXEC_TEST_LIST) 使用VPATH设置搜索路径VPATH = path1:path2:...,make 会自动找到指定文件的目录并添加到文件上 可以指定文件输入/输出路径,OBJS_TEST_SORT=$(SRCS_TEST_SORT:.c=.o)使用源文件集合推到编译输出文件名,当源文件增加路径后,如src/Common.c后,输出路径也变为src/Common.o,不是需要的bin/Common.o,使用函数patsubst替换输出文件集合中文件路径. 使用模式匹配%.o:%.c替换后缀规则.c.o: patsubst ( patten substitude,匹配替换的缩写)函数。它需要3个参数——第一个是一个需要匹配的式样，第二个表示用什么来替换它，第三个是一个需要处理由空格分隔的序列。我们将两个函数合起来用：objects := $(patsubst %.c,%.o,$(wildcard *.c))会被处理为: objects := a.o b.o同理： executables := $(patsubst %.c,%,$(wildcard *.c))会被处理为： executables := a b.%o：所有以“.o”结尾的目标，也就是如Common.o alist.o等,依赖模式“%.c”：取模式“%.o”的%Common alist，并为其加上.c后缀，即Common.c，alist.c $&lt;：表示所有依赖目标集，也就是Common.c alist.c,$@：表示目标集，也就是Common.o alist.o.命令前加@，表示在终端中不打印，如@mkdir -p ./bin makefile之隐含规则和模式规则Makefile有很多灵活的写法，可以写得更简洁，同时减少出错的可能。本节我们来看看这样一个例子还有哪些改进的余地。 一个目标依赖的所有条件不一定非得写在一条规则中，也可以拆开写，例如： 1234main.o: main.h stack.h maze.h main.o: main.c gcc-c main.c 就相当于： 12main.o: main.c main.h stack.h maze.h gcc-c main.c 如果一个目标拆开写多条规则，其中只有一条规则允许有命令列表，其它规则应该没有命令列表，否则make会报警告并且采用最后一条规则的命令列表。 这样我们的例子可以改写成： 1234567891011121314151617181920main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o: main.h stack.h maze.h stack.o: stack.h main.h maze.o: maze.h main.h main.o: main.c gcc-c main.c stack.o: stack.c gcc-c stack.c maze.o: maze.c gcc-c maze.c clean: -rmmain *.o .PHONY: clean 这不是比原来更繁琐了吗？现在可以把提出来的三条规则删去，写成： 1234567891011main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o: main.h stack.h maze.h stack.o: stack.h main.h maze.o: maze.h main.h clean: -rmmain *.o .PHONY: clean 这就比原来简单多了。可是现在main.o、stack.o和maze.o这三个目标连编译命令都没有了，怎么编译的呢？试试看： 12345$ make cc -c -o main.o main.c cc -c -o stack.o stack.c cc -c -o maze.o maze.c gcc main.o stack.o maze.o -o main 现在解释一下前三条编译命令是怎么来。如果一个目标在Makefile中的所有规则都没有命令列表，make会尝试在内建的隐含规则（Implicit Rule）数据库中查找适用的规则。make的隐含规则数据库可以用make -p命令打印，打印出来的格式也是Makefile的格式，包括很多变量和规则，其中和我们这个例子有关的隐含规则有： 123456789101112# default OUTPUT_OPTION = -o $@ # default CC = cc # default COMPILE.c = $(CC) $(CFLAGS) $(CPPFLAGS)$(TARGET_ARCH) -c %.o: %.c # commands to execute (built-in): $(COMPILE.c) $(OUTPUT_OPTION) $&lt; #号在Makefile中表示单行注释，就像C语言的//注释一样。CC是一个Makefile变量，用CC = cc定义和赋值，用$(CC)取它的值，其值应该是cc。Makefile变量像C的宏定义一样，代表一串字符，在取值的地方展开。cc是一个符号链接，通常指向gcc，在有些UNIX系统上可能指向另外一种C编译器。 CFLAGS这个变量没有定义，$(CFLAGS)展开是空，CPPFLAGS和TARGET_ARCH也是如此。这样$(COMPILE.c)展开应该是cc 空 空 空 -c，去掉“空”得到cc -c，注意中间留下4个空格，所以%.o:%.c规则的命令$(COMPILE.c) $(OUTPUT_OPTION) $&lt;展开之后是cc -c -o $@$&lt;，和上面的编译命令已经很接近了。 $@和$&lt;是两个特殊的变量，$@的取值为规则中的目标，$&lt;的取值为规则中的第一个条件。%.o: %.c是一种特殊的规则，称为模式规则（Pattern Rule）。现在回顾一下整个过程，在我们的Makefile中以main.o为目标的规则都没有命令列表，所以make会查找隐含规则，发现隐含规则中有这样一条模式规则适用，main.o符合%.o的模式，现在%就代表main（称为main.o这个名字的Stem），再替换到%.c中就是main.c。所以这条模式规则相当于： 12main.o: main.c cc -c -o main.o main.c 随后，在处理stack.o目标时又用到这条模式规则，这时又相当于： 12stack.o: stack.c cc -c -o stack.o stack.c maze.o也同样处理。这三条规则可以由make的隐含规则推导出来，所以不必写在Makefile中。 先前我们写Makefile都是以目标为中心，一个目标依赖于若干条件，现在换个角度，以条件为中心，Makefile还可以这么写： 1234567891011main: main.o stack.o maze.o gccmain.o stack.o maze.o -o main main.o stack.o maze.o: main.h main.o maze.o: maze.h main.o stack.o: stack.h clean: -rmmain *.o .PHONY: clean 我们知道，写规则的目的是让make建立依赖关系图，不管怎么写，只要把所有的依赖关系都描述清楚了就行。对于多目标的规则，make会拆成几条单目标的规则来处理，例如 12target1 target2: prerequisite1prerequisite2 command$&lt; -o $@ 这样一条规则相当于： 123456target1: prerequisite1 prerequisite2 commandprerequisite1 -o target1 target2: prerequisite1 prerequisite2 commandprerequisite1 -o target2 注意两条规则的命令列表是一样的，但$@的取值不同。 Linux Makefile与shell脚本区别在Makefile可以调用shell脚本，但是Makefile和shell脚本是不同的。本文试着归纳一下Makefile和shell脚本的不同。 1. shell中所有引用以$打头的变量其后要加{},而在Makefile中的变量是以$打头的后加()。实例如下： 123456Makefile:PATH=&quot;/data/&quot;SUBPATH=$(PATH)Shell:PATH=&quot;/data/&quot;SUBPATH=$&#123;PATH&#125; 2. Makefile中所有以$打头的单词都会被解释成Makefile中的变量。如果你需要调用shell中的变量（或者正则表达式中锚定句位$），都需要加两个$符号（$$）。 Makfile实例如下： 1234PATH=&quot;/data/&quot;all: echo $&#123;PATH&#125; echo $$PATH 例子中的第一个${PATH}引用的是Makefile中的变量，而不是shell中的PATH环境变量，后者引用的是Shell中的PATH环境变量。 ####3. 通配符区别 shell 中通配符*表示所有的字符 Makefile 中通配符%表示所有的字符 ####4. 在Makefile中只能在target中调用Shell脚本，其他地方是不能输出的。比如如下代码就是没有任何输出： 1234VAR=&quot;Hello&quot;echo &quot;$VAR&quot; all: ..... 以上代码任何时候都不会输出，而且还会报错，如下：Makefile:*** command commence before first target.Stop,因为没有在target内。如果上述代码改为如下： 1234VAR=&quot;Hello&quot;all: echo &quot;$VAR&quot; ..... 以上代码，在make all的时候将会执行echo命令，同时必须注意echo &quot;$VAR&quot;之前必须有一个table，这样Makefile才会认为其为一条command，如果没有table会报错如下：Makefile:*** missing separator.Stop. ####5. 在Makefile中执行shell命令，一行创建一个进程来执行。 这也是为什么很多Makefile中有很多行的末尾都是“; \”，以此来保证代码是一行而不是多行，这样Makefile可以在一个进程中执行，例如： 123456SUBDIR=src exampleall: @for subdir in $(SUBDIR); \ do\ echo &quot;building &quot;; \ done 上述可以看出for循环中每行都是以”; \”结尾的。 ####6. 获取当前目录 1PATH=`pwd` 注意是``,不是&apos;&apos; ####7. shell总=两边不允许有空格，Makfile中=两边允许有空格。]]></content>
      <categories>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell开发使用小技巧]]></title>
    <url>%2F2017%2F09%2F30%2Ftips-shell-language%2F</url>
    <content type="text"><![CDATA[写脚本修改数据库中表的某一字段值12345678910111213141516171819202122###########################################################修改表TBL_BAT_TASK_CTL的USE_FLAG字段，启动或停止贷记卡销卡的批处理#useage：执行脚本时加-n参数就是关闭批处理# 执行脚本时加-y参数就是打开批处理###########################################################!/bin/bashif test &quot;$1&quot; = &quot;-n&quot;then db2 connect to $DBLINK db2 &quot;update TBL_BAT_TASK_CTL set USE_FLAG=&apos;N&apos; where BAT_ID=&apos;0024&apos; or BAT_ID=&apos;0025&apos;&quot; db2 terminate# exit 0fiif test &quot;$1&quot; = &quot;-y&quot;then db2 connect to $DBLINK db2 &quot;update TBL_BAT_TASK_CTL set USE_FLAG=&apos;Y&apos; where BAT_ID=&apos;0024&apos; or BAT_ID=&apos;0025&apos;&quot; db2 terminatefi]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>tips</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv核心类型]]></title>
    <url>%2F2017%2F09%2F29%2Fopencv-core%2F</url>
    <content type="text"><![CDATA[matMat替代lplImage 创建和清理mat空间 Mat mat(3000, 4000, CV_8UC3);//3000行,4000列数组,数组里存放3个unsigned char类型的数据 mat.create(rows, cols, CV_8UC1);//行数,列数,如果mat已经有空间,create时会自动清理已有空间 release或者析构:引用计数为1时释放 处理类型一定要用unsigned char而不是char 3*3RGB图像存放方式(连续) isContinuous 判断存储空间是否连续 通过step记录 直接地址访问连续空间1234567int size = mat.rows*mat.cols*mat.elemSize();for(int i = 0; i&lt; size; i+3)//3是因为RGB&#123; mat.data[i] = 0; //B mat.data[i+1] = 0; //G mat.data[i+2] = 0; //R&#125; //优化编码后效率高13ms (4000*3000) 直接地址访问不连续空间123456789for(int i = 0; i &lt; mat.row; i++)&#123; for(int j = 0; j &lt; mat.cols; j++) &#123; (&amp;mat.data[i*mat.step])[j*3] = 255;//B (&amp;mat.data[i*mat.step])[j*3 + 1] = 255;//G (&amp;mat.data[i*mat.step])[j*3 + 2] = 1;//R &#125;&#125; 通过ptr接口遍历Mat(模板函数) 性能基本等同与地址访问 mat.ptr(row);//返回的指针 mat.ptr(row, col); 通过at接口遍历Mat(模板函数) 接口最简单的遍历方法123mat.at&lt;Vec3b&gt;(row, col)[0] = 255;mat.at&lt;Vec3b&gt;(row, col)[1] = 0;mat.at&lt;Vec3b&gt;(row, col)[2] = 0; at可以使用try{} catch(…/cv::Exception &amp;ex){}捕获异常 通过迭代器遍历Mat 可以不用管mat的行列 auto it = mr.begin(); auto it_end = mr.end(); ROI感兴趣区域cv::Rect rect(100, 100, 300, 300); 像素格式和灰度图RGB, YUV, GRAY cvtColor(src, img, COLOR_BGR2GRAY);//源图像,目标凸显,转换方式,利用多线程等方式提高效率 自己实现转换: Gray = (R30 + G59 + B*11 + 50)/100 二值化和阈值 THRESH_BINARY 二进制阈值化 THRESH_BINARY_INV 反二进制阈值化 改变图片的对比度和亮度g(i,j) = a*f(i,j) + b a 1.0~3.0(对比) b 0~100(亮度) saturate_cast防止移除函数 图像尺寸调整 INTER_NEAREST 近邻算法(最快) 1234567891011int sx, sy = 0;//原图对应的坐标float fy = float(src.rows)/out.rows;float fx = float(src.cols)/out.cols;for(int y = 0; y&lt; out.rows;y++)&#123; sy = fy*y + 0.5;//+0.5四舍五入 for(int x = 0; x &lt; out.cols;x++)&#123; sx = fx*x + 0.5; out.at&lt;Vec3b&gt;(y,x) = src.at&lt;Vec3b&gt;(sy, sx); &#125;&#125; CV_INTER_LINEAR 双线程差值(缺省使用) 滤波: 输入图像中像素的小领域来产生输出图像的方法,在信号处理中,这种方法称为滤波(filtering).其中,最常用的是线性滤波:输出像素是输入领域像素的加权和. 双线性内插值: 是由源图像位置在它附近的2*2区域4个邻近像素的值通过加权平均计算得出的. 低通滤波性质,使高频分量受损,图像轮廓可能会有一点模糊. 图像金字塔高斯金字塔(Gaussian pyramid):用来向下采样 获取G(i+1)将G(i)与高斯内核卷积 将所有偶数行和列去除 - 拉普拉斯金字塔(Laplacian pyramid):用来从金字塔底层图像重建上层未采样图像 用来从金字塔底层图像重建上层未采样图像 首先,将图像扩大两杯,新增以0填充 高斯内核(乘以4)与放大后的图像卷积 两幅图像混合(blending) dst = src1*a + src2*(1-a) + gamma//gamma增益 a=[0~1] 画面叠化(cross-dissolve)效果 addWeighted(src1, a, src2, 1-a, 0.0, dst);//两幅图像大小需一致 图像旋转和镜像 cv::rotate(src, dst, type); ROTATE_180 ROTATE_90_CLOCKWISE ROTATE_90_COUNTERCLOCKWISE cv::flip(src,dst, type);//镜像type 0(x), 1(y), -1 ###通过ROI图像合并 打开摄像头接口说明和源码分析 VideoCapture bool open(int index) VideoCapture cap(index) open(int cameraNum, int apiPrefrence) 打开视频流文件 bool open(const String &amp;filename) VideoCapture cap(const String &amp;file) bool open(const String &amp;filename, int apiPrefrence) 关闭和空间释放 ~VideoCapture release 读取一帧视频read(OutputArray image); bool grab() 读取并解码 virtual bool retrieve(OUtputArray , intflag= 0):图像色彩转换 vc&gt;&gt;mat 获取视频,相机属性 CAP_PROP_FPS帧率 CAP_PROP_FRAME_COUNT 总帧数 CAP_PROP_POS_FRAMES 播放帧的位置 CAP_PROP_FRAME_WIDTH HEIGHT VideoWriter open(const String &amp;filename, int fourcc, //VideoWrite::fourcc(‘H’, ‘2’, ‘6’, ‘4’) double fps, Size frameSize,bool isColor=true) release void write(const Mat&amp;) cvVideoWriter_FFMPEG::writeFrame]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv开发环境搭建]]></title>
    <url>%2F2017%2F09%2F29%2Fopencv-env%2F</url>
    <content type="text"><![CDATA[从github下载opencv最新源码https://github.com/opencv/opencv,目前最新是`5e93c8202363a13fc72df30f8c14069c5ab66e42`. Ubuntu环境下编译安装依赖库: 123456789sudo apt-get install build-essentialsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-devgit clone https://github.com/opencv/opencv.gitsudo apt-get install cmake-gui Mac环境下编译进入源码路径,新建一个release的文件夹,并进入,执行: 123cmake -G &quot;Unix Makefiles&quot; ..makesudo make install 编译完成后会在release生成lib目录,lib下存放所有编译成的动态库,可能与ubuntu下编译结果不同,ubuntu下编译只生成libopencv_world.so一个动态库,而mac下会生成opencv_core opencv_highgui opencv_imgproc opencv_ml opencv_objdetect opencv_photo opencv_video opencv_dnn opencv_imgcodecs opencv_shape等多个动态库.执行make install后会将头文件拷贝到/usr/local/include/下,将动态库拷贝到/usr/local/lib/下,将jar包等其他文件拷贝到/usr/local/share/OpenCV/下,makefile脚本加入动态链接库: 12testopencv:main.cpp g++ $+ -o $@ -lopencv_core -lopencv_highgui -lopencv_imgproc -lopencv_ml -lopencv_objdetect -lopencv_photo -lopencv_video -lopencv_dnn -lopencv_imgcodecs -lopencv_shape main.cpp下输入下面测试代码: 123456789101112#include &lt;opencv2/core.hpp&gt;#include &lt;opencv2/imgcodecs.hpp&gt;#include &lt;opencv2/highgui.hpp&gt;using namespace cv;int main(int argc, char *argv[])&#123; Mat image = imread(&quot;1.png&quot;); namedWindow(&quot;img&quot;); imshow(&quot;img&quot;, image); waitKey(0); return 0;&#125; 在生成的执行文件同目录下放入名字为1.png的图片. 配置QT环境在新建的QT工程中的.pro文件中添加如下配置代码: 1234567INCLUDEPATH += /usr/local/includeINCLUDEPATH += /usr/local/include/opencvINCLUDEPATH += /usr/local/include/opencv2LIBS += -L/usr/local/lib \ -lopencv_core \ -lopencv_highgui \ -lopencv_imgproc \ 完成以上步骤后按理应该是能成功的，但是运行时发现会出现如下的错误。 1234dyld: Symbol not found: __cg_jpeg_resync_to_restartReferenced from: /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIOExpected in: /usr/local/lib/libjpeg.8.dylibin /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO 针对以上问题,在项目-运行配置中,增加变量DYLD_LIBRARY_PATH值为/Application/QT5.7.0/5.7/clang_64/lib:/usr/local/lib qt+opencv常见问题在Mac上运行以上代码时，提示以下错误： 1234dyld: Symbol not found: __cg_jpeg_resync_to_restart Referenced from: /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO Expected in: /usr/local/lib/libJPEG.dylib in /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO 解决办法是将“”目录下的对应动态链接库文件创建软连接到“/usr/local/lib”目录下： 12345$ pwd/System/Library/Frameworks/ImageIO.framework/Versions/A/Resources$ sudo ln -sf libJPEG.dylib /usr/local/lib/libJPEG.dylib$ sudo ln -sf libPng.dylib /usr/local/lib/libPng.dylib$ sudo ln -sf libTIFF.dylib /usr/local/lib/libTIFF.dylib]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tips-android]]></title>
    <url>%2F2017%2F09%2F27%2Ftips-android%2F</url>
    <content type="text"><![CDATA[1.使用Glide库提取视频帧图片加载框架Glide就可以做到获取本地视频的缩略图(不能获取网络视频文件): 12345String filePath = &quot;/storage/emulated/0/Pictures/example_video.mp4&quot;;Glide .with( context ) .load( Uri.fromFile( new File( filePath ) ) ) .into( imageViewGifAsBitmap );]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于QT QAudioOutput push模式问题]]></title>
    <url>%2F2017%2F09%2F13%2Ftips-qt-audiooutput%2F</url>
    <content type="text"><![CDATA[在MAC上基于QT和ffmpeg实现最简单播放器,在完成声音播放模块后导致无法正常播放,QAudioOutput start后state仍是idel,将QAudioOutput buffer写满后就不能继续写数据了,导致播放被卡死. QAudioOutput创建代码: 12345678910111213141516171819QAudioFormat fmt;fmt.setSampleRate(this-&gt;sampleRate);fmt.setSampleSize(this-&gt;sampleSize);fmt.setChannelCount(this-&gt;channel);fmt.setCodec(&quot;audio/pcm&quot;);fmt.setByteOrder(QAudioFormat::LittleEndian);fmt.setSampleType(QAudioFormat::UnSignedInt);QAudioDeviceInfo info = QAudioDeviceInfo::defaultOutputDevice();printf(&quot;deviceName:%s\n&quot;,qPrintable(info.deviceName()));if (!info.isFormatSupported(fmt)) &#123; printf(&quot;default format not supported try to use nearest\n&quot;); fmt = info.nearestFormat(fmt);&#125;output = new QAudioOutput(fmt);//connect(output, SIGNAL(stateChanged(QAudio::State)), this, SLOT(handleStateChanged(QAudio::State)));io = output-&gt;start();printf(&quot;io:%p\n&quot;, io);//printf(&quot;state:%s&quot;,output-&gt;state());QAudio::State stat = output-&gt;state(); 在stackoverflow Qt QAudioOutput push mode看到别人的问题和解释,发现是setSampleType引起的,代码在window上可以正常跑,只是在mac上失败. 问题I’ve got a question about using QAudioOutput to directly write samples at a specific sample rate to the sound output device. I’m writing an emulator that emualates sound chips on a per-frame basis, and then gets a buffer containing a frame’s worth of audio samples, which I would like to write to the audio output. Currently, to test my audio output routine, I allocate a huge (5 minute) buffer to put random numbers into, like so: Header: 1234uint16_t *audio_outputBuffer;uint32_t audio_bytesRemainingToRead;QAudioOutput *audio_outputStream;QIODevice *audio_outputDevice; Implementation: 12345678910audio_outputBuffer = (uint16_t *) malloc((96000 * 4) * 300);int i = 0;uint16_t *tempAudioBuffer = audio_outputBuffer;for(i = 0; i &lt; ((96000 * 4) * 150); i++) &#123; *tempAudioBuffer = (uint16_t) rand() &amp; 0xFFFF; tempAudioBuffer++;&#125;audio_bytesRemainingToRead = (96000 * 4) * 300; Next, I set up my audio device with some basic parameters: 1234567891011121314151617// Set up the formatQAudioFormat format;format.setFrequency(96000); // Usually this is specified through an UI optionformat.setChannels(2);format.setSampleSize(16);format.setCodec(&quot;audio/pcm&quot;);format.setByteOrder(QAudioFormat::LittleEndian);format.setSampleType(QAudioFormat::UnSignedInt);// There&apos;s code here to notify the user of inability to match the format and choose an action, which is omitted for clarity// Create audio output stream, set up signalsaudio_outputStream = new QAudioOutput(format, this);connect(audio_outputStream, SIGNAL(stateChanged(QAudio::State)), this, SLOT(audio_stateChanged(QAudio::State)));audio_outputDevice = audio_outputStream-&gt;start(); Then, in my timer tick routine, which is called by a QTimer at 60 FPS, I do the following code to write a ‘chunk’ of audio data to the QAudioOutput’s buffer: 123456if(audio_outputDevice-&gt;isOpen() &amp;&amp; audio_outputStream-&gt;state() != QAudio::StoppedState) &#123; qint64 bytesOfAudioWrittenToDevice = audio_outputDevice-&gt;write((char *) audio_outputBuffer, audio_outputStream-&gt;periodSize()); audio_bytesRemainingToRead -= bytesOfAudioWrittenToDevice; qDebug() &lt;&lt; &quot;Wrote&quot; &lt;&lt; bytesOfAudioWrittenToDevice &lt;&lt; &quot;bytes of audio to output device. Remaining bytes to read:&quot; &lt;&lt; audio_bytesRemainingToRead; qDebug() &lt;&lt; &quot;Free bytes in audio output:&quot; &lt;&lt; audio_outputStream-&gt;bytesFree();&#125; Once I start the audio output process, I get the following output on the console: 12345678910Current audio state: 3 Error: 0Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115197952Free bytes in audio output: 6144Current audio state: 0 Error: 0Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115195904Free bytes in audio output: 4096Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115193856Free bytes in audio output: 2048Wrote 2048 bytes of audio to output device. Remaining bytes to read: 115191808Free bytes in audio output: 0 (This and the above line is repeated forever) To me, it looks like QAudioOutput isn’t flushing it’s internal buffer to the sound card, which goes along with the entire “no sound coming out of my computer” thing. What would cause this issue, and how could I fix it? (By the way, I’m compiling my code against Qt 4.8.1, on Mac OS X 10.7.4.) Thanks for any answers. 解释Upfront just wanna point out: This is not a Qt bug. Why? The answer is that in the WAV spec’, 8-bit samples are always unsigned, whereas 16-bit samples are always signed. Any other combination does not work. This is device related, the framework can not do anything about it. So this will not work because you have set 16 bit sample size and unsigned integer format. And yes, the solution is: you have to set the sample type to signed for 16-bit resolution: 1format.setSampleType(QAudioFormat::SignedInt); Inversely for 8-bit samples you would have to put: 1format.setSampleType(QAudioFormat:UnsignedInt); Also this very similar question (same problem but with 8-bit) shows you that it is not a particular problem of using signed or unsigned samples in Qt, but that it is the combination of samples size and type that matters (for the audio device, not for Qt ;) QAudioOutput in Qt5 is not producing any sound IMHO the fact that Qt does not take care of handling these cases by forcing the correct format is a flaw but not a lack in functionnality. You can learn more about this in the notes section of this page: https://ccrma.stanford.edu/courses/422/projects/WaveFormat/ I’ve figured this out — apparently Qt has issues with UNSIGNED samples. If you set the sample type to signed, everything works fine, regardless of platform.]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>QT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG api使用流程]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-arch%2F</url>
    <content type="text"><![CDATA[ffmpeg接口使用流程比较固定: av_register_all():注册所有模块 int ret = avformat_open_input(&amp;ic, ofn, 0, 0);:获取AVFormatContext ic(ofn为输入文件地址) for(i = 0; i &lt; ic-&gt;nb_streams; i++):遍历AVFormatContext中所有stream,分别找到Audio与Video对应的AVCodecContext; AVCodec *codec = avcodec_find_decoder(enc-&gt;codec_id);:根据AVCodecContext中codec_id获取到AVCodec; avcodec_open2(enc, codec,NULL):打开AVCodec; 接下来分配AVPacket与AVFrame]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG编解码]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-codec%2F</url>
    <content type="text"><![CDATA[解码ffmpeg3版本的解码接口做了调整,之前的视频解码接口avcodec_decode_video2和音频解码接口avcodec_decode_audio4被设置为deprecated,对这两个接口做了合并,使用同一的接口.并且将音视频解码步骤分成了两步,第一步avcodec_send_packet,第二步avcodec_receive_frame, 旧版本avcodec_decode_video2旧版本avcodec_decode_audio4123456789101112int got_picture; ret = avcodec_decode_audio4(enc, pcm,&amp;got_picture, pkt); if ( ret &lt; 0 ) &#123; char buf[1024] = &#123;0&#125;; av_strerror(err, buf, sizeof(buf)); printf(buf); printf(&quot;avcodec_decode_audio4 failed:%d&quot; ,got_picture); av_packet_unref(pkt); av_frame_free(&amp;pcm); if(ic) avformat_close_input(&amp;ic); return -1; &#125; 将AVPacket的pkt解码成AVFrame的pcm 新版本avcodec_send_packet接口源码:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Supply raw packet data as input to a decoder. * * Internally, this call will copy relevant AVCodecContext fields, which can * influence decoding per-packet, and apply them when the packet is actually * decoded. (For example AVCodecContext.skip_frame, which might direct the * decoder to drop the frame contained by the packet sent with this function.) * * @warning The input buffer, avpkt-&gt;data must be AV_INPUT_BUFFER_PADDING_SIZE * larger than the actual read bytes because some optimized bitstream * readers read 32 or 64 bits at once and could read over the end. * * @warning Do not mix this API with the legacy API (like avcodec_decode_video2()) * on the same AVCodecContext. It will return unexpected results now * or in future libavcodec versions. * * @note The AVCodecContext MUST have been opened with @ref avcodec_open2() * before packets may be fed to the decoder. * * @param avctx codec context * @param[in] avpkt The input AVPacket. Usually, this will be a single video * frame, or several complete audio frames. * Ownership of the packet remains with the caller, and the * decoder will not write to the packet. The decoder may create * a reference to the packet data (or copy it if the packet is * not reference-counted). * Unlike with older APIs, the packet is always fully consumed, * and if it contains multiple frames (e.g. some audio codecs), * will require you to call avcodec_receive_frame() multiple * times afterwards before you can send a new packet. * It can be NULL (or an AVPacket with data set to NULL and * size set to 0); in this case, it is considered a flush * packet, which signals the end of the stream. Sending the * first flush packet will return success. Subsequent ones are * unnecessary and will return AVERROR_EOF. If the decoder * still has frames buffered, it will return them after sending * a flush packet. * * @return 0 on success, otherwise negative error code: * AVERROR(EAGAIN): input is not accepted right now - the packet must be * resent after trying to read output * AVERROR_EOF: the decoder has been flushed, and no new packets can * be sent to it (also returned if more than 1 flush * packet is sent) * AVERROR(EINVAL): codec not opened, it is an encoder, or requires flush * AVERROR(ENOMEM): failed to add packet to internal queue, or similar * other errors: legitimate decoding errors */int avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt); 参数分析 AVCodecContext *avctx：第一个参数与旧的接口一致，是视频解码的上下文，包含解码器。 const AVPacket *avpkt： 编码的音视频帧数据 为什么要传递空的avpkt 这里有一个说明是可以传递NULL，什么情况下需要传递NULL，你平时看一些视频播放器，播放经常会少最后几帧，很多情况就是因为没有处理好缓冲帧的问题，ffmpeg内部会缓冲几帧，要想取出来就需要传递空的AVPacket进去。 新版本avcodec_receive_frame接口源码12345678910111213141516171819/** * Return decoded output data from a decoder. * * @param avctx codec context * @param frame This will be set to a reference-counted video or audio * frame (depending on the decoder type) allocated by the * decoder. Note that the function will always call * av_frame_unref(frame) before doing anything else. * * @return * 0: success, a frame was returned * AVERROR(EAGAIN): output is not available right now - user must try * to send new input * AVERROR_EOF: the decoder has been fully flushed, and there will be * no more output frames * AVERROR(EINVAL): codec not opened, or it is an encoder * other negative values: legitimate decoding errors */int avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame); 参数分析 AVCodecContext *avctx：第一个参数视频解码的上下文，与上面接口一致。 AVFrame *frame：解码后的视频帧数据。 空间申请和释放问题解码后图像空间由函数内部申请，你所做的只需要分配 AVFrame 对象空间，如果你每次调用avcodec_receive_frame传递同一个对象，接口内部会判断空间是否已经分配，如果没有分配会在函数内部分配。 avcodec_send_packet和avcodec_receive_frame调用关系并不一定是一对一的，比如一些音频数据一个AVPacket中包含了1秒钟的音频，调用一次avcodec_send_packet之后，可能需要调用25次 avcodec_receive_frame才能获取全部的解码音频数据，所以要做如下处理： 12345678910int re = avcodec_send_packet(codec, pkt);if (re != 0)&#123; return;&#125;while( avcodec_receive_frame(codec, frame) == 0)&#123; //读取到一帧音频或者视频 //处理解码后音视频 frame&#125; 参考 send/receive encoding and decoding API overview]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG工具方法]]></title>
    <url>%2F2017%2F09%2F13%2Fffmpeg-util%2F</url>
    <content type="text"><![CDATA[av_strerror1234int av_strerror ( int errnum,char * errbuf,size_t errbuf_size) ffmpeg获取与设置mp4文件旋转方向方法设置与获取都是对AVStream的dict操作. 设置 1234567891011121314151617181920212223242526272829for (i = 0; i &lt; ifmt_ctx_v-&gt;nb_streams; i++) &#123; //Create output AVStream according to input AVStream if(ifmt_ctx_v-&gt;streams[i]-&gt;codec-&gt;codec_type==AVMEDIA_TYPE_VIDEO)&#123; AVStream *in_stream = ifmt_ctx_v-&gt;streams[i]; AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream-&gt;codec-&gt;codec); videoindex_v=i; if (!out_stream) &#123; printf( &quot;Failed allocating output stream\n&quot;); ret = AVERROR_UNKNOWN; goto end; &#125; videoindex_out=out_stream-&gt;index; //Copy the settings of AVCodecContext ret = av_dict_set(&amp;out_stream-&gt;metadata,&quot;rotate&quot;,&quot;90&quot;,0); //设置旋转角度 if(ret&gt;=0) &#123; printf(&quot;=========yes=====set rotate success!===\n&quot;); &#125; if (avcodec_copy_context(out_stream-&gt;codec, in_stream-&gt;codec) &lt; 0) &#123; printf( &quot;Failed to copy context from input to output stream codec context\n&quot;); goto end; &#125; out_stream-&gt;codec-&gt;codec_tag = 0; if (ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER) out_stream-&gt;codec-&gt;flags |= CODEC_FLAG_GLOBAL_HEADER; break; &#125; &#125; 读取 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647for (i = 0; i &lt; ifmt_ctx_v-&gt;nb_streams; i++) &#123; //Create output AVStream according to input AVStream if(ifmt_ctx_v-&gt;streams[i]-&gt;codec-&gt;codec_type==AVMEDIA_TYPE_VIDEO)&#123; AVStream *in_stream = ifmt_ctx_v-&gt;streams[i]; AVStream *out_stream = avformat_new_stream(ofmt_ctx, in_stream-&gt;codec-&gt;codec); videoindex_v=i; if (!out_stream) &#123; printf( &quot;Failed allocating output stream\n&quot;); ret = AVERROR_UNKNOWN; goto end; &#125; videoindex_out=out_stream-&gt;index; //Copy the settings of AVCodecContext ret = av_dict_set(&amp;out_stream-&gt;metadata,&quot;rotate&quot;,&quot;90&quot;,0); //设置旋转角度 if(ret&gt;=0) &#123; printf(&quot;=========yes=====set rotate success!===\n&quot;); &#125; if (avcodec_copy_context(out_stream-&gt;codec, in_stream-&gt;codec) &lt; 0) &#123; printf( &quot;Failed to copy context from input to output stream codec context\n&quot;); goto end; &#125; out_stream-&gt;codec-&gt;codec_tag = 0; if (ofmt_ctx-&gt;oformat-&gt;flags &amp; AVFMT_GLOBALHEADER) out_stream-&gt;codec-&gt;flags |= CODEC_FLAG_GLOBAL_HEADER; break; &#125; &#125; double g_rotate_theta = get_rotation(decoder-&gt;is_video);//is_video是video的AVStream int rotate = 0; if (fabs(g_rotate_theta - 90) &lt; 1.0) &#123; rotate = 90; &#125; else if(fabs(g_rotate_theta - 180) &lt; 1.0||fabs(g_rotate_theta + 180) &lt; 1.0) &#123; rotate = 180; &#125; else if(fabs(g_rotate_theta - 270) &lt; 1.0||fabs(g_rotate_theta + 90) &lt; 1.0) &#123; rotate = 270; &#125; LOGI(&quot;get rotate is : %d&quot; , rotate); metadata-&gt;rotate = rotate;]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音视频参数之Profile]]></title>
    <url>%2F2017%2F09%2F12%2Ftips-media-profile%2F</url>
    <content type="text"><![CDATA[前两天发现公司产品 触发 有导入从微信等下载的外部小视频时失败的情况, 触发 导入视频时使用开源库media-for-mobile对视频进行重新编码.media-for-mobile使用android系统接口android.media.MediaExtractor对mp4文件解复用,使用android硬件编解码接口android.media.MediaCodec对视频解码-处理-编码操作,最后通过Android系统APIandroid.media.MediaMuxer将视频写成文件. 反馈的两个有问题视频,一个视频导入时报BufferOverFlowException错误,另一个视频不报错但是导入时进度一直为0%. 经分析出问题的两个视频的Video profile为High,普通视频为Baseline,报BufferOverFlowException错误的视频的Audio profile为HE-AAC,普通视频的Audio profile为LC. 详细了解了一下H264 与AAC profile: H264各种profile作为行业标准，H.264编码体系定义了4种不同的Profile(类)：Baseline(基线类),Main(主要类), Extended(扩展类)和High Profile(高端类)（它们各自下分成许多个层）： Baseline Profile: 提供I/P帧，仅支持progressive(逐行扫描)和CAVLC； Extended Profile: 提供I/P/B/SP/SI帧，仅支持progressive(逐行扫描)和CAVLC； Main Profile: 提供I/P/B帧，支持progressive(逐行扫描)和interlaced(隔行扫描)，提供CAVLC或CABAC； High Profile: （也就是FRExt）在Main Profile基础上新增：8x8 intra prediction(8x8 帧内预测), custom quant(自定义量化), lossless video coding(无损视频编码), 更多的yuv格式（4:4:4…）； H.264在高清中具有最小体积。在同等图像质量下，采用H.264技术压缩后的数据量只有MPEG2的1/8，MPEG4的1/3，相对Xvid、Divx等属于MPEG4编码而言，其体积优势明显，在互联网上，H.264资源处在爆发趋势。而High Profile是H.264解码中的高端类型，拥有最完善的支持程度、最优秀的特性，可以说是高清视频编码中的劳斯莱斯，只有征服了这个优秀的编码，MP4才能将H.264完全掌控，也才能充分享受到高清视频带来的视觉震撼，意义非凡。 针对当前高清是视频会议行业的主流发展趋势，而目前高清普及的主要阻力之一就是带宽的限制。而High Profile H.264技术在同等视频质量的情况下可节省50%的带宽，为客户节省大量的网络带宽成本。据业内专家介绍，此次H.264 High Profile的推出是视频技术的一个巨大进步，其意义不亚于2003年从H.263向H.264过渡的价值。它将为目前正在推广的高清视频通信应用扫清了令人头疼的网络带宽障碍，不仅如此，这些变化对于包括CIF、标清等品质的视频通信应用也同样适用。 鉴于High Profile H.264对于视频会议行业的非凡影响，目前已有国内外厂商尝鲜，宣布其旗下产品全面支持该项技术，包括宝利通、华平、华腾网讯。从这一趋势来看，未来视频会议产品全面支持High Profile H.264也经成为不可逆转的潮流，而高清普及也在技术层面更近了一步。 参考: H264 各种profile AAC各种profileAAC共有9种规格，以适应不同的场合的需要： MPEG-2 AAC LC: 低复杂度规格（Low Complexity）–比较简单，没有增益控制，但提高了编码效率，在中等码率的编码效率以及音质方面，都能找到平衡点 MPEG-2 AAC Main: 主规格 MPEG-2 AAC SSR: 可变采样率规格（Scaleable Sample Rate） MPEG-4 AAC LC: 低复杂度规格（Low Complexity）——现在的手机比较常见的MP4文件中的音频部份就包括了该规格音频文件 MPEG-4 AAC Main: 主规格 ——包含了除增益控制之外的全部功能，其音质最好 MPEG-4 AAC SSR: 可变采样率规格（Scaleable Sample Rate） MPEG-4 AAC LTP: 长时期预测规格（Long Term Predicition） MPEG-4 AAC LD: 低延迟规格（Low Delay） MPEG-4 AAC HE: 高效率规格（High Efficiency）—–这种规格适合用于低码率编码，有Nero ACC 编码器支持 14496-3标准，里面定义的profile除了上述的一些规格，还有如Scalable 、 TwinVQ、 CELP、 HVXC等更多其他的profile。 目前听到用的比较多的应该是LC和HE(适合低码率)。流行的Nero AAC的命令行编码程序就支持LC，HE，HEv2这三种，试用后，用MediaInfo分析了编码后的AAC音频，发现规格显示都是LC，当时就感到奇怪，不是说支持三种规格吗？然后才又查资料发现，原来HE其实就是AAC（LC）+SBR技术，HEv2就是AAC（LC）+SBR+PS技术，难怪用MediaInfo分析后，HE规格的文件即显示: 123格式简介:LC格式设置,SBR:是格式设置,PS:否 HE与HEv2 HE：“high efficiency”（高效性）。HE-AAC v1（又称AACPlusV1，SBR)用容器的方法加了原AAC（LC）+SBR技术。SBR其实代表的是Spectral Band Replication(频段复制)。简单概括一下，音乐的主要频谱集中在低频段，高频段幅度很小（但很重要，决定了音质），如果对整个频段编码，要么为了保护高频造成低频段编码过细以致文件巨大，要么为了保存了低频的主要成分而失去高频成分以致丧失音质。SBR把频谱切割开来，低频单独编码保存主要成分，高频单独放大编码保存音质，“统筹兼顾”了，在减少文件大小的情况下还保存了音质，完美的化解了一对矛盾 HEv2 它用容器的方法包含了HE-AAC v1和PS技术。PS指“parametric stereo”（参数立体声）。这个其实好理解，原来的立体声文件，文件大小是一个声道的两倍。但是两个声道的声音存在某种相似性，根据香农信息熵编码定理，相关性应该被去掉才能减小文件大小。所以PS技术存储了一个声道的全部信息，然后，花很少的字节用参数描述另一个声道和它不同的地方 这样，HEv1和HEv2用个图简单表示下就是：(图中的AAC即指的是原来的AAC-LC) 由于NERO AAC编码后产生的是经过MP4容器封装后的，而我们的decoder需要处理的是未经封装的AAC流，因此还需要处理从MP4封装格式中extract出AAC流的步骤；哦，这里提到了MP4容器封装，就再把我看到的一些关于MP4容器的心得插入在此也说下： 其实.mp4格式规范是MPEG4 Part 1标准定义的。但是这个格式本身相当通用，并不是只能用来存贮MPEG4视频格式。举个例子，一个.mp4文件中包含的可能是H.263的视频轨及AMR的音频轨。这样它和MPEG4视频压缩算法就半点边都沾不上。但它绝对是一个合法的.mp4文件。从这个意义上讲，.mp4是一个独立的封包格式。也许它的原始设计意图是仅用于MPEG4，但事实上大家觉得它很好用，已经把它扩展成可以包容其它格式了。现在市场上比如某产品号称“支持MP4播放”，到底是什么意思呢？如果它是指可以播放.mp4这种文件，那里面的音频和视频格式它能支持多少种组合呢？没说清楚吧。举个极端的例子，假设一台设备仅支持“视频为未压缩YUV以及不带音频轨的.mp4文件，但它的文件名确实可以是.mp4，是不是也可以在盒子上印上“支持MP4”呢？那么，买回去，复制一个网上下载的.mp4文件（MPEG4视频和AAC音频应该是个比较流行的组合），结果却发现根本不能播放。就算不举这么极端的例子，一般.mp4文件中常见的视频音频格式也有多种，一个产品要做到支持所有的格式是很难的。所以，如果要准确的描述，应该写清楚类似“支持视频格式为MPEG4或H.264/AVC，音频为AMR或AAC的*.mp4文件”。其实更严格一些，还应该写清楚MPEG4支持到哪种profile, AMR是NB还是WB，AAC是LC还是HE等更多细节。当然，这种误导型的说明应该在减少，不过如果有比较确切的格式需求，最好还是先搞清楚这些细节。看到网上还有人说到N73，其实只支持视频为MPEG4 Simple Profile / Advanced Simple Profile及H.263 Profile 0 &amp; 3，音频为AMR-NB/WB或者AAC-LC, HE-AAC的mp4文件。如果你放一个视频格式为H.264/AVC的mp4上去，是无法播放出画面来的。 在网上找了一些工具，如MP4UI,MP4BOX,Yamb(mp4box的GUI程序),采用它们进行extract操作后发现，原来的SBR和PS等信息咋没有了，都变成LC规格的AAC文件啦。好容易准备的测试流，难道还是不能用？于是一番苦寻发现，可能是SBR和PS等信息在ADTS头中是无法体现的，所以分析ADTS格式头的AAC，就无法判别是否是HE和HEv2啦。但是我总觉得SBR和PS等技术信息在AAC流中应该还是存在的。因为我还在一个国外的论坛上看到这么几句话：There’s no requirement for MP4 with AAC to have SBR indicated in the headers. It’s still correct not to have it marked and have SBR or PS data in the stream anyway. Likewise, decoding a frame and not seeing any SBR or PS info doesn’t mean you can’t find it further up in the stream anyway（我理解就是说SBR OR PS信息不一定在Header中有，但是并不意味着你不能进一步在stream中发现它）。 HE-AAC的.mp4码流，经过extract出AAC(ADTS)后，44.1KHZ的变成了22.05KHZ。HEv2-AAC的.mp4码流，经过extract出AAC(ADTS)后，不但44.1KHZ的变成了22.05KHZ(一半)，连2channels也变成了1channels，这个问题更奇怪了，在论坛上找，发现也有人有此问题：“I get 22050Hz, 1 channel for audio that is in fact 44100Hz, 2channels and having both SBR and PS”。 后来看到MSDN中的AAC Decoder的描述中有这么一小段话： The media type gives the sample rate and number of channels prior to the application of spectral band replication (SBR) and parametric stereo (PS) tools, if present. The effect of the SBR tool is to double the decoded sample rate relative to the core AAC-LC sample rate. The effect of the PS tool is to decode stereo from a mono-channel core AAC-LC stream. 我的理解是AAC的decoder如果支持SBR和PS，会将AAC-HEV1(SBR)中的sample rate提高一倍，而会将AAC-HEV2(SBR+PS)中不仅sample rate提高一倍，单声道也提高至双声道了。结合前面提到的SBR(频段复制)和PS(参数立体声）技术的简单介绍，好像觉得这样是有点儿道理的哦~~ 用IPP example提供的解码工具simple_player简单试了下，对于44.1khz，stereo的HEv2-AAC的.mp4码流，经过extract出22.05KHZ，mono 的AAC(ADTS)后，再使用simple_player进行音频解码测试，解完后，果然发现又恢复了44.1khz和stereo。（但目前也测试了好几种extract出的HE和HEv2的aac码流，有的能将sample rate和channel 又double回来，有的又不能，这个具体原因是不是由于Ipp example提供的解码器的问题还不确定）。 另外，用simple_player如果直接decoder编码出的经过封装的.mp4格式的AAC音频的话，发现：其它都正常，只AAC-HEv2格式的.mp4音频解码后变成了单声道。难道是解码器中的PS tools没能发挥作用？初步估计应该是IPP 的那个小解码器的问题吧。 关于ADTS&amp;ADIF上面说到了ADTS头格式的AAC。其实，AAC的音频文件格式有以下两种： ADIF：Audio Data Interchange Format 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不需进行在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。故这种格式常用在磁盘文件中。 ADTS：Audio Data Transport Stream 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。 简单说，ADTS可以在任意帧解码，也就是说它每一帧都有头信息。ADIF只有一个统一的头，所以必须得到所有的数据后解码。且这两种的header的格式也是不同的，具体的组织结构在这里就不详说了。 参考: AAC的各种规格 问题原因分析首先BufferOverFlowException问题,由于音频采用AAC-HE导致MediaExtractor解析出的音频采样率为本身采样率的一半,同时创建出的解码OutputBuffer的大小是编码InputBuffer的2倍,而media-for-mobile开源项目直接将从解码器OutputBuffer取出的数据塞入编码器InputBuffer中,2倍的数据放入一倍的Buffer导致溢出,暂时的解决办法手动指定编码器InputBuffer max-size为一个较大值(10*1024).同时,由于MediaExtractor不能获取正确的audio profile,也无法确认获取到的采样率是否不正确采样率的一半,所以采用ffmpeg接口获取profile,但是ffmpeg调用avcodec_open2获取到的profile为-99,而且采样率依然为正常采样率一半,只有在解码一帧音频后才能得到正确的profile与采样率. 其次,转码进度不增加的问题,主要是High的H264视频,media-for-mobile使用一个MediaExtractor一次抽取音视频帧,如果是音频则交音频解码器,如果为视频则交视频解码器,解码后将解码帧转交编码器,编码后将数据写入MediaMuxer,将数据写入MediaMuxer的前提是吊用过addTrack,将音视频track加入到Muxer中,而addTrack需要在音视频解码若干帧后产生INFO_OUTPUT_FORMAT_CHANGED,若没有addTrack会导致编码后数据如法写入Muxer,卡死编码器,Baseline视频只需要少量帧就可以产生INFO_OUTPUT_FORMAT_CHANGED,但High视频产生INFO_OUTPUT_FORMAT_CHANGED需要更多的帧,而media-for-mobile中,MediaExtractor首先一直获取到的是音频数据,音频一直解码编码,但是输出的muxer时,videotrack未被添加,所以无法将音频编码器的数据写入muxer,音频解码器被卡死,而mediasource一直被产生的audio数据无法被消费,无法获取到视频数据导致视频INFO_OUTPUT_FORMAT_CHANGED一直无法产生,最终产生死锁,导致audio等待video的INFO_OUTPUT_FORMAT_CHANGED,video等待audio被读完后读到video解码产生INFO_OUTPUT_FORMAT_CHANGED. 最后将audio和video使用两个MediaExtractor各读取各自内容.]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试(一):UiAutomator官方介绍]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-start%2F</url>
    <content type="text"><![CDATA[了解android测试需要查询android官方文档,android官方培训教程Getting Started with Testing介绍了android提供的测试类型,测试接口等,相较与网上总结的android自动化测试框架,官方文档显然分类更合理,定位更准确. 两种测试类型在使用Android Studio创建模块时会在src下生成androidTest和test两个用于测试的的目录,对应下面两种测试类型. 本地单元测试(Local unit tests)位于module-name/src/test/java/.下,运行在PC端本地的JVM虚拟机上,并且不能访问Android框架的接口. 参考Building Local Tests 设备化测试位于module-name/src/androidTest/java/.下,必须运行在Android物理设备和虚拟机上. 参考Building Instrumented Unit Tests Instrumented unit tests are tests that run on physical devices and emulators, and they can take advantage of the Android framework APIs and supporting APIs, such as the Android Testing Support Library. You should create instrumented unit tests if your tests need access to instrumentation information (such as the target app’s Context) or if they require the real implementation of an Android framework component (such as a Parcelable or SharedPreferences object). Using instrumented unit tests also helps to reduce the effort required to write and maintain mock code. You are still free to use a mocking framework, if you choose, to simulate any dependency relationships. 设备化单元测试分为: 设备化单元测试(Instrumented Unit Test):Building Instrumented Unit Tests: Build complex unit tests with Android dependencies that cannot be satisfied with mock objects. 组件集成测试:Automating User Interface Tests: Create tests to verify that the user interface behaves correctly for user interactions within a single app or for interactions across multiple apps. app集成测试:Testing App Component Integrations: Verify the behavior of components that users do not directly interact with, such as a Service or aContent Provider.]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试(N):UiAutomator官方介绍]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-uiautomator-official%2F</url>
    <content type="text"><![CDATA[Automating User Interface TestsUser interface (UI) testing lets you ensure that your app meets its functional requirements and achieves a high standard of quality such that it is more likely to be successfully adopted by users. One approach to UI testing is to simply have a human tester perform a set of user operations on the target app and verify that it is behaving correctly. However, this manual approach can be time-consuming, tedious, and error-prone. A more efficient approach is to write your UI tests such that user actions are performed in an automated way. The automated approach allows you to run your tests quickly and reliably in a repeatable manner. Note: It is strongly encouraged that you use Android Studio for building your test apps, because it provides project setup, library inclusion, and packaging conveniences. This class assumes you are using Android Studio. To automate UI tests with Android Studio, you implement your test code in a separate Android test folder (src/androidTest/java). The Android Plug-in for Gradle builds a test app based on your test code, then loads the test app on the same device as the target app. In your test code, you can use UI testing frameworks to simulate user interactions on the target app, in order to perform testing tasks that cover specific usage scenarios. For testing Android apps, you typically create these types of automated UI tests: UI tests that span a single app: This type of test verifies that the target app behaves as expected when a user performs a specific action or enters a specific input in its activities. It allows you to check that the target app returns the correct UI output in response to user interactions in the app’s activities. UI testing frameworks like Espresso allow you to programmatically simulate user actions and test complex intra-app user interactions. UI tests that span multiple apps: This type of test verifies the correct behavior of interactions between different user apps or between user apps and system apps. For example, you might want to test that your camera app shares images correctly with a 3rd-party social media app, or with the default Android Photos app. UI testing frameworks that support cross-app interactions, such as UI Automator, allow you to create tests for such scenarios. The lessons in this class teach you how to use the tools and APIs in the Android Testing Support Library to build these types of automated tests. Before you begin building tests using these APIs, you must install the Android Testing Support Library, as described in Downloading the Android Testing Support Library. UI TestingIn addition to unit testing the individual components that make up your Android application (such as activities, services, and content providers), it is also important that you test the behavior of your application’s user interface (UI) when it is running on a device. UI testing ensures that your application returns the correct UI output in response to a sequence of user actions on a device, such as entering keyboard input or pressing toolbars, menus, dialogs, images, and other UI controls. Functional or black-box UI testing does not require testers to know the internal implementation details of the app, only its expected output when a user performs a specific action or enters a specific input. This approach allows for better separation of development and testing roles in your organization. One common approach to UI testing is to run tests manually and verify that the app is behaving as expected. However, this approach can be time-consuming, tedious, and error-prone. A more efficient and reliable approach is to automate the UI testing with a software testing framework. Automated testing involves creating programs to perform testing tasks (test cases) to cover specific usage scenarios, and then using the testing framework to run the test cases automatically and in a repeatable manner. Overviewhe Android SDK provides the following tools to support automated, functional UI testing on your application: uiautomatorviewer - A GUI tool to scan and analyze the UI components of an Android application. uiautomator - A Java library containing APIs to create customized functional UI tests, and an execution engine to automate and run the tests. To use these tools, you must have the following versions of the Android development tools installed: Android SDK Tools, Revision 21 or higher Android SDK Platform, API 16 or higher Workflow for the the uiautomator testing framework Here’s a short overview of the steps required to automate UI testing: Prepare to test by installing the app on a test device, analyzing the app’s UI components, and ensuring that your application is accessible by the test automation framework. Create automated tests to simulate specific user interactions on your application. Compile your test cases into a JAR file and install it on your test device along with your app. Run the tests and view the test results. Correct any bugs or defects discovered in testing. Analyzing Your Application’s UIBefore you start writing your test cases, it’s helpful to familiarize yourself with the UI components (including the views and controls) of the targeted application. You can use the uiautomatorviewer tool to take a snapshot of the foreground UI screen on any Android device that is connected to your development machine. The uiautomatorviewer tool provides a convenient visual interface to inspect the layout hierarchy and view the properties of the individual UI components that are displayed on the test device. Using this information, you can later create uiautomator tests with selector objects that target specific UI components to test. To analyze the UI components of the application that you want to test: Connect your Android device to your development machine. Open a terminal window and navigate to /tools/. Run the tool with this command: 1$ uiautomatorviewer To capture a screen for analysis, click the Device Screenshot button in the GUI of the uiautomatorviewer tool. Note: If you have more than one device connected, specify the device for screen capture by setting the ANDROID_SERIAL environment variable: a. Find the serial numbers for your connected devices by running this command: 123$ adb devices``` b. Set the ANDROID_SERIAL environment variable to select the device to test: #In Windows: set ANDROID_SERIAL= #In UNIX: export ANDROID_SERIAL= 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657If you are connected to only a single device, you do not need to set the ANDROID_SERIAL environment variable.5. View the UI properties for your application:- Hover over the snapshot in the left-hand panel to see the UI components identified by the uiautomatorviewer tool. You can view the component’s properties listed in the lower right-hand panel, and the layout hierarchy in the upper right-hand panel.- Optionally, click on the Toggle NAF Nodes button to see UI components that are not accessible to the uiautomator testing framework. Only limited information may be available for these components.#### Preparing to TestBefore using the uiautomator testing framework, complete these pre-flight tasks:##### Load the application to a deviceIf you are reading this document, chances are that the Android application that you want to test has not been published yet. If you have a copy of the APK file, you can install the APK onto a test device by using the adb tool. To learn how to install an APK file using the adb tool, see the [adb](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/adb.html#move) documentation.##### Identify the application’s UI componentsBefore writing your `uiautomator` tests, first identify the UI components in the application that you want to test. Typically, good candidates for testing are UI components that are visible and that users can interact with. The UI components should also have visible text labels, `android:contentDescription` values, or both.You can inspect the visible screen objects in an application conveniently by using the `uiautomatorviewer` tool. For more information about how to analyze an application screen with this tool, see the section [Analyzing Your Application’s UI](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/testing/testing_ui.html#uianalaysis). For more information about the common types of UI components provided by Android, see [User Interface](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/index.html).##### Ensure that the application is accessibleThis step is required because the `uiautomator` tool depends on the accessibility features of the Android framework to execute your functional UI tests. You should include these minimum optimizations to support the `uiautomator` tool:- Use the `android:contentDescription` attribute to label the `ImageButton`, `ImageView`, `CheckBox` and other user interface controls.- Provide an `android:hint` attribute instead of a content description for `EditText` fields- Associate an `android:hint` attribute with any graphical icons used by controls that provide feedback to the user (for example, status or state information).- Make sure that all the user interface elements are accessible with a directional controller, such as a trackball or D-pad.- Use the `uiautomatorviewer` tool to ensure that the UI component is accessible to the testing framework. You can also test the application by turning on accessibility services like TalkBack and Explore by Touch, and try using your application using only directional controls.For more information about implementing and testing accessibility, see [Making Applications Accessible](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/accessibility/apps.html).&gt; Note: To identify the non-accessible components in the UI, click on the Toggle NAF Nodes option in the `uiautomatorviewer` tool.Generally, Android application developers get accessibility support for free, courtesy of the `View` and `ViewGroup` classes. However, some applications use custom view components to provide a richer user experience. Such custom components won&apos;t get the accessibility support that is provided by the standard Android UI components. If this applies to your application, ensure that the application developer exposes the custom drawn UI components to Android accessibility services, by implementing the `AccessibilityNodeProvider` class. For more information about making custom view components accessible, see [Making Applications Accessible](https://stuff.mit.edu/afs/sipb/project/android/docs/guide/topics/ui/accessibility/apps.html#custom-views).##### Configure your development environmentIf you&apos;re developing in Eclipse, the Android SDK provides additional tools that help you write test cases using `uiautomator` and buiild your JAR file. In order to set up Eclipse to assist you, you need to create a project that includes the `uiautomator` client library, along with the Android SDK library. To configure Eclipse:1. Create a new Java project in Eclipse, and give your project a name that is relevant to the tests you’re about to create (for example, &quot;MyAppNameTests&quot;). In the project, you will create the test cases that are specific to the application that you want to test.2. From the Project Explorer, right-click on the new project that you created, then select Properties &gt; Java Build Path, and do the following: - Click Add Library &gt; JUnit then select JUnit3 to add JUnit support. - Click Add External JARs... and navigate to the SDK directory. Under the platforms directory, select the latest SDK version and add both the uiautomator.jar and android.jar files.If you did not configure Eclipse as your development environment, make sure that the `uiautomator.jar` and `android.jar` files from the `&lt;android-sdk&gt;/platforms/&lt;sdk&gt;` directory are in your Java class path.Once you have completed these prerequisite tasks, you&apos;re almost ready to start creating your `uiautomator` tests.#### Creating uiautomator TestsTo build a test that runs in the `uiautomator` framework, create a test case that extends the `UiAutomatorTestCase` class. In Eclipse, the test case file goes under the `src` directory in your project. Later, you will build the test case as a JAR file, then copy this file to the test device. The test JAR file is not an APK file and resides separately from the application that you want to test on the device.Because the `UiAutomatorTestCase` class extends `junit.framework.TestCase`, you can use the `JUnit` Assert class to test that UI components in the app return the expected results. To learn more about JUnit, you can read the documentation on the `junit.org` home page.The first thing your test case should do is access the device that contains the target app. It’s also good practice to start the test from the Home screen of the device. From the Home screen (or some other starting location you’ve chosen in the target app), you can use the classes provided by the `uiautomator` API to simulate user actions and to test specific UI components. For an example of how to put together a `uiautomator` test case, see the sample test case.##### uiautomator APIThe `uiautomator` API is bundled in the `uiautomator.jar` file under the `&lt;android-sdk&gt;/platforms/` directory. The API includes these key classes that allow you to capture and manipulate UI components on the target app:- [UiDevice](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiDevice.html)Represents the device state. In your tests, you can call methods on the UiDevice instance to check for the state of various properties, such as current orientation or display size. Your tests also can use the UiDevice instance to perform device level actions, such as forcing the device into a specific rotation, pressing the d-pad hardware button, or pressing the Home and Menu buttons.To get an instance of UiDevice and simulate a Home button press: getUiDevice().pressHome(); 12- [UiSelector](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiSelector.html)Represents a search criteria to query and get a handle on specific elements in the currently displayed UI. If more than one matching element is found, the first matching element in the layout hierarchy is returned as the target UiObject. When constructing a UiSelector, you can chain together multiple properties to refine your search. If no matching UI element is found, a `UiAutomatorObjectNotFoundException` is thrown. You can use the childSelector() method to nest multiple UiSelector instances. For example, the following code example shows how to specify a search to find the first ListView in the currently displayed UI, then search within that ListView to find a UI element with the text property Apps. UiObject appItem = new UiObject(new UiSelector() .className(“android.widget.ListView”).instance(1) .childSelector(new UiSelector().text(“Apps”))); 1234- [UiObject](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiObject.html)Represents a UI element. To create a UiObject instance, use a UiSelector that describes how to search for, or select, the UI element.The following code example shows how to construct UiObject instances that represent a Cancel button and a OK button in your application. UiObject cancelButton = new UiObject(new UiSelector().text(“Cancel”)); UiObject okButton = new UiObject(new UiSelector().text(“OK”)); 12You can reuse the UiObject instances that you have created in other parts of your app testing, as needed. Note that the `uiautomator` test framework searches the current display for a match every time your test uses a UiObject instance to click on a UI element or query a property.In the following code example, the `uiautomator` test framework searches for a UI element with the text property OK. If a match is found and if the element is enabled, the framework simulates a user click action on the element. if(okButton.exists() &amp;&amp; okButton.isEnabled()) { okButton.click(); } 1You can also restrict the search to find only elements of a specific class. For example, to find matches of the Button class: UiObject cancelButton = new UiObject(new UiSelector().text(“Cancel”) .className(“android.widget.Button”)); UiObject okButton = new UiObject(new UiSelector().text(“OK”) .className(“android.widget.Button”)); 12- [UiCollection](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiCollection.html)Represents a collection of items, for example songs in a music album or a list of emails in an inbox. Similar to a UiObject, you construct a UiCollection instance by specifying a UiSelector. The UiSelector for a UiCollection should search for a UI element that is a container or wrapper of other child UI elements (such as a layout view that contains child UI elements). For example, the following code snippet shows how to construct a UiCollection to represent a video album that is displayed within a FrameLayout: UiCollection videos = new UiCollection(new UiSelector() .className(“android.widget.FrameLayout”)); 1If the videos are listed within a LinearLayout view, and you want to to retrieve the number of videos in this collection: int count = videos.getChildCount(new UiSelector() .className(“android.widget.LinearLayout”)); 1If you want to find a specific video that is labeled with the text element Cute Baby Laughing from the collection and simulate a user-click on the video: UiObject video = videos.getChildByText(new UiSelector() .className(“android.widget.LinearLayout”), “Cute Baby Laughing”); video.click(); 12Similarly, you can simulate other user actions on the UI object. For example, if you want to simulate selecting a checkbox that is associated with the video: UiObject checkBox = video.getChild(new UiSelector() .className(“android.widget.Checkbox”)); if(!checkBox.isSelected()) checkbox.click(); 123- [UiScrollable](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/UiScrollable.html)Represents a scrollable collection of UI elements. You can use the UiScrollable class to simulate vertical or horizontal scrolling across a display. This technique is helpful when a UI element is positioned off-screen and you need to scroll to bring it into view.For example, the following code shows how to simulate scrolling down the Settings menu and clicking on an About tablet option: UiScrollable settingsItem = new UiScrollable(new UiSelector() .className(“android.widget.ListView”)); UiObject about = settingsItem.getChildByText(new UiSelector() .className(“android.widget.LinearLayout”), “About tablet”); about.click() 1234For more information about these APIs, see the uiautomator reference.##### A sample uiautomator test caseThe following code example shows a simple test case which simulates a user bringing up the Settings app in a stock Android device. The test case mimics all the steps that a user would typically take to perform this task, including opening the Home screen, launching the All Apps screen, scrolling to the Settings app icon, and clicking on the icon to enter the Settings app. package com.uia.example.my; // Import the uiautomator libraries import com.android.uiautomator.core.UiObject; import com.android.uiautomator.core.UiObjectNotFoundException; import com.android.uiautomator.core.UiScrollable; import com.android.uiautomator.core.UiSelector; import com.android.uiautomator.testrunner.UiAutomatorTestCase; public class LaunchSettings extends UiAutomatorTestCase { public void testDemo() throws UiObjectNotFoundException { // Simulate a short press on the HOME button. getUiDevice().pressHome(); // We’re now in the home screen. Next, we want to simulate // a user bringing up the All Apps screen. // If you use the uiautomatorviewer tool to capture a snapshot // of the Home screen, notice that the All Apps button’s // content-description property has the value “Apps”. We can // use this property to create a UiSelector to find the button. UiObject allAppsButton = new UiObject(new UiSelector() .description(&quot;Apps&quot;)); // Simulate a click to bring up the All Apps screen. allAppsButton.clickAndWaitForNewWindow(); // In the All Apps screen, the Settings app is located in // the Apps tab. To simulate the user bringing up the Apps tab, // we create a UiSelector to find a tab with the text // label “Apps”. UiObject appsTab = new UiObject(new UiSelector() .text(&quot;Apps&quot;)); // Simulate a click to enter the Apps tab. appsTab.click(); // Next, in the apps tabs, we can simulate a user swiping until // they come to the Settings app icon. Since the container view // is scrollable, we can use a UiScrollable object. UiScrollable appViews = new UiScrollable(new UiSelector() .scrollable(true)); // Set the swiping mode to horizontal (the default is vertical) appViews.setAsHorizontalList(); // Create a UiSelector to find the Settings app and simulate // a user click to launch the app. UiObject settingsApp = appViews.getChildByText(new UiSelector() .className(android.widget.TextView.class.getName()), &quot;Settings&quot;); settingsApp.clickAndWaitForNewWindow(); // Validate that the package name is the expected one UiObject settingsValidation = new UiObject(new UiSelector() .packageName(&quot;com.android.settings&quot;)); assertTrue(&quot;Unable to detect Settings&quot;, settingsValidation.exists()); }} 1234#### Building and Deploying Your uiautomator Tests1. Once you have coded your test, follow these steps to build and deploy your test JAR to your target Android test device:Create the required build configuration files to build the output JAR. To generate the build configuration files, open a terminal and run the following command: /tools/android create uitest-project -n -t 1 -p 12345The &lt;name&gt; is the name of the project that contains your uiautomator test source files, and the &lt;path&gt; is the path to the corresponding project directory.2. From the command line, set the ANDROID_HOME variable:- In Windows:`set ANDROID_HOME=&lt;path_to_your_sdk&gt;`- In UNIX:`export ANDROID_HOME=&lt;path_to_your_sdk&gt;`3. Go to the project directory where your build.xml file is located and build your test JAR. ant build 14. Deploy your generated test JAR file to the test device by using the adb push command: adb push /data/local/tmp/ 1Here’s an example: adb push ~/dev/workspace/LaunchSettings/bin/LaunchSettings.jar /data/local/tmp/ 123#### Running uiautomator TestsHere’s an example of how to run a test that is implemented in the `LaunchSettings.jar` file. The tests are bundled in the `com.uia.example.my` package: adb shell uiautomator runtest LaunchSettings.jar -c com.uia.example.my.LaunchSettings 123456789101112131415To learn more about the syntax, subcommands, and options for uiautomator, see the [uiautomator](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/index.html) reference.#### Best PracticesHere are some best practices for functional UI testing with the uiautomator framework:- Ensure that you validate the same UI functions on your application across the various types of devices that your application might run on (for example, devices with different screen densities).- You should also test your UI against common scenarios such as in-coming phone calls, network interruptions, and user-initiated switching to other applications on the device.### [uiautomator tools](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/help/uiautomator/index.html)The uiautomator testing framework lets you test your user interface (UI) efficiently by creating automated functional UI testcases that can be run against your app on one or more devices.For more information on testing with the uiautomator framework, see [UI Testing](https://stuff.mit.edu/afs/sipb/project/android/docs/tools/testing/testing_ui.html).#### SyntaxTo run your testcases on the target device, you can use the `adb shell` command to invoke the `uiautomator` tool. The syntax is: adb shell uiautomator runtest -c [options] 1Here’s an example: adb shell uiautomator runtest LaunchSettings.jar -c com.uia.example.my.LaunchSettings ``` Command-line OptionsThe following table describes the subcommands and options for uiautomator. Table 1. Command-line options for uiautomator Subcommand Option Description runtest &lt;jar&gt; Required. The argument is the name of one or more JAR files that you deployed to the target device which contain your uiautomator testcases. You can list more than one JAR file by using a space as a separator. -c &lt;test_class_or_method&gt; Required. The argument is a list of one or more specific test classes or test methods from the JARs that you want uiautomator to run.Each class or method must be fully qualified with the package name, in one of these formats: package_name.class_name package_name.class_name#method_name You can list multiple classes or methods by using a space as a separator. –nohup Runs the test to completion on the device even if its parent process is terminated (for example, if the device is disconnected). -e Specify other name-value pairs to be passed to test classes. May be repeated.Note: The -e options cannot be combined; you must prefix each option with a separate -e flag. -e debug [true false] Wait for debugger to connect before starting. dump [file] Generate an XML file with a dump of the current UI hierarchy. If a filepath is not specified, by default, the generated dump file is stored on the device in this location /storage/sdcard0/window_dump.xml. events Prints out accessibility events to the console until the connection to the device is terminated UiAutomation apiClass for interacting with the device’s UI by simulation user actions and introspection of the screen content. It relies on the platform accessibility APIs to introspect the screen and to perform some actions on the remote view tree. It also allows injecting of arbitrary raw input events simulating user interaction with keyboards and touch devices. One can think of a UiAutomation as a special type of AccessibilityService which does not provide hooks for the service life cycle and exposes other APIs that are useful for UI test automation. 这是一个通过模拟用户操作来与设备用户界面交互以及获取屏幕内容的类。它依赖于平台的辅助功能APIs来在远程的控件树上获取屏幕内容以及执行一些操作。同时它也允许通过注入原生事件(译者注:指的就是InputEvent. KeyEvent也是继承于InputEvent的，所以说它是原生事件)来模拟用户的按键和触屏操作。我们可以认为UiAutomation就是一个特殊类型的AccessibilityService,其既不会为控制服务的生命周期而提供钩子函数，也不会暴露任何其他可以直接用于用户界面测试自动化的APIs. The APIs exposed by this class are low-level to maximize flexibility when developing UI test automation tools and libraries. Generally, a UiAutomation client should be using a higher-level library or implement high-level functions. For example, performing a tap on the screen requires construction and injecting of a touch down and up events which have to be delivered to the system by a call to injectInputEvent(InputEvent, boolean). 这个类暴露出来的APIs是很低层的，目的就是为了在开发用户界面测试自动化框架和库时提供最大的弹性。总的来说，一个UiAutomation客户端应该使用一些（基于UiAutomation的)更高层次的库或者实现更高层次的方法。比如，模拟一个用户在屏幕上的点击事件需要构造并注入一个按下和一个弹起事件，然后必须调用UiAutomation的一个injectInputEvent(InputEvent, boolean)的调用来发送给操作系统。 The APIs exposed by this class operate across applications enabling a client to write tests that cover use cases spanning over multiple applications. For example, going to the settings application to change a setting and then interacting with another application whose behavior depends on that setting. 这个类暴露出来的APIs可以跨应用，这样用户就可以编写可以跨越多个应用的测试用例脚本了。比如，打开系统的设置应用去修改一些设置然后再与另外一个依赖于该设置的应用进行交互（译者注：这个在instrumentation这个框架可以做不到的）]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试之(N):测试支持库]]></title>
    <url>%2F2017%2F08%2F30%2Fat-android-support-library%2F</url>
    <content type="text"><![CDATA[Android官方文档-测试支持库 Android 测试支持库提供了大量用于测试 Android 应用的框架。此库提供了一组 API，让您可以为应用快速构建何运行测试代码，包括 JUnit 4 和功能性用户界面 (UI) 测试。您可以从 Android Studio IDE 或命令行运行使用这些 API 创建的测试。 Android 测试支持库通过 Android SDK 管理器提供。如需了解详细信息，请参阅测试支持库设置 本页介绍了 Android 测试支持库提供了哪些工具、如何在测试环境中使用这些工具，以及库版本的相关信息。 测试支持库功能Android 测试支持库包括以下自动化测试工具： AndroidJUnitRunner：适用于 Android 且与 JUnit 4 兼容的测试运行器 Espresso：UI 测试框架；适合应用中的功能性 UI 测试 UI Automator：UI 测试框架；适合跨系统和已安装应用的跨应用功能性 UI 测试 AndroidJUnitRunnerAndroidJUnitRunner 类是一个 JUnit 测试运行器，可让您在 Android 设备上运行 JUnit 3 或 JUnit 4 样式测试类，包括使用 Espresso 和 UI Automator 测试框架的设备。测试运行器可以将测试软件包和要测试的应用加载到设备、运行测试并报告测试结果。此类将替换 InstrumentationTestRunner 类，后者仅支持 JUnit 3 测试。 此测试运行器的主要功能包括： JUnit 支持 访问仪器信息 测试筛选 测试分片 要求 Android 2.2（API 级别 8）或更高版本。 JUnit 支持测试运行器与 JUnit 3 和 JUnit 4（最高版本为 JUnit 4.10）测试兼容。不过，请勿在同一软件包中混用 JUnit 3 和 JUnit 4 测试代码，因为这可能会导致意外结果。如果要创建一个 JUnit 4 仪器测试类以在设备或模拟器上运行，则测试类必须以 @RunWith(AndroidJUnit4.class) 注解作为前缀。 以下代码段显示了如何编写 JUnit 4 仪器测试来验证 CalculatorActivity 类中的 add 操作是否正常工作。 1234567891011121314151617181920212223242526272829import android.support.test.runner.AndroidJUnit4;import android.support.test.runner.AndroidJUnitRunner;import android.test.ActivityInstrumentationTestCase2;@RunWith(AndroidJUnit4.class)public class CalculatorInstrumentationTest extends ActivityInstrumentationTestCase2&lt;CalculatorActivity&gt; &#123; @Before public void setUp() throws Exception &#123; super.setUp(); // Injecting the Instrumentation instance is required // for your test to run with AndroidJUnitRunner. injectInstrumentation(InstrumentationRegistry.getInstrumentation()); mActivity = getActivity(); &#125; @Test public void typeOperandsAndPerformAddOperation() &#123; // Call the CalculatorActivity add() method and pass in some operand values, then // check that the expected value is returned. &#125; @After public void tearDown() throws Exception &#123; super.tearDown(); &#125;&#125; 访问仪器信息您可以使用 InstrumentationRegistry 类访问与测试运行相关的信息。此类包括 Instrumentation 对象、目标应用 Context 对象、测试应用 Context 对象，以及传递到测试中的命令行参数。使用 UI Automator 框架编写测试或编写依赖于 Instrumentation 或 Context 对象的测试时，此数据非常有用。 测试筛选在 JUnit 4.x 测试中，您可以使用注解对测试运行进行配置。此功能可将向测试中添加样板文件和条件代码的需求降至最低。除了 JUnit 4 支持的标准注解外，测试运行器还支持 Android 特定的注解，包括： @RequiresDevice：指定测试仅在物理设备而不在模拟器上运行。 @SdkSupress：禁止在低于给定级别的 Android API 级别上运行测试。例如，要禁止在低于 18 的所有 API 级别上运行测试，请使用注解 - - @SDKSupress(minSdkVersion=18)。 @SmallTest、@MediumTest 和 @LargeTest：指定测试的运行时长以及运行频率。测试分片测试运行器支持将单一测试套件拆分成多个碎片，因此您可以将属于同一碎片的测试作为一个组在同一 Instrumentation 实例下运行。每个分片由一个索引号进行标识。运行测试时，使用 -e numShards 选项指定要创建的独立分片数量，并使用 -e shardIndex 选项指定要运行哪个分片。 例如，要将测试套件拆分成 10 个分片，且仅运行第二个碎片中的测试，请使用以下命令： adb shell am instrument -w -e numShards 10 -e shardIndex 2 要详细了解如何使用此测试运行器，请参阅 API 参考。 EspressoEspresso 测试框架提供了一组 API 来构建 UI 测试，用于测试应用中的用户流。利用这些 API，您可以编写简洁、运行可靠的自动化 UI 测试。Espresso 非常适合编写白盒自动化测试，其中测试代码将利用所测试应用的实现代码详情。 Espresso 测试框架的主要功能包括： 灵活的 API，用于目标应用中的视图和适配器匹配。如需了解详细信息，请参阅视图匹配。 一组丰富的操作 API，用于自动化 UI 交互。如需了解详细信息，请参阅操作 API。 UI 线程同步，用于提升测试可靠性。如需了解详细信息，请参阅 UI 线程同步。 要求 Android 2.2（API 级别 8）或更高版本。 视图匹配利用 Espresso.onView() 方法，您可以访问目标应用中的 UI 组件并与之交互。此方法接受 Matcher 参数并搜索视图层次结构，以找到符合给定条件的相应 View 实例。您可以通过指定以下条件来优化搜索： 视图的类名称 视图的内容描述 视图的 R.id 在视图中显示的文本 例如，要找到 ID 值为 my_button 的按钮，可以指定如下匹配器：1onView(withId(R.id.my_button)); 如果搜索成功，onView() 方法将返回一个引用，让您可以执行用户操作并基于目标视图对断言进行测试。 适配器匹配在 AdapterView 布局中，布局在运行时由子视图动态填充。如果目标视图位于某个布局内部，而该布局是从 AdapterView（例如 ListView 或 GridView）派生出的子类，则 onView() 方法可能无法工作，因为只有布局视图的子集会加载到当前视图层次结构中。 因此，请使用 Espresso.onData() 方法访问目标视图元素。Espresso.onData() 方法将返回一个引用，让您可以执行用户操作并根据 AdapterView 中的元素对断言进行测试。 操作 API通常情况下，您可以通过根据应用的用户界面执行某些用户交互来测试应用。借助 ViewActions API，您可以轻松地实现这些操作的自动化。您可以执行多种 UI 交互，例如： 视图点击 滑动 按下按键和按钮 键入文本 打开链接 例如，要模拟输入字符串值并按下按钮以提交该值，您可以像下面一样编写自动化测试脚本。ViewInteraction.perform() 和 DataInteraction.perform() 方法采用一个或多个 ViewAction 参数，并以提供的顺序运行操作。123456// Type text into an EditText view, then close the soft keyboardonView(withId(R.id.editTextUserInput)) .perform(typeText(STRING_TO_BE_TYPED), closeSoftKeyboard());// Press the button to submit the text changeonView(withId(R.id.changeTextBt)).perform(click()); UI 线程同步由于计时问题，Android 设备上的测试可能随机失败。此测试问题称为测试不稳定。在 Espresso 之前，解决方法是在测试中插入足够长的休眠或超时期或添加代码，以便重试失败的操作。Espresso 测试框架可以处理 Instrumentation 与 UI 线程之间的同步；这就消除了对之前的计时解决方法的需求，并确保测试操作与断言更可靠地运行。 要详细了解如何使用 Espresso，请参阅 API 参考和测试单个应用的 UI 培训。 UI AutomatorUI Automator 测试框架提供了一组 API 来构建 UI 测试，用于在用户应用和系统应用中执行交互。利用 UI Automator API，您可以执行在测试设备中打开“设置”菜单或应用启动器等操作。UI Automator 测试框架非常适合编写黑盒自动化测试，其中的测试代码不依赖于目标应用的内部实现详情。 UI Automator 测试框架的主要功能包括： 用于检查布局层次结构的查看器。如需了解详细信息，请参阅 UI Automator 查看器。 在目标设备上检索状态信息并执行操作的 API。如需了解详细信息，请参阅访问设备状态。 支持跨应用 UI 测试的 API。如需了解详细信息，请参阅 UI Automator API。 要求 Android 4.3（API 级别 18）或更高版本。 UI Automator 查看器uiautomatorviewer 工具提供了一个方便的 GUI，可以扫描和分析 Android 设备上当前显示的 UI 组件。您可以使用此工具检查布局层次结构，并查看在设备前台显示的 UI 组件属性。利用此信息，您可以使用 UI Automator（例如，通过创建与特定可见属性匹配的 UI 选择器）创建控制更加精确的测试。 uiautomatorviewer 工具位于 &lt;android-sdk&gt;/tools/目录中。 访问设备状态UI Automator 测试框架提供了一个 UiDevice 类，用于在目标应用运行的设备上访问和执行操作。您可以调用其方法来访问设备属性，如当前屏幕方向或显示尺寸。UiDevice 类还可用于执行以下操作： 更改设备旋转 按 D-pad 按钮 按“返回”、“主屏幕”或“菜单”按钮 打开通知栏 对当前窗口进行屏幕截图 例如，要模拟按下“主屏幕”按钮，请调用 UiDevice.pressHome() 方法。 UI Automator API利用 UI Automator API，您可以编写稳健可靠的测试，而无需了解目标应用的实现详情。您可以使用这些 API 在多个应用中捕获和操作 UI 组件： UiCollection：枚举容器的 UI 元素以便计算子元素个数，或者通过可见的文本或内容描述属性来指代子元素。 UiObject：表示设备上可见的 UI 元素。 UiScrollable：为在可滚动 UI 容器中搜索项目提供支持。 UiSelector：表示在设备上查询一个或多个目标 UI 元素。 Configurator：允许您设置运行 UI Automator 测试所需的关键参数。 例如，以下代码显示了如何编写可在设备中调用默认应用启动器的测试脚本：12345678910111213// Initialize UiDevice instancemDevice = UiDevice.getInstance(getInstrumentation());// Perform a short press on the HOME buttonmDevice.pressHome();// Bring up the default launcher by searching for// a UI component that matches the content-description for the launcher buttonUiObject allAppsButton = mDevice .findObject(new UiSelector().description(&quot;Apps&quot;));// Perform a click on the button to bring up the launcherallAppsButton.clickAndWaitForNewWindow(); 要详细了解如何使用 UI Automator，请参阅 API 参考和测试多个应用的 UI 培训。 测试支持库设置Android 测试支持库软件包在最新版本的 Android 支持存储库中提供，后者可作为辅助组件通过 Android SDK 管理器下载。 要通过 SDK 管理器下载 Android 支持存储库，请执行以下操作： 启动 Android SDK 管理器。 在 SDK 管理器窗口中，滚动到 Packages 列表末尾，找到 Extras 文件夹并展开（如有必要）以显示其内容。 选择 Android Support Repository 项。 点击 Install packages… 按钮。 下载后，此工具会将支持存储库文件安装到您现有的 Android SDK 目录中。库文件位于 SDK 的以下子目录中：&lt;sdk&gt;/extras/android/m2repository 目录。 Android 测试支持库的类位于 android.support.test 软件包中。 要在 Gradle 项目中使用 Android 测试支持库，请在 build.gradle 文件中添加这些依赖关系： 123456789dependencies &#123; androidTestCompile &apos;com.android.support.test:runner:0.4&apos; // Set this dependency to use JUnit 4 rules androidTestCompile &apos;com.android.support.test:rules:0.4&apos; // Set this dependency to build and run Espresso tests androidTestCompile &apos;com.android.support.test.espresso:espresso-core:2.2.1&apos; // Set this dependency to build and run UI Automator tests androidTestCompile &apos;com.android.support.test.uiautomator:uiautomator-v18:2.1.2&apos;&#125; 要将 AndroidJUnitRunner 设置为 Gradle 项目中的默认测试仪器运行器，请在 build.gradle 文件中指定此依赖关系： `` android { defaultConfig { testInstrumentationRunner “android.support.test.runner.AndroidJUnitRunner” } } ```]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android自动化测试之(N):adb工具]]></title>
    <url>%2F2017%2F08%2F29%2Fat-android-adb%2F</url>
    <content type="text"><![CDATA[Android手机自动化测试过程离不开adb工具,介绍几个常用的adb命令. 1. adb forward命令示例: 1adb forward tcp:8000 tcp:9000 作用: 把PC端8000端口的数据, 转发到Android端的9000端口上,PC端的8000端口会被 adb 监听, 这个时候我们只需要往8000端口写数据, 这个数据就会发送到手机端的9000端口上. 2. adb connect命令示例: 1adb connect + IP 作用: 通过无线网络在PC端adb连接手机端 注意: 要链接的IP ，必须和自己的PC的网络在同一个局域网内，adb 不能跨局域网链接设备 如果通过usb链接Android设备，通过adb devices 可以看见设备列表，但是使用不了，可以参考下面的命令说明手机端的服务未开启,需要连接usb开启手机服务,默认端口5555:adb tcpip 5555,开启后拔掉usb通过adb connect 192.168.0.101:5555即可连接]]></content>
      <categories>
        <category>autotest</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>autotest</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RecyclerView实现单选列表]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-recyclerview-selectable%2F</url>
    <content type="text"><![CDATA[常规方法： 在Javabean里增加一个boolean isSelected字段， 并在Adapter里根据这个字段的值设置“CheckBox”的选中状态。 在每次选中一个新优惠券时，改变数据源里的isSelected字段， 并notifyDataSetChanged()刷新整个列表。 这样实现起来很简单，代码量也很少，唯一不足的地方就是性能有损耗，不是最优雅。 So作为一个有追求 今天比较闲 的程序员，我决心分享一波优雅方案。 本文会列举分析一下在ListView和RecyclerView中, 列表实现单选的几种方案，并推荐采用定向刷新 部分绑定的方案，因为更高效and优雅 1常规方案:常规方案 请光速阅读，直接上码： Bean结构： 1234567public class TestBean extends SelectedBean &#123; private String name; public TestBean(String name,boolean isSelected) &#123; this.name = name; setSelected(isSelected); &#125;&#125; 我项目里有好多单选需求，懒得写isSelected字段，所以弄了个父类供子类继承。 123456789public class SelectedBean &#123; private boolean isSelected; public boolean isSelected() &#123; return isSelected; &#125; public void setSelected(boolean selected) &#123; isSelected = selected; &#125;&#125; Acitivity 和Adapter其他方法都是最普通的不再赘述。 Adapter的onBindViewHolder()如下： 1234567891011121314151617181920212223242526272829Log.d(&quot;TAG&quot;, &quot;onBindViewHolder() called with: holder = [&quot; + holder + &quot;], position = [&quot; + position + &quot;]&quot;); holder.ivSelect.setSelected(mDatas.get(position).isSelected());//“CheckBox” holder.tvCoupon.setText(mDatas.get(position).getName());//TextView holder.ivSelect.setOnClickListener(new View.OnClickListener() &#123; @Override public void onClick(View view) &#123; //实现单选，第一种方法，十分简单， Lv Rv通用,因为它们都有notifyDataSetChanged()方法 // 每次点击时，先将所有的selected设为false，并且将当前点击的item 设为true， 刷新整个视图 for (TestBean data : mDatas) &#123; data.setSelected(false); &#125; mDatas.get(position).setSelected(true); notifyDataSetChanged(); &#125; &#125;);ViewHolder： public static class CouponVH extends RecyclerView.ViewHolder &#123; private ImageView ivSelect; private TextView tvCoupon; public CouponVH(View itemView) &#123; super(itemView); ivSelect = (ImageView) itemView.findViewById(R.id.ivSelect); tvCoupon = (TextView) itemView.findViewById(R.id.tvCoupon); &#125; &#125; 方案优点：简单粗暴 方案缺点： 其实需要修改的Item只有两项： 一个当前处于选中状态的Item-&gt;普通状态 再将当前手指点击的这个Item-&gt;选中状态 但采用普通方案，则会刷新整个一屏可见的Item，重走他们的getView()/onBindViewHolder()方法。 其实一个屏幕一般最多可见10+个Item，遍历一遍也无伤大雅。 但咱们还是要有追求优雅的心，所以我们继续往下看。 2 利用Rv的notifyItemChanged()定向刷新:本方案可以中速阅读 本方案需要在Adapter里新增一个字段： 1private int mSelectedPos = -1;//实现单选 方法二，变量保存当前选中的position 在设置数据集时(构造函数，setData()方法等：)，初始化 mSelectedPos 的值。 123456//实现单选方法二： 设置数据集时，找到默认选中的posfor (int i = 0; i &lt; mDatas.size(); i++) &#123; if (mDatas.get(i).isSelected()) &#123; mSelectedPos = i; &#125;&#125; onClick里代码如下： 1234567891011//实现单选方法二： notifyItemChanged() 定向刷新两个视图//如果勾选的不是已经勾选状态的Itemif (mSelectedPos!=position)&#123; //先取消上个item的勾选状态 mDatas.get(mSelectedPos).setSelected(false); notifyItemChanged(mSelectedPos); //设置新Item的勾选状态 mSelectedPos = position; mDatas.get(mSelectedPos).setSelected(true); notifyItemChanged(mSelectedPos);&#125; 本方案由于调用了notifyItemChanged()，所以还会伴有“白光一闪”的动画。 方案优点： 本方案，较优雅了，不会重走一屏可见的Item的getView()/onBindViewHolder()方法， 但仍然会重走需要修改的两个Item的getView()/onBindViewHolder()方法， 方案缺点： 我们实际上需要修改的，只是里面“CheckBox”的值， 按照在DiffUtil一文学习到的姿势，术语应该是“Partial bind “， （安利时间,没听过DiffUtil和Partial bind的 戳-&gt;：【Android】详解7.0带来的新工具类：DiffUtil） 我们需要的只是部分绑定。 一个疑点： 使用方法2 在第一次选中其他Item时，切换selected状态时， 查看log，并不是只重走了新旧Item的onBindViewHolder()方法，还走了两个根本不在屏幕范围里的Item的onBindViewHolder()方法， 如，本例中 在还有item 0-3 在屏幕里，默认勾选item1，我选中item0后，log显示postion 4,5,0,1 依次执行了onBindViewHolder()方法。 但是再次切换其他Item时， 会符合预期：只走需要修改的两个Item的getView()/onBindViewHolder()方法。 原因未知，有朋友知道烦请告知，多谢。 3 Rv 实现部分绑定（推荐）:利用RecyclerView的 findViewHolderForLayoutPosition()方法，获取某个postion的ViewHolder，按照源码里这个方法的注释，它可能返回null。所以我们需要注意判空，（空即在屏幕不可见）。 与方法2只有onClick里的代码不一样，核心还是利用mSelectedPos 字段搞事情。 1234567891011121314//实现单选方法三： RecyclerView另一种定向刷新方法：不会有白光一闪动画 也不会重复onBindVIewHolderCouponVH couponVH = (CouponVH) mRv.findViewHolderForLayoutPosition(mSelectedPos);if (couponVH != null) &#123;//还在屏幕里 couponVH.ivSelect.setSelected(false);&#125;else &#123; //add by 2016 11 22 for 一些极端情况，holder被缓存在Recycler的cacheView里， //此时拿不到ViewHolder，但是也不会回调onBindViewHolder方法。所以add一个异常处理 notifyItemChanged(mSelectedPos);&#125;mDatas.get(mSelectedPos).setSelected(false);//不管在不在屏幕里 都需要改变数据//设置新Item的勾选状态mSelectedPos = position;mDatas.get(mSelectedPos).setSelected(true);holder.ivSelect.setSelected(true); 方案优点： 定向刷新两个Item，只修改必要的部分，不会重走onBindViewHolder()，属于手动部分绑定。代码量也适中，不多。 方案缺点： 没有白光一闪动画？？？（如果这算缺点） 4 Rv 利用payloads实现部分绑定(不推荐):本方案属于开拓思维，是在方案2的基础上，利用payloads和notifyItemChanged(int position, Object payload)搞事情。 不知道payloads是什么的，看不懂此方案的，我又要安利：（戳-&gt;：【Android】详解7.0带来的新工具类：DiffUtil） onClick代码如下： 123456789101112131415//实现单选方法四：if (mSelectedPos != position) &#123; //先取消上个item的勾选状态 mDatas.get(mSelectedPos).setSelected(false); //传递一个payload Bundle payloadOld = new Bundle(); payloadOld.putBoolean(&quot;KEY_BOOLEAN&quot;, false); notifyItemChanged(mSelectedPos, payloadOld); //设置新Item的勾选状态 mSelectedPos = position; mDatas.get(mSelectedPos).setSelected(true); Bundle payloadNew = new Bundle(); payloadNew.putBoolean(&quot;KEY_BOOLEAN&quot;, true); notifyItemChanged(mSelectedPos, payloadNew);&#125; 需要重写三参数的onBindViewHolder() 方法： 123456789101112@Overridepublic void onBindViewHolder(CouponVH holder, int position, List&lt;Object&gt; payloads) &#123; if (payloads.isEmpty()) &#123; onBindViewHolder(holder, position); &#125; else &#123; Bundle payload = (Bundle) payloads.get(0); if (payload.containsKey(&quot;KEY_BOOLEAN&quot;)) &#123; boolean aBoolean = payload.getBoolean(&quot;KEY_BOOLEAN&quot;); holder.ivSelect.setSelected(aBoolean); &#125; &#125;&#125; 方案优点： 同方法3 方案缺点： 代码量多，实现效果和方法三一样，仅做开拓思维用，所以选择方法三。 作者：张旭童 链接：http://www.jianshu.com/p/1ac13f74da63 來源：简书]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Activity任务和返回栈]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-activity-stack%2F</url>
    <content type="text"><![CDATA[问题:homeActivity为正常启动模式activity,另一个activity为singleTask Activity.从package installers启动homeaty,再启动另一个activity,桌面,再点击桌面图标进入应用,会重新打开homeaty,而不是另一个activity.但是如果是从桌面首次进入home再进入另一个activity,切换到到桌面回来是在正常的另一个activity.同事发现homeaty, 另一个aty,桌面重新回来的homeaty, taskid相同. 解决办法是使用application记录front activity. 实例化launcher activity 这个问题表现: 在package installers 安装界面安装完一个应用后，直接打开app，然后进入了 Activity_1, 此时再通过此activity用startActivity(intent)的方法打开 Activity_2. 然后按home键返回桌面，在桌面点击app图标进入，你觉得应该进入的是 Activity_2 ，实际上却是launcher Activity_1 . 然而还没完，这时候你按 back 返回键，会发现返回到了之前打开的 Activity_2，再按返回，又出现 launcherActivity_1. 也就是说系统重复实例化了Activity_1. 退出app后再次点击桌面图标进入，反复试验，没有再出现这个问题。也就是说，这个问题（bug ？）只出现在操作步骤（1）后才会产生. 以上问题我在一些知名厂商的app 上发现也存在这个BUG ： 百度云 陌陌 去哪儿旅行 …QQ没有出现这个问题 另外，如果以root方式静默安装的话不会出现这个问题，在eclipse里直接发布到模拟器上运行也没有出现这个问题 解决方案: 在super.onCreate(…)方法之后插入代码： 123456789if(!this.isTaskRoot()) &#123; //判断该Activity是不是任务空间的源Activity，“非”也就是说是被系统重新实例化出来 //如果你就放在launcher Activity中话，这里可以直接return了 Intent mainIntent=getIntent(); String action=mainIntent.getAction(); if(mainIntent.hasCategory(Intent.CATEGORY_LAUNCHER) &amp;&amp; action.equals(Intent.ACTION_MAIN)) &#123; finish(); return;//finish()之后该活动会继续执行后面的代码，你可以logCat验证，加return避免可能的exception &#125; &#125; 来源google ： https://code.google.com/p/android/issues/detail?id=14262 https://code.google.com/p/android/issues/detail?id=2373#c40 还有另一种方案： http://stackoverflow.com/questions/3042420/home-key-press-behaviour/4782423#4782423 以下引用自google官方文档 应用通常包含多个 Activity。每个 Activity 均应围绕用户可以执行的特定操作设计，并且能够启动其他 Activity。 例如，电子邮件应用可能有一个 Activity 显示新邮件的列表。用户选择某邮件时，会打开一个新 Activity 以查看该邮件。 一个 Activity 甚至可以启动设备上其他应用中存在的 Activity。例如，如果应用想要发送电子邮件，则可将 Intent 定义为执行“发送”操作并加入一些数据，如电子邮件地址和电子邮件。 然后，系统将打开其他应用中声明自己处理此类 Intent 的 Activity。在这种情况下，Intent 是要发送电子邮件，因此将启动电子邮件应用的“撰写”Activity（如果多个 Activity 支持相同 Intent，则系统会让用户选择要使用的 Activity）。发送电子邮件时，Activity 将恢复，看起来好像电子邮件 Activity 是您的应用的一部分。 即使这两个 Activity 可能来自不同的应用，但是 Android 仍会将 Activity 保留在相同的任务中，以维护这种无缝的用户体验。 任务是指在执行特定作业时与用户交互的一系列 Activity。 这些 Activity 按照各自的打开顺序排列在堆栈（即返回栈）中。 设备主屏幕是大多数任务的起点。当用户触摸应用启动器中的图标（或主屏幕上的快捷方式）时，该应用的任务将出现在前台。 如果应用不存在任务（应用最近未曾使用），则会创建一个新任务，并且该应用的“主”Activity 将作为堆栈中的根 Activity 打开。 当前 Activity 启动另一个 Activity 时，该新 Activity 会被推送到堆栈顶部，成为焦点所在。 前一个 Activity 仍保留在堆栈中，但是处于停止状态。Activity 停止时，系统会保持其用户界面的当前状态。 用户按“返回”按钮时，当前 Activity 会从堆栈顶部弹出（Activity 被销毁），而前一个 Activity 恢复执行（恢复其 UI 的前一状态）。 堆栈中的 Activity 永远不会重新排列，仅推入和弹出堆栈：由当前 Activity 启动时推入堆栈；用户使用“返回”按钮退出时弹出堆栈。 因此，返回栈以“后进先出”对象结构运行。 图 1 通过时间线显示 Activity 之间的进度以及每个时间点的当前返回栈，直观呈现了这种行为。 图 1. 显示任务中的每个新 Activity 如何向返回栈添加项目。 用户按“返回”按钮时，当前 Activity 随即被销毁，而前一个 Activity 恢复执行。 如果用户继续按“返回”，堆栈中的相应 Activity 就会弹出，以显示前一个 Activity，直到用户返回主屏幕为止（或者，返回任务开始时正在运行的任意 Activity）。 当所有 Activity 均从堆栈中移除后，任务即不复存在。 任务是一个有机整体，当用户开始新任务或通过“主页”按钮转到主屏幕时，可以移动到“后台”。 尽管在后台时，该任务中的所有 Activity 全部停止，但是任务的返回栈仍旧不变，也就是说，当另一个任务发生时，该任务仅仅失去焦点而已，如图 2 中所示。然后，任务可以返回到“前台”，用户就能够回到离开时的状态。 例如，假设当前任务（任务 A）的堆栈中有三个 Activity，即当前 Activity 下方还有两个 Activity。 用户先按“主页”按钮，然后从应用启动器启动新应用。 显示主屏幕时，任务 A 进入后台。新应用启动时，系统会使用自己的 Activity 堆栈为该应用启动一个任务（任务 B）。与该应用交互之后，用户再次返回主屏幕并选择最初启动任务 A 的应用。现在，任务 A 出现在前台，其堆栈中的所有三个 Activity 保持不变，而位于堆栈顶部的 Activity 则会恢复执行。 此时，用户还可以通过转到主屏幕并选择启动该任务的应用图标（或者，通过从概览屏幕选择该应用的任务）切换回任务 B。这是 Android 系统中的一个多任务示例。 图 2. 两个任务：任务 B 在前台接收用户交互，而任务 A 则在后台等待恢复。 注：后台可以同时运行多个任务。但是，如果用户同时运行多个后台任务，则系统可能会开始销毁后台 Activity，以回收内存资源，从而导致 Activity 状态丢失。请参阅下面有关 Activity 状态的部分。 由于返回栈中的 Activity 永远不会重新排列，因此如果应用允许用户从多个 Activity 中启动特定 Activity，则会创建该 Activity 的新实例并推入堆栈中（而不是将 Activity 的任一先前实例置于顶部）。 因此，应用中的一个 Activity 可能会多次实例化（即使 Activity 来自不同的任务），如图 3 所示。因此，如果用户使用“返回”按钮向后导航，则会按 Activity 每个实例的打开顺序显示这些实例（每个实例的 UI 状态各不相同）。 但是，如果您不希望 Activity 多次实例化，则可修改此行为。 具体操作方法将在后面的管理任务部分中讨论。 图 3. 一个 Activity 将多次实例化。 Activity 和任务的默认行为总结如下： 当 Activity A 启动 Activity B 时，Activity A 将会停止，但系统会保留其状态（例如，滚动位置和已输入表单中的文本）。如果用户在处于 Activity B 时按“返回”按钮，则 Activity A 将恢复其状态，继续执行。 用户通过按“主页”按钮离开任务时，当前 Activity 将停止且其任务会进入后台。 系统将保留任务中每个 Activity 的状态。如果用户稍后通过选择开始任务的启动器图标来恢复任务，则任务将出现在前台并恢复执行堆栈顶部的 Activity。 如果用户按“返回”按钮，则当前 Activity 会从堆栈弹出并被销毁。 堆栈中的前一个 Activity 恢复执行。销毁 Activity 时，系统不会保留该 Activity 的状态。 即使来自其他任务，Activity 也可以多次实例化。 保存 Activity 状态正如上文所述，当 Activity 停止时，系统的默认行为会保留其状态。 这样一来，当用户导航回到上一个 Activity 时，其用户界面与用户离开时一样。 但是，在 Activity 被销毁且必须重建时，您可以而且应当主动使用回调方法保留 Activity 的状态。 系统停止您的一个 Activity 时（例如，新 Activity 启动或任务转到前台），如果系统需要回收系统内存资源，则可能会完全销毁该 Activity。 发生这种情况时，有关该 Activity 状态的信息将会丢失。如果发生这种情况，系统仍会知道该 Activity 存在于返回栈中，但是当该 Activity 被置于堆栈顶部时，系统一定会重建 Activity（而不是恢复 Activity）。 为了避免用户的工作丢失，您应主动通过在 Activity 中实现 onSaveInstanceState() 回调方法来保留工作。 如需了解有关如何保存 Activity 状态的详细信息，请参阅 Activity 文档。 管理任务Android 管理任务和返回栈的方式（如上所述，即：将所有连续启动的 Activity 放入同一任务和“后进先出”堆栈中）非常适用于大多数应用，而您不必担心 Activity 如何与任务关联或者如何存在于返回栈中。 但是，您可能会决定要中断正常行为。 也许您希望应用中的 Activity 在启动时开始新任务（而不是放置在当前任务中）；或者，当启动 Activity 时，您希望将其现有实例上移一层（而不是在返回栈的顶部创建新实例）；或者，您希望在用户离开任务时，清除返回栈中除根 Activity 以外的所有其他 Activity。 通过使用 清单文件元素中的属性和传递给 startActivity() 的 Intent 中的标志，您可以执行所有这些操作以及其他操作。 在这一方面，您可以使用的主要 属性包括： taskAffinity launchMode allowTaskReparenting clearTaskOnLaunch alwaysRetainTaskState finishOnTaskLaunch 您可以使用的主要 Intent 标志包括： FLAG_ACTIVITY_NEW_TASK FLAG_ACTIVITY_CLEAR_TOP FLAG_ACTIVITY_SINGLE_TOP 在下文中，您将了解如何使用这些清单文件属性和 Intent 标志定义 Activity 与任务的关联方式，以及 Activity 在返回栈中的行为方式。 此外，我们还单独介绍了有关如何在概览屏幕中显示和管理任务与 Activity 的注意事项。 如需了解详细信息，请参阅概览屏幕。 通常，您应该允许系统定义任务和 Activity 在概览屏幕中的显示方法，并且无需修改此行为。 注意：大多数应用都不得中断 Activity 和任务的默认行为： 如果确定您的 Activity 必须修改默认行为，当使用“返回”按钮从其他 Activity 和任务导航回到该 Activity 时，请务必要谨慎并确保在启动期间测试该 Activity 的可用性。请确保测试导航行为是否有可能与用户的预期行为冲突。 定义启动模式启动模式允许您定义 Activity 的新实例如何与当前任务关联。 您可以通过两种方法定义不同的启动模式： 使用清单文件 在清单文件中声明 Activity 时，您可以指定 Activity 在启动时应该如何与任务关联。 使用 Intent 标志 调用 startActivity() 时，可以在 Intent 中加入一个标志，用于声明新 Activity 如何（或是否）与当前任务关联。 因此，如果 Activity A 启动 Activity B，则 Activity B 可以在其清单文件中定义它应该如何与当前任务关联（如果可能），并且 Activity A 还可以请求 Activity B 应该如何与当前任务关联。如果这两个 Activity 均定义 Activity B 应该如何与任务关联，则 Activity A 的请求（如 Intent 中所定义）优先级要高于 Activity B 的请求（如其清单文件中所定义）。 注：某些适用于清单文件的启动模式不可用作 Intent 标志，同样，某些可用作 Intent 标志的启动模式无法在清单文件中定义。 使用清单文件在清单文件中声明 Activity 时，您可以使用 元素的 launchMode 属性指定 Activity 应该如何与任务关联。 launchMode 属性指定有关应如何将 Activity 启动到任务中的指令。您可以分配给 launchMode 属性的启动模式共有四种： “standard”（默认模式） 默认。系统在启动 Activity 的任务中创建 Activity 的新实例并向其传送 Intent。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例。 “singleTop” 如果当前任务的顶部已存在 Activity 的一个实例，则系统会通过调用该实例的 onNewIntent() 方法向其传送 Intent，而不是创建 Activity 的新实例。Activity 可以多次实例化，而每个实例均可属于不同的任务，并且一个任务可以拥有多个实例（但前提是位于返回栈顶部的 Activity 并不是 Activity 的现有实例）。 例如，假设任务的返回栈包含根 Activity A 以及 Activity B、C 和位于顶部的 D（堆栈是 A-B-C-D；D 位于顶部）。收到针对 D 类 Activity 的 Intent。如果 D 具有默认的 “standard” 启动模式，则会启动该类的新实例，且堆栈会变成 A-B-C-D-D。但是，如果 D 的启动模式是 “singleTop”，则 D 的现有实例会通过 onNewIntent() 接收 Intent，因为它位于堆栈的顶部；而堆栈仍为 A-B-C-D。但是，如果收到针对 B 类 Activity 的 Intent，则会向堆栈添加 B 的新实例，即便其启动模式为 “singleTop” 也是如此。 注：为某个 Activity 创建新实例时，用户可以按“返回”按钮返回到前一个 Activity。 但是，当 Activity 的现有实例处理新 Intent 时，则在新 Intent 到达 onNewIntent() 之前，用户无法按“返回”按钮返回到 Activity 的状态。 “singleTask” 系统创建新任务并实例化位于新任务底部的 Activity。但是，如果该 Activity 的一个实例已存在于一个单独的任务中，则系统会通过调用现有实例的 onNewIntent() 方法向其传送 Intent，而不是创建新实例。一次只能存在 Activity 的一个实例。 注：尽管 Activity 在新任务中启动，但是用户按“返回”按钮仍会返回到前一个 Activity。 “singleInstance”. 与 “singleTask” 相同，只是系统不会将任何其他 Activity 启动到包含实例的任务中。该 Activity 始终是其任务唯一仅有的成员；由此 Activity 启动的任何 Activity 均在单独的任务中打开。 我们再来看另一示例，Android 浏览器应用声明网络浏览器 Activity 应始终在其自己的任务中打开（通过在 元素中指定 singleTask 启动模式）。这意味着，如果您的应用发出打开 Android 浏览器的 Intent，则其 Activity 与您的应用位于不同的任务中。相反，系统会为浏览器启动新任务，或者如果浏览器已有任务正在后台运行，则会将该任务上移一层以处理新 Intent。 无论 Activity 是在新任务中启动，还是在与启动 Activity 相同的任务中启动，用户按“返回”按钮始终会转到前一个 Activity。 但是，如果启动指定 singleTask 启动模式的 Activity，则当某后台任务中存在该 Activity 的实例时，整个任务都会转移到前台。此时，返回栈包括上移到堆栈顶部的任务中的所有 Activity。 图 4 显示了这种情况。 图 4. 显示如何将启动模式为“singleTask”的 Activity 添加到返回栈。 如果 Activity 已经是某个拥有自己的返回栈的后台任务的一部分，则整个返回栈也会上移到当前任务的顶部。 如需了解有关在清单文件中使用启动模式的详细信息，请参阅 元素文档，其中更详细地讨论了 launchMode 属性和可接受的值。 注：使用 launchMode 属性为 Activity 指定的行为可由 Intent 附带的 Activity 启动标志替代，下文将对此进行讨论。 使用 Intent 标志启动 Activity 时，您可以通过在传递给 startActivity() 的 Intent 中加入相应的标志，修改 Activity 与其任务的默认关联方式。可用于修改默认行为的标志包括： FLAG_ACTIVITY_NEW_TASK 在新任务中启动 Activity。如果已为正在启动的 Activity 运行任务，则该任务会转到前台并恢复其最后状态，同时 Activity 会在 onNewIntent() 中收到新 Intent。 正如前文所述，这会产生与 “singleTask”launchMode 值相同的行为。 FLAG_ACTIVITY_SINGLE_TOP 如果正在启动的 Activity 是当前 Activity（位于返回栈的顶部），则 现有实例会接收对 onNewIntent() 的调用，而不是创建 Activity 的新实例。 正如前文所述，这会产生与 “singleTop”launchMode 值相同的行为。 FLAG_ACTIVITY_CLEAR_TOP 如果正在启动的 Activity 已在当前任务中运行，则会销毁当前任务顶部的所有 Activity，并通过 onNewIntent() 将此 Intent 传递给 Activity 已恢复的实例（现在位于顶部），而不是启动该 Activity 的新实例。 产生这种行为的 launchMode 属性没有值。 FLAG_ACTIVITY_CLEAR_TOP 通常与 FLAG_ACTIVITY_NEW_TASK 结合使用。一起使用时，通过这些标志，可以找到其他任务中的现有 Activity，并将其放入可从中响应 Intent 的位置。 注：如果指定 Activity 的启动模式为 “standard”，则该 Activity 也会从堆栈中移除，并在其位置启动一个新实例，以便处理传入的 Intent。 这是因为当启动模式为 “standard” 时，将始终为新 Intent 创建新实例。 处理关联“关联”指示 Activity 优先属于哪个任务。默认情况下，同一应用中的所有 Activity 彼此关联。 因此，默认情况下，同一应用中的所有 Activity 优先位于相同任务中。 不过，您可以修改 Activity 的默认关联。 在不同应用中定义的 Activity 可以共享关联，或者可为在同一应用中定义的 Activity 分配不同的任务关联。 可以使用 元素的 taskAffinity 属性修改任何给定 Activity 的关联。 taskAffinity 属性取字符串值，该值必须不同于在 元素中声明的默认软件包名称，因为系统使用该名称标识应用的默认任务关联。 在两种情况下，关联会起作用： 启动 Activity 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志。 默认情况下，新 Activity 会启动到调用 startActivity() 的 Activity 任务中。它将推入与调用方相同的返回栈。 但是，如果传递给 startActivity() 的 Intent 包含 FLAG_ACTIVITY_NEW_TASK 标志，则系统会寻找其他任务来储存新 Activity。这通常是新任务，但未做强制要求。 如果现有任务与新 Activity 具有相同关联，则会将 Activity 启动到该任务中。 否则，将开始新任务。 如果此标志导致 Activity 开始新任务，且用户按“主页”按钮离开，则必须为用户提供导航回任务的方式。 有些实体（如通知管理器）始终在外部任务中启动 Activity，而从不作为其自身的一部分启动 Activity，因此它们始终将 FLAG_ACTIVITY_NEW_TASK 放入传递给 startActivity() 的 Intent 中。请注意，如果 Activity 能够由可以使用此标志的外部实体调用，则用户可以通过独立方式返回到启动的任务，例如，使用启动器图标（任务的根 Activity 具有 CATEGORY_LAUNCHER Intent 过滤器；请参阅下面的启动任务部分）。 Activity 将其 allowTaskReparenting 属性设置为 “true”。 在这种情况下，Activity 可以从其启动的任务移动到与其具有关联的任务（如果该任务出现在前台）。 提示：如果从用户的角度来看，一个 .apk 文件包含多个“应用”，则您可能需要使用 taskAffinity 属性将不同关联分配给与每个“应用”相关的 Activity。 清理返回栈如果用户长时间离开任务，则系统会清除所有 Activity 的任务，根 Activity 除外。 当用户再次返回到任务时，仅恢复根 Activity。系统这样做的原因是，经过很长一段时间后，用户可能已经放弃之前执行的操作，返回到任务是要开始执行新的操作。 您可以使用下列几个 Activity 属性修改此行为： alwaysRetainTaskState 如果在任务的根 Activity 中将此属性设置为 “true”，则不会发生刚才所述的默认行为。即使在很长一段时间后，任务仍将所有 Activity 保留在其堆栈中。 clearTaskOnLaunch 如果在任务的根 Activity 中将此属性设置为 “true”，则每当用户离开任务然后返回时，系统都会将堆栈清除到只剩下根 Activity。 换而言之，它与 alwaysRetainTaskState 正好相反。 即使只离开任务片刻时间，用户也始终会返回到任务的初始状态。 finishOnTaskLaunch 此属性类似于 clearTaskOnLaunch，但它对单个 Activity 起作用，而非整个任务。 此外，它还有可能会导致任何 Activity 停止，包括根 Activity。 设置为 “true” 时，Activity 仍是任务的一部分，但是仅限于当前会话。如果用户离开然后返回任务，则任务将不复存在。启动任务通过为 Activity 提供一个以 “android.intent.action.MAIN” 为指定操作、以 “android.intent.category.LAUNCHER” 为指定类别的 Intent 过滤器，您可以将 Activity 设置为任务的入口点。 例如：1234567&lt;activity ... &gt; &lt;intent-filter ... &gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot; /&gt; &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot; /&gt; &lt;/intent-filter&gt; ...&lt;/activity&gt; 此类 Intent 过滤器会使 Activity 的图标和标签显示在应用启动器中，让用户能够启动 Activity 并在启动之后随时返回到创建的任务中。 第二个功能非常重要：用户必须能够在离开任务后，再使用此 Activity 启动器返回该任务。 因此，只有在 Activity 具有 ACTION_MAIN 和 CATEGORY_LAUNCHER 过滤器时，才应该使用将 Activity 标记为“始终启动任务”的两种启动模式，即 “singleTask” 和 “singleInstance”。例如，我们可以想像一下如果缺少过滤器会发生什么情况： Intent 启动一个 “singleTask” Activity，从而启动一个新任务，并且用户花了些时间处理该任务。然后，用户按“主页”按钮。 任务现已发送到后台，而且不可见。现在，用户无法返回到任务，因为该任务未显示在应用启动器中。 如果您并不想用户能够返回到 Activity，对于这些情况，请将 元素的 finishOnTaskLaunch 设置为 “true”（请参阅清理堆栈）。 有关如何在概览屏幕中显示和管理任务与 Activity 的更多信息，请参阅概览屏幕。]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[home后从service重新启动activity延迟问题]]></title>
    <url>%2F2017%2F08%2F24%2Ftips-starting-an-activity-from-a-service-after-home-button%2F</url>
    <content type="text"><![CDATA[问题: 在Activity界面，按下HOME键后，点击悬浮层按钮，再启动Activity， Activity要延时5S后才出来。 经验证，这个问题不是应用自身的BUG。那怕该Activity是空的，也会有这个问题 Android为了避免应用在按下HOME键退出后还可以强制把自己启动，特意加的限制。 在现有的API情况下，不能解决这个问题，除非你的应用是一个启动器（Launcher）， 添加了home/ launcher intent filter。如果你不是启动器，又要从悬浮层启动一个Activity，就把该Activity也改成悬浮层吧 1. 不从后台启动 Activity 准则：在谷歌的 Android API Guides 中，特意提醒开发者不要在后台启动 activity，包括在 Service 和 BroadcastReceiver 中，这样的设计是为了避免在用户毫不知情的情况下突然中断用户正在进行的工作，在 http://developer.android.com/guide/practices/seamlessness.html#interrupt 中有如下解释： That is, don’t call startActivity() from BroadcastReceivers or Services running in the background. Doing so will interrupt whatever application is currently running, and result in an annoyed user. Perhaps even worse, your Activity may become a “keystroke bandit” and receive some of the input the user was in the middle of providing to the previous Activity. Depending on what your application does, this could be bad news. 2. 需要违反“不从后台启动 Activity”准则的特例：特例：即便如此，手机厂商的开发者们在开发基于系统级的应用的时候，可能仍然需要有从 Service 或 BroadcastReceiver 中 startActivity 的需求，往往这样的前提是连这样的 Service 或 BroadcastReceiver 也是由用户的某些操作而触发的，Service 或 BroadcastReceiver 只是充当了即将启动 activity 之前的一些代理参数检查工作以便决定是否需要 start 该 activity。 除非是上述笔者所述的特殊情况，应用开发者都应该遵循 “不要从后台启动 Activity”准则。 一个需要特别注意的问题是，特例中所述的情况还会遇到一个问题，就是当通过 home 键将当前 activity 置于后台时，任何在后台startActivity 的操作都将会延迟 5 秒，除非该应用获取了 “android.permission.STOP_APP_SWITCHES” 权限。 关于延迟 5 秒的操作在 com.android.server.am.ActivityManagerService 中的 stopAppSwitches() 方法中，系统级的应用当获取了 “android.permission.STOP_APP_SWITCHES” 后将不会调用到这个方法来延迟通过后台启动 activity 的操作，事实上 android 原生的 Phone 应用就是这样的情况，它是一个获取了”android.permission.STOP_APP_SWITCHES” 权限的系统级应用，当有来电时，一个从后台启动的 activity 将突然出现在用户的面前，警醒用户有新的来电，这样的设计是合理的。 所以，当你需要开发类似 Phone 这样的应用时，需要做如下工作： root 你的手机； 在 AndroidManifest.xml 中添加 “android.permission.STOP_APP_SWITCHES” 用户权限； 将你开发的应用程序 push 到手机的 /system/app 目录中。 3. 参考资料：无缝的设计之——不要中断你的用户 stackoverflow 中关于后台 startActivity 被延迟 5 秒的探讨]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下C开发使用小技巧]]></title>
    <url>%2F2017%2F08%2F06%2Ftips-c-language%2F</url>
    <content type="text"><![CDATA[基础类整形,字符串互转C语言提供了几个标准库函数，可以将任意类型(整型、长整型、浮点型等)的数字转换为字符串，下面列举了各函数的方法及其说明。 ● itoa()：将整型值转换为字符串。 ● ltoa()：将长整型值转换为字符串。 ● ultoa()：将无符号长整型值转换为字符串。 ● gcvt()：将浮点型数转换为字符串，取四舍五入。 ● ecvt()：将双精度浮点型值转换为字符串，转换结果中不包含十进制小数点。 ● fcvt()：指定位数为转换精度，其余同ecvt()。 除此外，还可以使用sprintf系列函数把数字转换成字符串，其比itoa()系列函数运行速度慢 以下是用itoa()函数将整数转换为字符串的一个例子： 12345678910# include &lt;stdio.h&gt;# include &lt;stdlib.h&gt;void main (void)&#123;int num = 100;char str[25];itoa(num, str, 10);printf(&quot;The number &apos;num&apos; is %d and the string &apos;str&apos; is %s. \n&quot; ,num, str);&#125; itoa()函数有3个参数：第一个参数是要转换的数字，第二个参数是要写入转换结果的目标字符串，第三个参数是转移数字时所用 的基数。在上例中，转换基数为10。10：十进制；2：二进制… itoa并不是一个标准的C函数，它是Windows特有的，如果要写跨平台的程序，请用sprintf。是Windows平台下扩展的，标准库中有sprintf，功能比这个更强，用法跟printf类似： 12char str[255];sprintf(str, &quot;%x&quot;, 100); //将100转为16进制表示的字符串。 cpp中string转int: 1234void str2int(int &amp;int_temp,const string &amp;string_temp) &#123; int_temp=atoi(string_temp.c_str()); &#125; cpp中int转string: 123456void int2str(const int &amp;int_temp,string &amp;string_temp) &#123; char s[12]; //设定12位对于存储32位int值足够 itoa(int_temp,s,10); //itoa函数亦可以实现，但是属于C中函数，在C++中推荐用流的方法 string_temp=s; &#125; 架构类Linux C代码实现主函数参数选项解析1. 手动解析版本使用argc、argv，逐个字符比较，得到要想的参数名字即进行判断、解析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;ctype.h&gt;int debug;void show_version(char* name)&#123; printf(&quot;%s by Late Lee, version: 1.0\n&quot;, name);&#125;void usage(char* name)&#123; show_version(name); printf(&quot; -h, --help short help\n&quot;); printf(&quot; -v, --version show version\n&quot;);&#125;int main(int argc, char *argv[])&#123; int i = 0; /* early check for debug and config parameter */ if (argc &gt; 1) &#123; for (i = 1; i &lt; argc; i++) &#123; if ((strcmp(argv[i], &quot;-D&quot;)==0) || (strcmp(argv[i], &quot;--debug&quot;)==0)) &#123; debug = 1; &#125; &#125; &#125; // /* parse parameters, maybe not the best way but... */ for (i = 1; i &lt; argc; i++) &#123; if (debug) printf(&quot;arg %d: \&quot;%s\&quot;\n&quot;,i,argv[i]); // help if ((strcmp(argv[i],&quot;-h&quot;)==0) || (strcmp(argv[i],&quot;--help&quot;)==0)) &#123; usage(argv[0]); return 0; &#125; // version else if ((strcmp(argv[i],&quot;-v&quot;)==0) || (strcmp(argv[i],&quot;--version&quot;)==0)) &#123; show_version(argv[0]); return 0; &#125; // debug else if ((strcmp(argv[i],&quot;-D&quot;)==0) || (strcmp(argv[i],&quot;--debug&quot;)==0)) &#123; debug=1; &#125; else if ((strcmp(argv[i],&quot;fpga&quot;)==0)) &#123; printf(&quot;test of fpga...\n&quot;); &#125; // string else if ((strcmp(argv[i],&quot;-i&quot;)==0) || (strcmp(argv[i],&quot;--iface&quot;)==0)) &#123; if (i+1&lt;argc) &#123; char interface[32] = &#123;0&#125;; strncpy(interface, argv[i+1], 32); if (debug) printf(&quot;Used interface: %s\n&quot;, interface); i++; continue; &#125; else &#123; printf(&quot;Error: Interface for -i missing.\n&quot;); return 1; &#125; &#125; // number else if ((strcmp(argv[i],&quot;-ru&quot;)==0) || (strcmp(argv[i],&quot;--rateunit&quot;))==0) &#123; if (i+1&lt;argc &amp;&amp; isdigit(argv[i+1][0])) &#123; int rateunit = 0; rateunit = atoi(argv[i+1]); if (rateunit &lt; 0 || rateunit &gt; 1) &#123; printf(&quot;Error: Invalid parameter \&quot;%d\&quot; for --rateunit.\n&quot;, rateunit); printf(&quot; Valid parameters:\n&quot;); printf(&quot; 0 - bytes\n&quot;); printf(&quot; 1 - bits\n&quot;); return 1; &#125; if (debug) printf(&quot;Rateunit changed: %d\n&quot;, rateunit); i++; continue; &#125; else &#123; &#125; &#125; // only one else if (strcmp(argv[i],&quot;--enable&quot;)==0) &#123; int enable = 0; enable = 1; &#125; else &#123; printf(&quot;Unknown parameter \&quot;%s\&quot;. Use --help for help.\n&quot;,argv[i]); return 1; &#125; &#125;&#125; 2. 利用getopt函数完成123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140/**解析命令选项示例#include &lt;unistd.h&gt;extern char *optarg; //选项的参数指针extern int optind, //下一次调用getopt的时，从optind存储的位置处重新开始检查选项。extern int opterr, //当opterr=0时，getopt不向stderr输出错误信息。extern int optopt; //当命令行选项字符不包括在optstring中或者选项缺少必要的参数时，该选项存储在optopt中，getopt返回&apos;？’、int getopt(int argc, char * const argv[], const char *optstring);使用：$ ./a.out -Wall -o hello.c*/#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdarg.h&gt;int debug_level = 0;#define _AUTHOR &quot;Late Lee&quot;#define _VERSION_STR &quot;1.0&quot;#define _DATE &quot;&quot;// 默认打印error等级enum&#123; MSG_ERROR = 0, MSG_WARNING, MSG_INFO, MSG_DEBUG, MSG_MSGDUMP, MSG_EXCESSIVE,&#125;;void ll_printf(int level, const char *fmt, ...) __attribute__ ((format (printf, 2, 3)));void ll_printf(int level, const char *fmt, ...)&#123; va_list ap; va_start(ap, fmt); if (debug_level &gt;= level) &#123;#ifdef CONFIG_DEBUG_SYSLOG if (wpa_debug_syslog) &#123; vsyslog(syslog_priority(level), fmt, ap); &#125; else &#123;#endif /* CONFIG_DEBUG_SYSLOG */ //debug_print_timestamp();#ifdef CONFIG_DEBUG_FILE if (out_file) &#123; vfprintf(out_file, fmt, ap); fprintf(out_file, &quot;\n&quot;); &#125; else &#123;#endif /* CONFIG_DEBUG_FILE */ vprintf(fmt, ap); printf(&quot;\n&quot;);#ifdef CONFIG_DEBUG_FILE &#125;#endif /* CONFIG_DEBUG_FILE */#ifdef CONFIG_DEBUG_SYSLOG &#125;#endif /* CONFIG_DEBUG_SYSLOG */ &#125; va_end(ap);&#125;void show_version(char* name)&#123; printf(&quot;%s by %s, version: %s\n&quot;, name, _AUTHOR, _VERSION_STR);&#125;void usage(char* name)&#123; show_version(name); printf(&quot; -h, short help\n&quot;); printf(&quot; -v, show version\n&quot;); printf(&quot; -d, debug level\n&quot;); exit(0);&#125;const char* my_opt = &quot;hOo:W:d:&quot;;int main(int argc, char *argv[])&#123; int c; const char* p1 = NULL; const char* p2 = NULL; const char* p3 = NULL; while(1) &#123; c = getopt(argc, argv, my_opt); printf(&quot;optind: %d\n&quot;, optind); if (c &lt; 0) &#123; break; &#125; printf(&quot;option char: %x %c\n&quot;, c, c); switch(c) &#123; case &apos;d&apos;: debug_level = atoi(optarg); printf(&quot;debug level: %d\n&quot;, debug_level); break; case &apos;O&apos;: printf(&quot;optimization flag is open.\n\n&quot;); break; case &apos;o&apos;: printf(&quot;the obj is: %s\n\n&quot;, optarg); p1 = optarg; break; case &apos;W&apos;: printf(&quot;optarg: %s\n\n&quot;, optarg); p2 = optarg; break; case &apos;:&apos;: fprintf(stderr, &quot;miss option char in optstring.\n&quot;); break; case &apos;?&apos;: case &apos;h&apos;: default: usage(argv[0]); break; //return 0; &#125; &#125; if (optind == 1) &#123; usage(argv[0]); &#125; ll_printf(MSG_ERROR, &quot;p1: %s p2: %s\n&quot;, p1, p2); return 0;&#125; 使用 getopt() 进行命令行处理 网络模块 日志模块读取配置文件模块内存池模块缓存库模块文件系统模块管理后台模块数据库模块技巧类Linux程序中预定义的几个调试宏Linux下C语言编程中有几个很实用的调试宏 1__LINE__ __FILE__ __FUNCTION__ __TIME__ __DATA__ 这几个预定义宏是属于ANSI标准的，内置于编译器，全局性的变量，可以方便地实现代码跟踪调试，不是在哪个头文件中包含的，见下例： 1234567891011#include &lt;stdio.h&gt;int main()&#123; printf(&quot;The file is %s.\n&quot;,__FILE__); printf( &quot;The date is %s.\n&quot;, __DATE__ ); printf( &quot;The time is %s.\n&quot;, __TIME__ ); printf( &quot;This is line %d.\n&quot;, __LINE__ ); printf( &quot;This function is %s.\n&quot;, __FUNCTION__ ); return 0;&#125; 运行结果: 12345The file is macro.c.The date is Aug 24 2012.The time is 23:13:26.This is line 8.This function is main. line 行数 文件名指令可以改变它的值，简单的讲，编译时，它们包含程序的当前行数和文件名。 DATE 宏指令含有形式为月/日/年的串,表示源文件被翻译到代码时的日期。 TIME 宏指令包含程序编译的时间。时间用字符串表示，其形式为时：分：秒 __func__代表这条语句所在的函数的函数名 联合体用途字节序有两种表示方法：大端法（big ending），小端法（little ending）。网络字节序采用的是大端法。主机字节序不同的CPU采用的方法不一样，可以通过代码来查看自己主机的字节序。 大端法：高位字节排放在内存低地址端，低位字节排放在内存的高地址端。 小端法：低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 看一个unsigned short 数据，它占2个字节，给它赋值0x1234。 若采用的大端法，则其低地址端应该存放的是0x12； 若采用的小端法，则其低地址端应该存放的是0x34； 可以通过联合体来获得其高低地址的数据。测试主机字节序的代码：123456789101112131415161718192021typedef union&#123; unsigned short value; unsigned char bytes[2];&#125;Test;int main(void)&#123; Test test_value; test_value.value = 0x1234; if(test_value.bytes[0] == 0x12 &amp;&amp; test_value.bytes[1] == 0x34) &#123; printf(&quot;big ending&quot;); &#125; else if(test_value.bytes[0] == 0x34 &amp;&amp; test_value.bytes[1] == 0x12) &#123; printf(&quot;little ending&quot;); &#125;else&#123; printf(&quot;use test_value error&quot;); &#125; return 0;&#125; 工具类自定义日志的调试打印信息12345678910111213141516171819202122232425#define TRACE_NONE 0#define TRACE_FATAL 1#define TRACE_ERROR 2#define TRACE_WARNING 3#define TRACE_INFO 4#define TRACE_DEBUG 5#define TRACE_LEN_MAX 64extern int *TraceLevel;extern char TraceName[TRACE_LEN_MAX + 1];#define Log(A, format,args...) \ ((TraceLevel == NULL || TraceName == NULL || *TraceLevel &lt; (A)) ? 0 : LogMsg(A, __FILE__, __LINE__, format, ##args))#define LogFatal(format,args...) \ Log(TRACE_FATAL, format, ##args)#define LogError(format,args...) \ Log(TRACE_ERROR, format, ##args)#define LogWarning(format,args...) \ Log(TRACE_WARNING, format, ##args)#define LogInfo(format,args...) \ Log(TRACE_INFO, format, ##args)#define LogDebug(format,args...) \ Log(TRACE_DEBUG, format, ##args) 12345678910111213141516171819202122232425262728293031int LogMsg(int level, const char *filename, int line, const char *fmt, ...)&#123; va_list ap; FILE *fp; char sLogFile[128 + 1]; char sCurrTime[6 + 1]; struct timeb tTimeB; char sMilliTM[4]; memset(sLogFile, 0, sizeof(sLogFile)); LogFile(sLogFile); GetTime_HHMMSS(sCurrTime); memset(&amp;tTimeB, 0, sizeof(tTimeB)); ftime(&amp;tTimeB); snprintf(sMilliTM, sizeof(sMilliTM), &quot;%03d&quot;, tTimeB.millitm); fp = fopen(sLogFile, &quot;a+&quot;); if (fp != (FILE*)NULL) &#123; fprintf(fp, &quot;[%08d][%.6s:%.3s][%16s][%04d][%7s]&quot;, getpid(), sCurrTime, sMilliTM, filename, line, g_LevelDsp[level]); va_start(ap, fmt); vfprintf(fp, fmt, ap); va_end(ap); fprintf(fp, &quot;\n&quot;); fflush(fp); fclose(fp); &#125; return 0;&#125; 再在后台进程中设置TraceLevel和TraceName即可。 获取当前系统日期、时间12345678910111213141516171819202122232425/***************************************************************************** ** 函数名称: GetDate ** 功能描述: 取当前系统日期 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psDate -- 系统日期, 格式为yyyymmdd ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetDate(char * psDate)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统日期, 格式：YYYYMMDD */ sprintf( psDate,&quot;%04d%02d%02d&quot;, pTM-&gt;tm_year + 1900, pTM-&gt;tm_mon + 1,pTM-&gt;tm_mday ); return 0;&#125; 12345678910111213141516171819202122232425/***************************************************************************** ** 函数名称: GetTime ** 功能描述: 取当前系统时间 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psTime -- 系统时间, 格式为HHMMSS ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetTime(char * psTime)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统时间, 格式：HHMMSS */ sprintf( psTime,&quot;%02d%02d%02d&quot;, pTM-&gt;tm_hour,pTM-&gt;tm_min, pTM-&gt;tm_sec); return 0;&#125; 1234567891011121314151617181920212223242526/***************************************************************************** ** 函数名称: GetDateTime ** 功能描述: 取当前系统日期和时间 ** 当前版本: 1.0.0.0 ** 作 者: ** 修 改： ** 输入参数: ** 输出参数: char * psDateTime -- 系统日期时间, 格式为yyyymmddHHMMSS ** 返回结果：int 0 ---&gt; 成功 ****************************************************************************/int GetDateTime(char * psDateTime)&#123; time_t nSeconds; struct tm * pTM; time(&amp;nSeconds); pTM = localtime(&amp;nSeconds); /* 系统日期和时间, 格式：yyyymmddHHMMSS */ sprintf( psDateTime,&quot;%04d%02d%02d%02d%02d%02d&quot;, pTM-&gt;tm_year + 1900, pTM-&gt;tm_mon + 1,pTM-&gt;tm_mday, pTM-&gt;tm_hour,pTM-&gt;tm_min, pTM-&gt;tm_sec ); return 0;&#125; 调用的时候定义一个char数组，大小为日期的长度大小加1，然后直接调用上面的函数，参数为数组名即可。 当然，还有其他许多关于日期、时间操作的函数，比如不同日期、时间格式间的转换等。]]></content>
      <categories>
        <category>language</category>
      </categories>
      <tags>
        <tag>language</tag>
        <tag>C</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FQA]]></title>
    <url>%2F2017%2F07%2F25%2FFQA%2F</url>
    <content type="text"><![CDATA[ssh连接服务器出错12345678910111213@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the RSA key sent by the remote host isda:f7:3e:ba:f7:00:e6:44:76:f2:58:6e:48:**.Please contact your system administrator.Add correct host key in /用户home目录/.ssh/known_hosts to get rid of this message.Offending RSA key in /用户home目录/.ssh/known_hosts:1RSA host key for ip地址 has changed and you have requested strict checking.Host key verification failed. 出现这个问题的原因是,第一次使用SSH连接时，会生成一个认证，储存在客户端的known_hosts中. 可使用以下指令查看: 1ssh-keygen -l -f ~/.ssh/known_hosts 由于服务器重新安装系统了，所以会出现以上错误。 解决办法: 1ssh-keygen -R 服务器端的ip地址 或者直接在known_hosts中删除对应ip的行]]></content>
  </entry>
  <entry>
    <title><![CDATA[Webrtc线程模型]]></title>
    <url>%2F2017%2F07%2F23%2Fwebrtc-source-thread%2F</url>
    <content type="text"><![CDATA[webrtc的base的 thread，是我见过的封装最帅的c++线程库，根据比qt的还好用,发个例子给你 1234567891011121314151617181920212223242526 using namespace webrtc;using namespace rtc;//std::cout&lt;&lt;&quot;Thread::Current()：&quot; &lt;&lt; Thread::Current()-&gt;GetId();//Thread::Current()-&gt;Start(); 不能调用start，因为不是我创建的，他已经开始了 //Thread::Current()-&gt;Run(); //阻塞当前线程进入线程循环Thread * thread = new Thread();//MyRunnable run;//thread-&gt;Start(&amp;run);//可以带一个Runnable参数运行,运行完就结束，否则运行Thread::Run进入消息循环thread-&gt;Start();//std::cout &lt;&lt; &quot;Thread::Invoke()：&quot;&lt;&lt; thread-&gt;Invoke&lt;bool&gt;(RTC_FROM_HERE, &amp;task)&lt;&lt; &quot; at &quot; &lt;&lt; Thread::Current()-&gt;GetId() &lt;&lt; std::endl;thread-&gt;Post(RTC_FROM_HERE, Bind(task2));//将最常用的auto handler= new MessageClient;//thread-&gt;PostAt(RTC_FROM_HERE, (int64_t)3000,handler);//thread-&gt;PostDelayed(RTC_FROM_HERE, (int64_t)5000, handler);//thread-&gt;Stop();Thread * thread2 = new Thread();thread2-&gt;Start();thread2-&gt;Post(RTC_FROM_HERE, Bind(task2));//将最常用的//thread2-&gt;Invoke() 非常有用，在任何地方可以指定我的代码运行在某个线程//api下的proxy机制，实际上就是设置要执行的线程，然后加锁等待线程执行结果。这是我设计对外接口可以在任何线程调用而不出错的常用方法//base的asyncinvoker与proxy类似的机制。 有ios的gdc，android的handler异曲同工 因为编写复杂稳定的多线程C++项目实在太难，所以一个好的跨平台C++基础库是我最求的目标,目前比较欣赏的项目有： Boost:大而全，缺少一些可以直接上手的东西如线程消息队列，智能指针并非线程安全。 QT core：非常好 C++11：也需要线程消息队列，线程安全智能指针。 chromium的base库：太大了 当我看到webrtc的base时，非常惊讶的发现它正是我想要的,特点： 小：只有几M 纯：基于c++标准库和各操作系统sdk 跨平台 对智能指针、线程、socket封装非常好。 不断更新（需要一直跟踪官方代码） 移植出来单独使用，方案有三： 把源码拷贝出来用通用的编译工具（makefile，cmake，qmake）管理。（makefile较复杂，cmake简单，qmake最简单） 把源码拷贝出来用基于自带的gn管理 在webrtc项目里面编译和合并需要的静态库和pdb 因为google官方说了：引用计数+引用计数的智能化（scoped_ref_ptr）+弱引用就可以解决问题。 shared_ptr不是线程安全的，因为shared_ptr有两个成员：引用计数，和源对象指针。没办法对两个成员同时实现原子操作。 但unique_ptr是个好东西 智能指针的使用： 不用再使用delete。 尽量使用unique_ptr。 多个线程读写同一个 shared_ptr 对象，那么需要加锁。 shared_ptr 和weak_ptr配合解决循环引用的问题。 weak_ptr必须，oc，swift的ViewControler和控件都是weak关系 内存管理模型的三种级别： 1 手动内存管理(c/c++的malloc与free，new与delete)：容易出错。 2 自动内存管理（oc的arc，c++的智能指针，scoped_ptr）：存在循环引用问题，通过程序员自己管理强弱引用关系解决。 3 垃圾回收机制（如java,python）：后台GC降低了程序效率，好的程序员仍然好考虑java的强引用[表情]引用/软引用/ 3 线程模型 1 生产者消费模型（mutex，condition）：最最常用的模型。 2 线程池模型：解决大量请求分配太多线程的问题。比如一个android和ios的app，http请求会很多很多。 3 (着重强调）串行模型：ios有GCD(Grand Central Dispatch，global queue是线程池），android有looper， win32有PostMessage，boost有strand 读写锁：特别只有写才会不安全的情况。 再结合其他的手段会让程序简洁优美易读：java的handler，oc的delegate和block、swift的闭包，mvc模式 ，c++的function/bind/lambda，python和javascript的function 而串行模型就成了解决这类多线程问题的首选，就是线程消息模型。 在android 系统里面，无数这样的例子。 模块处理线程Call构造方法中创建module_process_thread与pacer_thread两个ProcessThread.接着为module_process_thread注册CallStats, ReceiveSideCongestionController, SendSideCongestionController模块,为pacer_thread注册PacedSender, RemoteBitrateEstimator模块. Call::CreateVideoSendStream创建VideoSendStream时,将module_process_thread做构造参数传入,调用RegisterProcessThread方法,注册所有的rtc_rtcp模块到module_process_thread线程.同样的为VideoReceiveStream中设置.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidStudio常见问题]]></title>
    <url>%2F2017%2F07%2F23%2Ftips-androidstudio%2F</url>
    <content type="text"><![CDATA[如何解决Unsupported major.minor version 52.0问题？ http://www.jianshu.com/p/5eebd3c609d6 运行./gradlew :PandaAndroidDemo:release出现如下错误： 12345678910111213FAILURE: Build failed with an exception.* Where:Build file &apos;/Users/shitianci/work/Lab/panda.android/PandaAndroidDemo/build.gradle&apos; line: 1* What went wrong:A problem occurred evaluating project &apos;:PandaAndroidDemo&apos;.&gt; java.lang.UnsupportedClassVersionError: com/android/build/gradle/AppPlugin : Unsupported major.minor version 52.0* Try:Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.BUILD FAILED 直接点击 run按钮 或者 Build→Generate Build APK 却运行正常。 这里面有两个问题： 为什么出现Unsupported major.minor version 52.0？ 为什么gradle命令和android studio按钮运行结果不一样？ 问题一：为什么出现Unsupported major.minor version 52.0？在网上找了一圈，最后在stackoverflow找到了本质原因 12345You get this error because a Java 7 VM tries to load a class compiled for Java 8Java 8 has the class file version 52.0 but a Java 7 VM can only load class files up to version 51.0In your case the Java 7 VM is your gradle build and the class is com.android.build.gradle.AppPlugin 简单来说，就是java的编译环境版本太低，java 8 class file的版本是52，Java 7虚拟机只能支持到51。所以需要升级到java 8 vm才行。 问题二：为什么gradle命令和android studio按钮运行结果不一样？从问题1来看，肯定Android Studio按钮调用的是java 8 vm，所以查找一下系统配置，最终在Project Structure找到了如下设置： Android Studio 2.2.2使用了自带的JDK环境，其地址为 1/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home 而gradle命令的执行环境是在gradle.properties配置的，其指向为： 1org.gradle.java.home=/Library/Java/JavaVirtualMachines/jdk1.7.0_71.jdk/Contents/home 将其修改为： 1org.gradle.java.home=/Applications/Android Studio.app/Contents/jre/jdk/Contents/Home INSTALL_PARSE_FAILED_NO_CERTIFICATES安装问题Android studio 更新到25后打包问题，打包后的应用安装提示：INSTALL_PARSE_FAILED_NO_CERTIFICATES Android N 引入一项新的应用签名方案 APK Signature Scheme v2，它能提供更快的应用安装时间和更多针对未授权 APK 文件更改的保护。 在默认情况下，Android Studio 2.2 和 Android Gradle 2.2 插件会使用 APK Signature Scheme v2 和传统签名方案来签署您的应用。 脏的解决方式：使用v1打包 INSTALL FAILED CONFLICTING PROVIDER问题完美解决方案在安装Android应用时出现INSTALL FAILED CONFLICTING PROVIDER问题，是不是感觉很抓狂呢，下面就跟大家分享一下出现这个问题的原因及解决方案。 问题原因: 在Android中authority要求必须是唯一的，比如你在定义一个provider时需要为它指定一个唯一的authority。如果你在安装一个带有provider的应用时，系统会检查当前已安装应用的authority是否和你要安装应用的authority相同，如果相同则会弹出上述警告，并且安装失败。 解决方案 在定义provider是，使用软编码的形式，如下： 123456789&lt;provider android:name=&quot;android.support.v4.content.FileProvider&quot; android:authorities=&quot;$&#123;applicationId&#125;.fileprovider&quot; android:grantUriPermissions=&quot;true&quot; android:exported=&quot;false&quot;&gt; &lt;meta-data android:name=&quot;android.support.FILE_PROVIDER_PATHS&quot; android:resource=&quot;@xml/file_paths&quot; /&gt;&lt;/provider&gt; 上述代码中通过${applicationId}.fileprovider的形式来指定provider的authorities，所以该provider的authorities会根据applicationId的不同而不同，从而避免了authorities的冲突问题。 那么如何使用刚才定义的authorities呢？ 我们在定义authorities是采用了applicationId+fileprovider的形式，在获取authorities的时候，我们就可以通过包名+fileprovider来获取，代码如下: 123public final static String getFileProviderName(Context context)&#123; return context.getPackageName()+&quot;.fileprovider&quot;;&#125;]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>AndroidStudio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RFC3550 RTP中文版]]></title>
    <url>%2F2017%2F07%2F22%2Fp-rfc-3550-zh%2F</url>
    <content type="text"><![CDATA[RFC3550 RTP：实时应用程序传输协议 摘要 本文描述RTP（real-time transport protocol），实时传输协议。RTP在多点传送（多播）或单点传送（单播）的网络服务上，提供端对端的网络传输功能，适合应用程序传输实时数据，如：音频，视频或者仿真数据。RTP没有为实时服务提供资源预留的功能，也不能保证QoS（服务质量）。数据传输功能由一个控制协议（RTCP）来扩展，通过扩展，可以用一种方式对数据传输进行监测控制，该协议（RTCP）可以升级到大型的多点传送（多播）网络，并提供最小限度的控制和鉴别功能。RTP和RTCP被设计成和下面的传输层和网络层无关。协议支持RTP标准的转换器和混合器的使用。 本文的大多数内容和旧版的RFC1889相同。在线路里传输的数据包格式没有改变，唯一的改变是使用协议的规则和控制算法。为了最小化传输，发送RTCP数据包时超过了设定的速率，而在这时，很多的参与者同时加入了一个会话，在这样的情况下，一个新加入到（用于计算的可升级的）计时器算法中的元素是最大的改变。 目录（Table of Contents） 1 引言 （Introduction） 1 1 术语（Terminology） 2 RTP使用场景（RTP Use Scenarios） 2 1 简单多播音频会议（ Simple Multicast Audio Conference） 2 2 音频和视频会议（Audio and Video Conference） 2 3 混频器和转换器（Mixers and Translators） 2 4 分层编码（Layered Encodings） 3 定义（Definitions） 4 字节序，校正和时间格式（Byte Order, Alignment, and Time Format） 5 RTP数据传输协议（RTP Data Transfer Protocol） 5 1 RTP固定头域（RTP Fixed Header Fields） 5 2 多路复用RTP会话（Multiplexing RTP Sessions） 5 3 RTP头的配置文件详细变更（Profile-Specific Modifications to the RTP Header） 5 3 1 RTP报头扩展（RTP Header Extension） 6 RTP控制协议（RTP Control Protocol） – RTCP 6 1 RTCP包格式（RTCP Packet Format） 6 2 RTCP传输间隔（RTCP Transmission Interval） 6 2 1 维护会话成员数目（Maintaining the number of session members） 6 3 RTCP包的发送与接收规则（RTCP Packet Send and Receive Rules） 6 3 1 计算RTCP传输间隔（Computing the RTCP Transmission Interval） 6 3 2 初始化（Initialization） 6 3 3 接收RTP或RTCP（非BYE)包（Receiving an RTP or Non-BYE RTCP Packet） 6 3 4 接收RTCP（BYE）包（Receiving an RTCP BYE Packet） 6 3 5 SSRC计时失效（Timing Out an SSRC） 6 3 6 关于传输计时器的到期（Expiration of Transmission Timer） 6 3 7 传输一个 BYE 包（Transmitting a BYE Packet） 6 3 8 更新we_sent（Updating we_sent） 6 3 9 分配源描述带宽（Allocation of Source Description Bandwidth） 6 4 发送方和接收方报告（Sender and Receiver Reports） 6 4 1 SR：发送方报告的RTCP包（SR: Sender report RTCP packet） 6 4 2 RR：接收方报告的RTCP包（RR: Receiver Report RTCP Packet） 6 4 3 扩展发送方和接收方报告（Extending the Sender and Receiver Reports ） 6 4 4 分析发送方和接收方报告（Analyzing Sender and Receiver Reports ） 6 5 SDES：源描述RTCP包（SDES: Source description RTCP packet） 6 5 1 CNAME：规范终端标识符的SDES数据项(CNAME: Canonical End-Point Identifier SDES Item） 6 5 2 NAME：用户名的SDES数据项（NAME: User name SDES item) 6 5 3 EMAIL:电子邮件地址的SDES数据项（EMAIL: Electronic Mail Address SDES Item） 6 5 4 PHONE：电话号码的SDES数据项（PHONE: Phone Number SDES Item） 6 5 5 LOC:地理用户地址的SDES数据项（LOC: Geographic User Location SDES Item） 6 5 6 TOOL：应用程序或工具名字的SDES数据项（TOOL: Application or Tool Name SDES Item） 6 5 7 NOTE：通知/状态的SDES数据项（NOTE: Notice/Status SDES Item） 6 5 8 PRIV:私有扩展的SDES数据项（PRIV: Private Extensions SDES Item） 6 6 BYE：Goodbye RTCP包（BYE: Goodbye RTCP packet） 6 7 APP:定义应用程序的RTCP包（APP: Application-Defined RTCP Packet） 7 RTP转换器和混频器（RTP Translators and Mixers） 7 1 概述（General Description ） 7 2 在转换器中的RTCP数据处理（RTCP Processing in Translators） 7 3 在混频器中的RTCP数据处理（RTCP Processing in Mixers ） 7 4 级联混频器（Cascaded Mixers） 8 SSRC标识符的分配和使用（SSRC Identifier Allocation and Use） 8 1 冲突概率（Probability of Collision ） 8 2 冲突解决和循环检测（Collision Resolution and Loop Detection） 8 3 在分层编码中使用（Use with Layered Encodings） 9 安全（Security ） 9 1 机密性（Confidentiality） 9 2 身份验证和消息完整性（Authentication and Message Integrity） 10 拥塞控制（Congestion Control） 11 网络和传输协议之上的RTP（RTP over Network and Transport Protocols） 12 协议常量摘要（Summary of Protocol Constants） 12 1 RTCP 包类型（RTCP Packet Types） 12 2 SDES 类型（SDES Types） 13 RTP概况和负载格式详细说明 （RTP Profiles and Payload Format Specifications） 14 安全考虑（Security Considerations） 15 IANA考虑（IANA Considerations） 16 知识产权声明（Intellectual Property Rights Statement） 17 鸣谢（Acknowledgments） 附录 A 算法（Algorithms） 附录 A 1 RTP数据头有效性检查（RTP Data Header Validity Checks ） 附录 A 2 RTCP数据头有效性检查（RTCP Header Validity Checks） 附录 A 3 确定RTP包预期数目和丢失数目（Determining Number of Packets Expected and Lost） 附录 A 4 生成SDES RTCP包（Generating RTCP SDES Packets） 附录 A 5 解析RTCP SDES包（Parsing RTCP SDES Packets） 附录 A 6 生成32位随机标识符（Generating a Random 32-bit Identifier 附录 A 7 计算RTCP传输间隔（Computing the RTCP Transmission Interval） 附录 A 8 估测两次到达间隔的抖动（Estimating the Interarrival Jitter） 附录 B 与RFC1889不同之外（Changes from RFC 1889） 参考书目（References） 标准化引用（Normative References ） 资料性引用（Informative References） 作者地址 完整的版权声明 1.绪论 本文详细的介绍实时传输协议RTP，RTP提供带有实时特性的端对端数据传输服务，传输的数据如：交互式的音频和视频。那些服务包括有效载荷类型定义，序列号，时间戳和传输监测控制。应用程序在UDP上运行RTP来使用它的多路技术和checksum服务。2种协议都提供传输协议的部分功能。不过，RTP可能被其他适当的下层网络和传输协议使用（见11节）。如果下层网络支持，RTP支持数据使用多播分发机制转发到多个目的地。 注意RTP本身没有提供任何的机制来确保实时的传输或其他的服务质量保证，而是由低层的服务来完成。它不保证传输或防止乱序传输，它不假定下层网络是否可靠，是否按顺序传送数据包。RTP包含的序列号允许接受方重构发送方的数据包顺序，但序列号也用来确定一个数据包的正确位置，例如，在视频解码的时候不用按顺序的对数据包进行解码。 但是RTP原先的设计是用来满足多参与者的多媒体会议的需要，它没有限定于专门的应用。连续数据的储存，交互分布式仿真，动态标记，以及控制和测量应用程序也可能会适合使用RTP。 该文档定义RTP，由2个密切联系的部分组成： ○实时传输协议RTP，用于实时传输数据。 ○RTP控制协议RTCP，用于监控服务质量和传达关于在一个正在进行的会议中的参与者的信息。后者对“宽松控制”的会议可能已经足够，但是并没有必要去支持一个应用程序所有的通讯控制条件。这个功能可能充分的或者部分的被一个单独的会议控制协议所包含，这超过了本文档的范围。 RTP表现了协议的一种新的类型，该类型由Clark和Tennenhouse提出[10]，遵循应用级（framing）框架和（integrated layer processing）统一层处理的原则。就是说，RTP被规定为可扩展的，用来提供一个专门的应用程序需要的信息，并将会经常性的被归并到应用程序的处理中，而不是作为一个单独的层被实现。RTP只是一个故意不完成的协议框架。本文档详细说明那些功能，希望这些功能能够普遍贯穿于所有适合使用RTP的应用程序。和常规的协议不同，额外的功能可能通过完善协议本身或者增加一个可能需要分析的选项机制来增加，RTP被规定为可以根据需要通过修改和/或增加操作，“剪裁”到报头。具体的例子见5.3和6.4.3节。 因此，除了本文档，用于专门应用程序的RTP完整的说明将还需要一个或者更多的同类文档（见13节）： ○ 一个框架（大致轮廓）的说明文档，该文档定义了一系列的有效载荷类型编码和它们与有效载荷格式之间的映射（例如，媒体编码）。一个框架可能也定义了应用程序对RTP的一些扩展和修改，详细到一个专门的类。典型的情况，一个应用程序将在一个框架下运行。一个用于音频和视频数据的框架可以在同类RFC3551[1]文档里找到。 ○有效载荷格式说明文档，该文档定义了一个像一个音频或者视频编码的特殊载荷，在RTP里是如何被传输的。 一个关于实时服务和算法如何实现的讨论和关于一些RTP设计结果的后台讨论能够在[11]中找到。 1.1术语 在这个文档里的关键词“一定要”，“一定不能”，“必需的”，“会”，“不会”，“应该”，“不应该”，“推荐”，“可能”和“可选” 将会像在BCP 14（Basic Control Program，基本控制程序），RFC2119[2]里描述一样的解释。并指出适合RTP实现的需要的级别。 2 RTP使用场景（RTP Use Scenarios） 2.1 简单多播音频会议（ Simple Multicast Audio Conference） 2.2 音频和视频会议（Audio and Video Conference） 2.3 混频器和转换器（Mixers and Translators） 2.4 分层编码（Layered Encodings） 以下章节描述了用到RTP的一些方面。所举例子用来说明RTP应用的基本操作，但RTP的用途不限于此。在这些例子中，RTP运行于IP和UDP之上，并且遵循RFC3551所描述的音频和视频的配置文件中的约定。 2.1 简单多播音频会议（Simple Multicast Audio Conference） IETF的一个工作组开会讨论最新协议草案时，使用Internet的IP多播服务来进行语音通讯。工作组中心分配到一个多播的组地址和一对端口。一个端口用于音频数据，另一个端口用于控制（RTCP）数据包。该地址和端口信息发布给预定的参与者。如果有私密性要求，则可用章节9.1中说明的方法，对数据和控制包进行加密，这时就需要生成和发布加密密钥。分配和发布机制的精确细节不在RTP的讨论范围之内。 每个与会者所使用的音频会议应用程序，都以小块形式（比方说持续２０秒时间）来发送音频数据。每个音频数据块都前导RTP报头；RTP报头和数据依次包含在UDP包里。RTP报头指明了各个包里音频编码的类型（如PCM,ADPCM,LPC），这样发送方可以在会议过程中改变编码方式，以适应状况的变化，例如，要加进一个低带宽接入的参与者，或是要应付网络拥塞。 Internet，像其他的报文分组网络一样，偶而会丢失和重排包，造成时长不等的延迟。为弥补这个不足，RTP报头里包含计时信息和一个序列号，允许接收方重建来自源的计时信息，比如前文例子中音频块以20s的间隔在扬声器中连续播放。会议中，对每个RTP包的源,单独地实施计时重建。序列号还被接收方用来评估丢失包数目。 由于会议期间不断有工作组成员加入或离开，因此有必要知道任一时刻的实际参与者及他们接收音频数据的状况好坏。出于这个目的，会议中每个音频应用程序的实例，都在RTCP（控制）端口上周期性地多播一个附加用户名的接收报告。接收报告指明了当前说话者被收听到的状况，可用于控制自适应性编码。除了用户名外，通过控制带宽限度，可以包含其他标识信息。一个站点在离开会议时发送RTCP BYE包（章节6.5）。 2.2 音频和视频会议（Audio and Video Conference） 一个会议如果同时使用音频和视频媒体，则二者传输时使用不同的RTP会话。也就是说，两种媒体中RTP包和RTCP包的传输，是使用两个不同的UDP端口对和（或）多播地址。在RTP层次，音频和视频会话没有直接的耦合，下面这种情况除外：一个同时参加两个会话的参与者，在两个会话的RTCP包中，使用了相同的规范名，这样两个会话就发生关联（耦合）了。 这样区隔开来的目的之一，是允许一些会议参与者只接受自己选择的单一媒体（或者音频，或者视频）。更进一步的说明在章节5.2给出。尽管两种媒体区分开来了，但通过两个会话RTCP包内载有的计时信息，同源的音频与视频还是能够同步回放。 2.3 混频器和转换器（Mixers and Translators） 到目前为止，我们皆假设所有站点都收到相同格式的媒体数据。然而这并不总是行得通。考虑一下这种情况，一个地方的参与者只能低速接入会议，而其他大部分参与者都能享受高速连接。与其让强迫大家都忍受低带宽，不如在只能低速接入的地方，放置一个减质量音频编码的RTP层次的中继（称作混频器）。混频器将重新同步输入的音频包，重建发送方产生的20ms固定间隔，混频已重建过的音频流为单一的流，转换音频编码为低带宽格式，最后通过低带宽连接转发数据包流（package stream)。这些包可能被单播到一个接收方，也可能多播到另一个的地址而发给多个接收方。RTP报头为混频器提供了一种方法，使其能辨识出对混频后的包有用的源，从而保证提供给接收方正确的说话者指示。 在音频会议中，一些预定参与者尽管有高带宽连接，但不能通过IP多播直接接入会议。例如，他们可能位于一个不允许任何IP包通过的应用层防火墙后面。对这些站点，可能就不需要混频，而需要另一种称为转换器的RTP层次中继。可以在防火墙两侧分别安装一个转换器，外侧转换器将所有多播包通过安全连接转入内侧转换器，内侧转换器再转发给内部网的一个多播组（multicast group)。 混频器和转换器可以设计成用于各种目的。比如，一个视频混频器在测量多个不同视频流中各人的单独影像后，将它们组合成一个单一视频流来模拟群组场景。又如，在只用IP/UDP和只用ST_II的两个主机群之间通过转换建立连接。再如，在没有重新同步或混频时，用packet-by-packet编码转换来自各个独立源的视频流。混频器和转换器的操作细节见章节7。 2.4 分层编码（Layered Encodings） 为了匹配接收方的能力（容量）以及适应网络拥塞，多媒体应用程序应当能够调整其传输速率。许多应用实现把调适传输速率的责任放在源端。这种做法在多播传输中并不好，因为不同接收方对带宽存在着冲突性需求。这经常导致最小公分母的场景，网格中最小的管道支配了全部实况多媒体“广播”的质量和保真度。 相反地，可以把分层编码和分层传输系统组合起来，从而把调适速率的责任放在接收端。在IP多播之上的RTP上下文中，对一个横跨多个RTP会话（每个会话在独自多播组上开展）的分级表示信号(a hierarchically represented signal)，源能够把它的分层（layers)分割成条。 接收方仅需合并适当的多播组子集，就能适应异种网络和控制接收带宽。 RTP分层编码的细节在章节6.3.9，8.3和11中给出。 3. 定义（definitions) RTP负载（RTP payload）：通过RTP传输的包中的数据，例如，音频样本或压缩好的视频数据。负载格式与解释不在本文讨论范围。 RTP包（RTP packet）：一种数据包，其组成部分有：一个固定RTP报头，一个可能为空的作用源（contributing sources）列表（见下文），以及负载数据。一些下层协议可能要求对RTP包的封装进行定义。一般地，下层协议的一个包包含一个RTP包，但若封装方法允许，也可包含数个RTP包（见章节11）。 RTCP包（RTCP packet）：一种控制包，其组成部分有：一个类似RTP包的固定报头，后跟一个结构化的部分，该部分具体元素依不同RTCP包的类型而定。格式的定义见章节６。一般地，多个RTCP包将在一个下层协议的包中以合成RTCP包的形式传输；这依靠RTCP包的固定报头中的长度字段来实现。 端口（Port）：“传输协议用来在同一主机中区分不同目的地的一种抽象。TCP/IP协议使用正整数来标识不同端口。”[12] OSI传输层使用的传输选择器（TSEL,the transport selectors）等同于这里的端口。RTP需依靠低层协议提供的多种机制，如“端口”用以多路复用会话中的RTP和RTCP包。 传输地址(Transport address)：是网络地址与端口的结合，用来标识一个传输层次的终端，例如一个IP地址与一个UDP端口。包是从源传输地址发送到目的传输地址。 RTP媒体类型（RTP media type）：一个RTP媒体类型是一个单独RTP会话所载有的负载类型的集合。RTP配置文件把RTP媒体类型指派给RTP负载类型。 多媒体会话（Multimedia session）：在一个参与者公共组中，并发的RTP会话的集合。例如，一个视频会议（为多媒体会话）可能包含一个音频RTP会话和一个视频RTP会话。 RTP会话（RTP session）：一群参与者通过RTP进行通信时所产生的关联。一个参与者可能同时参与多个RTP会话。在一个多媒体会话中，除非编码方式把多种媒体多路复用到一个单一数据流中，否则每种媒体都将使用各自的RTCP包，通过单独的RTP会话来传送。通过使用不同的目的传输地址对（一个网络地址加上一对分别用于RTP和RTCP的端口，构成了一个传输地址对）来接收不同的会话，参与者能把多个RTP会话区隔开来。单个RTP会话中的所有参与者，可能共享一个公用目的传输地址对，比如IP多播的情况；也可能各自使用不同的目的传输地址对，比如个体单播网络地址加上一个端口对。对于单播的情况，参与者可能使用相同端口对来收听其他所有参与者，也可能对来其他每个参与者使用不同的端口对来收听。 RTP会话间相互区别的特征，在于每个RTP会话都维护一个用于SSRC标识符的独立完整的空间。RTP会话所包含的参与者组，由能接收SSRC标识符的参与者组成，这些SSRC标识符由RTP（同步源或作用源）或RTCP中的任意参与者传递。例如，考虑下述情况，用单播UDP实现的三方会议，每方都用不同的端口对来收听其他两方。如果收到一方的数据，就只把RTCP反馈发送给那一方，则会议就相当于由三个单独的点到点RTP会话构成；如果收到一方的数据，却把RTCP反馈发送另两方，则会议就是由一个多方（multi-party)RTP会话构成。后者模拟了三方间进行IP多播通信时的行为。 RTP框架允许上述规定发生变化，但一个特定的控制协议或者应用程序在设计时常常对变化作出约束。 同步源(SSRC，Synchronization source)：RTP包流的源，用RTP报头中32位数值的SSRC标识符进行标识，使其不依赖于网络地址。一个同步源的所有包构成了相同计时和序列号空间的一部分，这样接收方就可以把一个同步源的包放在一起，来进行重放。举些同步源的例子，像来自同一信号源的包流的发送方，如麦克风、摄影机、RTP混频器（见下文）就是同步源。一个同步源可能随着时间变化而改变其数据格式，如音频编码。SSRC标识符是一个随机选取的值，它在特定的RTP会话中是全局唯一（globally unique）的（见章节8）。参与者并不需要在一个多媒体会议的所有RTP会话中，使用相同的SSRC标识符；SSRC标识符的绑定通过RTCP（见章节6.5.1）。如果参与者在一个RTP会话中生成了多个流，例如来自多个摄影机，则每个摄影机都必须标识成单独的同步源。 作用源（CSRC，Contributing source )：若一个RTP包流的源，对由RTP混频器生成的组合流起了作用，则它就是一个作用源。对特定包的生成起作用的源，其SSRC标识符组成的列表，被混频器插入到包的RTP报头中。这个列表叫做CSRC表。相关应用的例子如，在音频会议中，混频器向所有的说话人（talker)指出，谁的话语（speech)将被组合到即将发出的包中，即便所有的包都包含在同一个（混频器的）SSRC标识符中，也可让听者（接收者）可以清楚谁是当前说话人。 终端系统（End system)：一种应用程序，它产生发送出的RTP包中内容，或者使用接收到的RTP包中内容。在一个特定的RTP会话中，一个终端系统可以扮演一个或多个同步源角色，但通常是一个。 混频器（Mixer)：一种中间系统，它从一个或多个源中接收RTP包，可能改变其数据格式，再按某种方式把这些包组合成一个新的包，然后转发出去。由于多个输入源的计时一般不会同步，所以混频器会对各个流的计时作出调整，并为组合流生成一个新的计时。因此，混频器将被标识成它所产生所有数据包的同步源。 转换器（Translator)：一种中间系统，它转发RTP包而不改变各包的同步源标识符。转换器的例子如下：不作混频地转变编码的设备，把多播复制到单播的重复装置，以及防火墙里应用层次的过滤器。 监视器(Monitor)：一种应用程序，它接收RTP会话参与者所发送的RTCP包，特别是接收报告（reception report)，而且对当前服务质量进行评估，评估结果用于分配监视任务，故障诊断和长期统计。监视器常常被内建到参与会话的应用程序中，但也可以是一个的独立的应用程序——不参加会话、也不发送或接收RTP数据包（因为它们在不同的端口上）。这些被称作第三方监视器。还有一种情况也是可以接受的，第三方监视器只接收但不发送数据包，或者另外地算入到会话中。 非RTP途径（Non-RTP means)：为提供一个可用的服务，可能还需要其他的协议和机制。特别地，对多媒体会议来说，一个控制协议可以发布多播地址，发布加密密钥，协商所用的加密算法，以及为没有预定义负载类型值的格式，建立负载类型值和其所代表的负载格式之间的动态映射。其他协议的例子如下：会话初始化协议（SIRFC3261[13]），ITU推荐的H.323[14]，还有使用SDP(RFC2327[15])的应用程序，如RTSP(RFC 2326[16]). 对于简单的应用程序，电子邮件或者会议数据库也可能用到。对这些协议和机制的详细说明已经超出了本文档的讨论范围。 5 RTP数据传输协议 5.1 RTP固定头中的各字段 RTP头有以下格式:123456789101112 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|V=2|P|X| CC |M| PT | sequence number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| timestamp |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| synchronization source (SSRC) identifier |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+| contributing source (CSRC) identifiers || .... |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ RTP包头格式 前12个字节出现在每个RTP包中，仅仅在被混合器插入时，才出现CSRC识别符列表。这些域有以下意义： 版本(V)：2比特 此域定义了RTP的版本。此协议定义的版本是2。(值1被RTP草案版本使用，值0用在最初”vat”语音工具使用的协议中。) 填充(P)：1比特 若填料比特被设置，则此包包含一到多个附加在末端的填充比特，填充比特不算作负载的一部分。填充的最后一个字节指明可以忽略多少个填充比特。填充可能用于某些具有固定长度的加密算法，或者用于在底层数据单元中传输多个RTP包。 扩展(X)：1比特 若设置扩展比特，固定头(仅)后面跟随一个头扩展。 CSRC计数(CC)：4比特 CSRC计数包含了跟在固定头后面CSRC识别符的数目。 标志(M)：1比特 标志的解释由具体协议规定。它用来允许在比特流中标记重要的事件，如帧边界。 负载类型(PT)：7比特 此域定义了负载的格式，由具体应用决定其解释。协议可以规定负载类型码和负载格式之间一个默认的匹配。其他的负载类型码可以通过非RTP方法动态定义。RTP发送端在任意给定时间发出一个单独的RTP负载类型；此域不用来复用不同的媒体流。 序列号（sequence number）：16比特 每发送一个RTP数据包，序列号加1，接收端可以据此检测丢包和重建包序列。序列号的初始值是随机的(不可预测)，以使即便在源本身不加密时(有时包要通过翻译器，它会这样做)，对加密算法泛知的普通文本攻击也会更加困难。 时间戳（timestamp） 32比特时间戳反映了RTP数据包中第一个字节的采样时间。时钟频率依赖于负载数据格式，并在描述文件（profile）中进行描述。也可以通过RTP方法对负载格式动态描述。 如果RTP包是周期性产生的，那么将使用由采样时钟决定的名义上的采样时刻，而不是读取系统时间。例如，对一个固定速率的音频，采样时钟将在每个周期内增加1。如果一个音频从输入设备中读取含有160个采样周期的块，那么对每个块，时间戳的值增加160。 时间戳的初始值应当是随机的，就像序号一样。几个连续的RTP包如果是同时产生的。如：属于同一个视频帧的RTP包，将有相同的序列号。 不同媒体流的RTP时间戳可能以不同的速率增长。而且会有独立的随机偏移量。因此，虽然这些时间戳足以重构一个单独的流的时间，但直接比较不同的媒体流的时间戳不能进行同步。对于每一个媒体，我们把与采样时刻相关联的RTP时间戳与来自于参考时钟上的时间戳（NTP）相关联。因此参考时钟的时间戳就了数据的采样时间。（即：RTP时间戳可用来实现不同媒体流的同步，NTP时间戳解决了RTP时间戳有随机偏移量的问题。）参考时钟用于同步所有媒体的共同时间。这一时间戳对（RTP时间戳和NTP时间戳），用于判断RTP时间戳和NTP时间戳的对应关系，以进行媒体流的同步。它们不是在每一个数据包中都被发送，而在发送速率更低的RTCP的SR（发送者报告）中。 如果传输的数据是存贮好的，而不是实时采样等到的，那么会使用从参考时钟得到的虚的表示时间线（virtual presentation timeline）。以确定存贮数据中的每个媒体下一帧或下一个单元应该呈现的时间。此种情况下RTP时间戳反映了每一个单元应当回放的时间。真正的回放将由接收者决定。 SSRC：32比特 用以识别同步源。标识符被随机生成，以使在同一个RTP会话期中没有任何两个同步源有相同的SSRC识别符。尽管多个源选择同一个SSRC识别符的概率很低，所有RTP实现工具都必须准备检测和解决冲突。若一个源改变本身的源传输地址，必须选择新的SSRC识别符，以避免被当作一个环路源。 CSRC列表：0到15项，每项32比特 CSRC列表识别在此包中负载的所有贡献源。识别符的数目在CC域中给定。若有贡献源多于15个，仅识别15个。CSRC识别符由混合器插入，并列出所有贡献源的SSRC识别符。例如语音包，混合产生新包的所有源的SSRC标识符都被列出，以在接收端处正确指示参与者。 5.3.1 RTP头扩展 RTP提供扩展机制以允许实现个性化：某些新的与负载格式独立的功能要求的附加信息在RTP数据包头中传输。设计此方法可以使其它没有扩展的交互忽略此头扩展。RTP头扩展的格式如下图所示。 12345670 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | defined by profile | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | header extension | | .... | 若RTP头中的扩展比特位置1，则一个长度可变的头扩展部分被加到RTP固定头之后。头扩展包含16比特的长度域，指示扩展项中32比特字的个数，不包括4个字节扩展头(因此零是有效值)。RTP固定头之后只允许有一个头扩展。为允许多个互操作实现独立生成不同的头扩展，或某种特定实现有多种不同的头扩展，扩展项的前16比特用以识别标识符或参数。这16比特的格式由具体实现的上层协议定义。基本的RTP说明并不定义任何头扩展本身。 6 RTP控制协议RTCP RTP控制协议(RTCP)向会议中所有成员周期性发送控制包。它使用与数据包相同的传输机制。底层协议必须提供数据包和控制包的复用，例如用不同的UDP端口。RTCP提供以下四个功能：○基本功能是提供数据传输质量的反馈。这是RTP作为一种传输协议的主要作用，它与其他协议的流量和拥塞控制相关。反馈可能对自适应编码有直接作用，并且IP组播的实验表明它对于从接收端得到反馈信息以诊断传输故障也有决定性作用。向所有成员发送接收反馈可以使”观察员”评估这些问题是局部的还是全局的。利用类似多点广播的传输机制，可以使某些实体，诸如没有加入会议的网络业务观察员，接收到反馈信息并作为第三方监视员来诊断网络故障。反馈功能通过RTCP发送者和接收者报告实现。 ○RTCP为每个RTP源传输一个固定的识别符，称为规范名（CNAME）。由于当发生冲突或程序重启时SSRC可能改变，接收者要用CNAME来跟踪每个成员。接收者还要用CNAME来关联一系列相关RTP会话中来自同一个成员的多个数据流，例如同步语音和图像。 ○前两个功能要求所有成员都发送RTCP包，因此必须控制速率以使RTP成员数可以逐级增长。通过让每个成员向所有成员发送控制包，各个成员都可以独立地观察会议中所有成员的数目。此数目可以用来估计发包速率。 ○第四个可选的功能是传输最少的会议控制信息，例如在用户接口中显示参与的成员。这最可能在”松散控制”的会议中起作用，在”松散控制”会议里，成员可以不经过资格控制和参数协商而加入或退出会议。RTCP作为一个延伸到所有成员的方便通路，必须要支持具体应用所需的所有控制信息通信。 ○在RTP用于IP多点广播时，功能1-3是强制的，在所有情况下都推荐使用。建议RTP应用开发商避免使用只能用于单向广播而不能扩充到多用户的方法。 6.1 RTCP包格式这部分定义了几个RTCP包类型，可以传送不同的控制信息： ○SR：发送者报告，描述作为活跃发送者成员的发送和接收统计数字； ○RR：接收者报告，描述非活跃发送者成员的接收统计数字； ○SDES：源描述项，其中包括规范名CNAME。 ○BYE：表明参与者将结束会话。 ○APP：应用描述功能。 在本文中将详细介绍SR和RR。 每个RTCP包的开始部分是与RTP数据包相类似的固定部分，随后是一块结构化单元，它随负载类型不同长度发生变化，但是总以32比特终止。对齐要求和长度域使RTCP包可”堆栈”，即可以将多个RTCP包形成一个复合RTCP包，在底层协议(如UDP)中，通常都是将复合包作为一个包传输的。复合包中的每个RTCP单包可以单独处理，而无需考虑包复合的顺序。然而，为了实现某些协议功能，添加以下限制： ○接收数据的统计信息(在SR或RR中)。只要带宽允许应尽可能经常的发送，以达到统计数字的最大分辨率。因此每个周期发送的RTCP包必须包含一个报告包。 ○新的参与者需要尽快接收一个源的规范名以识别数据源并与媒体建立会话。因此，每个包中必须包含源描述项中的规范名。除非复合包进行了分割以进行部分加密（见9.1节的描述）。 ○必须限制首次在复合包中出现的包类型的数目，以增加在第一个字中常数比特的数目，这样可以增加RTCP包的有效性，以区分误传的RTP包和其他无关的包。因此，所有RTCP包必须以复合包的形式发送。复合包中至少有两个单个的RTCP包。具有以下格式： ○加密前缀：当且仅当复合包被加密时，对每个RTCP复合包加32比特的前缀。 ○SR或RR：复合包中的第一个RTCP包必须是一个报告包。即使没有数据发送和接收，此时发送空的RR包，或者复合包中其他的唯一包是BYE包，也必须发送报告包。 ○附加的RR：若被报告的接收统计源数目超过SR/RR包中最大允许的31个，附加的RR必须跟在最初的报告包后面。 ○源描述SDES ○BYE或APP包 每个RTP参与者在一个报告间隔内应只发送一个RTCP复合包，以便正确估计每个参与者的RTCP带宽。除非像9.1节描述的情况——把一个RTCP复合包分割以进行加密。如果数据源的个数太多，以至于不能把所有的RR包都放到同一个RTCP包中而不超过网络路径的最大传输单元（maximum transport unit MTU），那么可在每个间隔中发送其中的一部分包。在多个发送间隔中，所有的包应该被等概率的选中。这样就可以报告所有数据源的接收数据的情况。如果一个RTCP复合包的长度超过了网络路径的MTU，则它应当被分割为多个更短的RTCP包来传输。这不会影响对RTCP带宽的估计，因为每一个复合包至少代表了一个参与者。要注意的是每个RTCP复合包必须以SR或RR包开头。 1234567891011| |[--------- packet --------][---------- packet ----------][-packet-] | | receiver chunk chunk V reports item item item item -------------------------------------------------------------------- R[SR #sendinfo #site1#site2][SDES #CNAME PHONE #CNAME LOC][BYE##why] -------------------------------------------------------------------- | | |&lt;----------------------- compound packet -----------------------&gt;| |&lt;-------------------------- UDP packet -------------------------&gt;| #: SSRC/CSRC identifier 图1: RTCP复合包举例 6.2 RTCP传输时间间隔 RTP被设计为允许应用自动适应不同的规模的会话――从几个参与者到几千个参与者的会话。 对每一个会话，我们假定数据传输受到一个上限――会话带宽的限制。会话带宽分配给所有的参与者。这个带宽会被预留，并由网络所限制。如果没有预留，基于环境的其他约束将会确定合理的最大带宽供会话使用，这就是会话带宽。会话带宽在一定程度上独立于媒体编码，但媒体编码却依赖于会话带宽。 在涉及媒体应用时，会话带宽参数最好由一个会话控制应用提供。但媒体应用可能设置一个默认参数。此参数由单个发送者选择的编码方式的数据带宽算出。会话管理可能会基于多播范围的规则或其他标准确定带宽限制。所有的参与者应使用相同的会话带宽值以保证计算出相同的RTCP间隔。 控制传输带宽应当是会话带宽的一小部分，这部分所占总的会话带宽的百分比应是已知的。一小部分：传输协议的首要功能是传输数据；已知：控制传输带宽可以被放进带宽描述中提供给资源预留协议，并且使每个参与者都可以独立的计算出他所占有的带宽份额。 控制传输带宽作为额外的一部分加入到会话带宽中。建议RTCP控制传输带宽为RTCP会话带宽的5%。其中的1/4分配给发送者；当发送者的比例超过所有参与者的1/4时，其RTCP控制带宽相应增加。所有的会话参与者必须使用相同的常数（以上提到的百分比），以便计算出相同的发送时间间隔。这些常数应在一个特殊的描述文件中确定。 计算出的RTCP复合包的发送时间间隔应该有一个下限，以免参与者数量较少时大量发送RTCP包。这也使网络暂时断开时，发送间隔不会太小。在应用开始时，一个延迟应加到第一个的TCP复合包发送之前，以便从其他参与者接收RTCP复合包。这样，发送时间间隔能更快的收敛到正确的值。这个延迟可以设为最小时间间隔的一半。固定的时间间隔建议为5秒。 一个实现可能使RTCP最小发送时间间隔与会话带宽参数成比例。则应满足下列约束： ○对多播会话，只有活动的数据发送者使用减小的最小化的值计算RTCP复合包的发送时间间隔。 ○对单播会话，减小的值也可能被不是活动的数据发送者使用，发送初始的RTCP复合包之前的延迟可能是0。 ○对所有会话，在计算参与者的离开时间时，这个固定最小值会被用到。因此，不使用减小的值进行RTCP包的发送，就不会被其他参与者提前宣布超时。 ○减小的最小时间间隔建议为：360/sb(秒)，其中sb：会话带宽（千字节/秒）。当sb&gt;72kb/s时，最小时间间隔将小于5s。 6.3节所描述的算法和附录A.7将实现本节列出的目标： ○计算出的RTCP包的时间间隔与组中参与者的人数成正比。（参与者越多，发送时间间隔越长，每个参与者占有的RTCP带宽越小）。 ○RTCP包的（真实）时间间隔是计算出的时间间隔的0.5～1.5倍之间某个随机的值，以避免所有的参与者意外的同步。 ○RTCP复合包的平均大小将会被动态估计，包括所有发送的包和接收的包。以自动适应携带的控制信息数量的变化。 ○由于计算出的时间间隔依赖于组中的人数。因此，当一个的用户加入一个已经存在的会话或者大量的用户几乎同时加入一个新的会话时，就会有意外的初始化效应。这些新用户将在开始时错误的估计组中的人数（估计太小）。因此他们的RTCP包的发送时间间隔就会太短。如果许多用户同时加入一个会话，这个问题就很重要了。为了处理这处问题考虑了一种叫“时间重估”的算法。这个算法使得组中人数增加时，用户能够支持RTCP包的传输。 当有用户离开会话，不管是发送BYE包还是超时，组中的人数会减少。计算出的时间间隔也应当减少。因此，应用“逆向重估”算法，使组中的成员更快的减少他们的时间间隔，以对组中的人数减少做出响应。 ○BYE包的处理和其他RTCP包的处理不同。BYE包的发送用到一个“放弃支持”算法。以避免大量的BYE包同时发送，使大量参与者同时离开会话。 这个算法适用于所有参与者都允许RTCP包的情况。此时，会话带宽＝每个发送者的带宽×会话中参与者的总人数。详细算法见随后小节，附录A.7给出了算法的一个实现。 6.2.1维持会话成员的人数 当侦听到新的站点的时候，应当把他们加入计数。每一个登录都应在表中创建一条记录，并以SSRC或CSRC进行索引。新的登录直到接收到含有SSRC的包或含有与此SSRC相联系的规范名的SDES包才视为有效（见附录A.1）。当一个与SSRC标识符相对RTCP BYE包收到时，登录会被从表中删除。除非一个“掉队”的数据包到达，使登录重新创建。 如果在几个RTCP报告时间间隔内没有RTP或RTCP包收到，一个参与者可能标记另外一个站点静止，并删除它。这是针对丢包提供的一个很强健的机制。所有站点对这个超时时间间隔乘子应大体相同，以使这种超时机制正常工作。因此这个乘子应在特别的描述文件中确定。 对于一个有大量参与者的会话，维持并存贮一个有所有参与者的SSRC及各项信息的表几乎是不可能的因此，只可以只存贮SSRC。其他算法类似。关键的问题就是，任何算法都不应当低估组的规模，虽然它有可能被高估。 6.3 RTCP包的发送和接收规则 下面列出了如何发送RTCP包，当接收到的TCP包时该干什么的规则。 为执行规则，一个会话参与者就维持下列变量： tp: RTCP包发送的最后时间。 tc: 当前时间。 tn: 估计的下一个RTCP包要发送的时间。 pmembers: tn最后被重新计算时，会计的会话成员的人数。 members: 会话成员人数的当前估计。 senders: 会话成员中发送者人数的估计。 rtcp_bw: 目标RTCP带宽。例如用于会话中所有成员的RTCP带宽。单位bit/s。这将是程序开始时，指定给“会话带宽”参数的一部分。 we_sent: 自当前第二个前面的RTCP发送后，应用程序又发送了数据，则此项为true。 avg_rtcp_size: 此参与者收到的和发送的RTCP复合包的平均大小。单位：bit。按6.2节，此大小包括底层传输层和网络层协议头。 initial: 如果应用程序还未发送RTCP包，则标记为true。 许多规则都用到了RTCP包传输的“计算时间间隔”。此时间间隔将在随后的小节描述。 6.3.1计算RTCP传输时间间隔 一个会话参与者包的平均发送时间间隔应当和所在会话组中人数成正比。这个间隔称为计算时间间隔。它由上面提到的各个状态参量结合起来计算得出。计算时间间隔T的计算如下： 1（1）如果发送者人数≤会话总人数×25%。则T取决于此参与者是否是发送者（we_sent的值）；否则，发送者和接收者将统一处理。 1234567891011121314senders&lt;=25%*memberswe_sentc=avg_rtcp_size/(0.25*rtcp_bw);n=senders;c=avg_rtcp_size/(0.75*rtcp_bw);n=members-senders;c=avg_rtcp_size/rtcp_bw;n=members;notyesyesnot 图：确定c ，n 如6.2节所述，RTP描述文件可能用两个独立的参数（S，R）确定发送者与非发送者。此时，25%和75%只要相应的换成S/(S+R),R/(S+R)即可。注意R＝0的情况。 2 如果initial为true(则未发送过RTCP包)，则设Tmin=2.5s;否则设Tmin=5s。 3 决定性的计算时间间隔（deterministic calculated interval）Td=max(Tmin ,nc)。 4 T=Tdλ；其中λ~U(0.5,1.5)。即λ服从0.5到1.5之间的均匀分布。 5 T=T/(e-0.5)≈T/1.21828，补偿时间重估算法，使之收敛到比计算出的平均RTCP带宽小的一个值。 这个算法产生了一个随机的计算时间间隔，并把至少25%的RTCP带宽分配给发送者，其余的分给接收者。若发送者超过会话总人数的25%，此算法将把带宽平均分给所有的参与者。 6 3.2初始化 一加入会话，参与者的各状态参量初始化为：tp=0； tc=0； senders=0； pmembers=1； members=1； vw_sent=false； rtcp_bw:由会话带宽参数的相应部分得到；initial=true；avg_rtcp_size:初始化为应用程序稍后将发送的RTCP包的可能大小；T：如6.3.1节；tn=T（这意味着，一个计时器将经T时间后被唤醒）；应用程序可以用任何它需要的方式实现计时器。 参与者把它自己的SSRC加到成员列表中。 6.3.3接收到的TP包或一个非BYE的RTCP包 当收到一个参与者的RTP或RTCP包时，若其SSRC不在成员列表中，将其SSRC加入列表；若此参与者被确认有效（如6.2.1节描述），就把列表中成员的值更新。对每个有效的RTP包中的CSRC执行相同的过程。 当收到一个参与者的RTP包时，若其SSRC不在发送者列表中，则将其SSRC加入发送者列表，更新相应的值。 每收到一个RTCP复合包，avg_rtcp_size更新为avg_rtcp_size = 1/16 packet_size + 15/16 avg_rtcp_size ；其中packet_size是刚收到的RTCP复合包的大小。 6.3.4接收RTCP BYE包 除6.3.7小节描述的发送RTCP BYE包之外，如果收到一个RTCP BYE包，则检测成员列表。若SSRC存在；先移除之，并更新成员的值。 另外，为使RTCP包的发送速率与组中人数变化更加协调，当收到一个BYE包使得members的值pmembers时，下面的逆向重估算法应当执行： （1）tn的更新：tn = tc + ( members / pmembers ) ( tn –tc )； （2）tp的更新：tp = tc – ( members / pmembers ) ( tc – tp )；下一个RTCP包将在时刻tn 被发送，比更新前更早一些。 （3）pmembers的更新：pmembers=members； 这个算法并没有防止组的大小被错误的在短时间内估计为0的情况。如：在一个较多人数的会话中，多数参与者几乎同时离开而少数几个参与者没有离开的情况。这个算法并没有使估计迅速返回正确的值。因为这种情况较罕见，且影响不大。 6.3.5 SSRC超时 在随机的时间间隔中，一个参与者必须检测其他参与者是否已经超时。为此，对接收者（we_sent为false），要计算决定性时间间隔Td，如果从时刻Tc-MTd(M为超时因子，默认为5秒)开始，未发送过RTP或RTCP包，则超时。其SSRC将被从列表中移除，成员被更新。在发送者列表中也要进行类似的检测。发送者列表中，任何从时间tc-2T(在最后两个RTCP报告时间间隔内)未发送RTP包的发送者，其SSRC从发送者列表中移除，列表更新。 如果有成员超时，应该执行6.3.4节中的逆向检测算法。每个参与者在一个RTCP包发送时间间隔内至少要进行一次这样的检测。 6.3.6发送时钟到时了 当包传输的发送时钟到时，参与者执行下列操作： （1）按6.3.1节的办法计算T。 （2）更新发送时钟的定时时间，判断是否发送RTCP包，更新pmembers。如图： tp+T&lt;=tc 发送RTCP包 tp=tc; tn=tc+T; initial=false; avg_rtcp_size=1/16 packet_size + 15/16 avg_rtcp_size tn=tp+T Pmemvers=members yes no //不发送RTCP包 图：发送时钟到时的操作 6.3.7发送一个BTE包 当一个参与者离开会话时，应发送BYE包，通知其他参与者。为避免大量参与者同时离开系统时，大量BYE包的发送，若会话人数超过50，则参与者在要离开会话时，应执行下面的算法。这个算法实际上“篡夺”了一般可变成员的角色来统计BYE包。 （1）tp=tc ； members=1； pmembers=1； sinitial=1； we_sent=false； senders=0； rtcp_size:设置为将要发送的RTCP包大小；计算“计算时间间隔”T；tn=tc+T；(BYE包预计在时刻tn被发送)。 (2)每当从另外一个参与者接收到BYE包时，成员人数加1。不管此成员是否存在于成员列表中，也不管SSRC采样何时使用及BYE包的SSRC是否包含在采样之中。如果收到RTP包或甚的RTCP包（除BYE包之外的RTCP包），成员人数不增加。类似，只有在收到BYE包时，avg_rtcp_size才更新。当RTP包到达时，发送者人数senders不更新，保持为0。 （3）在此基础上，BYE包的传输服从上面规定的一般的RTCP包的传输。 （BYE包的传输，是专注于统计会话中发送BYE包的人数的。） 这允许BYE包被立即发送，并控制总的带宽使用。在最坏情况下上，这可能会使RTCP控制包使用两倍于正常水平的带宽，达到10%――其中5%给BYE包的RTCP包，其余5%给BYE包。 一个参与者若不想用上面的机制进行RTCP包的发送，可以直接离开会话，而根本不发送BYE包。他会被其他参与者因超时而删除。 一个参与者想离开会话时，如果组中的人数会计数目小于50，则参与者可以直接发送BYE包。 另外，一个从未发送过RTP或RTCP包的参与者，在离开会话时，不能发送BYE包。 6.3.8更新we_sent变量 如果一个参与者最近发过RTP包，则变量we_sent值为true,否则为false。相同的机制可以管理发送者中的其他参与者。如果参与者发送了TPT包而此时，其对应的we_sent变量值为false,则就把它自己加到发送者列表中，并设置其we_sent变量为true。6.3.4节中描述的逆向重估算法（reverse reconsideration algorithm）应当被执行。以可能减少发送SR包前的延迟。每次发送一个RTP包，其相应的传输时间都会记录在表中。一般发送者的超时算法应用到参与者自身：从tc-2T时开始，一直没有发送RTP包，则此参与者就从发送者列表中将其自身移除，减少发送者总数，并设置we_sent变量值为false。 6.3.9源描述带宽的分配 这里定义了几种源描述项，强制性的规范名（CNAME）除外。例如，个人姓名（NAME）和电子邮件地址（EMAIL）。它也提供了方法定义新的RTCP包的类型。应用程序在给这些额外信息分配带宽时应额外小心。因为这会降低接收报告及CNAME的发送速率，可能破坏协议发挥作用。建议分配给一个参与者用于传输这些额外信息的带宽不超过总的RTCP带宽的20%。另外，并非所有的源描述项都将包含进每一个应用程序中。包含进应用程序的源描述项应根据其用途分配给相应的带宽百分比。建议不要动态会计这些百分比，而应根据一个源描述项的典型长度将所占带宽的百分比的转化为报告间隔。 例如，一个应用程序可能仅发送CNAME，NAME和EMAIL，而不需要其他项。NAME可能会比EMAIL给予更高的优先级。因为NAME可能会在应用程序的用户界面上持续显示，但EMAIL可能仅仅在需要时才会显示。在每一个RTCP时间间隔内，一个包含CNAME项的SDES包和一个RR包将会被发送。最小的会话时间间隔平均为5秒。每经过3个时间间隔（15秒），一个额外的项将会包含进这个SDES包中。7/8的时间是NAME项，每经过8个这样的间隔（15s8=2min）,将会是EMAIL项。 当多个会话考虑使用一个通用的规范名为每个参与者进行绑定时，如在一个RTP会话组成的多媒体会议中，额外的SDES信息可能只在一次RTP会话中被发送。其余的会话将只发送CNAME。特别，这个办法也应该用在分层编码的多个会话中。 6.4 发送者和接收者报告 RTP接收者利用RTCP报告包提供接收质量反馈。根据接收者是否同时还是发送者，RTCP包采取两种不同的形式。发送者报告(SR)和接收者报告(RR)格式中唯一的不同，除包类型码之外，在于发送者报告包括20字节的发送者信息。 SR包和RR包都包括零到多个接收报告块。针对该接收者发出上一个报告块后接收到RTP包的起始同步源，每个源一个块。报告不发送给CSRC列表中的贡献源。每个接收报告块提供从特定数据源接收到数据的统计信息。由于SR/RR包最多允许31个接收报告块，故可以在最初的SR或RR包之后附加RR包，以包含从上一个报告以来的间隔内收听到的所有源的接收报告。如果数据源太多，致使若把所有的RR包放到同一个RTCP复合包中会超出网络的MTU。那么就在一个周期内选择上面RR包的一部分以不超过MTU。这些RR包的选取应让各个包都有同等的几率被取到。这样在几个发送周期间隔中，对所有的数据源就都发送接收报告了。 以下部分定义了两种报告的格式。如果应用程序需要其他信息，他们可以被扩展。 6.4.1 SR：发送者报告RTCP包 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| RC | PT=SR=200 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ sender | NTP timestamp, most significant word | info +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | NTP timestamp, least significant word | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | RTP timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender’s packet count | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender’s octet count | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_1 (SSRC of first source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 1 | fraction lost | cumulative number of packets lost | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | extended highest sequence number received | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | interarrival jitter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | last SR (LSR) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | delay since last SR (DLSR) | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_2 (SSRC of second source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 2 : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | profile-specific extensions | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 发送者报告包由3部分组成，若定义，可能跟随第4个面向协议的扩展部分。 第一部分，头部，8字节长。该域有以下意义： 版本(V)：2比特 RTP版本识别符，在RTCP包内的意义与RTP包中的相同。此协议中定义的版本号为2。 填充(P)：1比特 若设置填充比特，该RTCP包在末端包含一些附加填充比特，并不是控制信息的基本部分。填充的最后一个比特统计了多少个字节必须被忽略。填充可能会用于需要固定长度块的加密算法。在复合RTCP包中，复合包作为一个整体加密，填料比特只能加在最后一个单个RTCP包的后面。 接收报告块计数(RC)：5比特 该包中所含接收报告块的数目。零值有效。 包类型(PT)：8比特 包含常数200，用以识别这个为SR包。 长度：16比特 该RTCP包的长度减1。其单位是32比特字，包括头和任何填充字节。(偏移量1保证零值有效，避免了在扫描RTCP包长度时可能发生的无限循环，同时以32比特为单位避免了对以4为倍数的有效性检测。) SSRC：32比特 SR包发送者的同步源标识符。 第二部分，发送者信息，20字节长。在每个发送者报告包中出现。它概括了从此发送者发出的数据传输情况。此域有以下意义： NTP时间戳：64比特 指示了此报告发送时的背景时钟（wallclock）时刻，它可以与从其它接收者返回的接收报告块中的时间标志结合起来，计算往返每个接收者所花的时间。接收者应让NTP时间戳的精度远大于其他时间戳的精度。时间戳测量的不确定性不可知，因此也无需指示。一个系统可能没有背景时钟的概念，而只有系统指定的时钟，如系统时间（system uptime）。在这样的系统中，此时钟可以作为参考计算相对NTP时间戳。选择一个公用的时名是非常重要的。这样多个独立的应用都可以使用相同的时钟。到2036年，相对和绝对NTP时间戳会产生大的差异。到那时，我们希望不再需要相对时钟。一个发送者，如果不用背景时钟时间或逝去时间，可以设置此项为零。 RTP时间戳：32比特 与以上的NTP时间标志对应同一时刻。与数据包中的RTP时间戳具有相同的单位和偏移量。这个一致性可以用来让NTP时间标志已经同步的源之间进行媒体内/间同步，还可以让与媒体无关的接收者估计名义RTP时钟频率。注意在大多数情况下此时间戳不等于任何临近的RTP包中的时间戳。RTP时间戳可以由相应的NTP时间戳计算得到。依据的是“RTP时间戳计数器”和“在采样时通过周期性检测背景时钟时间得到的实际时间”两者之间的关系。 （在RTCP SR包中有NTP时间戳、RTP时间戳，它们可以计算背景时钟和RTP时钟之间的对应关系，通过这个关系，可以由RTP数据包中的RTP时间戳计算也相应的回放时刻。这样就可以进行多个流的同步了。之所以要有NTP时间戳，是因为不同流的RTP时间戳有不同的随机偏移量，无法直接进行同步：笔者注。） 发送的报文数：32比特 从开始传输到此SR包产生时该发送者发送的RTP数据包总数。若发送者改变SSRC识别符，该计数器重设。 发送的字节文数：32比特 从开始传输到此SR包产生时该发送者在RTP数据包发送的字节总数(不包括头和填充)。若发送者改变SSRC识别符，该计数器重设。此域可以用来估计平均的负载数据发送速率。 第三部分：零到多个接收报告块。块数等于从上一个报告以来该发送者侦听到的其它源（不包括自身）的数目。每个接收报告块传输从某个同步源来的数据包的接收统计信息。若数据源因冲突而改变其SSRC标识符，接收者重新设置统计信息。这些统计信息有： SSRC_n(同步源标识符)：32比特 在此接收报告块中信息所属源的SSRC标识符。 丢包率：8比特 自从前一SR包或RR包发送以来，从SSRC_n传来的RTP数据包的丢失比例。以定点小数的形式表示。该值定义为损失包数／期望接收的包数。若由于包重复而导致包丢失数为负值，丢包率设为零。注意在收到上一个包后，接收者无法知道以后的包是否丢失。如：若在上一个接收报告间隔内从某个源发出的所有数据包都丢失，那么将不为此数据源发送接收报告块。 累计包丢失数：24比特 从开始接收到现在，从源SSRC_n发到本源的RTP数据包的丢包总数。该值定义为：期望接收的包数－实际接收的包数。接收的包括复制的或迟到的。由于迟到的包不算作损失，在发生复制时丢包数可能为负值。期望接收的包数定义为：扩展的上一接收序号(随后定义)减去最初接收序号。 接收到的扩展的最高序列号：32比特 低16比特包含从源SSRC_n来的最高接收序列号，高16比特用相应的序列号周期计数器扩展该序列号。注意在同一会议中的不同接收者，若启动时间明显不同，将产生不同的扩展项。 到达间隔抖动：32比特 RTP数据包到达时刻统计方差的估计值。测量单位同时间戳单位，用无符号整数表达。到达时间抖动定义为一对包中接收者相对发送者的时间间隔差值的平均偏差(平滑后的绝对值)。如以下等式所示，该值等于两个包相对传输时间的差值。相对传输时间是指：包的RTP时间戳和到达时刻接收者时钟时间的差值。若Si是包i中的RTP时间戳，Ri是包i到达时刻（单位为：RTP时间戳单位）。对于两个包i和j，D可以表示为 D(i，j)=(Rj-Sj)-(Ri-Si)； 到达时刻抖动可以在收到从源SSRC_n来的每个数据包i后连续计算。利用该包和前一包i-1的偏差D(按到达顺序，而非序号顺序)，根据公式J=J+(|D(i-1，i)|-J)/16计算。无论何时发送接收报告，都用当前的J值。 此处描述的抖动计算允许与协议独立的监视器对来自不同实现的报告进行有效的解释。 上一SR报文 (LSR)：32比特 接收到的来自源SSRC_n的最新RTCP发送者报告(SR)的64位NTP时间标志的中间32位。若还没有接收到SR，该域值为零。 自上一SR的时间(DLSR)：32比特 是从收到来自SSRC_n的SR包到发送此接收报告块之间的延时，以1/65536秒为单位。若还未收到来自SSRC_n的SR包，该域值为零。 假设SSRC_r为发出此接收报告块的接收者。源SSRC_n可以通过记录收到此接收报告块的时刻A来计算到SSRC_r的环路传输时延。可以利用最新的SR时间标志(LSR)计算整个环路时间A-LSR，然后减去此DLSR域得到环路传输的时延。 如下图所示。 [10 Nov 1995 11:33:25.125 UTC] [10 Nov 1995 11:33:36.5 UTC] n SR(n) A=b710:8000 (46864.500 s) —————————————————————-&gt; v ^ ntp_sec =0xb44db705 v ^ dlsr=0x0005:4000 ( 5.250s) ntp_frac=0x20000000 v ^ lsr =0xb705:2000 (46853.125s) (3024992005.125 s) v ^ r v ^ RR(n) —————————————————————-&gt; |&lt;-DLSR-&gt;| (5.250 s) A 0xb710:8000 (46864.500 s) DLSR -0x0005:4000 ( 5.250 s) LSR -0xb705:2000 (46853.125 s) delay 0x0006:2000 ( 6.125 s) 图2: 往返路程时间的计算举例 可以用此来近似测量到一组接收者的距离，尽管有些连接可能有非常不对称的时延。 6.4.2 RR：接收者报告包 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| RC | PT=RR=201 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of packet sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_1 (SSRC of first source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 1 | fraction lost | cumulative number of packets lost | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | extended highest sequence number received | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | interarrival jitter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | last SR (LSR) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | delay since last SR (DLSR) | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ report | SSRC_2 (SSRC of second source) | block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 2 : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | profile-specific extensions | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 接收者报告包(RR)与发送者报告包基本相同，除了包类型域包含常数201和没有发送者信息的5个字(NTP和RTP时间标志和发送者包和字节计数)。余下区域与SR包意义相同。若没有发送和接收据报告，在RTCP复合包头部加入空的RR包(RC=0)。 6.4.3发送者和接收者报告扩展 如果有额外的关于发送者和接收者的信息要周期性的，描述文件（profile）应该定义接收者报告和发送者报告描述文件扩展。此时，应采用这里的办法，而不是定义另外的RTCP包。因为这种办法需要的头部信息更少。 扩展部分是发送报告包和接收报告包的第四部分。如果有的话，应紧跟在接收报告块的后面。如果需要更多的发送者信息，它应当跟在发送者报告的开关，而不应在报告中出现。如果要包含进接收者的信息，它应该以块数组的方式放到接收报告块的后面。即这些块也应被计入RC字段中。 6.4.4分析发送者和接收者报告 接收质量反馈不仅对发送者有用，而且对于其它接收者和第三方监视器也有作用。发送者可以基于反馈修正发送信息量；接收者可以判断问题是本地的，区域内的还是全局的；网络管理者可以利用与协议无关的监视器(只接收RTCP包而不接收相应的RTP包)去评估多点传送网络的性能。 在发送者信息和接收者报告块中都连续统计丢包数，因此可以计算任何两个报告块中的差别。在短时间和长时间内都可以进行测算。最近收到的两个包之间差值可以评估当前传输质量。包中有NTP时间戳，可以用两个报告间隔的差值计算传输速率。由于此时间间隔与数据编码速率独立，因此可以实现与编码及协议独立的质量监视。 一个例子是计算两个报告间隔时间内的丢包率。丢包率＝此间隔内丢失的包／此间隔内期望收到的包。如果此值与“丢失比例”字段中的值相同，说明包是连续的；若否，说明包不是连续的。间隔时间内的丢包率／间隔时间＝每秒的丢包率。 从发送者信息中，第三方监视器可以在一个时间间隔内计算平均负载数据发送速率和平均发包速率，而无需考虑数据接收。两个值的比就是平均负载大小（平均每个包的负载大小）。（即：平均负载大小＝平均负载数据发送速率／平均发包率。）若能假定丢包与包的大小无关，那么某个特定接收者收到的包数乘以平均负载大小(或相应的包大小)就得出接收者可得到的外在吞吐量。 除了累计计数允许利用报告间差值进行长期包损测量外，单个报告的“丢包比例”字段提供一个短时测量数据。当会话规模增加到无法为所有接收者保存接收状态信息，或者报告间隔变得足够长以至于从一个特定接收者只能收到一个报告时，短时测量数据变得更重要。 到达间隔抖动字段提供另一个有关网络阻塞的短时测量量。丢包反映了长期阻塞，抖动测量反映出短时间的阻塞。抖动测量可以在导致丢包前预示阻塞。由于到达间隔抖动字段仅仅是发送报告时刻抖动的一个快照，因此需要在一个网络内在一段时间内分析来自某个接收者的报告，或者分析来自多个接收者的报告。 6.5源描述RTCP包 源描述（SDES）包由一个头及0个或多个块组成。每个块都由块中所标识的数据源的标识符及其后的各个描述构成。 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ header |V=2|P| SC | PT=SDES=202 | length | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ chunk | SSRC/CSRC_1 | 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SDES items | | … | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ chunk | SSRC/CSRC_2 | 2 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SDES items | | … | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ 6.6 BYE（BYE包） 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| SC | PT=BYE=203 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC/CSRC | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ : … : +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ (opt) | length | reason for leaving … +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ BYE包表明一个或多个源将要离开。如果混合器收到BYE包，混合器应当发送这个BYE包，并保持SSRC/CSRC不变。如果混合器关闭，应向贡献源列表中的所有SSRC，包括它自己的SSRC发送BYE包。BYE包可能会有选择的包含8个字节的统计字段，其后跟上几个字节的文本表明离开的原因。文本字符串编码格式和SDES中描述的相同。 9安全性 底层协议将最终提供由RTP应用要求的所有安全服务，包括真实性、完整性、保密性。这些服务在参考文献[27]中的IP协议有详细描述。由于使用RTP的初始音频和视频应用在IP层可用之前就要求保密性服务，因此，随后的一小节描述了使用RTP和RTCP的保密性服务。新的RTP应用可以实现这里描述的RTP保密性服务，以用于向后兼容，也可以实现替代这里的安全服务。这种安全服务的RTP开销是比较小的。因此，如果这项服务被将来的某种服务所替代，代价也是比较小的。 另一方面，RTP的其他服务，服务的其他实现及其他的算法可能会在将来定义。特别是为RTP负载提供可靠性的实时安全传输协议（ Secure Real-time Transport, SRTP）正在制定中。它可以使RTP头部不被加密。这样，链路层的头部压缩算法可以继续使用。SRTP基于高级企业标准（Advanced Encryption Standard, AES）制定。它比这里描述的服务提供更强健的安全性。 密钥和证书分配超出了本文的范围。 9.1 保密性 保密性意味着只有特定的接收者才能够对收到的包进行解码；对其他人，包里含有的都是无用信息。内容的保密性通过加密来实现。 当用这节指定的方法RTP、RTCP加密时，为了传输而封装的所有字节将在底层的包中作为一个单元加密。对RTCP，每个单元在加密之前必须在前面附加一个32字节的随机数。对RTP，不必在前面加前缀，而是让序列号和时间戳字段都用随机偏移量初始化。由于较差的随机性质。这其实是一个弱的初始化向量（initialization vector, IV）。另外，如果其后的SSRC字段被攻击者得到，则加密算法将出现新的薄弱点。 对RTCP，一个应用程序可能将RTCP复合包中的一个RTCP包分割成两个RTCP复合包。其中，一个在发送时加密，另一个发送时不加密。例如，SDES信息可能会被加密，但接收者报告却不加密，以适用于没有密钥的第三方监视者。如图4所示。源描述信息后必须附加没有报告的空RR包，以满足所有RTCP复合包必须以SR或RR包开头的要求。SDES的CNAME字段包含在加密或未加密的包中之一即可，但并不都需要包含。相同的源描述信息不应在两个包中都携带。否则会使加密算法不安全。 UDP packet UDP packet [random][RR][SDES #CNAME …] [SR #senderinfo #site1 #site2] encrypted not encrypted #: SSRC identifier 图4: 加密的和未加密的RTCP包 接收者加密的使用和正确密钥的使用通过头或负载的有效性检查进行确认。RTP和RTCP头的有效性检查由附录A.1和A.2给出。 为和RFC1889中RTP初始描述中的实现相一致。默认的算法是链式加密块模式（cipher block chaining (CBC) mode）下的数据加密算法，见RFC1423中1.1节的描述。除非出现由5.1节描述指明的填充多个字节的情况，否则，初始的随机向量是0，因为随机值由RTP头或RTCP复合包的随机前缀提供。CBC初始向量的细节见参考文献[30]。支持本节的加密算法的实现也应当支持CBC下的DES算法。因为此算法可实现最大程度的交互可操作性。采用这种方法的原因是，因特网上通过音频、视频工具做实验证明它简便且有效。但DES被发现很容易被破解。建议用更强健的加密算法，例如三层DES加密算法来代替默认的加密算法。另外，安全CBC模式要求每个包的第一个块和一个随机数求异或。对于RTCP，这通过在每个包前附加一个32位的随机数实现。每个包的随机数相互独立。对RTP，时间戳和序列号将从附加的数值开始，但对连续的包，它们并不是被独立的随机化的。应该注意到对RTP和RTCP，这种随机性都受到了限制。高安全性的应用应当考虑其他更加简捷安全的方法。其他加密算法应通过非RTP方法对一个会话动态指定。特别是基于AES的SRTP描述文件（见参考文献[23]）将会是未来的一个不错的选择。以上描述了IP层或RTP层加密。作为它的替代，描述文件可以定义另外的负载类型以用于加密、编码。这些编码必须描述如何填充，以及编码的其他方面如何控制。这种方法可以按照应用的要求，只加密数据，不加密头部。这可能对同时处理解密和解码的硬件服务特别重要。这也可能对RTP和底层头部的链路层的应用很有用。既然头部的加密已经进行了压缩，负载（而不是地址）的保密性就足够了。 9.2 真实性和信息完整性 真实性和信息完整性没有在RTP层定义，因为这些服务离不开密钥管理体系。可以期望真实性和信息完整性将由底层协议完成。 10 拥塞控制 因特网上的所有传输协议都需要通过一些方法进行地址拥塞控制（见参考文献[31]），RTP也不例外。但由于RTP数据传输经常缺少弹性（以固定的或控制好的速率产生包）。因此，RTP的拥塞控制方法和其他的传输协议，如TCP很不相同。在某种程度上，缺乏弹性意味着降低了拥塞的风险。因为RTP流不会像TCP流那样增长到消耗掉所有可用的带宽程度。但是，缺乏弹性也意味着RTP流不能任意减小它在网络上的负载量，以在出现拥塞时消除之。 由于RTP可能会在许多不同的情况下用于相当广的。因此就没有一个全都通用一个拥塞控制机制。因此，拥塞控制应当在描述文件中定义。对于某些描述，可能加上可应用性陈述以限制描述应用在已设计消除拥塞的环境中。对其它描述，可能需要特别的方法，如基于RTCP反馈的自适应数据传输速率。 参考文献： 正式参考文献 [1] Schulzrinne, H. and S. Casner, “音频和视频会议最小控制的RTP描述”, RFC 3551, 2003.6 [2] Bradner, S., “表示需求层的RFC关键字”, BCP 14, RFC 2119, 1997.3 [3] Postel, J., “网络协议”, STD 5, RFC 791, 1981.9 [4] Mills, D., “网络时间协议（第三版）描述、实现和分析”, RFC 1305,1992.3 [5] Yergeau, F., “UTF-8, 一个ISO 10646传输格式”, RFC 2279,1998.1 [6] Mockapetris, P., “域名――概念和工具”, STD 13, RFC 1034,1987.11 [7] Mockapetris, P., “域名――实现和描述”, STD 13, RFC 1035,1987.1 [8] Braden, R., “因特网主机需求――应用和支持”, STD 3, RFC 1123,1989.10 [9] Resnick, P., “因特网信息格式”, RFC 2822,2001.4 非正式参考文献 [10] Clark, D. and D. Tennenhouse, “新一代协议的建构考虑,” 关于通信体系结构和协议的数据通信专业组讨论班, (宾夕法尼亚州，费城), IEEE 计算机通信回顾 卷. 20(4), 200－208页,1990.9 [11] Schulzrinne, H., “关于设计音频、视频会话传输协议及其它多参与者实时应用的讨论”, 1993.10 [12] Comer, D., TCP/IP网络协议 ,卷1. Englewood Cliffs, New Jersey: Prentice Hall, 1991. [13] Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A.,Peterson, J., Sparks, R., Handley, M. and E. Schooler, “SIP:会话初始协议”, RFC 3261,2002.6 [14] International Telecommunication Union, “对不保证质量的局域网的可视电话系统和设备”, Recommendation H.323,ITU的无线电通讯标准一节, Geneva, Switzerland, 2003.7 [15] Handley, M. and V. Jacobson, “SDP: 会话描述协议”, RFC 2327,1998.4 [16] Schulzrinne, H., Rao, A. and R. Lanphier, “实时流协议(RTSP)”, RFC 2326,1998.4 [17] Eastlake 3rd, D., Crocker, S. and J. Schiller, “关于安全性的随机化建议”, RFC 1750, 1994.12 [18] Bolot, J.-C., Turletti, T. and I. Wakeman, “因特网多播视频分布的可升级的反馈控制”,关于通信体系结构和协议的数据通信专业组讨论班（英国，伦敦）, ACM,58—67页, 1994.8 [19] Busse, I., Deffner, B. and H. Schulzrinne, “基于RTP的多媒体应用的动态 QoS控制”, 计算机通讯,卷19,49—58页,1996.1 [20] Floyd, S. and V. Jacobson, “周期性路由信息的同步”,关于通信体系结构和协议的数据通信专业组讨论班 (旧金山,加利福尼亚), 33—44页, ACM,1993.9 并参见[34]. [21] Rosenberg, J. and H. Schulzrinne, “RTP中成员组的采样”, RFC 2762,2000.2 [22] Cadzow, J., “纽约数字信号处理和数据分析基础” 纽约: Macmillan, 1987. [23] Hinden, R. and S. Deering, “IPv6地址结构”, RFC 3513,2003.4 [24] Rekhter, Y., Moskowitz, B., Karrenberg, D., de Groot, G. and E.Lear, “保密因特网中的地址分配”, RFC 1918,1996.2 [25] Lear, E., Fair, E., Crocker, D. and T. Kessler, “考虑可能有害的网络10 (一些实现不应成为标准)”, RFC 1627,1994.7 [26] Feller, W.,概率论及其应用入门,卷1. 纽约: John Wiley and Sons , 1968. [27] Kent, S. and R. Atkinson, “因特网协议的安全体系”, RFC 2401,1998.11 [28] Baugher, M., Blom, R., Carrara, E., McGrew, D., Naslund, M.,Norrman, K. and D. Oran, “安全实时传输协议”,2003.4 [29] Balenson, D., “增强因特网电子邮件的保密性:第三部分”, RFC 1423,1993.2 [30] Voydock, V. and S. Kent, “高层网络协议的安全机制”, ACM 计算调查,卷15,135-171页,1983.6 [31] Floyd, S., “拥塞控制原理”, BCP 41, RFC 2914,2000.9 [32] Rivest, R., “MD5通讯――算法摘要”, RFC 1321,1992.4 [33] Stubblebine, S., “多媒体会话的安全服务”, 第16届国际安全会议，(巴尔的摩,马里兰州),391—395页,1993.9 [34] Floyd, S. and V. Jacobson, “周期路由信息同步”, IEEE/ACM 网络传输,卷2,122—136页,1994.4]]></content>
      <categories>
        <category>RFC</category>
      </categories>
      <tags>
        <tag>协议</tag>
        <tag>RTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc-source-android]]></title>
    <url>%2F2017%2F07%2F15%2Fwebrtc-source-android%2F</url>
    <content type="text"><![CDATA[nativeCreateVideoSource 初始化PeerConnectionFactory(pc/peerconnectionfactory) 创建PeerConnection方法中: 12345678910111213141516171819202122232425262728293031rtc::scoped_refptr&lt;PeerConnectionInterface&gt;PeerConnectionFactory::CreatePeerConnection( const PeerConnectionInterface::RTCConfiguration&amp; configuration, std::unique_ptr&lt;cricket::PortAllocator&gt; allocator, std::unique_ptr&lt;rtc::RTCCertificateGeneratorInterface&gt; cert_generator, PeerConnectionObserver* observer) &#123; RTC_DCHECK(signaling_thread_-&gt;IsCurrent()); if (!cert_generator.get()) &#123; // No certificate generator specified, use the default one. cert_generator.reset( new rtc::RTCCertificateGenerator(signaling_thread_, network_thread_)); &#125; if (!allocator) &#123; allocator.reset(new cricket::BasicPortAllocator( default_network_manager_.get(), default_socket_factory_.get())); &#125; network_thread_-&gt;Invoke&lt;void&gt;( RTC_FROM_HERE, rtc::Bind(&amp;cricket::PortAllocator::SetNetworkIgnoreMask, allocator.get(), options_.network_ignore_mask)); rtc::scoped_refptr&lt;PeerConnection&gt; pc( new rtc::RefCountedObject&lt;PeerConnection&gt;(this)); if (!pc-&gt;Initialize(configuration, std::move(allocator), std::move(cert_generator), observer)) &#123; return nullptr; &#125; return PeerConnectionProxy::Create(signaling_thread(), pc);&#125; 构造PeerConnection对象pc,并调用初始化方法Initialize,Initialize中: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182ool PeerConnection::Initialize( const PeerConnectionInterface::RTCConfiguration&amp; configuration, std::unique_ptr&lt;cricket::PortAllocator&gt; allocator, std::unique_ptr&lt;rtc::RTCCertificateGeneratorInterface&gt; cert_generator, PeerConnectionObserver* observer) &#123; TRACE_EVENT0(&quot;webrtc&quot;, &quot;PeerConnection::Initialize&quot;); if (!allocator) &#123; LOG(LS_ERROR) &lt;&lt; &quot;PeerConnection initialized without a PortAllocator? &quot; &lt;&lt; &quot;This shouldn&apos;t happen if using PeerConnectionFactory.&quot;; return false; &#125; if (!observer) &#123; // TODO(deadbeef): Why do we do this? LOG(LS_ERROR) &lt;&lt; &quot;PeerConnection initialized without a &quot; &lt;&lt; &quot;PeerConnectionObserver&quot;; return false; &#125; observer_ = observer; port_allocator_ = std::move(allocator); // The port allocator lives on the network thread and should be initialized // there. if (!network_thread()-&gt;Invoke&lt;bool&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnection::InitializePortAllocator_n, this, configuration))) &#123; return false; &#125; // Call must be constructed on the worker thread. factory_-&gt;worker_thread()-&gt;Invoke&lt;void&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnection::CreateCall_w, this)); session_.reset(new WebRtcSession( call_.get(), factory_-&gt;channel_manager(), configuration.media_config, event_log_.get(), factory_-&gt;network_thread(), factory_-&gt;worker_thread(), factory_-&gt;signaling_thread(), port_allocator_.get(), std::unique_ptr&lt;cricket::TransportController&gt;( factory_-&gt;CreateTransportController( port_allocator_.get(), configuration.redetermine_role_on_ice_restart)),#ifdef HAVE_SCTP std::unique_ptr&lt;cricket::SctpTransportInternalFactory&gt;( new cricket::SctpTransportFactory(factory_-&gt;network_thread()))#else nullptr#endif )); stats_.reset(new StatsCollector(this)); stats_collector_ = RTCStatsCollector::Create(this); // Initialize the WebRtcSession. It creates transport channels etc. if (!session_-&gt;Initialize(factory_-&gt;options(), std::move(cert_generator), configuration)) &#123; return false; &#125; // Register PeerConnection as receiver of local ice candidates. // All the callbacks will be posted to the application from PeerConnection. session_-&gt;RegisterIceObserver(this); session_-&gt;SignalState.connect(this, &amp;PeerConnection::OnSessionStateChange); session_-&gt;SignalVoiceChannelCreated.connect( this, &amp;PeerConnection::OnVoiceChannelCreated); session_-&gt;SignalVoiceChannelDestroyed.connect( this, &amp;PeerConnection::OnVoiceChannelDestroyed); session_-&gt;SignalVideoChannelCreated.connect( this, &amp;PeerConnection::OnVideoChannelCreated); session_-&gt;SignalVideoChannelDestroyed.connect( this, &amp;PeerConnection::OnVideoChannelDestroyed); session_-&gt;SignalDataChannelCreated.connect( this, &amp;PeerConnection::OnDataChannelCreated); session_-&gt;SignalDataChannelDestroyed.connect( this, &amp;PeerConnection::OnDataChannelDestroyed); session_-&gt;SignalDataChannelOpenMessage.connect( this, &amp;PeerConnection::OnDataChannelOpenMessage); configuration_ = configuration; return true;&#125; 调用CreateCall_w创建call对象: 12345678910111213141516void PeerConnection::CreateCall_w() &#123; RTC_DCHECK(!call_); const int kMinBandwidthBps = 30000; const int kStartBandwidthBps = 300000; const int kMaxBandwidthBps = 2000000; webrtc::Call::Config call_config(event_log_.get()); call_config.audio_state = factory_-&gt;channel_manager() -&gt;media_engine()-&gt;GetAudioState(); call_config.bitrate_config.min_bitrate_bps = kMinBandwidthBps; call_config.bitrate_config.start_bitrate_bps = kStartBandwidthBps; call_config.bitrate_config.max_bitrate_bps = kMaxBandwidthBps; call_.reset(webrtc::Call::Create(call_config));&#125; 使用call对象以及PeerConnectionFactory中channelmanager(PeerConnectionFactory中Initialize中创建)构造WebRtcSession对象session,调用Initialize方法初始化session,初始化session槽函数等.session_初始化方法中创建WebRtcSessionDescriptionFactory对象webrtc_session_descfactory. 创建ChannelWebRtcSession::SetLocalDescription: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051bool WebRtcSession::SetLocalDescription(SessionDescriptionInterface* desc, std::string* err_desc) &#123; RTC_DCHECK(signaling_thread()-&gt;IsCurrent()); // Takes the ownership of |desc| regardless of the result. std::unique_ptr&lt;SessionDescriptionInterface&gt; desc_temp(desc); // Validate SDP. if (!ValidateSessionDescription(desc, cricket::CS_LOCAL, err_desc)) &#123; return false; &#125; // Update the initial_offerer flag if this session is the initial_offerer. Action action = GetAction(desc-&gt;type()); if (state() == STATE_INIT &amp;&amp; action == kOffer) &#123; initial_offerer_ = true; transport_controller_-&gt;SetIceRole(cricket::ICEROLE_CONTROLLING); &#125; if (action == kAnswer) &#123; current_local_description_.reset(desc_temp.release()); pending_local_description_.reset(nullptr); current_remote_description_.reset(pending_remote_description_.release()); &#125; else &#123; pending_local_description_.reset(desc_temp.release()); &#125; // Transport and Media channels will be created only when offer is set. if (action == kOffer &amp;&amp; !CreateChannels(local_description()-&gt;description())) &#123; // TODO(mallinath) - Handle CreateChannel failure, as new local description // is applied. Restore back to old description. return BadLocalSdp(desc-&gt;type(), kCreateChannelFailed, err_desc); &#125; // Remove unused channels if MediaContentDescription is rejected. RemoveUnusedChannels(local_description()-&gt;description()); if (!UpdateSessionState(action, cricket::CS_LOCAL, err_desc)) &#123; return false; &#125; if (remote_description()) &#123; // Now that we have a local description, we can push down remote candidates. UseCandidatesInSessionDescription(remote_description()); &#125; pending_ice_restarts_.clear(); if (error() != ERROR_NONE) &#123; return BadLocalSdp(desc-&gt;type(), GetSessionErrorMsg(), err_desc); &#125; return true;&#125; action为offer时CreateChannel创建channels: 123456789101112131415161718192021222324252627282930313233343536373839bool WebRtcSession::CreateChannels(const SessionDescription* desc) &#123; const cricket::ContentGroup* bundle_group = nullptr; if (bundle_policy_ == PeerConnectionInterface::kBundlePolicyMaxBundle) &#123; bundle_group = desc-&gt;GetGroupByName(cricket::GROUP_TYPE_BUNDLE); if (!bundle_group) &#123; LOG(LS_WARNING) &lt;&lt; &quot;max-bundle specified without BUNDLE specified&quot;; return false; &#125; &#125; // Creating the media channels and transport proxies. const cricket::ContentInfo* voice = cricket::GetFirstAudioContent(desc); if (voice &amp;&amp; !voice-&gt;rejected &amp;&amp; !voice_channel_) &#123; if (!CreateVoiceChannel(voice, GetBundleTransportName(voice, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create voice channel.&quot;; return false; &#125; &#125; const cricket::ContentInfo* video = cricket::GetFirstVideoContent(desc); if (video &amp;&amp; !video-&gt;rejected &amp;&amp; !video_channel_) &#123; if (!CreateVideoChannel(video, GetBundleTransportName(video, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create video channel.&quot;; return false; &#125; &#125; const cricket::ContentInfo* data = cricket::GetFirstDataContent(desc); if (data_channel_type_ != cricket::DCT_NONE &amp;&amp; data &amp;&amp; !data-&gt;rejected &amp;&amp; !rtp_data_channel_ &amp;&amp; !sctp_transport_) &#123; if (!CreateDataChannel(data, GetBundleTransportName(data, bundle_group))) &#123; LOG(LS_ERROR) &lt;&lt; &quot;Failed to create data channel.&quot;; return false; &#125; &#125; return true;&#125; CreateChannels中创建三个Channel,其中CreateVideoChannel创建视频Channel: 123456789101112131415161718192021222324252627282930313233343536373839404142bool WebRtcSession::CreateVideoChannel(const cricket::ContentInfo* content, const std::string* bundle_transport) &#123; bool require_rtcp_mux = rtcp_mux_policy_ == PeerConnectionInterface::kRtcpMuxPolicyRequire; std::string transport_name = bundle_transport ? *bundle_transport : content-&gt;name; cricket::DtlsTransportInternal* rtp_dtls_transport = transport_controller_-&gt;CreateDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); cricket::DtlsTransportInternal* rtcp_dtls_transport = nullptr; if (!require_rtcp_mux) &#123; rtcp_dtls_transport = transport_controller_-&gt;CreateDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTCP); &#125; video_channel_.reset(channel_manager_-&gt;CreateVideoChannel( call_, media_config_, rtp_dtls_transport, rtcp_dtls_transport, transport_controller_-&gt;signaling_thread(), content-&gt;name, SrtpRequired(), video_options_)); if (!video_channel_) &#123; transport_controller_-&gt;DestroyDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); if (rtcp_dtls_transport) &#123; transport_controller_-&gt;DestroyDtlsTransport( transport_name, cricket::ICE_CANDIDATE_COMPONENT_RTP); &#125; return false; &#125; video_channel_-&gt;SignalRtcpMuxFullyActive.connect( this, &amp;WebRtcSession::DestroyRtcpTransport_n); video_channel_-&gt;SignalDtlsSrtpSetupFailure.connect( this, &amp;WebRtcSession::OnDtlsSrtpSetupFailure); SignalVideoChannelCreated(); video_channel_-&gt;SignalSentPacket.connect(this, &amp;WebRtcSession::OnSentPacket_w); return true;&#125; 调用channel_manager的CreateVideoChannel创建BaseChannel基类的cricket::VideoChannel. VideoChannel需要传入VideoMediaChannel作为构造参数: 1234567891011121314151617181920212223242526272829303132//pc/channelmanager.h/ccVideoChannel* ChannelManager::CreateVideoChannel_w( webrtc::Call* call, const cricket::MediaConfig&amp; media_config, DtlsTransportInternal* rtp_dtls_transport, DtlsTransportInternal* rtcp_dtls_transport, rtc::PacketTransportInternal* rtp_packet_transport, rtc::PacketTransportInternal* rtcp_packet_transport, rtc::Thread* signaling_thread, const std::string&amp; content_name, bool srtp_required, const VideoOptions&amp; options) &#123; RTC_DCHECK(initialized_); RTC_DCHECK(worker_thread_ == rtc::Thread::Current()); RTC_DCHECK(nullptr != call); VideoMediaChannel* media_channel = media_engine_-&gt;CreateVideoChannel( call, media_config, options); if (media_channel == NULL) &#123; return NULL; &#125; VideoChannel* video_channel = new VideoChannel( worker_thread_, network_thread_, signaling_thread, media_channel, content_name, rtcp_packet_transport == nullptr, srtp_required); if (!video_channel-&gt;Init_w(rtp_dtls_transport, rtcp_dtls_transport, rtp_packet_transport, rtcp_packet_transport)) &#123; delete video_channel; return NULL; &#125; video_channels_.push_back(video_channel); return video_channel;&#125; VideoMediaChannel实例media_channel由MediaEngineInterface对象media_engine创建,media_engine由ChannelManager构造方法传入并初始化,ChannelManager由PeerConnectionFactory创建,在PeerConnection初始化方法中,media_engine被创建: 123456789101112131415161718192021222324252627282930313233343536373839404142//pc/peerconnectionfactory.ccbool PeerConnectionFactory::Initialize() &#123; RTC_DCHECK(signaling_thread_-&gt;IsCurrent()); rtc::InitRandom(rtc::Time32()); default_network_manager_.reset(new rtc::BasicNetworkManager()); if (!default_network_manager_) &#123; return false; &#125; default_socket_factory_.reset( new rtc::BasicPacketSocketFactory(network_thread_)); if (!default_socket_factory_) &#123; return false; &#125; std::unique_ptr&lt;cricket::MediaEngineInterface&gt; media_engine = worker_thread_-&gt;Invoke&lt;std::unique_ptr&lt;cricket::MediaEngineInterface&gt;&gt;( RTC_FROM_HERE, rtc::Bind(&amp;PeerConnectionFactory::CreateMediaEngine_w, this)); channel_manager_.reset(new cricket::ChannelManager( std::move(media_engine), worker_thread_, network_thread_)); channel_manager_-&gt;SetVideoRtxEnabled(true); if (!channel_manager_-&gt;Init()) &#123; return false; &#125; return true;&#125;std::unique_ptr&lt;cricket::MediaEngineInterface&gt;PeerConnectionFactory::CreateMediaEngine_w() &#123; RTC_DCHECK(worker_thread_ == rtc::Thread::Current()); return std::unique_ptr&lt;cricket::MediaEngineInterface&gt;( cricket::WebRtcMediaEngineFactory::Create( default_adm_.get(), audio_encoder_factory_, audio_decoder_factory_, video_encoder_factory_.get(), video_decoder_factory_.get(), external_audio_mixer_));&#125; WebRtcMediaEngine2继承自CompositeMediaEngine,CompositeMediaEngine父类MediaEngineInterface有WebRtcVoiceEngine voice与WebRtcVideoEngine2 video两个对象 WebRtcVideoEngine2WebRtcVideoEngine2定义在media/engine/webrtcvideoengine2.h下,用于创建WebRtcVideoChannel2(定义在同一头文件),WebRtcVideoChannel2定义了WebRtcVideoSendStream与WebRtcVideoReceiveStream两个内部类.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRtc源码分析(1) PeerConnection]]></title>
    <url>%2F2017%2F07%2F11%2Fwebrtc-source-peerconnection%2F</url>
    <content type="text"><![CDATA[ChannelManagerpc/channelmanager.h 12345678// ChannelManager allows the MediaEngine to run on a separate thread, and takes// care of marshalling calls between threads. It also creates and keeps track of// voice and video channels; by doing so, it can temporarily(暂时的) pause all the// channels when a new audio or video device is chosen. The voice and video// channels are stored in separate vectors, to easily allow operations on just// voice or just video channels.// ChannelManager also allows the application to discover what devices it has// using device manager. WebRtcSession构造中通过MediaControllerInterface初始化ChannelManager变量channelmanager , ChannelManager通过构造传入MediaEngineInterface. WebRtcSessionpc/webrtcsession.h 1234567// A WebRtcSession manages general session state. This includes negotiation// of both the application-level and network-level protocols: the former// defines what will be sent and the latter defines how it will be sent. Each// network-level protocol is represented by a Transport object. Each Transport// participates in the network-level negotiation. The individual streams of// packets are represented by TransportChannels. The application-level protocol// is represented by SessionDecription objects. MediaControllerInterfacepc/mediacontroller.h 123// The MediaController currently owns shared state between media channels.// Abstract interface is defined here such that it can be faked/mocked for// tests, but no other real reason. 实现类MediaController,管理ChannelManager,cricket::ChannelManager* const channel_manager_;,在PeerConnection的Initialize方法中,通过PeerConnectionFactory创建.PeerConnectionFactory中Initialize中真正创建ChannelManager,创建ChannelManager之前,先创建出MediaEngine,实际在PeerConnectionFactory::CreateMediaEngine_w中通过cricket::WebRtcMediaEngineFactory::Create创建. 7&gt; Downloading src/resources/voice_engine/audio_tiny44.wav… 4&gt; Downloading src/resources/voice_engine/audio_tiny48.wav… 2&gt; Downloading src/resources/voice_engine/audio_tiny8.wav… Hook ‘download_from_google_storage –directory –recursive –num_threads=10 –no_auth –quiet –bucket chromium-webrtc-resources src/resources’ took 528.97 secs WARNING: ‘src/testing/gmock’ has been moved from DEPS to a higher level checkout. The git folder containing all the local branches has been saved to /Users/shenjunwei/soft-source/webrtc/old_src_testing_gmock.git. If you don’t care about its state you can safely remove that folder to free up space. WARNING: ‘src/testing/gtest’ has been moved from DEPS to a higher level checkout. The git folder containing all the local branches has been saved to /Users/shenjunwei/soft-source/webrtc/old_src_testing_gtest.git. If you don’t care about its state you can safely remove that folder to free up space.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于内存对齐那些事]]></title>
    <url>%2F2017%2F07%2F09%2Ftips-about-data-structure-alignment%2F</url>
    <content type="text"><![CDATA[Wrote by mutouyun. 1. 内存对齐（Data Structure Alignment）是什么内存对齐，或者说字节对齐，是一个数据类型所能存放的内存地址的属性（Alignment is a property of a memory address）。 这个属性是一个无符号整数，并且这个整数必须是2的N次方（1、2、4、8、……、1024、……）。 当我们说，一个数据类型的内存对齐为8时，意思就是指这个数据类型所定义出来的所有变量，其内存地址都是8的倍数。 当一个基本数据类型（fundamental types）的对齐属性，和这个数据类型的大小相等时，这种对齐方式称作自然对齐（naturally aligned）。 比如，一个4字节大小的int型数据，默认情况下它的字节对齐也是4。 2. 为什么我们需要内存对齐这是因为，并不是每一个硬件平台都能够随便访问任意位置的内存的。 微软的MSDN里有这样一段话： Many CPUs, such as those based on Alpha, IA-64, MIPS, and SuperH architectures, refuse to read misaligned data. When a program requests that one of these CPUs access data that is not aligned, the CPU enters an exception state and notifies the software that it cannot continue. On ARM, MIPS, and SH device platforms, for example, the operating system default is to give the application an exception notification when a misaligned access is requested. 大意是说，有不少平台的CPU，比如Alpha、IA-64、MIPS还有SuperH架构，若读取的数据是未对齐的（比如一个4字节的int在一个奇数内存地址上），将拒绝访问，或抛出硬件异常。 另外，在维基百科里也记载着如下内容： Data alignment means putting the data at a memory offset equal to some multiple of the word size, which increases the system’s performance due to the way the CPU handles memory. 意思是，考虑到CPU处理内存的方式（32位的x86 CPU，一个时钟周期可以读取4个连续的内存单元，即4字节），使用字节对齐将会提高系统的性能（也就是CPU读取内存数据的效率。比如你一个int放在奇数内存位置上，想把这4个字节读出来，32位CPU就需要两次。但对齐之后一次就可以了）。 3. 内存对齐带来的数据结构大小变化因为有了内存对齐，因此数据在内存里的存放就不是紧挨着的，而是可能会出现一些空隙（Data Structure Padding，也就是用于填充的空白内容）。因此对基本数据类型来说可能还好说，对于一个内部有多个基本类型的结构体（struct）或类而言，sizeof的结果往往和想象中不大一样。 让我们来看一个例子： 12345678struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; 我们可以看到，MyStruct中有5个成员，如果直接相加的话大小应该是16，但在32位MSVC里它的sizeof结果是32。 之所以结果出现偏差，为了保证这个结构体里的每个成员都应该在它对齐了的内存位置上，而在某些位置插入了Padding。 下面我们尝试考虑内存对齐，来计算一下这个结构体的大小。首先，我们可以假设MyStruct的整体偏移从0x00开始，这样就可以暂时忽略MyStruct本身的对齐。这时，结构体的整体内存分布如下图所示： 我们可以看到，char和int之间；short和long long之间，为了保证成员各自的对齐属性，分别插入了一些Padding。 因此整个结构体会被填充得看起来像这样： 123456789101112struct MyStruct &#123; char a; // 1 byte char pad_0[3]; // Padding 3 int b; // 4 bytes short c; // 2 bytes char pad_1[6]; // Padding 6 long long d; // 8 bytes char e; // 1 byte char pad_2[7]; // Padding 7 &#125;; 注意到上面加了Padding的示意结构体里，e的后面还跟了7个字节的填充。这是因为结构体的整体大小必须可被对齐值整除，所以“char e”的后面还会被继续填充7个字节好让结构体的整体大小是8的倍数32。 我们可以在gcc + 32位linux中尝试计算sizeof(MyStruct)，得到的结果是24。 这是因为gcc中的对齐规则和MSVC不一样，不同的平台下会使用不同的默认对齐值（The default alignment is fixed for a particular target ABI）。在gcc + 32位linux中，大小超过4字节的基本类型仍然按4字节对齐。因此MyStruct的内存布局这时看起来应该像这个样子： 下面我们来确定这个结构体类型本身的内存对齐是多少。为了保证结构体内的每个成员都能够放在它自然对齐的位置上，对这个结构体本身来说最理想的内存对齐数值应该是结构体里内存对齐数值最大的成员的内存对齐数。 也就是说，对于上面的MyStruct，结构体类型本身的内存对齐应该是8。并且，当我们强制对齐方式小于8时，比如设置MyStruct对齐为2，那么其内部成员的对齐也将被强制不能超过2。 为什么？因为对于一个数据类型来说，其内部成员的位置应该是相对固定的。假如上面这个结构体整体按1或者2字节对齐，而成员却按照各自的方式自然对齐，就有可能出现成员的相对偏移量随内存位置而改变的问题。 比如说，我们可以画一下整个结构体按1字节对齐，并且结构体内的每个成员按自然位置对齐的内存布局： 上面的第一种情况，假设MyStruct的起始地址是0x01（因为结构体本身的偏移按1字节对齐），那么char和int之间将会被填充2个字节的Padding，以保证int的对齐还是4字节。 如果第二次分配MyStruct的内存时起始地址变为0x03，由于int还是4字节对齐，则char和int之间将不会填充Padding（填充了反而不对齐了）。 以此类推，若MyStruct按1字节对齐时不强制所有成员的对齐均不超过1的话，这个结构体里的相对偏移方式一共有4种。 因此对于结构体来说，默认的对齐将等于其中对齐最大的成员的对齐值。并且，当我们限定结构体的内存对齐时，同时也限定了结构体内所有成员的内存对齐不能超过结构体本身的内存对齐。 4. 指定内存对齐在C++98/03里，对内存对齐的操作在不同的编译器里可能有不同的方法。 在MSVC中，一般使用#progma pack来指定内存对齐： 12345678910#pragma pack(1) // 指定后面的内容内存对齐为1 struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; #pragma pack() // 还原默认的内存对齐 这时，MyStruct由于按1字节对齐，其中的所有成员都将变为1字节对齐，因此sizeof(MyStruct)将等于16。 还有另外一个简单的方法： 12345678__declspec(align(64)) struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; __declspec(align(64))将指定内存对齐为64。比较坑的是，这种方法不能指定内存对齐小于默认对齐，也就是说它只能调大不能调小（__declspec(align(#)) can only increase alignment restrictions）。因此下面这样写会忽略掉declspec： 12__declspec(align(1)) struct MyStruct // ... // warning C4359: &apos;MyStruct&apos;: Alignment specifier is less than actual alignment (8), and will be ignored. 微软的__declspec(align(#))，其#的内容可以是预编译宏，但不能是编译期数值： 12345678#define XX 32 struct __declspec(align(XX)) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY&gt; struct __declspec(align(YY)) MyStruct_2 &#123;&#125;; // error C2059: syntax error: &apos;identifier&apos; static const unsigned ZZ = 32; struct __declspec(align(ZZ)) MyStruct_3 &#123;&#125;; // error C2057: expected constant expression 在Visual C++ Compiler November 2013 CTP之后，微软终于支持编译期数值的写法了： 123template &lt;size_t YY&gt; struct __declspec(align(YY)) MyStruct_2 &#123;&#125;; // OK in 2013 CTP __declspec(align(#))最大支持对齐为8192（Valid entries are integer powers of two from 1 to 8192）。 下面再来看gcc。gcc和MSVC一样，可以使用#pragma pack： 123456#pragma pack(1) struct MyStruct &#123; // ... &#125;; #pragma pack() 另外，也可以使用__attribute__((__aligned__((#))))： 123456789struct __attribute__((__aligned__((1)))) MyStruct_1 &#123; // ... &#125;; struct MyStruct_2 &#123; // ... &#125; __attribute__((__aligned__((1)))); 这东西写上面写下面都是可以的，但是不能写在struct前面。 和MSVC一样，__attribute__也只能把字节对齐改大，不能改小（The aligned attribute can only increase the alignment）。比较坑的是当你试图改小的时候，gcc没有任何编译提示信息。 gcc可以接受一个宏或编译期数值： 12345678910#define XX 1 struct __attribute__((__aligned__((XX)))) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY&gt; struct __attribute__((__aligned__((YY)))) MyStruct_2 &#123;&#125;; // OK static const unsigned ZZ = 1; struct __attribute__((__aligned__((ZZ)))) MyStruct_3 &#123;&#125;; // ^ // error: requested alignment is not an integer constant gcc的__attribute__((__aligned__((#))))支持的上限受限于链接器（Note that the effectiveness of aligned attributes may be limited by inherent limitations in your linker）。 5. 获得内存对齐同样的，在C++98/03里，不同的编译器可能有不同的方法来获得一个类型的内存对齐。 MSVC使用__alignof操作符获得内存对齐大小： 123MyStruct xx; std::cout &lt;&lt; __alignof(xx) &lt;&lt; std::endl; std::cout &lt;&lt; __alignof(MyStruct) &lt;&lt; std::endl; gcc则使用__alignof__： 123MyStruct xx; std::cout &lt;&lt; __alignof__(xx) &lt;&lt; std::endl; std::cout &lt;&lt; __alignof__(MyStruct) &lt;&lt; std::endl; 需要注意的是，不论是__alignof还是__alignof__，对于对齐的计算都发生在编译期。因此像下面这样写： 123int a; char&amp; c = reinterpret_cast&lt;char&amp;&gt;(a); std::cout &lt;&lt; __alignof__(c) &lt;&lt; std::endl; 得到的结果将是1。 如果需要在运行时动态计算一个变量的内存对齐，比如根据一个void*指针指向的内存地址来判断这个地址的内存对齐是多少，我们可以用下面这个简单的方法： 1234__declspec(align(128)) long a = 0; size_t x = reinterpret_cast&lt;size_t&gt;(&amp;a); x &amp;= ~(x - 1); // 计算a的内存对齐大小 std::cout &lt;&lt; x &lt;&lt; std::endl; 用这种方式得到的内存对齐大小可能比实际的大，因为它是切实的获得这个内存地址到底能被多大的2^N整除。 6. 堆内存的内存对齐我们在讨论内存对齐的时候很容易忽略掉堆内存。我们经常会使用malloc分配内存，却不理会这块内存的对齐方式，仿佛堆内存不需要考虑内存对齐一样。 实际上，malloc一般使用当前平台默认的最大内存对齐数对齐内存。比如MSVC在32位下一般是8字节对齐；64位下则是16字节（In Visual C++, the fundamental alignment is the alignment that’s required for a double, or 8 bytes. In code that targets 64-bit platforms, it’s 16 bytes）。这样对于常规的数据都是没有问题的。 但是如果我们自定义的内存对齐超出了这个范围，则是不能直接使用malloc来获取内存的。 当我们需要分配一块具有特定内存对齐的内存块时，在MSVC下应当使用_aligned_malloc；而在gcc下一般使用memalign等函数。 其实自己实现一个简易的aligned_malloc是很容易的： 1234567891011121314151617181920212223242526#include &lt;assert.h&gt; inline void* aligned_malloc(size_t size, size_t alignment) &#123; // 检查alignment是否是2^N assert(!(alignment &amp; (alignment - 1))); // 计算出一个最大的offset，sizeof(void*)是为了存储原始指针地址 size_t offset = sizeof(void*) + (--alignment); // 分配一块带offset的内存 char* p = static_cast&lt;char*&gt;(malloc(offset + size)); if (!p) return nullptr; // 通过“&amp; (~alignment)”把多计算的offset减掉 void* r = reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;size_t&gt;(p + offset) &amp; (~alignment)); // 将r当做一个指向void*的指针，在r当前地址前面放入原始地址 static_cast&lt;void**&gt;(r)[-1] = p; // 返回经过对齐的内存地址 return r; &#125; inline void aligned_free(void* p) &#123; // 还原回原始地址，并free free(static_cast&lt;void**&gt;(p)[-1]); &#125; 7. C++11中对内存对齐的操作C++11标准里统一了内存对齐的相关操作。 指定内存对齐使用alignas说明符： 12345678910alignas(32) long long a = 0; #define XX 1 struct alignas(XX) MyStruct_1 &#123;&#125;; // OK template &lt;size_t YY = 1&gt; struct alignas(YY) MyStruct_2 &#123;&#125;; // OK static const unsigned ZZ = 1; struct alignas(ZZ) MyStruct_3 &#123;&#125;; // OK 注意到MyStruct_3编译是OK的。在C++11里，只要是一个编译期数值（包括static const）都支持alignas（the assignment-expression shall be an integral constant expression，参考ISO/IEC-14882:2011，7.6.2 Alignment specifier，第2款）。 但是需要小心的是，目前微软的编译器（Visual C++ Compiler November 2013 CTP）在MyStruct_3的情况下仍然会报error C2057。 另外，alignas同前面介绍的__declspec、__attribute__一样，只能改大不能改小（参考ISO/IEC-14882:2011，7.6.2 Alignment specifier，第5款）。如果需要改小，比如设置对齐为1的话，仍然需要使用#pragma pack。或者，可以使用C++11里#pragma的等价物_Pragma（微软暂不支持这个）： 12345678910_Pragma(&quot;pack(1)&quot;) struct MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; _Pragma(&quot;pack()&quot;) 除了这些之外，alignas比__declspec、这个char就按int的方式对齐了。 获取内存对齐使用alignof操作符：强大的地方在于它还可以这样用： 1alignas(int) char c; 这个char就按int的方式对齐了。 获取内存对齐使用alignof操作符： 123MyStruct xx; std::cout &lt;&lt; alignof(xx) &lt;&lt; std::endl; std::cout &lt;&lt; alignof(MyStruct) &lt;&lt; std::endl; 相关注意点和前面介绍的__alignof、__alignof__并无二致。 除了alignas和alignof，C++11中还提供了几个有用的工具。 A. std::alignment_of 功能是编译期计算类型的内存对齐。 std里提供这个是为了补充alignof的功能。alignof只能返回一个size_t，而alignment_of则继承自std::integral_constant，因此拥有value_type、type、operator()等接口（或者说操作）。 B. std::aligned_storage 这是个好东西。我们知道，很多时候需要分配一块单纯的内存块，比如new char[32]，之后再使用placement new在这块内存上构建对象： 12char xx[32]; ::new (xx) MyStruct; 但是char[32]是1字节对齐的，xx很有可能并不在MyStruct指定的对齐位置上。这时调用placement new构造内存块，可能会引起效率问题或出错，这时我们应该使用std::aligned_storage来构造内存块： 12std::aligned_storage&lt;sizeof(MyStruct), alignof(MyStruct)&gt;::type xx; ::new (&amp;xx) MyStruct; 需要注意的是，当使用堆内存的时候我们可能还是需要aligned_malloc。因为现在的编译器里new并不能在超出默认最大对齐后，还能保证内存的对齐是正确的。比如在MSVC 2013里，下面的代码： 1234567891011struct alignas(32) MyStruct &#123; char a; // 1 byte int b; // 4 bytes short c; // 2 bytes long long d; // 8 bytes char e; // 1 byte &#125;; void* p = new MyStruct; // warning C4316: &apos;MyStruct&apos; : object allocated on the heap may not be aligned 32 将会得到一个编译警告。 C. std::max_align_t 返回当前平台的最大默认内存对齐类型。malloc返回的内存，其对齐和max_align_t类型的对齐大小应当是一致的。 我们可以通过下面这个方式获得当前平台的最大默认内存对齐数： 12std::cout &lt;&lt; alignof(std::max_align_t) &lt;&lt; std::endl; D. std::align 这货是一个函数，用来在一大块内存当中获取一个符合指定内存要求的地址。 看下面这个例子： 1234char buffer[] = &quot;------------------------&quot;; void * pt = buffer; std::size_t space = sizeof(buffer) - 1; std::align(alignof(int), sizeof(char), pt, space); 意思是，在buffer这个大内存块中，指定内存对齐为alignof(int)，找一块sizeof(char)大小的内存，并在找到这块内存后，将地址放入pt，将buffer从pt开始的长度放入space。 关于这个函数的更多信息，可以参考这里。 关于内存对齐，该说的就是这么多了。我们经常会看到内存对齐的应用，是在网络收发包中。一般用于发送的结构体，都是1字节对齐的，目的是统一收发双方（可能处于不同平台）之间的数据内存布局，以及减少不必要的流量消耗。 C++11中为我们提供了不少有用的工具，可以让我们方便的操作内存对齐。但是在堆内存方面，我们很可能还是需要自己想办法。不过在平时的应用中，因为很少会手动指定内存对齐到大于系统默认的对齐数，所以倒也不比每次new/delete的时候都提心吊胆。 参考文章： Data structure alignment About Data Alignment #pragma pack align (C++) __alignof Operator 6.57.8 Structure-Packing Pragmas 5.32 Specifying Attributes of Types C/C++ Data alignment 及 struct size深入分析 C++ 内存对齐 结构/类对齐的声明方式 字节对齐（强制对齐以及自然对齐） malloc函数字节对齐很经典的问题 C语言字节对齐 网络编程(9)内存对齐对跨平台通讯的影响 Usage Issue of std::align std::align and std::aligned_storage for aligned allocation of memory blocks http://www.cnblogs.com/fangkm/p/4370492.html]]></content>
      <categories>
        <category>Memory</category>
      </categories>
      <tags>
        <tag>Memory</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebRTC的模块处理机制]]></title>
    <url>%2F2017%2F07%2F06%2Fwebrtc-modules%2F</url>
    <content type="text"><![CDATA[对于实时音视频应用来讲，媒体数据从采集到渲染，在数据流水线上依次完成一系列处理。流水线由不同的功能模块组成，彼此分工协作：数据采集模块负责从摄像头/麦克风采集音视频数据，编解码模块负责对数据进行编解码，RTP模块负责数据打包和解包。数据流水线上的数据处理速度是影响应用实时性的最重要因素。与此同时，从服务质量保证角度讲，应用需要知道数据流水线的运行状态，如视频采集模块的实时帧率、当前网络的实时速率、接收端的数据丢包率，等等。各个功能模块可以基于这些运行状态信息作相应调整，从而在质量、速度等方面优化数据流水线的运行，实现更快、更好的用户体验。 WebRTC采用模块机制，把数据流水线上功能相对独立的处理点定义为模块，每个模块专注于自己的任务，模块之间基于数据流进行通信。与此同时，专有线程收集和处理模块内部的运行状态信息，并把这些信息反馈到目标模块，实现模块运行状态监控和服务质量保证。本文在深入分析WebRTC源代码基础上，学习研究其模块处理机制的实现细节，从另一个角度理解WebRTC的技术原理。 1 WebRTC数据流水线我们可以把WebRTC看作是一个专注于实时音视频通信的SDK。其对外的API主要负责PeerConnection建立、MediaStream创建、NAT穿透、SDP协商等工作，对内则主要集中于音视频数据的处理，从数据采集到渲染的整个处理过程可以用一个数据流水线来描述，如图1所示。 音视频数据首先从采集端进行采集，一般来说音频数据来自麦克风，视频数据来自摄像头。在某些应用场景下，音频数据来自扬声器，视频数据来自桌面共享。采集端的输出是音视频Raw Data。然后Raw Data到达编码模块，数据被编码器编码成符合语法规则的NAL单元，到达发送端缓冲区PacedSender处。接下来PacedSender把NAL单元发送到RTP模块打包为RTP数据包，最后经过网络模块发送到网络。 在接收端，RTP数据包经过网络模块接收后进行解包得到NAL单元，接下来NAL单元到达接收端缓冲区(JitterBuffer或者NetEQ)进行乱序重排和组帧。一帧完整的数据接收并组帧之后，调用解码模块进行解码，得到该帧数据的Raw Data。最后Raw Data交给渲染模块进行播放/显示。 在数据流水线上，还有一系列模块负责服务质量监控，如丢帧策略，丢包策略，编码器过度使用保护，码率估计，前向纠错，丢包重传，等等。 WebRTC数据流水线上的功能单元被定义为模块，每个模块从上游模块获取输入数据，在本模块进行加工后得到输出数据，交给下游模块进行下一步处理。WebRTC的模块处理机制包括模块和模块处理线程，前者把WebRTC数据流水线上的功能部件封装为模块，后者驱动模块内部状态更新和模块之间状态传递。模块一般挂载到模块处理线程上，由处理线程驱动模块的处理函数。下面分别描述之。 WebRTC模块WebRTC模块虚基类Module定义在webrtc/modules/include/modue.h中，如图2所示。 Module虚基类对外提供三个函数作为API：TimeUntilNextProcess()用来计算距下次调用处理函数Process()的时间间隔；Process()是模块的处理函数，负责模块内部运行监控、状态更新和模块间通信；ProcessThreadAttached()用来把模块挂载到模块处理线程，或者从模块处理线程分离出来，实际实现中这个函数暂时没有被用到。 Module的派生类分布在WebRTC数据流水线上的不同部分，各自承担自己的数据处理和服务质量保证任务。 3 WebRTC模块处理线程WebRTC模块处理线程是模块处理机制的驱动器，它的核心作用是对所有挂载在本线程下的模块，周期性调用其Process()处理函数处理模块内部事务，并处理异步任务。其虚基类ProcessThread和派生类ProcessThreadImpl如图3所示。 ProcessThread基类提供一系列API完成线程功能：Start()/Stop()函数用来启动和结束线程；WakeUp()函数用来唤醒挂载在本线程下的某个模块，使得该模块有机会马上执行其Process()处理函数；PostTask()函数用来邮递一个任务给本线程；RegisterModule()和DeRegisterModule()用来向线程注册/注销模块。 WebRTC基于ProcessThread线程实现派生类ProcessThreadImpl，如图3所示。在成员变量方面，wakeup用来唤醒处于等待状态的线程；thread是平台相关的线程实现如POSIX线程；modules是注册在本线程下的模块集合；queue_是邮递给本线程的任务集合；threadname是线程名字。在成员函数方面，Process()完成ProcessThread的核心任务，其伪代码如下所示。 1234567891011121314151617181920212223bool ProcessThreadImpl::Process() &#123; for (ModuleCallback&amp; m : modules_) &#123; if (m.next_callback == 0) m.next_callback = GetNextCallbackTime(m.module, now); if (m.next_callback &lt;= now || m.next_callback == kCallProcessImmediately) &#123; m.module-&gt;Process(); m.next_callback = GetNextCallbackTime(m.module, rtc::TimeMillis();); &#125; if (m.next_callback &lt; next_checkpoint) next_checkpoint = m.next_callback; &#125; while (!queue_.empty()) &#123; ProcessTask* task = queue_.front(); queue_.pop(); task-&gt;Run(); delete task; &#125; &#125; int64_t time_to_wait = next_checkpoint - rtc::TimeMillis(); if (time_to_wait &gt; 0) wake_up_-&gt;Wait(static_cast&lt;unsigned long&gt;(time_to_wait)); return true;&#125; Process()函数首先处理挂载在本线程下的模块，这也是模块处理线程的核心任务：针对每个模块，计算其下次调用模块Process()处理函数的时刻(调用该模块的TimeUntilNextProcess()函数)。如果时刻是当前时刻，则调用模块的Process()处理函数，并更新下次调用时刻。需要注意，不同模块的执行频率不一样，线程在本轮调用末尾的等待时间和本线程下所有模块的最近下次调用时刻相关。 接下来线程Process()函数处理ProcessTask队列中的异步任务，针对每个任务调用Run()函数，然后任务出队列并销毁。等模块调用和任务都处理完后，则把本次时间片的剩余时间等待完毕，然后返回。如果在等待期间其他线程向本线程Wakeup模块或者邮递一个任务，则线程被立即唤醒并返回，进行下一轮时间片的执行。 至此，关于WebRTC的模块和模块处理线程的基本实现分析完毕，下一节将对WebRTC SDK内模块实例和模块处理线程实例进行详细分析。 4 WebRTC模块处理线程实例WebRTC关于模块和处理线程的实现在webrtc/modules目录下，该目录汇集了所有派生类模块和模块处理线程的实现及实例分布。本节对这些内容进行总结。 WebRTC目前创建三个ProcessThreadImpl线程实例，分别是负责处理音频的VoiceProcessTread，负责处理视频和音视频同步的ModuleProcessThread，以及负责数据平滑发送的PacerThread。这三个线程和挂载在线程下的模块如图4所示。 VoiceProcessThread线程由Worker线程在创建VoiceEngine时创建，负责音频端模块的处理。挂载在该线程下的模块如图4所示，其中MonitorModule负责对音频数据混音处理过程中产生的警告和错误进行处理，AudioDeviceModuleImpl负责对音频设备采集和播放音频数据时产生的警告和错误进行处理，ModuleRtpRtcpImpl负责音频RTP数据包发送过程中的码率计算、RTT更新、RTCP报文发送等内容。 ModuleProcessThread线程由Worker线程在创建VideoChannel时创建，负责视频端模块的处理。挂载在该线程下的模块如图4所示，其中CallStats负责Call对象统计数据(如RTT)的更新，CongestionController负责拥塞控制[1][2]，VideoSender负责视频发送端统计数据的更新，VideoReceiver负责视频接收端统计数据更新和处理状态反馈(如请求关键帧)，ModuleRtpRtcpImpl负责视频RTP数据包发送过程中的码率计算、RTT更新、RTCP报文发送等内容，OveruseFrameDetector负责视频帧采集端过载监控，ReceiveStatisticsImpl负责由接收端统计数据触发的码率更新过程，ViESyncModule负责音视频同步。 PacerThread线程由Worker线程在创建VideoChannel时创建，负责数据平滑发送。挂载在该线程下的PacedSender负责发送端数据平滑发送；RemoteEstimatorProxy派生自RemoteBitrateEstimator，负责在启用发送端码率估计的情况下把接收端收集到的反馈信息发送回发送端。 由以上分析可知，WebRTC创建的模块处理线程实例基本上涵盖了音视频数据从采集到渲染过程中的大部分数据操作。但还有一些模块不依赖于模块线程工作，这部分模块是少数，本文不展开具体的描述。 参考文献[1] WebRTC基于GCC的拥塞控制(上) – 算法分析 [2] WebRTC基于GCC的拥塞控制(下) - 实现分析 转至]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android应用性能优化]]></title>
    <url>%2F2017%2F07%2F03%2Ftips-android-performance%2F</url>
    <content type="text"><![CDATA[Android手机由于其本身的后台机制和硬件特点，性能上一直被诟病，所以软件开发者对软件本身的性能优化就显得尤为重要；本文将对Android开发过程中性能优化的各个方面做一个回顾与总结。 Cache优化 ListView缓存： ListView中有一个回收器，Item滑出界面的时候View会回收到这里，需要显示新的Item的时候，就尽量重用回收器里面的View；每次在getView函数中inflate新的item之前会先判断回收器中是否有缓存的view，即判断convertView是否为null，是则inflate一个新的item View，否则重用回收器中的item。 此外，ListView还使用静态的ViewHolder减少findViewById的次数 ListView中有getViewTypeCount()函数用于获取列表有几种布局类型，getItemViewType(int position)用于获取在position位置上的布局类型; 我们可以利用ViewType来给不同类型的item创建不同的View，这样可以利于ListView的回收 对Item中图片进行适当压缩, 并进行异步加载；如果快速滑动，不加载图片；实现数据的分页加载 IO缓存：在文件和网络IO中使用具有缓存策略的输入流，BufferedInputStream替代InputStream，BufferedReader替代Reader，BufferedReader替代BufferedInputStream data缓存(空间换时间)：①缓存数据库的查询结果，比如缓存数据库表中的数据条数，这样就可以避免多次的select count查询 ②缓存磁盘文件中需要频繁访问的数据到内存中 ③缓存耗时计算的结果 Battery优化 cpu的使用率和使用频率将直接或间接的影响电量的分配和使用，cpu降频可以节约电量 service优化 service作为一个运行在主线程中的后台服务，应该尽量避免耗时动作，而应该尽量新开线程去处理耗时动作 监听系统广播看service是否存活，否则kill掉；降低service优先级使得系统内存吃紧时会被自动kill掉 使用Android提供的IntentService代替service，因为IntentService会在运行完成之后自动停止，而service需要手动调用stopService()才能停止运行 定时执行任务的Alarm机制：Android的定时任务有两种实现方式，Timer类和Alarm机制；Timer不适合长期后台运行的定时任务。因为每种手机都会有自己的休眠策略，Android手机就会在长时间不操作的情况下自动让CPU进入到睡眠状态，这就有可能导致Timer中的定时任务无法正常运行。而Alarm机制则不存在这种情况，它具有唤醒CPU的功能，即可以保证每次需要执行定时任务的时候CPU能正常工作。然而从Android4.4之后，Alarm任务的触发时间将会变得不准确，有可能会延迟一段时间后任务才能得到执行。这不是bug，而是系统在耗电性方面进行的优化。系统会自动检测目前有多少Alarm任务存在，然后将触发时间将近的几个任务放在一起执行，这就可以大幅度的减少CPU被唤醒的次数，从而有效延长电池的使用时间 渲染层优化 Android 界面卡顿的原因？ UI线程中做耗时操作，比如进行网络请求,磁盘读取，位图修改，更新UI等耗时操作，从而导致UI线程卡顿 布局Layout过于复杂，无法在16ms内完成渲染，或者嵌套层次过深 View过度绘制或者频繁的触发measure、layout，同一时间动画执行的次数过多，导致CPU或GPU负载过重 冗余资源及逻辑等导致加载和执行缓慢 Android 界面卡顿怎么处理？ xml布局优化：尽量使用include、merge、ViewStub标签，尽量不存在冗余嵌套及过于复杂布局（譬如10层就会直接异常），例如使用RelativeLayout代替LinearLayout可以减少布局层次和复杂性，View的嵌套层次不能过深，尽量使用GONE替换INVISIBLE，使用weight后尽量将width和heigh设置为0dp，减少运算，Item存在非常复杂的嵌套时考虑使用自定义Item View来取代，减少measure与layout次数等。 ListView及Adapter优化；尽量复用getView方法中的相关View，不重复获取实例导致卡顿，列表尽量在滑动过程中不进行UI元素刷新等。 背景和图片等内存分配优化；尽量减少不必要的背景设置，图片尽量压缩处理显示，尽量避免频繁内存抖动等问题出现；尽可能为不同分辨率创建资源，以减少不必要的硬件缩放 自定义View等绘图与布局优化；尽量避免在draw、measure、layout中做过于耗时及耗内存操作，尤其是draw方法中，尽量减少draw、measure、layout等执行次数，避免过度渲染和绘制；减少不必要的inflate，尽量使用全局变量缓存View 避免ANR，不要在UI线程中做耗时操作，譬如多次数据库操作等 Layout常用的标签 include标签：该标签可以用于将布局文件中的公共部分提取出来给其它布局文件复用，从而使得布局模块化，代码轻量化; 注意点: ①如果标签已经定义了id，而嵌入布局文件的root布局文件也定义了id，标签的id会覆盖掉嵌入布局文件root的id，如果include标签没有定义id则会使用嵌入文件root的id ②如果想使用标签覆盖嵌入布局root布局属性，必须同时覆盖layout_height和layout_width属性，否则会直接报编译时语法错误 viewstub标签：该标签与include一样用于引入布局模块，只是引入的布局默认不会扩张，既不会占用显示也不会占用位置，从而在解析layout时节省cpu和内存，只有通过调用setVisibility函数或者Inflate函数才会将其要装载的目标布局给加载出来，从而达到延迟加载的效果；例如条目详情、进度条标识或者未读消息等，这些情况如果在一开始初始化，虽然设置可见性View.GONE,但是在Inflate的时候View仍然会被Inflate，仍然会创建对象。 merge标签：该标签在layout中会被自动忽略，从而减少一层布局嵌套，其主要用处是当一个布局作为子布局被其他布局include时，使用merge当作该布局的顶节点来代替layout顶节点就可以减少一层嵌套 hierarchy viewer：该工具可以方便的查看Activity的布局，各个View的属性、measure、layout、draw的时间，如果耗时较多会用红色标记，否则显示绿色 网络优化 异步请求网络数据，避免频繁请求数据（例如如果某个页面内请求过多，可以考虑做一定的请求合并），尽可能的减少网络请求次数和减小网络请求时间间隔 网络应用传输中使用高效率的数据格式，譬如使用JSON代替XML，使用WebP代替其他图片格式,并对数据进行Gzip压缩数据，比如post请求的body和header内容 及时缓存数据到内存/文件/数据库 执行某些操作前尽量先进行网络状态判断，比如wifi传输数据比蜂窝数据更省电，所以尽量在wifi下进行数据的预加载 httpClient和httpUrlConnection对比： httpClient是apache的开源实现，API数量多，非常稳定 httpUrlConnection是java自带的模块: ①可以直接支持GZIP压缩,而HttpClient虽然也支持GZIP，但要自己写代码处理 ②httpUrlConnection直接在系统层面做了缓存策略处理，加快重复请求的速度 ③API简单，体积较小,而且直接支持系统级连接池，即打开的连接不会直接关闭，在一段时间内所有程序可共用 HttpURLConnection在Android2.2之前有个重大Bug，调用close()函数会影响连接池，导致连接复用失效，需要关闭keepAlive;因此在2.2之前http请求都是用httpClient，2.2之后则是使用HttpURLConnection 但是!!!现在!!!Android不再推荐这两种方式！二是直接使用OKHttp这种成熟方案！支持Android 2.3及其以上版本 数据结构优化 ArrayList和LinkedList的选择：ArrayList根据index取值更快，LinkedList更占内存、随机插入删除更快速、扩容效率更高 ArrayList、HashMap、LinkedHashMap、HashSet的选择：hash系列数据结构查询速度更优，ArrayList存储有序元素，HashMap为键值对数据结构，LinkedHashMap可以记住加入次序的hashMap，HashSet不允许重复元素 HashMap、WeakHashMap选择：WeakHashMap中元素可在适当时候被系统垃圾回收器自动回收，所以适合在内存紧张时使用 Collections.synchronizedMap和ConcurrentHashMap的选择：ConcurrentHashMap为细分锁，锁粒度更小，并发性能更优；Collections.synchronizedMap为对象锁，自己添加函数进行锁控制更方便 Android中性能更优的数据类型：如SparseArray、SparseBooleanArray、SparseIntArray、Pair；Sparse系列的数据结构是为key为int情况的特殊处理，采用二分查找及简单的数组存储，加上不需要泛型转换的开销，相对Map来说性能更优 内存优化 Android应用内存溢出OOM 内存溢出的主要导致原因有如下几类：①应用代码存在内存泄露，长时间积累无法释放导致OOM；②应用的某些逻辑操作疯狂的消耗掉大量内存（譬如加载一张不经过处理的超大超高清图片等）导致超过阈值OOM 解决思路①在内存引用上做些处理，常用的有软引用、弱引用 ②在内存中加载图片时直接在内存中做处理，如：边界压缩 ③动态回收内存，手动recyle bitmap，回收对象 ④优化Dalvik虚拟机的堆内存分配 ⑤自定义堆内存大小]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>性能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多媒体之术语]]></title>
    <url>%2F2017%2F06%2F27%2Fmedia-terminology%2F</url>
    <content type="text"><![CDATA[一.编解码术语1.GOP/码流/比特率/帧速率/分辨率1.1GOP（Group of picture）关键帧的周期，也就是两个IDR帧之间的距离，一个帧组的最大帧数，一般而言，每一秒视频至少需要使用 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。 需要说明的是，通过提高GOP值来提高图像质量是有限度的，在遇到场景切换的情况时，H.264编码器会自动强制插入一个I帧，此时实际的GOP值被缩短了。另一方面，在一个GOP中，P、B帧是由I帧预测得到的，当I帧的图像质量比较差时，会影响到一个GOP中后续P、B帧的图像质量，直到下一个GOP开始才有可能得以恢复，所以GOP值也不宜设置过大。 同时，由于P、B帧的复杂度大于I帧，所以过多的P、B帧会影响编码效率，使编码效率降低。另外，过长的GOP还会影响Seek操作的响应速度，由于P、B帧是由前面的I或P帧预测得到的，所以Seek操作需要直接定位，解码某一个P或B帧时，需要先解码得到本GOP内的I帧及之前的N个预测帧才可以，GOP值越长，需要解码的预测帧就越多，seek响应的时间也越长。 1.12CABAC/CAVLCH.264/AVC标准中两种熵编码方法，CABAC叫自适应二进制算数编码，CAVLC叫前后自适应可变长度编码， CABAC：是一种无损编码方式，画质好，X264就会舍弃一些较小的DCT系数，码率降低，可以将码率再降低10-15%（特别是在高码率情况下），会降低编码和解码的速速。 CAVLC将占用更少的CPU资源，但会影响压缩性能。 其他: 帧：当采样视频信号时，如果是通过逐行扫描，那么得到的信号就是一帧图像，通常帧频为25帧每秒（PAL制）、30帧每秒（NTSC制）； 场：当采样视频信号时，如果是通过隔行扫描（奇、偶数行），那么一帧图像就被分成了两场，通常场频为50Hz（PAL制）、60Hz（NTSC制）； 帧频、场频的由来：最早由于抗干扰和滤波技术的限制，电视图像的场频通常与电网频率（交流电）相一致，于是根据各地交流电频率不同就有了欧洲和中国等PAL制的50Hz和北美等NTSC制的60Hz，但是现在并没有这样的限制了，帧频可以和场频一样，或者场频可以更高。 帧编码、场编码方式：逐行视频帧内邻近行空间相关性较强，因此当活动量非常小或者静止的图像比较适宜采用帧编码方式；而场内相邻行之间的时间相关性较强，对运动量较大的运动图像则适宜采用场编码方式。 1.1.3Deblocking开启会减少块效应. 1.1.4FORCE_IDR是否让每个I帧变成IDR帧，如果是IDR帧，支持随机访问。 1.1.5frame,tff,bff–frame 将两场合并作为一帧进行编码,–tff Enable interlaced mode (开启隔行编码并设置上半场在前),–bff Enable interlaced mode。 PAFF 和MBAFF：当对隔行扫描图像进行编码时，每帧包括两个场，由于两个场之间存在较大的扫描间隔，这样，对运动图像来说，帧中相邻两行之间的空间相关性相对于逐行扫描时就会减小，因此这时对两个场分别进行编码会更节省码流。 对帧来说，存在三种可选的编码方式：将两场合并作为一帧进行编码(frame 方式)或将两场分别编码(field 方式)或将两场合并起来作为一帧，但不同的是将帧中垂直相邻的两个宏块合并为宏块对进行编码；前两种称为PAFF 编码，对运动区域进行编码时field 方式有效，对非运区域编码时，由于相邻两行有较大的相关性，因而frame 方式会更有效。当图像同时存在运动区域和非运动区域时，在MB 层次上，对运动区域采取field 方式，对非运动区域采取frame 方式会更加有效，这种方式就称为MBAFF，预测的单位是宏块对。 1.2码流/码率码流(Data Rate)是指视频文件在单位时间内使用的数据流量，也叫码率或码流率，通俗一点的理解就是取样率,是视频编码中画面质量控制中最重要的部分，一般我们用的单位是kb/s或者Mb/s。一般来说同样分辨率下，视频文件的码流越大，压缩比就越小，画面质量就越高。码流越大，说明单位时间内取样率越大，数据流，精度就越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。 当然，码流越大，文件体积也越大，其计算公式是文件体积=时间X码率/8。例如，网络上常见的一部90分钟1Mbps码流的720P RMVB文件，其体积就=5400秒×1Mb/8=675MB。 通常来说，一个视频文件包括了画面及声音，例如一个RMVB的视频文件，里面包含了视频信息和音频信息，音频及视频都有各自不同的采样方式和比特率，也就是说，同一个视频文件音频和视频的比特率并不是一样的。而我们所说的一个视频文件码流率大小，一般是指视频文件中音频及视频信息码流率的总和。 以以国内最流行，大家最熟悉的RMVB视频文件为例，RMVB中的VB，指的是VBR，即Variable Bit Rate的缩写，中文含义是可变比特率，它表示RMVB采用的是动态编码的方式，把较高的采样率用于复杂的动态画面(歌舞、飞车、战争、动作等)，而把较低的采样率用于静态画面，合理利用资源，达到画质与体积可兼得的效果。 码率和取样率最根本的差别就是码率是针对源文件来讲的。 1.3采样率采样率（也称为采样速度或者采样频率）定义了每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示。采样率是指将模拟信号转换成数字信号时的采样频率，也就是单位时间内采样多少点。一个采样点数据有多少个比特。比特率是指每秒传送的比特(bit)数。单位为 bps(Bit Per Second)，比特率越高，传送的数据越大，音质越好.比特率 =采样率 x 采用位数 x声道数. 采样率类似于动态影像的帧数，比如电影的采样率是24赫兹，PAL制式的采样率是25赫兹，NTSC制式的采样率是30赫兹。当我们把采样到的一个个静止画面再以采样率同样的速度回放时，看到的就是连续的画面。同样的道理，把以44.1kHZ采样率记录的CD以同样的速率播放时，就能听到连续的声音。显然，这个采样率越高，听到的声音和看到的图像就越连贯。当然，人的听觉和视觉器官能分辨的采样率是有限的，基本上高于44.1kHZ采样的声音，绝大部分人已经觉察不到其中的分别了。 而声音的位数就相当于画面的颜色数，表示每个取样的数据量，当然数据量越大，回放的声音越准确，不至于把开水壶的叫声和火车的鸣笛混淆。同样的道理，对于画面来说就是更清晰和准确，不至于把血和西红柿酱混淆。不过受人的器官的机能限制，16位的声音和24位的画面基本已经是普通人类的极限了，更高位数就只能靠仪器才能分辨出来了。比如电话就是3kHZ取样的7位声音，而CD是44.1kHZ取样的16位声音，所以CD就比电话更清楚。 当你理解了以上这两个概念，比特率就很容易理解了。以电话为例，每秒3000次取样，每个取样是7比特，那么电话的比特率是21000。 而CD是每秒 44100次取样，两个声道，每个取样是13位PCM编码，所以CD的比特率是44100213=1146600，也就是说CD每秒的数据量大约是 144KB，而一张CD的容量是74分等于4440秒，就是639360KB＝640MB。 码率和取样率最根本的差别就是码率是针对源文件来讲的 1.4比特率比特率是指每秒传送的比特(bit)数。单位为bps(Bit Per Second)，比特率越高，传送的数据越大。在视频领域,比特率常翻译为码率 !!! 比特率表示经过编码（压缩）后的音、视频数据每秒钟需要用多少个比特来表示，而比特就是二进制里面最小的单位，要么是0，要么是1。比特率与音、视频压缩的关系，简单的说就是比特率越高，音、视频的质量就越好，但编码后的文件就越大；如果比特率越少则情况刚好相反。 比特率是指将数字声音、视频由模拟格式转化成数字格式的采样率，采样率越高，还原后的音质、画质就越好。 常见编码模式： VBR（Variable Bitrate）动态比特率 也就是没有固定的比特率，压缩软件在压缩时根据音频数据即时确定使用什么比特率，这是以质量为前提兼顾文件大小的方式，推荐编码模式； ABR（Average Bitrate）平均比特率 是VBR的一种插值参数。LAME针对CBR不佳的文件体积比和VBR生成文件大小不定的特点独创了这种编码模式。ABR在指定的文件大小内，以每50帧（30帧约1秒）为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量，可以做为VBR和CBR的一种折衷选择。 CBR（Constant Bitrate），常数比特率 指文件从头到尾都是一种位速率。相对于VBR和ABR来讲，它压缩出来的文件体积很大，而且音质相对于VBR和ABR不会有明显的提高。 1.5帧速率帧速率也称为FPS(Frames PerSecond)的缩写——帧/秒。是指每秒钟刷新的图片的帧数，也可以理解为图形处理器每秒钟能够刷新几次。越高的帧速率可以得到更流畅、更逼真的动画。每秒钟帧数(FPS)越多，所显示的动作就会越流畅。 1.6分辨率就是帧大小每一帧就是一副图像。 640*480分辨率的视频，建议视频的码速率设置在700以上，音频采样率44100就行了 一个音频编码率为128Kbps，视频编码率为800Kbps的文件，其总编码率为928Kbps，意思是经过编码后的数据每秒钟需要用928K比特来表示。 视频分辨率是指视频成像产品所成图像的大小或尺寸。常见的视像分辨率有352×288，176×144，640×480，1024×768。在成像的两组数字中，前者为图片长度，后者为图片的宽度，两者相乘得出的是图片的像素，长宽比一般为4：3. 目前监控行业中主要使用Qcif(176×144）、CIF(352×288）、HALF D1(704×288）、D1(704×576）等几种分辨率。 D1是数字电视系统显示格式的标准，共分为以下5种规格： D1：480i格式（525i）：720×480（水平480线，隔行扫描），和NTSC模拟电视清晰度相同，行频为15.25kHz，相当于我们所说的4CIF(720×576) D2：480P格式（525p）：720×480（水平480线，逐行扫描），较D1隔行扫描要清晰不少，和逐行扫描DVD规格相同，行频为31.5kHz D3：1080i格式（1125i）：1920×1080（水平1080线，隔行扫描），高清方式采用最多的一种分辨率，分辨率为1920×1080i/60Hz，行频为33.75kHz D4：720p格式（750p）：1280×720（水平720线，逐行扫描），虽然分辨率较D3要低，但是因为逐行扫描，市面上更多人感觉相对于1080I（实际逐次540线）视觉效果更加清晰。不过个人感觉来说，在最大分辨率达到1920×1080的情况下，D3要比D4感觉更加清晰，尤其是文字表现力上，分辨率为1280×720p/60Hz，行频为45kHz D5：1080p格式（1125p）：1920×1080（水平1080线，逐行扫描），目前民用高清视频的最高标准，分辨率为1920×1080P/60Hz，行频为67.5KHZ。 其中D1 和D2标准是我们一般模拟电视的最高标准，并不能称的上高清晰，D3的1080i标准是高清晰电视的基本标准，它可以兼容720p格式，而D5的1080P只是专业上的标准。 计算输出文件大小公式： （音频编码率（KBit为单位）/8 +视频编码率（KBit为单位）/8）×影片总长度（秒为单位）=文件大小（MB为单位） 2.高清视频目前的720P以及1080P采用了很多种编码，例如主流的MPEG2，VC-1以及H.264，还有Divx以及Xvid，至于封装格式更多到令人发指，ts、mkv、wmv以及蓝光专用等等。 720和1080代表视频流的分辨率，前者1280720，后者19201080，不同的编码需要不同的系统资源，大概可以认为是H.264&gt;VC-1&gt;MPEG2。 VC-1是最后被认可的高清编码格式，不过因为有微软的后台，所以这种编码格式不能小窥。相对于MPEG2，VC-1的压缩比更高，但相对于H.264而言，编码解码的计算则要稍小一些，目前来看，VC-1可能是一个比较好的平衡，辅以微软的支持，应该是一只不可忽视的力量。一般来说，VC-1多为 “.wmv”后缀，但这都不是绝对的，具体的编码格式还是要通过软件来查询。 总的来说，从压缩比上来看，H.264的压缩比率更高一些，也就是同样的视频，通过H.264编码算法压出来的视频容量要比VC-1的更小，但是VC-1 格式的视频在解码计算方面则更小一些，一般通过高性能的CPU就可以很流畅的观看高清视频。相信这也是目前NVIDIA Geforce 8系列显卡不能完全解码VC-1视频的主要原因。 PS&amp;TS是两种视频或影片封装格式，常用于高清片。扩展名分别为VOB/EVO和TS等；其文件编码一般用MPEG2/VC-1/H.264 高清，英文为“High Definition”，即指“高分辨率”。 高清电视(HDTV)，是由美国电影电视工程师协会确定的高清晰度电视标准格式。现在的大屏幕液晶电视机，一般都支持1080i和720P，而一些俗称的“全高清”(Full HD)，则是指支持1080P输出的电视机。 目前的高清视频编码格式主要有H.264、VC-1、MPEG-2、MPEG-4、DivX、XviD、WMA-HD以及X264。事实上，现在网络上流传的高清视频主要以两类文件的方式存在：一类是经过MPEG-2标准压缩，以tp和ts为后缀的视频流文件;一类是经过WMV-HD(Windows Media Video HighDefinition)标准压缩过的wmv文件，还有少数文件后缀为avi或mpg，其性质与wmv是一样的。真正效果好的高清视频更多地以H.264与VC-1这两种主流的编码格式流传。 一般来说，H.264格式以“.avi”、“.mkv”以及“.ts”封装比较常见。 3.位率（定码率，变码率）位率又称为“码率”。指单位时间内，单个录像通道所产生的数据量，其单位通常是bps、Kbps或Mbps。可以根据录像的时间与位率估算出一定时间内的录像文件大小。 位率是一个可调参数，不同的分辨率模式下和监控场景下，合适的位率大小是不同的。在设置时，要综合考虑三个因素： 分辨率:分辨率是决定位率（码率）的主要因素，不同的分辨率要采用不同的位率。总体而言，录像的分辨率越高，所要求的位率（码率）也越大，但并不总是如此，图1说明了不同分辨率的合理的码率选择范围。所谓“合理的范围”指的是，如果低于这个范围，图像质量看起来会变得不可接受；如果高于这个范围，则显得没有必要，对于网络资源以及存储资源来说是一种浪费。 场景:监控的场景是设置码率时要考虑的第二个因素。在视频监控中，图像的运动剧烈程度还与位率有一定的关系，运动越剧烈，编码所要求的码率就越高。反之则越低。因此在同样的图像分辨率条件下，监控人多的场景和人少的场景，所要求的位率也是不同的。 存储空间:最后需要考量的因素是存储空间，这个因素主要是决定了录像系统的成本。位率设置得越高，画质相对会越好，但所要求的存储空间就越大。所以在工程实施中，设置合适的位率即可以保证良好的回放图像质量，又可以避免不必要的资源浪费。 QP(quantizer parameter) 介于0~31之间，值越小，量化越精细，图像质量就越高，而产生的码流也越长。 PSNR 允许计算峰值信噪比(PSNR,Peak signal-to-noise ratio),编码结束后在屏幕上显示PSNR计算结果。开启与否与输出的视频质量无关，关闭后会带来微小的速度提升。 profile level 分别是BP、EP、MP、HP： BP-Baseline Profile：基本画质。支持I/P 帧，只支持无交错（Progressive）和CAVLC； EP-Extended profile：进阶画质。支持I/P/B/SP/SI 帧，只支持无交错（Progressive）和CAVLC； MP-Main profile：主流画质。提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），也支持CAVLC 和CABAC 的支持； HP-High profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码和更多的YUV 格式； H.264规定了三种档次，每个档次支持一组特定的编码功能，并支持一类特定的应用。 基本档次：利用I片和P片支持帧内和帧间编码，支持利用基于上下文的自适应的变长编码进行的熵编码（CAVLC）。主要用于可视电话、会议电视、无线通信等实时视频通信； 主要档次：支持隔行视频，采用B片的帧间编码和采用加权预测的帧内编码；支持利用基于上下文的自适应的算术编码（CABAC）。主要用于数字广播电视与数字视频存储； 扩展档次：支持码流之间有效的切换（SP和SI片）、改进误码性能（数据分割），但不支持隔行视频和CABAC。主要用于网络的视频流，如视频点播。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Image Stride(内存图像行跨度)]]></title>
    <url>%2F2017%2F06%2F27%2Fmedia-graphic-image-stride%2F</url>
    <content type="text"><![CDATA[When a video image is stored in memory, the memory buffer might contain extra padding bytes after each row of pixels. The padding bytes affect how the image is store in memory, but do not affect how the image is displayed. 当视频图像存储在内存时，图像的每一行末尾也许包含一些扩展的内容，这些扩展的内容只影响图像如何存储在内存中，但是不影响图像如何显示出来； The stride is the number of bytes from one row of pixels in memory to the next row of pixels in memory. Stride is also called pitch. If padding bytes are present, the stride is wider than the width of the image, as shown in the following illustration. Stride 就是这些扩展内容的名称，Stride 也被称作 Pitch，如果图像的每一行像素末尾拥有扩展内容，Stride 的值一定大于图像的宽度值，就像下图所示： Two buffers that contain video frames with equal dimensions can have two different strides. If you process a video image, you must take into the stride into account. 两个缓冲区包含同样大小（宽度和高度）的视频帧，却不一定拥有同样的 Stride 值，如果你处理一个视频帧，你必须在计算的时候把 Stride 考虑进去； In addition, there are two ways that an image can be arranged in memory. In a top-down image, the top row of pixels in the image appears first in memory. In a bottom-up image, the last row of pixels appears first in memory. The following illustration shows the difference between a top-down image and a bottom-up image. 另外，一张图像在内存中有两种不同的存储序列（arranged），对于一个从上而下存储（Top-Down） 的图像，最顶行的像素保存在内存中最开头的部分，对于一张从下而上存储（Bottom-Up）的图像，最后一行的像素保存在内存中最开头的部分，下面图示展示了这两种情况： A bottom-up image has a negative stride, because stride is defined as the number of bytes need to move down a row of pixels, relative to the displayed image. YUV images should always be top-down, and any image that is contained in a Direct3D surface must be top-down. RGB images in system memory are usually bottom-up. 一张从下而上的图像拥有一个负的 Stride 值，因为 Stride 被定义为[从一行像素移动到下一行像素时需要跨过多少个像素]，仅相对于被显示出来的图像而言；而 YUV 图像永远都是从上而下表示的，以及任何包含在 Direct3D Surface 中的图像必须是从上而下，RGB 图像保存在系统内存时通常是从下而上； Video transforms in particular need to handle buffers with mismatched strides, because the input buffer might not match the output buffer. For example, suppose that you want to convert a source image and write the result to a destination image. Assume that both images have the same width and height, but might not have the same pixel format or the same image stride. 尤其是视频变换，特别需要处理不同 Stride 值的图像，因为输入缓冲也许与输出缓冲不匹配，举个例子，假设你想要将源图像转换并且将结果写入到目标图像，假设两个图像拥有相同的宽度和高度，但是其像素格式与 Stride 值也许不同； The following example code shows a generalized approach for writing this kind of function. This is not a complete working example, because it abstracts many of the specific details. 下面代码演示了一种通用方法来编写这种功能，这段代码并不完整，因为这只是一个抽象的算法，没有完全考虑到真实需求中的所有细节； 12345678910111213141516171819202122void ProcessVideoImage( BYTE* pDestScanLine0, LONG lDestStride, const BYTE* pSrcScanLine0, LONG lSrcStride, DWORD dwWidthInPixels, DWORD dwHeightInPixels )&#123; for (DWORD y = 0; y &lt; dwHeightInPixels; y++) &#123; SOURCE_PIXEL_TYPE *pSrcPixel = (SOURCE_PIXEL_TYPE*)pDestScanLine0; DEST_PIXEL_TYPE *pDestPixel = (DEST_PIXEL_TYPE*)pSrcScanLine0; for (DWORD x = 0; x &lt; dwWidthInPixels; x +=2) &#123; pDestPixel[x] = TransformPixelValue(pSrcPixel[x]); &#125; pDestScanLine0 += lDestStride; pSrcScanLine0 += lSrcStride; &#125;&#125; This function takes six parameters: A pointer to the start of scan line 0 in the destination image. The stride of the destination image. A pointer to the start of scan line 0 in the source image. The stride of the source image. The width of the image in pixels. The height of the image in pixels. 这个函数需要六个参数： 目标图像的起始扫描行的内存指针 目标图像的 Stride 值 源图像的起始扫描行的内存指针 源图像的 Stride 值 图像的宽度值（以像素为单位） 图像的高度值（以像素为单位） The general idea is to process one row at a time, iterating over each pixel in the row. Assume that SOURCE_PIXEL_TYPE and DEST_PIXEL_TYPE are structures representing the pixel layout for the source and destination images, respectively. (For example, 32-bit RGB uses the RGBQUAD structure. Not every pixel format has a pre-defined structure.) Casting the array pointer to the structure type enables you to access the RGB or YUV components of each pixel. At the start of each row, the function stores a pointer to the row. At the end of the row, it increments the pointer by the width of the image stride, which advances the pointer to the next row. 这里的要点是如何一次处理一行像素，遍历一行里面的每一个像素，假设源像素类型与目标像素类型各自在像素的层面上已经结构化来表示一个源图像与目标图像的像素，（举个例子，32 位 RGB 像素使用 RGBQUAD 结构体，并不是每一种像素类型都有预定义结构体的）强制转换数组指针到这样的结构体指针，可以方便你直接读写每一个像素的 RGB 或者 YUV 值，在每一行的开头，这个函数保存了一个指向这行像素的指针，函数的最后一行，通过图像的 Stride 值直接将指针跳转到图像的下一行像素的起始点； This example calls a hypothetical function named TransformPixelValue for each pixel. This could be any function that calculates a target pixel from a source pixel. Of course, the exact details will depend on the particular task. For example, if you have a planar YUV format, you must access the chroma planes independently from the luma plane; with interlaced video, you might need to process the fields separately; and so forth. To give a more concrete example, the following code converts a 32-bit RGB image into an AYUV image. The RGB pixels are accessed using an RGBQUAD structure, and the AYUV pixels are accessed using aDXVA2_AYUVSample8 Structure structure. 引用: 如果你用的是 MSDN Library For Visual Studio 2008 SP1，那么你应该能够在下面地址中找到这篇文章的原文： ms-help://MS.MSDNQTR.v90.chs/medfound/html/13cd1106-48b3-4522-ac09-8efbaab5c31d.htm http://blog.csdn.net/g0ose/article/details/52116453]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL混色]]></title>
    <url>%2F2017%2F06%2F27%2Fgl-glBlendFunc%2F</url>
    <content type="text"><![CDATA[混合就是把两种颜色混在一起。具体一点，就是把某一像素位置原来的颜色和将要画上去的颜色，通过某种方式混在一起，从而实现特殊的效果。 假设我们需要绘制这样一个场景：透过红色的玻璃去看绿色的物体，那么可以先绘制绿色的物体，再绘制红色玻璃。在绘制红色玻璃的时候，利用“混合”功能，把将要绘制上去的红色和原来的绿色进行混合，于是得到一种新的颜色，看上去就好像玻璃是半透明的。 要使用OpenGL的混合功能，只需要调用：glEnable(GL_BLEND);即可。要关闭OpenGL的混合功能，只需要调用：glDisable(GL_BLEND);即可。 注意： 只有在RGBA模式下，才可以使用混合功能，颜色索引模式下是无法使用混合功能的。 1.源因子和目标因子混合需要把原来的颜色和将要画上去的颜色找出来，经过某种方式处理后得到一种新的颜色。这里把将要画上去的颜色称为“源颜色”，把原来的颜色称为“目标颜色”。 OpenGL 会把源颜色和目标颜色各自取出，并乘以一个系数（源颜色乘以的系数称为“源因子”，目标颜色乘以的系数称为“目标因子”），然后相加，这样就得到了新的颜 色。（也可以不是相加，新版本的OpenGL可以设置运算方式，包括加、减、取两者中较大的、取两者中较小的、逻辑运算等） 下面用数学公式来表达一下这个运算方式。假设源颜色的四个分量（指红色，绿色，蓝色，alpha值）是(Rs, Gs, Bs, As)，目标颜色的四个分量是(Rd, Gd, Bd, Ad)，又设源因子为(Sr, Sg, Sb, Sa)，目标因子为(Dr, Dg, Db, Da)。则混合产生的新颜色可以表示为： (Rs*Sr+Rd*Dr, Gs*Sg+Gd*Dg, Bs*Sb+Bd*Db, As*Sa+Ad*Da) 如果颜色的某一分量超过了1.0，则它会被自动截取为1.0，不需要考虑越界的问题。 源因子和目标因子是可以通过glBlendFunc函数来进行设置的。glBlendFunc有两个参数，前者表示源因子，后者表示目标因子。这两个参数可以是多种值，下面介绍比较常用的几种。 GL_ZERO：表示使用0.0作为因子，实际上相当于不使用这种颜色参与混合运算。 GL_ONE：表示使用1.0作为因子，实际上相当于完全的使用了这种颜色参与混合运算。 GL_SRC_ALPHA：表示使用源颜色的alpha值来作为因子。 GL_DST_ALPHA：表示使用目标颜色的alpha值来作为因子。 GL_ONE_MINUS_SRC_ALPHA：表示用1.0减去源颜色的alpha值来作为因子。 GL_ONE_MINUS_DST_ALPHA：表示用1.0减去目标颜色的alpha值来作为因子。 GL_SRC_COLOR: 把源颜色的四个分量分别作为因子的四个分量 GL_ONE_MINUS_SRC_COLOR GL_DST_COLOR GL_ONE_MINUS_DST_COLOR GL_SRC_COLOR与GL_ONE_MINUS_SRC_COLOR在OpenGL旧版本中只能用于设置目标因子，GL_DST_COLOR与GL_ONE_MINUS_DST_COLOR在OpenGL 旧版本中只能用于设置源因子。新版本的OpenGL则没有这个限制，并且支持新的GL_CONST_COLOR（设定一种常数颜色，将其四个分量分别作为 因子的四个分量）、GL_ONE_MINUS_CONST_COLOR、GL_CONST_ALPHA、 GL_ONE_MINUS_CONST_ALPHA。另外还有GL_SRC_ALPHA_SATURATE。新版本的OpenGL还允许颜色的alpha 值和RGB值采用不同的混合因子。 2.模式示例 如果设置了glBlendFunc(GL_ONE, GL_ZERO);，则表示完全使用源颜色，完全不使用目标颜色，因此画面效果和不使用混合的时候一致（当然效率可能会低一点点）。如果没有设置源因子和目标因子，则默认情况就是这样的设置。 如果设置了glBlendFunc(GL_ZERO, GL_ONE);，则表示完全不使用源颜色，因此无论你想画什么，最后都不会被画上去了。（但这并不是说这样设置就没有用，有些时候可能有特殊用途） 如果设置了glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);，则表示源颜色乘以自身的alpha 值，目标颜色乘以1.0减去源颜色的alpha值，这样一来，源颜色的alpha值越大，则产生的新颜色中源颜色所占比例就越大，而目标颜色所占比例则减 小。这种情况下，我们可以简单的将源颜色的alpha值理解为“不透明度”。这也是混合时最常用的方式。 如果设置了glBlendFunc(GL_ONE, GL_ONE);，则表示完全使用源颜色和目标颜色，最终的颜色实际上就是两种颜色的简单相加。例如红色(1, 0, 0)和绿色(0, 1, 0)相加得到(1, 1, 0)，结果为黄色。 注意： 所谓源颜色和目标颜色，是跟绘制的顺序有关的。假如先绘制了一个红色的物体，再在其上绘制绿色的物体。则绿色是源颜色，红色是目标颜色。如果顺序反过来，则 红色就是源颜色，绿色才是目标颜色。在绘制时，应该注意顺序，使得绘制的源颜色与设置的源因子对应，目标颜色与设置的目标因子对应。 3.对两种示例模式的具体解释:模式一: 12GLES20.glEnable(GLES20.GL_BLEND); GLES20.glBlendFunc(GLES20.GL_SRC_ALPHA, GLES20.GL_ONE_MINUS_SRC_ALPHA); 模式二: 12GLES20.glEnable(GLES20.GL_BLEND); GLES20.glBlendFunc(GLES20.GL_ONE, GLES20.GL_ONE_MINUS_SRC_ALPHA); 模式一是传统的alpha通道混合，这种模式下颜色和alpha值是分立的，rgb决定颜色，alpha决定..（英文是决定how solid it is 水平有限找不到准确的中文来表达） 在数学上表达式是：blend(source, dest) = (source.rgb * source.a) + (dest.rgb * (1 – source.a)).要注意的是这种模式下，透明只跟alpha有关，跟rgb值无关，一个透明的颜色，不透明的颜色有相同的rgb值，只要alpha=0即可。 模式二是alpha预乘的混合（Premultiplied Alpha Blending），这种模式下rgb与alpha是联系在一起的，数学上的表达式是 blend(source, dest) = source.rgb + (dest.rgb * (1 – source.a)),在这种模式下，透明的表示是rgb值都为0. 4.EGLSurface背景透明设置在OpenGL绘制中,除了设置混色外,还要设置EGLSurface配置支持Alpha,如果不设置EGL相关的EGLSurface支持透明,就算OpenGL函数中开启混色,绘制完成后仍是有黑色背景. 4.1GLSurfaceView在onSurfaceCreated里，调用GLES20.glClearColor(0f, 0f, 0f, 0f);alpha为0，即透明。 然后，对surfaceview要作一定处理： 12345mGLSurfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0);TestRenderer renderer = new TestRenderer();mGLSurfaceView.setRender(renderer);mGLSurfaceView.getHolder().setFormat(PixelFormat.TRANSLUCENT);mGLSurfaceView.setZOrderOnTop(true); 4.2SurfaceTexture或Surface构造的SurfaceEGL14.eglChooseConfig中config数组增加EGL10.EGL_ALPHA_SIZE配置: 12345678int[] CONFIG_RGBA = &#123; EGL10.EGL_RED_SIZE, 8, EGL10.EGL_GREEN_SIZE, 8, EGL10.EGL_BLUE_SIZE, 8, EGL10.EGL_ALPHA_SIZE, 8, EGL10.EGL_RENDERABLE_TYPE, EGL_OPENGL_ES2_BIT, EGL10.EGL_NONE &#125;; 5.实现三维混合在进行三维场景的混合时必须注意的是深度缓冲。 深度缓冲是这样一段数据，它记录了每一个像素距离观察者有多近。在启用深度缓冲测试的情况下，如果将要绘制的像素比原来的像素更近，则像素将被绘制。否则,像素就会被忽略掉，不进行绘制。这在绘制不透明的物体时非常有用——不管是先绘制近的物体再绘制远的物体，还是先绘制远的物体再绘制近的物体，或者干脆以 混乱的顺序进行绘制，最后的显示结果总是近的物体遮住远的物体。 然而在你需要实现半透明效果时，发现一切都不是那么美好了。如果你绘制了一个近距离的半透明物体，则它在深度缓冲区内保留了一些信息，使得远处的物体将无法再被绘制出来。虽然半透明的物体仍然半透明，但透过它看到的却不是正确的内容了。 要 解决以上问题，需要在绘制半透明物体时将深度缓冲区设置为只读，这样一来，虽然半透明物体被绘制上去了，深度缓冲区还保持在原来的状态。如果再有一个物体 出现在半透明物体之后，在不透明物体之前，则它也可以被绘制（因为此时深度缓冲区中记录的是那个不透明物体的深度）。以后再要绘制不透明物体时，只需要再 将深度缓冲区设置为可读可写的形式即可。怎么绘制一个一部分半透明一部分不透明的物体？这个好办，只需要把物体分为两个部分，一部分全是半透明 的，一部分全是不透明的，分别绘制就可以了。 即使使用了以上技巧，我们仍然不能随心所欲的按照混乱顺序来进行绘制。必须是先绘制不透明的物体，然 后绘制透明的物体。否则，假设背景为蓝色，近处一块红色玻璃，中间一个绿色物体。如果先绘制红色半透明玻璃的话，它先和蓝色背景进行混合，则以后绘制中间 的绿色物体时，想单独与红色玻璃混合已经不能实现了。 总结起来，绘制顺序就是：首先绘制所有不透明的物体。如果两个物体都是不透明的，则谁先谁后 都没有关系。然后，将深度缓冲区设置为只读。接下来，绘制所有半透明的物体。如果两个物体都是半透明的，则谁先谁后只需要根据自己的意愿（注意了，先绘制 的将成为“目标颜色”，后绘制的将成为“源颜色”，所以绘制的顺序将会对结果造成一些影响）。最后，将深度缓冲区设置为可读可写形式。 调用glDepthMask(GL_FALSE);可将深度缓冲区设置为只读形式。调用glDepthMask(GL_TRUE);可将深度缓冲区设置为可读可写形式。 glBlendFunc函数官网文档]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android系统编码MediaCodec]]></title>
    <url>%2F2017%2F06%2F25%2Ftips-android-mediacodec%2F</url>
    <content type="text"><![CDATA[android编码器局限性1. 颜色格式问题MediaCodec在初始化的时候，在configure的时候，需要传入一个MediaFormat对象，当作为编码器使用的时候，我们一般需要在MediaFormat中指定视频的宽高，帧率，码率，I帧间隔等基本信息，除此之外，还有一个重要的信息就是，指定编码器接受的YUV帧的颜色格式。这个是因为由于YUV根据其采样比例，UV分量的排列顺序有很多种不同的颜色格式，而对于Android的摄像头在onPreviewFrame输出的YUV帧格式，如果没有配置任何参数的情况下，基本上都是NV21格式，但Google对MediaCodec的API在设计和规范的时候，显得很不厚道，过于贴近Android的HAL层了，导致了NV21格式并不是所有机器的MediaCodec都支持这种格式作为编码器的输入格式！ 因此，在初始化MediaCodec的时候，我们需要通过codecInfo.getCapabilitiesForType来查询机器上的MediaCodec实现具体支持哪些YUV格式作为输入格式，一般来说，起码在4.4+的系统上，这两种格式在大部分机器都有支持： 12MediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420PlannderMediaCodecInfo.CodecCapabilities.COLOR_FormatYUV420SemiPlannder 两种格式分别是YUV420P和NV21，如果机器上只支持YUV420P格式的情况下，则需要先将摄像头输出的NV21格式先转换成YUV420P，才能送入编码器进行编码，否则最终出来的视频就会花屏，或者颜色出现错乱 这个算是一个不大不小的坑，基本上用上了MediaCodec进行视频编码都会遇上这个问题 2. 编码器支持特性相当有限如果使用MediaCodec来编码H264视频流，对于H264格式来说，会有一些针对压缩率以及码率相关的视频质量设置，典型的诸如Profile(baseline, main, high)，Profile Level, Bitrate mode(CBR, CQ, VBR)，合理配置这些参数可以让我们在同等的码率下，获得更高的压缩率，从而提升视频的质量，Android也提供了对应的API进行设置，可以设置到MediaFormat中这些设置项: 123MediaFormat.KEY_BITRATE_MODEMediaFormat.KEY_PROFILEMediaFormat.KEY_LEVEL 但问题是，对于Profile，Level, Bitrate mode这些设置，在大部分手机上都是不支持的，即使是设置了最终也不会生效，例如设置了Profile为high，最后出来的视频依然还会是Baseline…. 这个问题，在7.0以下的机器几乎是必现的，其中一个可能的原因是，Android在源码层级hardcode了profile的的设置： 12345//XXXXif(h264type.eProfile != OMX_VIDEO_AVCProfileBaseline)&#123; ALOGW(&quot;Use baseline profile instead of %d for AVC recording&quot;, h264type.eProfile); h264type.eProfile = OMX_VIDEO_AVCProfileBaseline;&#125; Android直到7.0之后才取消了这段地方的Hardcode: 123456if(h264type.eProfile == OMX_VIDEO_AVCProfileBaseline)&#123; ....&#125;else if(h264type.eProfile == OMX_VIDEO_AVCProfileMain || h264type.eProfile == OMX_VIDEO_AVCProfileBaseHigh) .....&#125; 这个问题可以说间接导致了MediaCodec编码出来的视频质量偏低，同等码率下，难以获得跟软编码甚至iOS那样的视频质量。 3. 16位对齐要求前面说到，MediaCodec这个API在设计的时候，过于贴近HAL层，这在很多Soc的实现上，是直接把传入MediaCodec的buffer，在不经过任何前置处理的情况下就直接送入了Soc中。而在编码h264视频流的时候，由于h264的编码块大小一般是16x16，于是乎在一开始设置视频的宽高的时候，如果设置了一个没有对齐16的大小，例如960x540，在某些cpu上，最终编码出来的视频就会直接花屏！ 很明显这还是因为厂商在实现这个API的时候，对传入的数据缺少校验以及前置处理导致的，目前来看，华为，三星的Soc出现这个问题会比较频繁，其他厂商的一些早期Soc也有这种问题，一般来说解决方法还是在设置视频宽高的时候，统一设置成对齐16位之后的大小就好了。 4.软编解码介绍除了使用MediaCodec进行编码之外，另外一种比较流行的方案就是使用ffmpeg+x264/openh264进行软编码，ffmpeg是用于一些视频帧的预处理。这里主要是使用x264/openh264作为视频的编码器。 x264基本上被认为是当今市面上最快的商用视频编码器，而且基本上所有h264的特性都支持，通过合理配置各种参数还是能够得到较好的压缩率和编码速度的，限于篇幅，这里不再阐述h264的参数配置，有兴趣可以看下这两篇文章对x264编码参数的调优： https://www.nmm-hd.org/d/index.php?title=X264%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D&amp;variant=zh-cn http://www.cnblogs.com/wainiwann/p/5647521.html openh264(https://github.com/cisco/openh264)则是由思科开源的另外一个h264编码器，项目在2013年开源，对比起x264来说略显年轻，不过由于思科支付满了h264的年度专利费，所以对于外部用户来说，相当于可以直接免费使用了，另外，firefox直接内置了openh264，作为其在webRTC中的视频的编解码器使用。 但对比起x264，openh264在h264高级特性的支持比较差： Profile只支持到baseline, level 5.2 多线程编码只支持slice based，不支持frame based的多线程编码 从编码效率上来看，openh264的速度也并不会比x264快，不过其最大的好处，还是能够直接免费使用吧。 参考微信Android视频编码爬过的那些坑 android编码器支持参数Supported Media FormatsVideo encoding recommendations The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the H.264 Baseline Profile codec. The same recommendations apply to the Main Profile codec, which is only available in Android 6.0 and later. SD (Low quality) SD (High quality) HD 720p (N/A on all devices) Video resolution 176 x 144 px 480 x 360 px 1280 x 720 px Video frame rate 12 fps 30 fps 30 fps Video bitrate 56 Kbps 500 Kbps 2 Mbps Audio codec AAC-LC AAC-LC AAC-LC Audio channels 1 (mono) 2 (stereo) 2 (stereo) Audio bitrate 24 Kbps 128 Kbps 192 Kbps The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the VP8 media codec. SD (Low quality) SD (High quality) HD 720p (N/A on all devices) HD 1080p (N/A on all devices) Video resolution 320 x 180 px 640 x 360 px 1280 x 720 px 1920 x 1080 px Video frame rate 30 fps 30 fps 30 fps 30 fps Video bitrate 800 Kbps 2 Mbps 4 Mbps 10 Mbps CamcorderProfileRetrieves the predefined camcorder profile settings for camcorder applications. These settings are read-only. The compressed output from a recording session with a given CamcorderProfile contains two tracks: one for audio and one for video. Each profile specifies the following set of parameters: The file output format Video codec format Video bit rate in bits per second Video frame rate in frames per second Video frame width and height, Audio codec format Audio bit rate in bits per second, Audio sample rate Number of audio channels for recording. Android编码器常见问题MediaCodec KEY_FRAME_RATE seems to be ignored总结起来就是和输入编码器的帧率有关系 I am trying to modify the source for screenrecord in android 4.4 and lower the captured frame rate, but no matter what value I put in: 1format-&gt;setFloat(&quot;frame-rate&quot;, 5); the result is always the same ( a very high frame rate ) Is the encoder ignoring this property ? how can I control the frame rate ? The frame-rate value is not ignored, but it doesn’t do what you want. The combination of frame-rate and i-frame-interval determines how often I-frames (also called “sync frames”) appear in the encoded output. The frame rate value might also play a role in meeting the bitrate target on some devices, but I’m not sure about that (see e.g. this post). The MediaCodec encoder does not drop frames. If you want to reduce the frame rate, you have to do so by sending fewer frames to it. The screenrecord command doesn’t “sample” the screen at a fixed frame rate. Instead, every frame it receives from the surface compositor (SurfaceFlinger) is sent to the encoder, with an appropriate time stamp. If screenrecord receives 60 frames per seconds, you’ll have 60fps output. If it receives 10 frames in quick succession, followed by nothing for 5 seconds, followed by a couple more, you’ll have exactly that in the output file. You can modify screenrecord to drop frames, but you have to be a bit careful. If you try to reduce the maximum frame rate from 60fps to 30fps by dropping every-other frame, you run the risk that in a “frame0 - frame1 - long_pause - frame2” sequence you’ll drop frame1, and the video will hold on frame0 instead, showing a not-quite-complete animation. So you need to buffer up a frame, and then encode or drop frame N-1 if the difference in presentation times between that and frame N is ~17ms. The tricky part is that screenrecord, in its default operating mode, directs the frames to the encoder without touching them, so all you see is the encoded output. You can’t arbitrarily drop individual frames of encoded data, so you really want to prevent the encoder from seeing them in the first place. If you use the screenrecord v1.1 sources you can tap into “overlay” mode, used for –bugreport, to have the frames pass through screenrecord on their way to the encoder. In some respects it might be simpler to write a post-processor that reduces the frame rate. I don’t know how much quality would be lost by decoding and re-encoding the video.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>多媒体</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[media-storage-and-transfer]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-storage-and-transfer%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[media-compress]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-compress%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[media-video]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-video%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[media-audio]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-audio%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[多媒体技术(一)之图形图像]]></title>
    <url>%2F2017%2F06%2F20%2Fmedia-graphic%2F</url>
    <content type="text"><![CDATA[1.图形与图像的基本概念1.1图形与图像的颜色模型1.1.1颜色的基本概念1.1.1.1 物体的颜色物体的颜色不同是因为他们对光的吸收和反射的属性不同.物体的颜色是由该物体所反射的光的波长来决定的. 人眼看到的物体的颜色不仅取决于该物体所反射的光的波长,还与照射它的光源有关.如果用单一蓝色去照射绿色的树叶, 则此时的树叶只能是黑色的.因为蓝色光源中没有绿色成分,树叶吸收了全部蓝色而呈现黑色. 在彩色显示器中,为了使颜色具有较好的还原度和真实感,通常采用类似自然光作为照明光源. 1.1.1.2 彩色三要素颜色信息对人的视觉反应,可通过色调,色饱和度和亮度这三个参量来表示: 色调:用来描述颜色的不同类别的物理量称为色调,如红,橙,黄,绿,青,蓝,紫.色调取决于该种颜色的主要波长. 色饱和度:色饱和度则是描述颜色的深浅程度的物理量,它按该种颜色混入白光的比例来表示,当某色光的饱和度为100%时,就是表示该色光是完全没有混入白色光的单色光饱和度越高则颜色也越浓.如果大量混入白色光使饱和度降低,人视觉会感到颜色变淡.例如,在浓的的红色光中混入大量的白光,由于饱和度降低就变成了粉红色,但是因为红色是基本色,所以色调并不改变.在某颜色中混入白光与增强白光对某颜色物体的照射是不同的.前者是在摄入人眼的眸色光中混入白光,而后者的结果则是加强了某色物体的反射光的强度,在摄入人眼的反射光中并没有混入白光,因此它并没有改变该色的饱和度. 亮度:用来描述色光的明暗变化的强度的物理量成为亮度.亮度是色光能量的一种描述,是指色调和色饱和度已经固定的光,当它的全部能量增强时感觉明亮,否则感觉暗淡. 色调和色饱和度统称为色度. 1.1.1.3 三基色原理三基色原理认为自然界中景物的绝大多数的彩色光,能分解为互相独立的红(R),绿(G),蓝(B)三种基色光;反之,用互相独立的红,绿,蓝3种基色光以不同的比例混合,可模拟出自然界中绝大多数景色的光.RGB三基色相互独立的含义是指,任一种基色都不能由另外两种基色混合而产生.三基色的选择并不是唯一的. 1.1.1.4 像素(pixel)像素是计算机图形与图像中能被单独处理的最小基本单元. 从像素的视觉属性看,它是一个最小可是单位.一幅彩色图像可以看成是由许多很小的可是点组成的,这个点就是像素.每个像素点都有确定的颜色和亮度,这个颜色就是有互相独立的红,绿,蓝三种基色光以不同的比例混合而成的. 从像素的量值属性看,它的数据结构应同时显示地址,色彩,亮度等数据信息,这些数据就称为像素值. 1.1.2 颜色模型颜色模型(或称色彩模型)就是定量颜色方法.在不同的领域应用于图像时,为了尽可能多地,有效地描述各种颜色,往往采用不同的颜色模型,例如,用显示器这类发光物体显示时采用的是RGB模型,用打印机这类吸光物体输出图像时用CMY模型,进行彩色电视信号的显示与传输时采用YUV模型,从事艺术绘画时习惯采用HSL模型. 1.1.2.1 RGB模型RGB模型也称为加色法混色模型.其混色规律是:以等量的红,绿,蓝基色光混合时: 红 + 绿 = 黄色 红 + 蓝 = 品红色 绿 + 蓝 = 青色 红 + 绿 + 蓝 = 白色 3种基色光全无 = 黑色 加色法的混色规律可以使用下图表示,3个圆分别红绿蓝3种基色,圆与圆的叠加区域表示以等量的基色相混合时所合成的颜色,其色调如该区域的文字表示.当3种基色等量相加时,就会得到白色.其中,又尝尝把品红色成为绿色的补色,青色称为红色的补色,黄色称为蓝色的补色. 物体的颜色是丰富多彩的,任何一种颜色和这3种基色之间的关系可以用下面的配色方程式来描述: F(物体颜色)=R(红色的百分比) + G(绿色的百分比) + B(蓝色的百分比) 由于人类的视觉特性,两种或3种基色产生混色效果,不一定要同时和同一空间位置混合.例如,在心理学实验中有一个色轮实验,它是在可旋转的圆盘上按扇形面积均等的分成3部分,并涂上3种基色,当圆盘慢慢旋转时能够分辨出3中基色,但当圆盘旋转的频率提高到闪光融合频率以上时,人眼不再能分辨出3种基色,而产生白颜色的感觉,以达到混色的效果.这就是 “时间混色法” .最初的顺序制彩色电视就应用了人的这一视觉效果.例如,很细小的红点和旅店均匀间置互相靠的很近,只有在近距离仔细观看才能区分出来,当观看距离很远时就只感觉到黄色的一篇了,这就是 “空间混色法” .目前广泛使用的彩色显像管以及大型LED真彩色广告屏就是利用了这一混色视觉效应. 在多媒体技术中,RGB颜色模型是最基本的模型,因为彩色显示器只有按RGB分量式输入,才能在显示屏幕上合成任意颜色. 1.1.2.2 CMY模型CMY(Cyan Magenta Yellow)模型是采用青,品红,黄色3种基本颜色按一定比例合成颜色的方法.CMY模型又称为减色法混色模型,因为色彩的显示不是直接来自于光线的色彩,而是光线被物体吸收掉一部分之后发射回来的剩余光线所产生的.光线都被吸收时称为黑色,当光线都被反射时成为白色.这种模式适合于彩色打印机等用彩色墨水或颜料进行混合显示的情况. 在相减混色中,当3种基本颜色等量相减时得到黑色;等量黄色(Y)和品红(M)相减而青色为0时,等到红色(R);等量青色(C)和品红(M)相减而黄色为0时,得到蓝色(B);等量黄色(Y)和青色(C)相减而品红(M)为0时,得到绿色(G). 由于颜料的化学特性,实际上等量的CMY混合后并不能产生真正的黑色,因此在印刷时通常再加上黑色(Black),这样又称为CMYK模式,四色印刷便是由此而来. 显然,RGB与CMY模型是颜色互补的模型,它们之间可以互相转换.如果按每个像素每种颜色用一位二进制数表示的话,RGB与CMY模型之间的颜色关系如下表所示.利用它们之间的关系,可以把显示器显示的颜色转换成打印的颜色.但实际上因为发射光与反射光的性质完全不同,显示器上的颜色不可能精确地在打印机上复制出来,因此实际的转换过程会利用一定的算法进行一定程度上的失真补偿. |RGB|CMY|颜色| |—|—|—| |000|111|黑| |001|110|蓝| |010|101|绿| |011|100|青| |100|011|红| |101|010|品红| |110|001|黄| |111|000|白| 1.1.2.3 YUV与YIQ模型在彩色电视系统中不采用RGB颜色模型,而采用YUV或YIQ模型表示彩色图像.YUV适用于PAL(Phase Altermation Line,同行倒相制式)和SECAM(法文)(Sequential C欧了让Memo,顺序传送彩色与存储制式)彩色电视制式,而YIQ适用于美国国家电视标准委员会(NTSC,National Television System Committee)彩色电视制式. Y是亮度信号,U和V则是两个色差信号,分别传送红基色分量和蓝基色分量与亮度分量的差值信号. 采用YUV颜色模型的好处是:其一,亮度信号Y解决了彩色电视与黑白电视的兼容性问题;其二,由于人眼对颜色细节的分辨率低于对亮度细节的分辨率,所以可以用一个通道来传送,Y,U,V这3个信号,给亮度信号较大的带宽(6MHz)来传送图像的细节,而给色差信号较小的带宽(1.3MHz)来进行大面积涂色.这样,总的传输数据量和RGB模型相比,要明显小一些,起到了一种数据压缩节省存储空间的作用,而对于这种数据压缩带来的画面变化人眼一般是感觉不到的. 电视系统通常采用摄像机把摄得的彩色图像信号经分色,放大和校正分成RGB这3个分量的信号,再经过矩阵变换电路将彩色信号分解成亮度信号Y和色差信号,U,V,而后对其进行编码,用同一信道发送出去.接收端再通过编码及矩阵逆变换还原成3个基色显示. 在NTSC彩色电视制式中使用YIQ模型,其特性与YUV模型相近.其中的Y表示亮度,I,Q也是两个色差分量,但它们在色度矢量图中与U,V的位置不同.Q,I正交坐标轴与U,V正交坐标轴之间有33度夹角,如图所示: I,Q与U,V之间的关系如下: I = Vcos33 - Usin33 Q = Vsin33 + Ucos33 人眼的彩色视觉特性表明,人眼分辨红与黄之间的颜色变化的能力最强,而分辨蓝,紫之间颜色变化的能力最弱.因此YIQ模型在色度矢量图中,选择I轴正好处于夹角123度处,即人眼具有最大彩色分辨率的红与黄之间的橙色和青色(相角为303度)处,选择与I轴正交的色度信号轴为Q轴(相角为33度),正是人眼最不敏感的色轴位置.因而YIQ模型传送分辨力较强的I信号时,用较宽的频带(1.3MHz~1.5MHz),传送分辨力弱的Q信号时,可用较窄的频带(0.5MHz),这就可以在保证较好的颜色传输特性情况下,最大限度地节省存储空间. 1.1.2.4 HSI颜色模型HSI或HSL是Hue Saturation Intensity(Lightness)的英文缩写,颜色模型用H,S,I这三个参数描述颜色特性,其中H定义颜色的波长,称为色调;S表示颜色的深浅程度,称为饱和度;I表示强度或亮度,这正是颜色的三要素. HSI模型更接近人对颜色更接近人对彩色的认识,符合人眼对颜色的感知方式,是一种从事艺术绘画的画家们习惯使用的描述色彩的方法.它比RGB模型使用更方便,从而能减少彩色图像处理的复杂性,增加快速性,因此一般的图像处理软件中,都提供了这种定量色彩的方式. 1.1.3 颜色模型的转换无论采用什么颜色模型来表示彩色图形与图像,由于所有的显示器都需要RGB值来驱动,所以在显示每个像素之前,必须要把彩色分量值转换成RGB值. 1.1.3.1 YUV与RGB颜色模型变换RGB与YUV的对应关系可以近似地用下面的方程表示: Y = 0.299R + 0.587G + 0.114B U = -0.147R - 0.289G + 0.436B V = 0.615R - 0.515G - 0.096B1.1.3.2 YIQ与RGB颜色模型变换YIQ与RGB的对应关系可以近似地用下面的方程表示: Y = 0.229R + 0.587G + 0.114B I = 0.596R - 0.275G - 0.321B Q = 0.212R - 0.523G + 0.311B HSI 与 RGB颜色变换HSI与RGB空间的转换关系可以用下面的方程表示: H = [90 - arctan(F/sqr(3)) + [0, G&gt;B;180,G&lt;B]]/360 S = 1 - min(R,G,B)/I I = (R+G+B)/3 其中,F=(2R-G-B)/(G-B),sqr为求平方根 1.2图形与图像的基本属性一幅彩色图像可以看成二维连续函数f(x,y),其彩色幅度是位置(x,y)的函数.计算机多媒体技术从其图像的生成,显示,处理和存储的机制出发,需要对彩色图像数字化.数字化一幅彩色图像就是要把连续函数f(x,y)在空间的坐标和彩色幅度进行离散和量化.空间坐标x,y的离散化通常以分辨率来表征,而彩色幅度的离散化则由像素的颜色深度来表征. 1.2.1分辨率分辨率是一个统称,分为显示分辨率,图像分辨率,扫描分辨率和打印分辨率等. 1.2.1.1显示分辨率是指某一种显示方式下,显示屏上能够显示出的像素数目,以水平和垂直的像素表示.例如,显示分辨率为640*480表示显示屏分成480行,每行显示640个像素,整个显示屏就含有307200个显像点.屏幕上的像素越多,分辨率就越高,显示出来的图像也就越细腻,显示的图像质量也就约高.屏幕能够显示的最大像素数目越多,也说明显示设备的最大分辨率越高.显示屏上的每个彩色像素由代表R,G,B这3种模拟信号的相对强度决定,这些彩色像素点就构成一幅彩色图像. 1.2.1.2图像分辨率图像分辨率指数字化图像的大小,以水平和垂直的像素数表示.如果组成图像的像素数目越多,则说明图像的分辨率越高,看起来就越逼真,图像分辨率实际上决定了图像的显示质量,也就是说,即使提高了显示分辨率,也无法真正改善图像的质量.图像分辨率与显示分辨率是两个不同的概念.图像分辨率的确定组成一幅图像的像素数目,而显示分辨率是确定显示图像的区域大小.当图像分辨率与屏幕分辨率一致时,图像正好占据满屏;当图像分辨率小于屏幕分辨率时,图像占据屏幕的一部分;当图像分辨率大于屏幕分辨率时,则屏幕仅能显示图像的一部分. 1.2.1.3扫描分辨率和打印分辨率在用于扫描仪扫描图像时,通常要指定扫描的分辨率,用每英寸包含的点(d/i,dots per inch)表示.如果用300d/i来扫描一幅86的彩色图像,就得到一幅24001800个像素的图像.分辨率越高,像素就越多. 打印分辨率是指图像打印时每英寸可识别的点数,也使用d/i(dots per inch)为衡量单位.两种分辨率之间是有区别的,扫描分辨率反映了扫描后的图像与原始图像之间的差异程度,分辨率越高,差异越小.打印分辨率反映了打印的图像与原数字图像之间的差异程度,分辨率越接近原图像的分辨率,打印质量越高.两种分辨率的最高值都受到设备的限制. 1.2.2颜色深度颜色深度是指图像中每个像素的颜色(或亮度)信息所占的二进制数位数,记做位/像素(b/p,bits per pixel).屏幕上的每一个像素都占有一个或多个位,用于存放与它相关的颜色信息.颜色深度决定了构成图像的每个像素可能出现的最大颜色数,因而颜色深度值越高,显示的图像色彩越丰富.反之,颜色深度太浅,会影响图像的质量,图像看起来让人觉得很粗糙和很不自然.常见颜色深度有一下5种: 4bit:这是VGA标准支持的颜色深度,共2的四次方16种颜色; 8bit:这是多媒体应用中的最低颜色深度,共2的8次方256种颜色,称为索引彩色图(由颜色查找决定); 16bit:在16bit中,用其中的15bit表示RGB这3种颜色,每种颜色5bit,用剩余的以为表示图像的其他属性,如透明度.所以16bit的颜色深度实际可以表示为2的15次方323232共32768种颜色.称为HI-Color(高彩色)图像. 24bit:用3个8bit分别表示RGB,可生成的颜色数2的24次16777216种,约16M种颜色,这已经成为真彩色; 32bit:同24bit颜色深度一样,也是用3个bit分别表示RGB这三种颜色,剩余的8bit用来表示图像的其他属性,如透明度等. 虽然像素的颜色颜色深度值越大图像色彩越丰富,但由于设备的限制,人眼分辨率的限制,不一定要追求特别深的颜色深度,一般来说,32bit的颜色深度已经足够.此外,像素颜色深度越深,所占用的存储空间越大. 一个像素的颜色深度位数除R,G,B分量占用固定bit数表示颜色外,一般要腾出1bit或几bit作为属性(Attribute)位.属性位用来指定该像素应具有的性质.例如,像素的颜色深度为32bit时,R,G,B分别用8bit表示,那么余下的8bit常称为a通道(Alpha Channel)位,或称为覆盖(Overlay)位,中断位,属性位,它用来控制该像素点的透明度.假如定义一个像素值(A,R,G,B)的4个分量(其中A为Alpha属性位数值)都用归一化的数值表示,那么像素91,1,0,0)时显示红色.当像素为(0.5,1,0,0)时,预乘的结果就变成了(0.5.0.5,0,0),这表示现在显示的红色的强度减低一半.用这种定义像素属性的办法可以实现两幅彩色图像之间的透明叠加效果.当Alpha数值很小时,渲染出来的效果是几乎透明的,如玻璃;当Alpha数值处于中间的位置时,则可以得到一种半透明的效果;当Alpha数值接近255时,是几乎不透明的效果.这种属性位的加入为实现透明和半透明的显示掉过带来了方便. 1.2.3文件的大小图形和图像文件的大小(也称为数据量)是指在磁盘上存储整幅图像所有点的字节数(Bytes),反映了图像所需数据存储空间的大小,可按下面的公式计算: 文件字节数 = 图像分辨率 * 图像深度/8 从公式看,图像文件的大小与图像的颜色和内容无关.其实在实际应用中,为了节省存储空间,总要对图像应用某种压缩文件格式.这样,不同的图像会因为内容的不同而使文件的大小有所不同.相对于颜色层次多,图形复杂的图像文件较大.但各种图像文件的最大值(文件字节数)都不会超越由上式决定的字节数. 1.2.4 真彩色,伪彩色与直接色 真彩色(True Color):真彩色是指在组成一幅彩色图像的每个像素值中,有R,G,B这3个基色分量,每个基色分量直接决定显示设备的基色强度,这样产生的彩色称为真彩色.例如,用RGB的8:8:8方式表示一幅彩色图像,就是R,G,B都用8bit来表示,每个基色分量占一个字节,共3个字节,每个像素的颜色就是由这3字节中的数值直接决定,可生成的颜色数就是2的24次中,共计16777216中. 伪彩色(Pseudo Color) 伪彩色图像是每个像素的颜色不是由每个基色分量的数值直接决定,而是把像素值当做彩色查找表(CLUT,Color-Look-Up Table)的表项入口地址,去查找一个显示图像时使用的RGB强度值,用查找出的R,G,B强度值产生的彩色称为伪彩色.彩色查找表是一个事先制作好的表,表项入口地址也称为索引号.彩色图像本身的像素值和彩色查找表中的索引号有一个变换关系,也可以是用自己定义的变换关系.使用查找得到的数值在显示器上显示的颜色是真的,但不是图像本身真正的颜色,因此称其为伪彩色; 直接色(Direct Color):把像素值的R,G,B分量作为单独的索引值,通过相应的彩色变换表找出R,G,B各自的基色程度,用这个强度值产生的彩色称其为直接色.真彩色系统虽然也是采用R,G,B分量来决定基色强度,但这是由R,G,B经变换后决定的,这与直接用R,G,B决定基色基色强度产生的颜色就有差别.比较而言,直接色在显示器上显示彩色图像看起来更真实,更自然. 伪彩色系统是把整个像素当做查找表的索引值进行彩色变换,而直接色系统是对R,G,B分量分别采用查找表进行变换,因此伪彩色系统色彩还原度自然就查多了. 1.3图形与图像的基本类型1.3.1位图与矢量图 位图(Bit-mapped Graphics) 矢量图(Vector Graphic) 位图和矢量图的关系 1.3.2 图形与图像的区别与联系2.图形与图像的处理2.1图形与图像的获取2.1.1 图形与图像的数字化2.1.2 图形的获取2.1.3 图像的获取2.2图形与图像的存储2.2.1静态图形与图像常见文件存储格式2.2.2 动态图形与图像常见文件存储格式2.2.3 文件存储格式的数据结构2.3图形与图像的显示2.3.1映射显示原理2.3.2硬复制设备2.4图形与图像的处理2.4.1 图形与图像处理的基本内容2.4.2 图像处理实例分析-图像识别2.4.3 图形与图像处理软件3.计算机动画3.1计算机动画的原理3.2计算机动画的类型3.3计算机动画的制作3.4虚拟现实动画技术]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac下打包qt程序成dmg]]></title>
    <url>%2F2017%2F06%2F18%2Ftips-qt-pack%2F</url>
    <content type="text"><![CDATA[参考http://doc.qt.digia.com/4.7-snapshot/appicon.html 图片格式在线转换http://iconverticons.com/，可以生成icns格式图片。 Test.pro中添加macx{ICON = Test.icns} （记得把Test.icns添加到工程中） 发布dmb包 QT在mac下有个发布命令：macdeployqt 我的mac上macdeployqt目录如下：/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin 将macdeployqt的路径添加到环境变量里面 终端里 vim /etc/profile（如果在保存时有问题，可以用 sudo vim /etc/profile）1234567891011121314#在最后添加一行，如下所示：# System-wide .profile for sh(1)if [ -x /usr/libexec/path_helper ]; then eval `/usr/libexec/path_helper -s`fiif [ &quot;$&#123;BASH-no&#125;&quot; != &quot;no&quot; ]; then [ -r /etc/bashrc ] &amp;&amp; . /etc/bashrcfi export PATH=/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin:$PATH cd进入到Test.app所在目录，然后执行macdeployqt extractor.app -verbose=1 -dmg，即可生成Test.dmg包。]]></content>
      <categories>
        <category>QT</category>
      </categories>
      <tags>
        <tag>QT</tag>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mpeg编码seekto方法精确定位到指定帧]]></title>
    <url>%2F2017%2F06%2F18%2Ftips-seekto%2F</url>
    <content type="text"><![CDATA[MediaExtractor有一个方法如下: 12//All selected tracks seek near the requested time according to the specified mode.public void seekTo (long timeUs, int mode) timeUs是要seek的时间戳，mode是seek的模式，可以是SEEK_TO_PREVIOUS_SYNC, SEEK_TO_CLOSEST_SYNC, SEEK_TO_NEXT_SYNC，分别是seek指定帧的上一帧，最近帧和下一帧。 此方法可用于视频播放时动态定位播放帧，用于动态改变视频播放进度，比如使用seekBar来跟踪视频播放进度，同时可拖动来动态改变播放进度。 mpeg编码决定seekTo方法无法精确定位到指定帧。即使使用的是某一帧精确的时间戳作为seekTo方法的输入参数也无法实现精确定位。 在google, stackoverlfow查询得出的结论是：在每次seekTo方法调用后，MediaCodec必须从关键帧开始解码。因此seekTo方法只会seek到最近的／上一个／下一个关键帧，也就是I-Frame(key frame = I frame = sync frame)。之所以要从关键帧开始解码，是因为每一帧不一定是单独编码的，只有I frame才是帧内编码，而P, B frame都是要参考别的帧来进行编码，因此单独拿出来是不完整的一帧。 stackoverflow上有人对此的做法是：seekTo的输入参数mode设置为SEEK_TO_PREVIOUS_SYNC,即seek的是指定帧的上一个关键帧。然后判断当前的时间戳是否小于定位关键帧的时间戳，如果是就调用MediaExtractor的advance方法，“快进”到指定帧。 1234extractor.seekTo(expectedPts, MediaExtractor.SEEK_TO_PREVIOUS_SYNC); while (currentPts &lt; expectedPts) &#123; extractor.advance(); &#125; 但是这个方法仍不理想，如果seek的位置和当前位置比较远的话，会有一定延迟。而且视频内容偶尔会出现不完整的帧的闪现。 经过一段时间的研究，终于解决了这个问题，现在播放时可以根据seekBar随时拖动到视频任何一帧，不会有任何延迟，甚至可以实现倒播了。 因为之前播放视频的是自己用MediaCodec, MediaMuxer等编码合成的视频文件，在编码参数设置的时候，将关键帧间隔KEY_I_FRAME_INTERVAL设置为了1（因为要求参数为整数）。注意这个参数的单位是秒，而不是帧数！网上看到很多例子包括fadden的bigflake和Grafika上都将这里设置为了20几。搞得我一开始还以为是每隔二十几帧就有一个关键帧。如果设置为20几，那么就是说你用MediaCodec编码录制一段20多秒的视频，只有开头的一个关键帧！剩下的都是P或者B帧。 这显然是不合理的。一般来说是每隔1秒有一个关键帧，这样就可以seek到对应秒的关键帧。或者说1秒内如果有30帧，那么这30帧至少有一个关键帧。因此我将KEY_I_FRAME_INTERVAL设置为了1。 1mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 1); 这也是为什么我在播放用这种参数编码的视频的时候，使用seekTo方法不能准确定位帧了。之前有讲，seekTo是定位到关键帧的，如果不是关键帧，那么它会去找上一个／最近一个／下一个关键帧，这取决于你输入参数mode的设置。 因此如果想使用seekBar准确拖动定位到任何一帧播放，必须保证每一帧都是关键帧。 于是，我将KEY_I_FRAME_INTERVAL设置为了0： 1mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 0); 事实也证明这样可以保证录制的每一帧都是关键帧，因此在使用seekTo方法的时候终于可以准确定位任何一帧了。拖动seekBar的时候视频内容也会立刻改变，无论是往前还是往后，都不会有任何延迟和画面不完整的情况. 但是，把视频每一帧都设置为关键帧是否合理呢？是否会占太大空间呢？ 带着这个疑问，我使用ffmpeg查看了我测试使用的手机（Lenovo X2)内置相机录制的视频。 只需一行代码： 1ffprobe -show_frames video.mp4 &gt; frames.txt 打开frames.txt可以看到每一帧的key_frame=1，表示是关键帧 这说明了手机本来录像就是把每一帧都作为关键帧的。 当然，不能以偏概全，于是我使用iPhone 6s录制的一段普通视频和慢动作视频。使用ffmpeg查看，发现每一帧也都是关键帧（慢动作视频1秒有240帧也都全部作为关键帧也是蛮拼的）。 目前我测试的两部手机都是如此，具体为什么手机录的视频每一帧都是关键帧我也不明白。而视频文件体积大小和是否将每一帧设为关键帧似乎不成线性关系，所以将KEY_I_FRAME_INTERVAL设置为0的方案是可行的。 因此只要保证视频每帧都是关键帧，那么seekTo方法就可以精确定位指定帧了。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>多媒体</tag>
        <tag>Mpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多媒体技术简介]]></title>
    <url>%2F2017%2F06%2F07%2Fmedia-intro%2F</url>
    <content type="text"><![CDATA[关键帧间隔关键帧包含了显示帧需要的所有信息 所有的视频都至少包含一个关键帧，作为文件的第一个帧。其它的关键帧可用来改善视频的质量，不过它们也会增加文件大小。一般而言，每一秒视频至少需要使用 1 个关键帧。若使用此公式，在每秒播放 25个帧的视频中，每 25 个帧就会有 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。 两种彩电视频制式： NTSC (525 lines @ 59.94 Hz) 29.97 fps PAL (625 lines @ 50 Hz) 25 fps NTSC和PAL属于全球两大主要的电视广播制式，但是由于系统投射颜色影像的频率而有所不同。NTSC是National Television System Committee的缩写，其标准主要应用于日本、美国，加拿大、墨西哥等等，PAL 则是Phase Alternating Line的缩写，主要应用于中国，香港、中东地区和欧洲一带。 GOP最大可含帧数目：18 (NTSC) / 15 (PAL) GOP是由固定模式的一系列I帧、P帧、B帧组成。 I帧编码是为了减少空间域冗余，P帧和B帧是为了减少时间域冗余。 常用的结构由15个帧组成，具有以下形式IBBPBBPBBPBBPBB。简称GOP(4,2)，指的是该图像组除了一个I帧外，包含了4个P帧，并且任何两个P帧或者I、P之间都有两个B帧。 GOP（Group of Pictures）策略影响编码质量：所谓GOP，意思是画面组，一个GOP就是一组连续的画面。MPEG编码将画面（即帧）分为I、P、B三种，I是内部编码帧，P是前向预测帧，B是双向内插帧。简单地讲，I帧是一个完整的画面，而P帧和B帧记录的是相对于I帧的变化。没有I帧，P帧和B帧就无法解码，这就是MPEG格式难以精确剪辑的原因，也是我们之所以要微调头和尾的原因。 MPEG-2 帧结构 MPEG-2压缩的帧结构有两个参数，一个是GOP（Group Of Picture）图像组的长度，一般可按编码方式从1－15；另一个是I帧和P帧之间B帧的数量，一般是1－2个。前者在理论上记录为N，即多少帧里面出现一次I帧；后者描述为多少帧里出现一次P帧，记录为M。]]></content>
      <categories>
        <category>media</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jni介绍]]></title>
    <url>%2F2017%2F06%2F07%2Fjni-intro%2F</url>
    <content type="text"><![CDATA[NDK技巧 加快ndk-build编译速度 NDK编译时加上-j参数,如:1ndk-build -j4 # -j4,让make最多允许4个编译命令同时执行 测试后编译速度至少可以提高一倍 C回调JAVA c中返回一个字符串 1（*env）-&gt;NewStringUTF(env,&quot;Huazi 华仔&quot;); c中返回一个数组 12345678910..................... int i = 0; jintArray array; array =(*env)-&gt;NewIntArray(env,8); for(;i&lt;8;i++) // 赋值成 0 ~ 7 (*env)-&gt;SetObjectArrayElement(env,array,i,i); &#125; return array; c中使用调用传入的参数是数组array 是传入的数组 123456789......... int sum =0, i; int len = (*env)-&gt;GetArrayLength(env,array); jint *element =(*env)-&gt;GetIntArrayElement(env,array,0); for(i=0;i&lt;len;i++) &#123; sum+= *(element+i); &#125; return sum; c中调用java中类的方法 没有参数 只有返回值String 1234567//()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型 JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123; jmethodID mid; jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名 mid =(*env)-&gt;GetMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);//TestMethod java中的方法名 jstring msg =(*env)-&gt;CallObjectMethod(env,object,mid); //object 注意下是jni传过来的jobject return msg; c中调用java中类的静态方法 没有参数 只有返回值String 12345678//@&quot;()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123; jmethodID mid; jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名 mid =(*env)-&gt;GeStatictMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);// TestMethod java中的方法名 jstring msg =(*env)-&gt;CallStaticObjectMethod(env,cls,mid); //object 注意下是jni传过来的jobject return msg; &#125;]]></content>
      <tags>
        <tag>Android</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFMPEG编译之Mac]]></title>
    <url>%2F2017%2F06%2F07%2Fffmpeg-compile-mac%2F</url>
    <content type="text"><![CDATA[Mac下FFMPEG使用There are a few ways to get FFmpeg on OS X. One is to build it yourself. Compiling on Mac OS X is as easy as any other *nix machine, there are just a few caveats(警告). The general procedure is get the source, then ./configure ; make &amp;&amp; sudo make install, though specific configure flags are possible. Another is to use some “build helper” tool, to install it for you. For example, homebrew or macports, see the homebrew section in this document. Alternatively, if you are unable to compile, or do not want to install homebrew, you can simply download a static build for OS X, but it may not contain the features you want. Typically this involves unzipping an FFmpeg distribution file [like .zip file], then running it from within the newly extracted files/directories. 手动编译FFMPEG1.下载FFMPEG源码使用git clone https://github.com/FFmpeg/FFmpeg从github下载ffmpeg源码,切换到要使用的目标分支(这里使用release/3.3):git checkout -b r3.3 origin/release/3.3,或者直接从github下载分支release/3.3的压缩包,解压. 2.准备XcodeStarting with Lion 10.7, Xcode is available for free from the Mac App Store and is required to compile anything on your Mac. Make sure you install the Command Line Tools from Preferences &gt; Downloads &gt; Components. Older versions are still available with an AppleID and free Developer account at ​developer.apple.com. 3.准备HomeBrew工具To get ffmpeg for OS X, you first have to install ​Homebrew. If you don’t want to use Homebrew, see the section below. 1ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Then: 12brew install automake fdk-aac git lame libass libtool libvorbis libvpx \opus sdl shtool texi2html theora wget x264 x265 xvid yasm Mac OS X Lion comes with Freetype already installed (older versions may need ‘X11’ selected during installation), but in an atypical location: /usr/X11. Running freetype-config in Terminal can give the locations of the individual folders, like headers, and libraries, so be prepared to add lines like CFLAGS=freetype-config --cflags LDFLAGS=freetype-config --libs PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig:/usr/lib/pkgconfig:/usr/X11/lib/pkgconfig before ./configure or add them to your $HOME/.profile file. 4.编译Once you have compiled all of the codecs/libraries you want, you can now download the FFmpeg source either with Git or the from release tarball links on the website. Study the output of ./configure –help and make sure you’ve enabled all the features you want, remembering that –enable-nonfree and –enable-gpl will be necessary for some of the dependencies above. A sample command is: 123456git clone http://source.ffmpeg.org/git/ffmpeg.git ffmpegcd ffmpeg./configure --prefix=/usr/local/ffmpeg --enable-gpl --enable-nonfree --enable-libass \--enable-libfdk-aac --enable-libfreetype --enable-libmp3lame \--enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libopus --enable-libxvidmake &amp;&amp; sudo make install --prefix指定编译完成后安装路径,这里指定到/usr/local/ffmpeg,安装完成会在/usr/local/ffmpeg下生成:bin,include,lib,share四个目录 安装环境介绍A package consists of several related files which are installed in several directories. The configure step usually allows the user to specify the so-called install prefix, and is usually specified through the configure option configure –prefix=PREFIX, where PREFIX usually is by default /usr/local. The prefix specifies the common directory where all the components are installed. The following directories are usually involved in the installation: PREFIX/bin: contains the generated binaries (e.g. ffmpeg, ffplay, ffprobe etc. in the case of FFmpeg) PREFIX/include: contains the library headers (e.g. libavutil/avstring.h, libavcodec/avcodec.h, libavformat/avformat.h etc. in case of FFmpeg) required to compile applications linked against the package libraries PREFIX/lib: contains the generated libraries (e.g. libavutil, libavcodec, libavformat etc. in the case of FFmpeg) PREFIX/share: contains various system-independent components; especially documentation files and examples By specifying the prefix it is possible to define the installation layout. By using a shared prefix like /usr/local/, different packages will be installed in the same directory, so in general it will be more difficult to revert the installation. Using a prefix like /opt/PROJECT/, the project will be installed in a dedicated directory, and to remove from the system you can simply remove the /opt/PREFIX path. On the other hand, such installation will require to edit all the environment variables to point to the custom path. Environment variablesSeveral variables defined in the environment affect your package install. In particular, depending on your installation prefix, you may need to update some of these variables in order to make sure that the installed components can be found by the system tools. The list of environment variables can be shown through the command env. A list of the affected variables follows: PATH: defines the list of :-separated paths where the system looks for binaries. For example if you install your package in /usr/local/, you should update the PATH so that it will contain /usr/local/bin. This can be done for example through the command export PATH=/usr/local/bin:$PATH. LD_LIBRARY_PATH: contains the :-separated paths where the system looks for libraries. For example if you install your package in /usr/local/, you should update the LD_LIBRARY_PATH so that it will contain /usr/local/lib. This can be done for example through the command export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH. This variable is sometimes deprecated in favor of the use of ldconfig. CFLAGS: contains flags used by the C compiler, and usually includes preprocessing directives like -IPREFIX/include or compilation flags. Custom CFLAGS are usually prefixed to the source package compiler flags by the source package build system. Alternatively many build systems allow to specify the configure option -extra-cflags. LDFLAGS: these are directives used by the linker, and usually include linking directives like -LPREFIX/lib needed to find libraries installed in custom paths. Custom LDFLAGS are usually prefixed to the source package linker flags by the source package build system. Alternatively, many build systems allow to specify the configure option -extra-ldflags. PKG_CONFIG_PATH: contains the :-separated paths used by pkg-config to detect the pkg-config files used by many build systems to detect the custom CFLAGS/LDFLAGS used by a specific library. In case you installed a package in a non standard path, you need to update these environment libraries so that system tools will be able to detect the package components. This is especially required when running a configure script for a package relying on other installed libraries/headers/tools. Environment variables are usually defined in the profile file, for example .profile defined in the user directory for sh/bash users, and in /etc/profile. This file can be edited to permanently set the custom environment. Alternatively, the variables can be set in a script or in a particular shell session. Remember to export the variables to the child process, e.g. using the export command. Read the fine documentation of your shell for more detailed information. MAC下的动态链接库扩展名Windows下.DLL,Linux下.so,Mac OS X下的扩展名是.dylib。 .dylib是Mach-O格式，也就是Mac OS X下的二进制文件格式。Mac OS X提供了一系列 工具，用于创建和访问动态链接库。 编译器/usr/bin/cc，也就是gcc了，Apple改过的。这个主要还是一个壳，去调用其他 的一些部件。当然同时还有/usr/bin/c++，等等。 汇编器/usr/bin/as 链接器/usr/bin/ld MAC下创建动态链接库步骤: 首先是生成module文件，也就是.o文件。这跟一般的unix没什么区别。例如cc -c a.c b.c,就得到a.o和b.o 可以用ld来合并.o文件，比如ld -r -o c.o a.o b.o 然后可以用libtool来创建动态链接库:libtool -dynamic -o c.dylib a.o b.o.（ 这里也可以用libtool -static -o c.a a.o b.o就创建静态库） 如果用gcc直接编译，我记得linux下一般是可以: gcc -shared -o c.so a.c b.c 而在Mac OS X下需要: gcc -dynamiclib -o c.dylib a.c b.c 动态链接库的工具nm是最常用的，这个用法跟linux下差不多:nm c.dylib,可以看到导出符号表，等等。 另一个常用的工具是otool，这个是Mac OS X独有的。比如想看看c.dylib的依赖关系otool -L c.dylib 官网方法 CompilationGuide-Generic CompilationGuide-MacOSX 编译ffmpeg3.3结果没有ffplay因为系统没有sdl环境或sdl版本不匹配,ffmpeg3.3需要sdl2 http://www.libsdl.org/download-2.0.php 下载Source Code SDL2-2.0.5.zip - GPG signed,解压缩,执行命令: 123./configure make sudo make install 进行编译]]></content>
      <categories>
        <category>FFMPEG</category>
      </categories>
      <tags>
        <tag>Mac</tag>
        <tag>多媒体</tag>
        <tag>FFMPEG</tag>
        <tag>音视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenGL Frame Buffer Object(FBO)]]></title>
    <url>%2F2017%2F06%2F03%2Fgl-fbo%2F</url>
    <content type="text"><![CDATA[Update: Framebuffer object extension is promoted as a core feature of OpenGL version 3.0, and is approved by ARB combining the following extensions; EXT_framebuffer_object EXT_framebuffer_blit EXT_framebuffer_multisample EXT_packed_depth_stencil OverviewIn OpenGL rendering pipeline, the geometry data and textures are transformed and passed several tests, and then finally rendered onto a screen as 2D pixels. The final rendering destination of the OpenGL pipeline is called framebuffer. Framebuffer is a collection of 2D arrays or storages utilized by OpenGL; colour buffers, depth buffer, stencil buffer and accumulation buffer. By default, OpenGL uses the framebuffer as a rendering destination that is created and managed entirely by the window system. This default framebuffer is called window-system-provided framebuffer. 在OpenGL渲染管线中，几何数据和纹理经过多次转化和多次测试，最后以二维像素的形式显示在屏幕上。OpenGL管线的最终渲染目的地被称作帧缓存（framebuffer）。帧缓冲是一些二维数组和OpenG所使用的存储区的集合：颜色缓存、深度缓存、模板缓存和累计缓存。一般情况下，帧缓存完全由window系统生成和管理，由OpenGL使用。这个默认的帧缓存被称作“window系统生成”（window-system-provided）的帧缓存。 The OpenGL extension, GL_ARB_framebuffer_object provides an interface to create additional non-displayable framebuffer objects (FBO). This framebuffer is called application-created framebuffer in order to distinguish from the default window-system-provided framebuffer. By using framebuffer object (FBO), an OpenGL application can redirect the rendering output to the application-created framebuffer object (FBO) other than the traditional window-system-provided framebuffer. And, it is fully controlled by OpenGL. 在OpenGL扩展中，GL_EXT_framebuffer_object提供了一种创建额外的不能显示的帧缓存对象的接口。为了和默认的“window系统生成”的帧缓存区别，这种帧缓冲成为应用程序帧缓存（application-createdframebuffer）。通过使用帧缓存对象（FBO），OpenGL可以将显示输出到引用程序帧缓存对象，而不是传统的“window系统生成”帧缓存。而且，它完全受OpenGL控制。 Similar to window-system-provided framebuffer, a FBO contains a collection of rendering destinations; color, depth and stencil buffer. (Note that accumulation buffer is not defined in FBO.) These logical buffers in a FBO are called framebuffer-attachable images, which are 2D arrays of pixels that can be attached to a framebuffer object. 相似于window系统提供的帧缓存，一个FBO也包含一些存储颜色、深度和模板数据的区域。（注意：没有累积缓存）我们把FBO中这些逻辑缓存称之为“帧缓存关联图像”，它们是一些能够和一个帧缓存对象关联起来的二维数组像素。 There are two types of framebuffer-attachable images; texture images and renderbuffer images. If an image of a texture object is attached to a framebuffer, OpenGL performs “render to texture”. And if an image of a renderbuffer object is attached to a framebuffer, then OpenGL performs “offscreen rendering”. 有两种类型的“帧缓存关联图像”：纹理图像（texture images）和渲染缓存图像（renderbuffer images）。如果纹理对象的图像数据关联到帧缓存，OpenGL执行的是“渲染到纹理”（render to texture）操作。如果渲染缓存的图像数据关联到帧缓存，OpenGL执行的是离线渲染（offscreen rendering）。 By the way, renderbuffer object is a new type of storage object defined in GL_ARB_framebuffer_object extension. It is used as a rendering destination for a single 2D image during rendering process. 这里要提到的是，渲染缓存对象是在GL_EXT_framebuffer_object扩展中定义的一种新的存储类型。在渲染过程中它被用作存储单幅二维图像。 The following diagram shows the connectivity among the framebuffer object, texture object and renderbuffer object. Multiple texture objects or renderbuffer objects can be attached to a framebuffer object through the attachment points. 下面这幅图显示了帧缓存对象、纹理对象和渲染缓存对象之间的联系。多多个纹理对象或者渲染缓存对象能够通过关联点关联到一个帧缓存对象上。 There are multiple color attachment points (GL_COLOR_ATTACHMENT0,…, GL_COLOR_ATTACHMENTn), one depth attachment point (GL_DEPTH_ATTACHMENT), and one stencil attachment point (GL_STENCIL_ATTACHMENT) in a framebuffer object. The number of color attachment points is implementation dependent, but each FBO must have at least one color attachement point. You can query the maximum number of color attachement points with GL_MAX_COLOR_ATTACHMENTS, which are supported by a graphics card. The reason that a FBO has multiple color attachement points is to allow to render the color buffer to multiple destinations at the same time. This “multiple render targets” (MRT) can be accomplished by GL_ARB_draw_buffers extension. Notice that the framebuffer object itself does not have any image storage(array) in it, but, it has only multiple attachment points. 在一个帧缓存对象中有多个颜色关联点（GL_COLOR_ATTACHMENT0_EXT,…,GL_COLOR_ATTACHMENTn_EXT），一个深度关联点（GL_DEPTH_ATTACHMENT_EXT），和一个模板关联点（GL_STENCIL_ATTACHMENT_EXT）。每个FBO中至少有一个颜色关联点，其数目与实体显卡相关。可以通过GL_MAX_COLOR_ATTACHMENTS_EXT来查询颜色关联点的最大数目。FBO有多个颜色关联点的原因是这样可以同时将颜色而换成渲染到多个FBO关联区。这种“多渲染目标”（multiple rendertargets,MRT）可以通过GL_ARB_draw_buffers扩展实现。需要注意的是：FBO本身并没有任何图像存储区，只有多个关联点。 Framebuffer object (FBO) provides an efficient switching mechanism; detach the previous framebuffer-attachable image from a FBO, and attach a new framebuffer-attachable image to the FBO. Switching framebuffer-attachable images is much faster than switching between FBOs. FBO provides glFramebufferTexture2D() to switch 2D texture objects, and glFramebufferRenderbuffer() to switch renderbuffer objects. FBO提供了一种高效的切换机制；将前面的帧缓存关联图像从FBO分离，然后把新的帧缓存关联图像关联到FBO。在帧缓存关联图像之间切换比在FBO之间切换要快得多。FBO提供了glFramebufferTexture2DEXT()来切换2D纹理对象和glFramebufferRenderbufferEXT()来切换渲染缓存对象。 Creating Frame Buffer Object (FBO)Creating framebuffer objects is similar to generating vertex buffer objects (VBO). 创建FBO和产生VBO类似。 12void glGenFramebuffers(GLsizei n, GLuint* ids)void glDeleteFramebuffers(GLsizei n, const GLuint* ids) glGenFramebuffers() requires 2 parameters; the first one is the number of framebuffers to create, and the second parameter is the pointer to a GLuint variable or an array to store a single ID or multiple IDs. It returns the IDs of unused framebuffer objects. ID 0 means the default framebuffer, which is the window-system-provided framebuffer. glGenFramebuffersEXT()需要两个参数：第一个是要创建的帧缓存的数目，第二个是指向存储一个或者多个ID的变量或数组的指针。它返回未使用的FBO的ID。ID为0表示默认帧缓存，即window系统提供的帧缓存。 And, FBO may be deleted by calling glDeleteFramebuffers() when it is not used anymore. 当FBO不再被使用时，FBO可以通过调用glDeleteFrameBuffersEXT()来删除。 1glBindFramebuffer() Once a FBO is created, it has to be bound before using it. 一旦一个FBO被创建，在使用它之前必须绑定。 1void glBindFramebuffer(GLenum target, GLuint id) The first parameter, target, should be GL_FRAMEBUFFER, and the second parameter is the ID of a framebuffer object. Once a FBO is bound, all OpenGL operations affect onto the current bound framebuffer object. The object ID 0 is reserved for the default window-system provided framebuffer. Therefore, in order to unbind the current framebuffer (FBO), use ID 0 in glBindFramebuffer(). 第一个参数target应该是GL_FRAMEBUFFER_EXT，第二个参数是FBO的ID号。一旦FBO被绑定，之后的所有的OpenGL操作都会对当前所绑定的FBO造成影响。ID号为0表示缺省帧缓存，即默认的window提供的帧缓存。因此，在glBindFramebufferEXT()中将ID号设置为0可以解绑定当前FBO。 Renderbuffer ObjectIn addition, renderbuffer object is newly introduced for offscreen rendering. It allows to render a scene directly to a renderbuffer object, instead of rendering to a texture object. Renderbuffer is simply a data storage object containing a single image of a renderable internal format. It is used to store OpenGL logical buffers that do not have corresponding texture format, such as stencil or depth buffer. 另外，渲染缓存是为离线渲染而新引进的。它允许将一个场景直接渲染到一个渲染缓存对象中，而不是渲染到纹理对象中。渲染缓存对象是用于存储单幅图像的数据存储区域。该图像按照一种可渲染的内部格式存储。它用于存储没有相关纹理格式的OpenGL逻辑缓存，比如模板缓存或者深度缓存。 glGenRenderbuffers()12void glGenRenderbuffers(GLsizei n, GLuint* ids)void glDeleteRenderbuffers(GLsizei n, const Gluint* ids) Once a renderbuffer is created, it returns non-zero positive integer. ID 0 is reserved for OpenGL. 一旦一个渲染缓存被创建，它返回一个非零的正整数。ID为0是OpenGL保留值。 glBindRenderbuffer()1void glBindRenderbuffer(GLenum target, GLuint id) Same as other OpenGL objects, you have to bind the current renderbuffer object before referencing it. The target parameter should be GL_RENDERBUFFER for renderbuffer object. 和OpenGL中其他对象一样，在引用渲染缓存之前必须绑定当前渲染缓存对象。他target参数应该是GL_RENDERBUFFER_EXT。 glRenderbufferStorage()1234void glRenderbufferStorage(GLenum target, GLenum internalFormat, GLsizei width, GLsizei height) When a renderbuffer object is created, it does not have any data storage, so we have to allocate a memory space for it. This can be done by using glRenderbufferStorage(). The first parameter must be GL_RENDERBUFFER. The second parameter would be color-renderable (GL_RGB, GL_RGBA, etc.), depth-renderable (GL_DEPTH_COMPONENT), or stencil-renderable formats (GL_STENCIL_INDEX). The width and height are the dimension of the renderbuffer image in pixels. 当一个渲染缓存被创建，它没有任何数据存储区域，所以我们还要为他分配空间。这可以通过用glRenderbufferStorageEXT()实现。第一个参数必须是GL_RENDERBUFFER_EXT。第二个参数可以是用于颜色的（GL_RGB，GL_RGBA，etc.），用于深度的（GL_DEPTH_COMPONENT），或者是用于模板的格式（GL_STENCIL_INDEX）。Width和height是渲染缓存图像的像素维度。 The width and height should be less than GL_MAX_RENDERBUFFER_SIZE, otherwise, it generates GL_INVALID_VALUE error. width和height必须比GL_MAX_RENDERBUFFER_SIZE_EXT小，否则将会产生GL_UNVALID_VALUE错误。 glGetRenderbufferParameteriv()123void glGetRenderbufferParameteriv(GLenum target, GLenum param, GLint* value) You also get various parameters of the currently bound renderbuffer object. target should be GL_RENDERBUFFER, and the second parameter is the name of parameter. The last is the pointer to an integer variable to store the returned value. The available names of the renderbuffer parameters are; 我们也可以得到当前绑定的渲染缓存对象的一些参数。Target应该是GL_RENDERBUFFER_EXT，第二个参数是所要得到的参数名字。最后一个是指向存储返回值的整型量的指针。渲染缓存的变量名有如下: 12345678910GL_RENDERBUFFER_WIDTHGL_RENDERBUFFER_HEIGHTGL_RENDERBUFFER_INTERNAL_FORMATGL_RENDERBUFFER_RED_SIZEGL_RENDERBUFFER_GREEN_SIZEGL_RENDERBUFFER_BLUE_SIZEGL_RENDERBUFFER_ALPHA_SIZEGL_RENDERBUFFER_DEPTH_SIZEGL_RENDERBUFFER_STENCIL_SIZE Attaching images to FBOFBO itself does not have any image storage(buffer) in it. Instead, we must attach framebuffer-attachable images (texture or renderbuffer objects) to the FBO. This mechanism allows that FBO quickly switch (detach and attach) the framebuffer-attachable images in a FBO. It is much faster to switch framebuffer-attachable images than to switch between FBOs. And, it saves unnecessary data copies and memory consumption. For example, a texture can be attached to multiple FBOs, and its image storage can be shared by multiple FBOs. FBO本身没有图像存储区。我们必须帧缓存关联图像（纹理或渲染对象）关联到FBO。这种机制允许FBO快速地切换（分离和关联）帧缓存关联图像。切换帧缓存关联图像比在FBO之间切换要快得多。而且，它节省了不必要的数据拷贝和内存消耗。比如，一个纹理可以被关联到多个FBO上，图像存储区可以被多个FBO共享。 Attaching a 2D texture image to FBO12345glFramebufferTexture2D(GLenum target, GLenum attachmentPoint, GLenum textureTarget, GLuint textureId, GLint level) glFramebufferTexture2D() is to attach a 2D texture image to a FBO. The first parameter must be GL_FRAMEBUFFER, and the second parameter is the attachment point where to connect the texture image. A FBO has multiple color attachment points (GL_COLOR_ATTACHMENT0, …, GL_COLOR_ATTACHMENTn), GL_DEPTH_ATTACHMENT, and GL_STENCIL_ATTACHMENT. The third parameter, “textureTarget” is GL_TEXTURE_2D in most cases. The fourth parameter is the identifier of the texture object. The last parameter is the mipmap level of the texture to be attached. glFramebufferTexture2DEXT()把一幅纹理图像关联到一个FBO。第一个参数一定是GL_FRAMEBUFFER_EXT，第二个参数是关联纹理图像的关联点。第三个参数textureTarget在多数情况下是GL_TEXTURE_2D。第四个参数是纹理对象的ID号。最后一个参数是要被关联的纹理的mipmap等级 If the textureId parameter is set to 0, then, the texture image will be detached from the FBO. If a texture object is deleted while it is still attached to a FBO, then, the texture image will be automatically detached from the currently bound FBO. However, if it is attached to multiple FBOs and deleted, then it will be detached from only the bound FBO, but will not be detached from any other un-bound FBOs. 如果参数textureId被设置为0，那么纹理图像将会被从FBO分离。如果纹理对象在依然关联在FBO上时被删除，那么纹理对象将会自动从当前帮的FBO上分离。然而，如果它被关联到多个FBO上然后被删除，那么它将只被从绑定的FBO上分离，而不会被从其他非绑定的FBO上分离。 Attaching a Renderbuffer image to FBO1234void glFramebufferRenderbuffer(GLenum target, GLenum attachmentPoint, GLenum renderbufferTarget, GLuint renderbufferId) A renderbuffer image can be attached by calling glFramebufferRenderbuffer(). The first and second parameters are same as glFramebufferTexture2D(). The third parameter must be GL_RENDERBUFFER, and the last parameter is the ID of the renderbuffer object. 通过调用glFramebufferRenderbufferEXT()可以关联渲染缓存图像。前两个参数和glFramebufferTexture2DEXT()一样。第三个参数只能是GL_RENDERBUFFER_EXT，最后一个参数是渲染缓存对象的ID号。 If renderbufferId parameter is set to 0, the renderbuffer image will be detached from the attachment point in the FBO. If a renderbuffer object is deleted while it is still attached in a FBO, then it will be automatically detached from the bound FBO. However, it will not be detached from any other non-bound FBOs. 如果参数renderbufferId被设置为0，渲染缓存图像将会从FBO的关联点分离。如果渲染缓存图像在依然关联在FBO上时被删除，那么纹理对象将会自动从当前绑定的FBO上分离，而不会从其他非绑定的FBO上分离。 FBO with MSAA (Multi Sample Anti Aliasing)When you render to a FBO, anti-aliasing is not automatically enabled even if you properly create a OpenGL rendering context with the multisampling attribute (SAMPLEBUFFERS_ARB) for window-system-provided framebuffer. In order to activate multisample anti-aliasing mode for rendering to a FBO, you need to prepare and attach multisample images to a FBO’s color and/or depth attachement points. FBO extension provides glRenderbufferStorageMultisample() to create a renderbuffer image for multisample anti-aliasing rendering mode. 12345void glRenderbufferStorageMultisample(GLenum target, GLsizei samples, GLenum internalFormat, GLsizei width, GLsizei height) It adds new parameter, samples on top of glRenderbufferStorage(), which is the number of multisamples for anti-aliased rendering mode. If it is 0, then no MSAA mode is enabled and glRenderbufferStorage() is called instead. You can query the maximum number of samples with GL_MAX_SAMPLES token in glGetIntegerv(). The following code is to create a FBO with multisample colorbuffer and depthbuffer images. Note that if multiple images are attached to a FBO, then all images must have the same number of multisamples. Otherwise, the FBO status is incomplete. 12345678910111213141516171819202122232425262728293031323334// create a 4x MSAA renderbuffer object for colorbufferint msaa = 4;GLuint rboColorId;glGenRenderbuffers(1, &amp;rboColorId);glBindRenderbuffer(GL_RENDERBUFFER, rboColorId);glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_RGB8, width, height);// create a 4x MSAA renderbuffer object for depthbufferGLuint rboDepthId;glGenRenderbuffers(1, &amp;rboDepthId);glBindRenderbuffer(GL_RENDERBUFFER, rboDepthId);glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_DEPTH_COMPONENT, width, height);// create a 4x MSAA framebuffer objectGLuint fboId;glGenFramebuffers(1, &amp;fboMsaaId);glBindFramebuffer(GL_FRAMEBUFFER, fboMsaaId);// attach colorbuffer image to FBOglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_COLOR_ATTACHMENT0, // 2. color attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboColorId); // 4. rbo ID// attach depthbuffer image to FBOglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_DEPTH_ATTACHMENT, // 2. depth attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboDepthId); // 4. rbo ID// check FBO statusGLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);if(status != GL_FRAMEBUFFER_COMPLETE) fboUsed = false; It is important to know that glRenderbufferStorageMultisample() only enables MSAA rendering to FBO. However, you cannot directly use the result from MSAA FBO. If you need to transfer the result to a texture or other non-multisampled framebuffer, you have to convert (downsample) the result to single-sample image using glBlitFramebuffer(). 1234void glBlitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, // source rectangle GLint dstX0, GLint dstY0, GLint dstX1, GLint dstY1, // destination rect GLbitfield mask, GLenum filter) glBlitFramebuffer() copies a rectangle of images from the source (GL_READ_BUFFER) to the destination framebuffer (GL_DRAW_BUFFER). The “mask” parameter is to specify which buffers are copied, GL_COLOR_BUFFER_BIT, GL_DEPTH_BUFFER_BIT and/or GL_STENCIL_BUFFER_BIT. The last parameter, “filter” is to specify the interpolation mode if the source and destination rectangles are not same. It is either GL_NEAREST or GL_LINEAR. The following code is to transfer a multisampled image from a FBO to another non-multisampled FBO. Notice it requires an additional FBO to get the result of MSAA rendering. Please see fboMsaa.zip for details to perform render-to-texture with MSAA. 12345678910// copy rendered image from MSAA (multi-sample) to normal (single-sample)// NOTE: The multi samples at a pixel in read buffer will be converted// to a single sample at the target pixel in draw buffer.glBindFramebuffer(GL_READ_FRAMEBUFFER, fboMsaaId); // src FBO (multi-sample)glBindFramebuffer(GL_DRAW_FRAMEBUFFER, fboId); // dst FBO (single-sample)glBlitFramebuffer(0, 0, width, height, // src rect 0, 0, width, height, // dst rect GL_COLOR_BUFFER_BIT, // buffer mask GL_LINEAR); // scale filter Checking FBO StatusOnce attachable images (textures and renderbuffers) are attached to a FBO and before performing FBO operation, you must validate if the FBO status is complete or incomplete by using glCheckFramebufferStatus(). If the FBO is not complete, then any drawing and reading command (glBegin(), glCopyTexImage2D(), etc) will be failed. 一旦关联图像（纹理和渲染缓存）被关联到FBO上，在执行FBO的操作之前，你必须检查FBO的状态，这可以通过调用glCheckFramebufferStatusEXT()实现。如果这个FBObuilding完整，那么任何绘制和读取命令（glBegin(),glCopyTexImage2D(), etc）都会失败。 1GLenum glCheckFramebufferStatus(GLenum target) glCheckFramebufferStatus() validates all its attached images and framebuffer parameters on the currently bound FBO. And, this function cannot be called within glBegin()/glEnd() pair. The target parameter should be GL_FRAMEBUFFER. It returns non-zero value after checking the FBO. If all requirements and rules are satisfied, then it returns GL_FRAMEBUFFER_COMPLETE. Otherwise, it returns a relevant error value, which tells what rule is violated. glCheckFramebufferStatusEXT()检查当前帧缓存的关联图像和帧缓存参数。这个函数不能在glBegin()/glEnd()之间调用。Target参数必须为GL_FRAMEBUFFER_EXT。它返回一个非零值。如果所有要求和准则都满足，它返回GL_FRAMEBUFFER_COMPLETE_EXT。否则，返回一个相关错误代码告诉我们哪条准则没有满足。 The rules of FBO completeness are: The width and height of framebuffer-attachable image must be not zero. If an image is attached to a color attachment point, then the image must have a color-renderable internal format. (GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc) If an image is attached to GL_DEPTH_ATTACHMENT, then the image must have a depth-renderable internal format. (GL_DEPTH_COMPONENT, GL_DEPTH_COMPONENT24, etc) If an image is attached to GL_STENCIL_ATTACHMENT, then the image must have a stencil-renderable internal format. (GL_STENCIL_INDEX, GL_STENCIL_INDEX8, etc) FBO must have at least one image attached. All images attached a FBO must have the same width and height. All images attached the color attachment points must have the same internal format. FBO完整性准则有： 帧缓存关联图像的宽度和高度必须非零。 如果一幅图像被关联到一个颜色关联点，那么这幅图像必须有颜色可渲染的内部格式（GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc)。 如果一幅被图像关联到GL_DEPTH_ATTACHMENT_EXT，那么这幅图像必须有深度可渲染的内部格式(GL_DEPTH_COMPONENT,GL_DEPTH_COMPONENT24_EXT, etc)。 如果一幅被图像关联到GL_STENCIL_ATTACHMENT_EXT，那么这幅图像必须有模板可渲染的内部格式(GL_STENCIL_INDEX,GL_STENCIL_INDEX8_EXT, etc)。 FBO至少有一幅图像关联。 被关联到FBO的缩影图像必须有相同的宽度和高度。 被关联到颜色关联点上的所有图像必须有相同的内部格式。 Note that even though all of the above conditions are satisfied, your OpenGL driver may not support some combinations of internal formats and parameters. If a particular implementation is not supported by OpenGL driver, then glCheckFramebufferStatus() returns GL_FRAMEBUFFER_UNSUPPORTED. 注意：即使以上所有条件都满足，你的OpenGL驱动也可能不支持某些格式和参数的组合。如果一种特别的实现不被OpenGL驱动支持，那么glCheckFramebufferStatusEXT()返回GL_FRAMEBUFFER_UNSUPPORTED_EXT。 The sample code provides some utility functions to report the information of the current FBO; printFramebufferInfo() and checkFramebufferStatus(). Java Code Examples for javax.media.opengl.GL.GL_FRAMEBUFFER_COMPLETE_EXT GL_EXT_discard_framebufferOverviewThis extension provides a new command, DiscardFramebufferEXT, which causes the contents of the named framebuffer attachable images to become undefined. The contents of the specified buffers are undefined until a subsequent operation modifies the content, and only the modified region is guaranteed to hold valid content. Effective usage of this command may provide an implementation with new optimization opportunities. Some OpenGL ES implementations cache framebuffer images in a small pool of fast memory. Before rendering, these implementations must load the existing contents of one or more of the logical buffers (color, depth, stencil, etc.) into this memory. After rendering, some or all of these buffers are likewise stored back to external memory so their contents can be used again in the future. In many applications, some or all of the logical buffers are cleared at the start of rendering. If so, the effort to load or store those buffers is wasted. Even without this extension, if a frame of rendering begins with a full-screen Clear, an OpenGL ES implementation may optimize away the loading of framebuffer contents prior to rendering the frame. With this extension, an application can use DiscardFramebufferEXT to signal that framebuffer contents will no longer be needed. In this case an OpenGL ES implementation may also optimize away the storing back of framebuffer contents after rendering the frame. Issues1) Should DiscardFramebufferEXT’s argument be a list of COLOR_ATTACHMENTx enums, or should it use the same bitfield from Clear and BlitFramebuffer? RESOLVED: We’ll use a sized list of framebuffer attachments. This will give us some future-proofing for when MRTs and multisampled FBOs are supported. 2) What happens if the app discards only one of the depth and stencil attachments, but those are backed by the same packed_depth_stencil buffer? a) Generate an error b) Both images become undefined c) Neither image becomes undefined d) Only one of the images becomes undefined RESOLVED: (b) which sort of falls out of Issue 4. 3) How should DiscardFramebufferEXT interact with the default framebuffer? a) Generate an error b) Ignore the hint silently c) The contents of the specified attachments become undefined RESOLVED: (c), with appropriate wording to map FBO attachments to the corresponding default framebuffer’s logical buffers 4) What happens when you discard an attachment that doesn’t exist? This is the case where a framebuffer is complete but doesn’t have, for example, a stencil attachment, yet the app tries to discard the stencil attachment. a) Generate an error b) Ignore the hint silently RESOLVED: (b) for two reasons. First, this is just a hint anyway, and if we required error detection, then suddenly an implementation can’t trivially ignore it. Second, this is consistent with Clear, which ignores specified buffers that aren’t present. Example: Render To TextureSometimes, you need to generate dynamic textures on the fly. The most common examples are generating mirroring/reflection effects, dynamic cube/environment maps and shadow maps. Dynamic texturing can be accomplished by rendering the scene to a texture. A traditional way of render-to-texture is to draw a scene to the framebuffer as normal, and then copy the framebuffer image to a texture by using glCopyTexSubImage2D(). 有时候，你需要产生动态纹理。比较常见的例子是产生镜面反射效果、动态环境贴图和阴影等效果。动态纹理可以通过把场景渲染到纹理来实现。渲染到纹理的一种传统方式是将场景绘制到普通的帧缓存上，然后调用glCopyTexSubImage2D()拷贝帧缓存图像至纹理。 Using FBO, we can render a scene directly onto a texture, so we don’t have to use the window-system-provided framebuffer at all. Further more, we can eliminate an additional data copy (from framebuffer to texture). 使用FBO，我们能够将场景直接渲染到纹理，所以我们不必使用window系统提供的帧缓存。并且，我们能够去除额外的数据拷贝（从帧缓存到纹理）；。 This demo program performs render to texture operation with/without FBO, and compares the performance difference. Other than performance gain, there is another advantage of using FBO. If the texture resolution is larger than the size of the rendering window in traditional render-to-texture mode (without FBO), then the area out of the window region will be clipped. However, FBO does not suffer from this clipping problem. You can create a framebuffer-renderable image larger than the display window. 这个demo实现了使用FBO和不使用FBO两种情况下渲染到纹理的操作，并且比较了性能差异。除了能够获得性能上的提升，使用FBO的还有另外一个优点。在传统的渲染到纹理的模式中（不使用FBO），如果纹理分辨率比渲染窗口的尺寸大，超出窗口区域的部分将被剪切掉。然后，使用FBO就不会有这个问题。你可以产生比显示窗口大的帧缓存渲染图像。 The following codes is to setup a FBO and framebuffer-attachable images before the rendering loop is started. Note that not only a texture image is attached to the FBO, but also, a renderbuffer image is attached to the depth attachment point of the FBO. We do not actually use this depth buffer, however, the FBO itself needs it for depth test. If we don’t attach this depth renderable image to the FBO, then the rendering output will be corrupted because of missing depth test. If stencil test is also required during FBO rendering, then additional renderbuffer image should be attached to GL_STENCIL_ATTACHMENT. 以下代码在渲染循环开始之前，对FBO和帧缓存关联图像进行了初始化。注意只有一幅纹理图像被关联到FBO，但是，一个深度渲染图像被关联到FBO的深度关联点。实际上我们并没有使用这个深度缓存，但是FBO本身需要它进行深度测试。如果我们不把这个深度可渲染的图像关联到FBO，那么由于缺少深度测试渲染输出结果是不正确的。如果在FBO渲染期间模板测试也是必要的，那么也需要把额外的渲染图像和GL_STENCIL_ATTACHMENT_EXT关联起来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748...// create a texture objectGLuint textureId;glGenTextures(1, &amp;textureId);glBindTexture(GL_TEXTURE_2D, textureId);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);glTexParameteri(GL_TEXTURE_2D, GL_GENERATE_MIPMAP, GL_TRUE); // automatic mipmapglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, TEXTURE_WIDTH, TEXTURE_HEIGHT, 0, GL_RGBA, GL_UNSIGNED_BYTE, 0);glBindTexture(GL_TEXTURE_2D, 0);// create a renderbuffer object to store depth infoGLuint rboId;glGenRenderbuffers(1, &amp;rboId);glBindRenderbuffer(GL_RENDERBUFFER, rboId);glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT, TEXTURE_WIDTH, TEXTURE_HEIGHT);glBindRenderbuffer(GL_RENDERBUFFER, 0);// create a framebuffer objectGLuint fboId;glGenFramebuffers(1, &amp;fboId);glBindFramebuffer(GL_FRAMEBUFFER, fboId);// attach the texture to FBO color attachment pointglFramebufferTexture2D(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_COLOR_ATTACHMENT0, // 2. attachment point GL_TEXTURE_2D, // 3. tex target: GL_TEXTURE_2D textureId, // 4. tex ID 0); // 5. mipmap level: 0(base)// attach the renderbuffer to depth attachment pointglFramebufferRenderbuffer(GL_FRAMEBUFFER, // 1. fbo target: GL_FRAMEBUFFER GL_DEPTH_ATTACHMENT, // 2. attachment point GL_RENDERBUFFER, // 3. rbo target: GL_RENDERBUFFER rboId); // 4. rbo ID// check FBO statusGLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);if(status != GL_FRAMEBUFFER_COMPLETE) fboUsed = false;// switch back to window-system-provided framebufferglBindFramebuffer(GL_FRAMEBUFFER, 0);... The rendering procedure of render-to-texture is almost same as normal drawing. We only need to switch the rendering destination from the window-system-provided to the non-displayable, application-created framebuffer (FBO). 渲染到纹理的过程和普通的绘制过程基本一样。我们只需要把渲染的目的地由window系统提供的帧缓存改成不可显示的应用程序创建的帧缓存（FBO）就可以了。 123456789101112131415161718192021...// set rendering destination to FBOglBindFramebuffer(GL_FRAMEBUFFER, fboId);// clear buffersglClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);// draw a scene to a texture directlydraw();// unbind FBOglBindFramebuffer(GL_FRAMEBUFFER, 0);// trigger mipmaps generation explicitly// NOTE: If GL_GENERATE_MIPMAP is set to GL_TRUE, then glCopyTexSubImage2D()// triggers mipmap generation automatically. However, the texture attached// onto a FBO should generate mipmaps manually via glGenerateMipmap().glBindTexture(GL_TEXTURE_2D, textureId);glGenerateMipmap(GL_TEXTURE_2D);glBindTexture(GL_TEXTURE_2D, 0);... Note that glGenerateMipmap() is also included as part of FBO extension in order to generate mipmaps explicitly after modifying the base level texture image. If GL_GENERATE_MIPMAP is set to GL_TRUE, then glTex{Sub}Image2D() and glCopyTex{Sub}Image2D() trigger automatic mipmap generation (in OpenGL version 1.4 or greater). However, FBO operation does not generate its mipmaps automatically when the base level texture is modified because FBO does not call glCopyTex{Sub}Image2D() to modify the texture. Therefore, glGenerateMipmap() must be explicitly called for mipmap generation. 注意到，glGenerateMipmapEXT()也是作为FBO扩展的一部分，用来在改变了纹理图像的基级之后显式生成mipmap的。如果GL_GENERATE_MIPMAP被设置为GL_TRUE，那么glTex{Sub}Image2D()和 glCopyTex{Sub}Image2D()将会启用自动mipmap生成（在OpenGL版本1.4或者更高版本中）。然后，当纹理基级被改变时，FBO操作不会自动产生mipmaps。因为FBO不会调用glCopyTex{Sub}Image2D()来修改纹理。因此，要产生mipmap，glGenerateMipmapEXT()必须被显示调用。 If you need to a post processing of the texture, it is possible to combine with Pixel Buffer Object (PBO) to modify the texture efficiently.PBuffer vs FBOopengles2.0渲染到纹理的方法有三种： 使用glCopyTexImage2D或者glCopyTexSubImage2D，这两个函数，复制framebuffer中的像素到纹理缓存里面，但这两个函数性能比较低下，并且要求纹理的尺寸必须小于等于framebuffer的尺寸。 使用一个附加到纹理的pbuffer，来执行渲染到纹理的操作。我们知道，窗口系统为我们提供的surface必须添加到一个渲染环境里面，但是，在某些平台上要求每个pbuffer和窗口系统提供的surface都需要一个单独的context，所以如果要渲染到pbuffer里面的话，就会发生context的切换，这种切换操作时很耗时的。 使用fbo，rbo等，这种是最高效的。 pbuffer跟framebuffer功能是一样的，都是用来做渲染到一个off-screen surface上的，但是如果要做的是渲染到一个纹理上，还是使用framebuffer，效率高些。pbuffer的用途是：渲染到纹理上，随后这个纹理可以给其他API用的，比如openVG。创建pbuffer的过程跟创建窗口surface差不多的： 1EGLSurface eglCreatePbufferSurface(EGLDisplay display,EGLConfig config,const EGLint *attribList); 需要在attribList指定一些pbuffer的属性。选择config的时候需要指定：EGL_SURFACE_TYPE：EGL_PBUFFER_BIT 频繁的在自己创建的fbo和窗口系统创建的vbo之间切换，比较影响性能。不要在每一帧都去创建，销毁fbo，vbo对象。要一次创建多次使用。如果一个纹理attach到一个fbo的attachment point，就要尽量避免调用glTexImage2D或glTexSubImage2D,glCopyTexImage2D等去修改纹理的值。 Presumably eglSwapBuffers has no effect on PBufferSurface (since it is not double-buffer surface) but if it is you would try to read pixels from undefined buffer, with undefined result..引用 原文 译文 GL_EXT_discard_framebuffer]]></content>
      <categories>
        <category>OpenGL</category>
      </categories>
      <tags>
        <tag>OpenGL</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android textureview处理预览摄像头变形问题]]></title>
    <url>%2F2017%2F05%2F04%2Fandroid-view-textureview%2F</url>
    <content type="text"><![CDATA[当TextureView的大小和匹配到的摄像头PreviewSize宽高比例不完全一致时,TextureView可通过setTransform函数对预览画面进行处理后再显示到TextureView,如下对图形居中裁剪: 1234567891011121314151617181920212223242526272829303132333435363738public void sizeNotify(Camera.Size size) &#123; float viewWidth = getWidth(); float viewHeight = getHeight(); float scaleX = 1.0f; float scaleY = 1.0f; int mPreviewWidth = size.width; int mPreviewHeight = size.height; if(viewWidth &lt; viewHeight) &#123; mPreviewWidth = size.height; mPreviewHeight = size.width; &#125; if (mPreviewWidth &gt; viewWidth &amp;&amp; mPreviewHeight &gt; viewHeight) &#123; scaleX = mPreviewWidth / viewWidth; scaleY = mPreviewHeight / viewHeight; &#125; else if (mPreviewWidth &lt; viewWidth &amp;&amp; mPreviewHeight &lt; viewHeight) &#123; scaleY = viewWidth / mPreviewWidth; scaleX = viewHeight / mPreviewHeight; &#125; else if (viewWidth &gt; mPreviewWidth) &#123; scaleY = (viewWidth / mPreviewWidth) / (viewHeight / mPreviewHeight); &#125; else if (viewHeight &gt; mPreviewHeight) &#123; scaleX = (viewHeight / mPreviewHeight) / (viewWidth / mPreviewWidth); &#125; // Calculate pivot points, in our case crop from center int pivotPointX = (int) (viewWidth / 2); int pivotPointY = (int) (viewHeight / 2); Matrix matrix = new Matrix(); matrix.setScale(scaleX, scaleY, pivotPointX, pivotPointY); /*Log.e(TAG, &quot;viewsize:&quot; + viewWidth + &quot; * &quot; + viewHeight + &quot;;prviewSize:&quot; + mPreviewWidth + &quot; * &quot; + mPreviewHeight + &quot;;scale:&quot; + scaleX + &quot; * &quot; + scaleY + &quot;;pivot:&quot; + pivotPointX + &quot; * &quot; + pivotPointY);*/ setTransform(matrix); &#125; TextureView中setTransform函数说明: Sets the transform to associate with this texture view. The specified transform applies to the underlying surface texture and does not affect the size or position of the view itself, only of its content. Some transforms might prevent the content from drawing all the pixels contained within this view’s bounds. In such situations, make sure this texture view is not marked opaque.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>view</tag>
        <tag>TextureView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之Native APIs]]></title>
    <url>%2F2017%2F05%2F03%2Fwebrtc-nativeapis%2F</url>
    <content type="text"><![CDATA[Block diagram Calling sequencesSet up a call Receive a call Close down a call Threading modelWebRTC native APIs use two globally available threads: the signaling thread and the worker thread. Depending on how the PeerConnection factory is created, the application can either provide those 2 threads or just let them be created internally. The calls to the Stream APIs and the PeerConnection APIs will be proxied to the signaling thread which means that the application can call those APIs from whatever thread. All callbacks will be made on the signaling thread. The application should return the callback as quickly as possible to avoid blocking the signaling thread. Resource intensive processes should be posted to a different thread. The worker thread is used to handle more resource intensive processes such as data streaming. https://sites.google.com/site/webrtc/native-code/native-apis]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之api]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-api%2F</url>
    <content type="text"><![CDATA[api目录下封装了webrtc相关的供外部调用接口. datachannel.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/datachannel.h&quot; datachannelinterface.h DataChannelObserver:Used to implement RTCDataChannel events.The code responding to these callbacks should unwind the stack before using any other webrtc APIs; re-entrancy is not supported. DataChannelInterface: dtmfsenderinterface.h DtmfSenderObserverInterface:DtmfSender callback interface, used to implement RTCDtmfSender events.Applications should implement this interface to get notifications from the DtmfSender. DtmfSenderInterface:The interface of native implementation of the RTCDTMFSender defined by the WebRTC W3C Editor’s Draft. fakemetricsobserver.h/cc FakeMetricsObserver jsep.h IceCandidateInterface:Class representation of an ICE candidate.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateIceCandidate. IceCandidateCollection:This class represents a collection of candidates for a specific m= section.Used in SessionDescriptionInterface. SessionDescriptionInterface:Class representation of an SDP session description.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateSessionDescription. CreateSessionDescriptionObserver:CreateOffer and CreateAnswer callback interface. SetSessionDescriptionObserver:SetLocalDescription and SetRemoteDescription callback interface. jsepicecandidate.h JsepIceCandidate:继承自IceCandidateInterface JsepCandidateCollection:继承自IceCandidateCollection jsepsessiondescription.h JsepSessionDescription:Implementation of SessionDescriptionInterface. mediaconstraintsinterface.h/cc MediaConstraintsInterface:Interface used for passing arguments about media constraints to the MediaStream and PeerConnection implementation.Constraints may be either “mandatory”, which means that unless satisfied,the method taking the constraints should fail, or “optional”, which means they may not be satisfied.. mediastream.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/mediastream.h&quot; mediastreaminterface.h/cc OberverInterface NotifierInterface MediaSourceInterface:Base class for sources. A MediaStreamTrack has an underlying source that provides media. A source can be shared by multiple tracks.继承自notifierInterface MediaStreamTrackInterface:继承自notifierInterface VideoTrackSourceInterface:VideoTrackSourceInterface is a reference counted source used for VideoTracks. The same source can be used by multiple VideoTracks.继承自MediaSourceinterface与VideoSourceInterface VideoTrackInterface: 继承自MediaStreamTrackInterface与VideoSourceInterface AudioTrackSinkinterface: AudioSourceInterface:AudioSourceInterface is a reference counted source used for AudioTracks.The same source can be used by multiple AudioTracks.继承自MediaSourceInterface. AudioProcessorInterface:Interface of the audio processor used by the audio track to collect statistics. AudioTrackInterface:继承自MediaStreamTrackInterface MediaStreamInterface: A major difference is that remote audio/video tracks (received by a PeerConnection/RtpReceiver) are not synchronized simply by adding them to the same stream; a session description with the correct “a=msid” attributes must be pushed down.Thus, this interface acts as simply a container for tracks. mediastreamproxy.hMove this to .cc file and out of api/. What threads methods // are called on is an implementation detail. mediastreamtrack.h123// Including this file is deprecated. It is no longer part of the public API.// This only includes the file in its new location for backwards compatibility.#include &quot;webrtc/pc/mediastreamtrack.h&quot; mediatypes.h/ccmediatype到string转换 notifier.h Notifier: peerconnectionfactoryproxy.hpeerconnectioninterface.h12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// This file contains the PeerConnection interface as defined in// http://dev.w3.org/2011/webrtc/editor/webrtc.html#peer-to-peer-connections.//// The PeerConnectionFactory class provides factory methods to create// PeerConnection, MediaStream and MediaStreamTrack objects.//// The following steps are needed to setup a typical call using WebRTC://// 1. Create a PeerConnectionFactoryInterface. Check constructors for more// information about input parameters.//// 2. Create a PeerConnection object. Provide a configuration struct which// points to STUN and/or TURN servers used to generate ICE candidates, and// provide an object that implements the PeerConnectionObserver interface,// which is used to receive callbacks from the PeerConnection.//// 3. Create local MediaStreamTracks using the PeerConnectionFactory and add// them to PeerConnection by calling AddTrack (or legacy method, AddStream).//// 4. Create an offer, call SetLocalDescription with it, serialize it, and send// it to the remote peer//// 5. Once an ICE candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. The candidates must also be serialized and// sent to the remote peer.//// 6. Once an answer is received from the remote peer, call// SetRemoteDescription with the remote answer.//// 7. Once a remote candidate is received from the remote peer, provide it to// the PeerConnection by calling AddIceCandidate.//// The receiver of a call (assuming the application is &quot;call&quot;-based) can decide// to accept or reject the call; this decision will be taken by the application,// not the PeerConnection.//// If the application decides to accept the call, it should://// 1. Create PeerConnectionFactoryInterface if it doesn&apos;t exist.//// 2. Create a new PeerConnection.//// 3. Provide the remote offer to the new PeerConnection object by calling// SetRemoteDescription.//// 4. Generate an answer to the remote offer by calling CreateAnswer and send it// back to the remote peer.//// 5. Provide the local answer to the new PeerConnection by calling// SetLocalDescription with the answer.//// 6. Provide the remote ICE candidates by calling AddIceCandidate.//// 7. Once a candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. Send these candidates to the remote peer. StreamCollectionInterface StatsObserver PeerConnectionInterface PeerConnectionObserver:PeerConnection callback interface, used for RTCPeerConnection events. Application should implement these methods. PeerConnectionFactoryInterface:PeerConnectionFactoryInterface is the factory interface used for creating PeerConnection, MediaStream and MediaStreamTrack objects.The simplest method for obtaiing one, CreatePeerConnectionFactory will create the required libjingle threads, socket and network manager factory classes for networking if none are provided, though it requires that the application runs a message loop on the thread that called the method (see explanation below) If an application decides to provide its own threads and/or implementation of networking classes, it should use the alternate CreatePeerConnectionFactory method which accepts threads as input, and use the CreatePeerConnection version that takes a PortAllocator as an argument. peerconnectionproxy.hproxy.h12345678910111213141516171819202122232425262728293031323334353637383940// This file contains Macros for creating proxies for webrtc MediaStream and// PeerConnection classes.// TODO(deadbeef): Move this to pc/; this is part of the implementation.//// Example usage://// class TestInterface : public rtc::RefCountInterface &#123;// public:// std::string FooA() = 0;// std::string FooB(bool arg1) const = 0;// std::string FooC(bool arg1) = 0;// &#125;;//// Note that return types can not be a const reference.//// class Test : public TestInterface &#123;// ... implementation of the interface.// &#125;;//// BEGIN_PROXY_MAP(Test)// PROXY_SIGNALING_THREAD_DESTRUCTOR()// PROXY_METHOD0(std::string, FooA)// PROXY_CONSTMETHOD1(std::string, FooB, arg1)// PROXY_WORKER_METHOD1(std::string, FooC, arg1)// END_PROXY_MAP()//// Where the destructor and first two methods are invoked on the signaling// thread, and the third is invoked on the worker thread.//// The proxy can be created using//// TestProxy::Create(Thread* signaling_thread, Thread* worker_thread,// TestInterface*).//// The variant defined with BEGIN_SIGNALING_PROXY_MAP is unaware of// the worker thread, and invokes all methods on the signaling thread.//// The variant defined with BEGIN_OWNED_PROXY_MAP does not use// refcounting, and instead just takes ownership of the object being proxied. rtcerror.h/ccrtcerror_unittest.ccrtpparameters.hrtpreceiverinterface.hrtpsender.hrtpsenderinterface.hstatstypes.h/ccstreamcollection.humametrics.hvideosourceproxy.hvideotracksource.hwebrtcsdp.haudio/audio_mixer.h AudioMixer:This class is under development and is not yet intended for for use outside of WebRtc/Libjingle. audio_codecs/audio_decoder.h/cc AudioDecoder audio_codecs/audio_decoder_factory.h AudioDecoderFactory audio_codecs/audio_encoder.h/cc-AudioEncoder: his is the interface class for encoders in AudioCoding module. Each codec type must have an implementation of this class. audio_codecs/audio_encoder_factory.h AudioEncoderFactory audio_codecs/audio_format.h/ccaudio_codecs/builtin_audio_encoder_factory.h/ccaudio_codecs/builtin_audio_decoder_factory.h/cccall/audio_sink.hcall/transport.hortc/mediadescription.h/ccortc/mediadescription_unittest.ccortc/ortcfactoryinterface.hortc/ortcrtpreceiverinterface.hortc/ortcrtpsenderinterface.hortc/packettransportinterface.hortc/rtptransportcontrollerinterface.hortc/rtptransportinterface.hortc/sessiondecription.h/ccortc/sessiondescription_unittest.ccortc/srtptransportinerface.hortc/udptransportinterface.h]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之base]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-base%2F</url>
    <content type="text"><![CDATA[src/webrtc/base是webrtc基础平台库，包括线程、锁、socket,智能指针等. 智能指针refcount.h定义了rtc::RefCountInterface: 123456789101112131415#include &quot;webrtc/base/refcountedobject.h&quot;namespace rtc &#123;// Reference count interface.class RefCountInterface &#123; public: virtual int AddRef() const = 0; virtual int Release() const = 0; protected: virtual ~RefCountInterface() &#123;&#125;&#125;;&#125; // namespace rtc refcountedobject.h下定义了RefCountedObject: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;utility&gt;#include &quot;webrtc/base/atomicops.h&quot;namespace rtc &#123;template &lt;class T&gt;class RefCountedObject : public T &#123; public: RefCountedObject() &#123;&#125; template &lt;class P0&gt; explicit RefCountedObject(P0&amp;&amp; p0) : T(std::forward&lt;P0&gt;(p0)) &#123;&#125; template &lt;class P0, class P1, class... Args&gt; RefCountedObject(P0&amp;&amp; p0, P1&amp;&amp; p1, Args&amp;&amp;... args) : T(std::forward&lt;P0&gt;(p0), std::forward&lt;P1&gt;(p1), std::forward&lt;Args&gt;(args)...) &#123;&#125; virtual int AddRef() const &#123; return AtomicOps::Increment(&amp;ref_count_); &#125; virtual int Release() const &#123; int count = AtomicOps::Decrement(&amp;ref_count_); if (!count) &#123; delete this; &#125; return count; &#125; // Return whether the reference count is one. If the reference count is used // in the conventional way, a reference count of 1 implies that the current // thread owns the reference and no other thread shares it. This call // performs the test for a reference count of one, and performs the memory // barrier needed for the owning thread to act on the object, knowing that it // has exclusive access to the object. virtual bool HasOneRef() const &#123; return AtomicOps::AcquireLoad(&amp;ref_count_) == 1; &#125; protected: virtual ~RefCountedObject() &#123;&#125; mutable volatile int ref_count_ = 0;&#125;;&#125; // namespace rtc 线程Thread网络Socket]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之sdp协议]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-sdp%2F</url>
    <content type="text"><![CDATA[Session Description Protocol(会话描述协议)RFC定义SDP的协议有两个: RFC3264: An Offer/Answer Model with the session Description Protocol(SDP),用来概述一个请求/响应模型 RFC2327: SDP:Session Description Protocol,描述数据格式. 1.RFC23271.1.概述SDP 完全是一种会话描述格式 ― 它不属于传输协议 ― 它只使用不同的适当的传输协议，包括会话通知协议（SAP）、会话初始协议（SIP）、实时流协议（RTSP）、MIME 扩展协议的电子邮件以及超文本传输协议（HTTP）。SDP协议是也是基于文本的协议，这样就能保证协议的可扩展性比较强，这样就使其具有广泛的应用范围。SDP 不支持会话内容或媒体编码的协商，所以在流媒体中只用来描述媒体信息。媒体协商这一块要用RTSP来实现． SDP包括以下一些方面： 会话的名称和目的 会话存活时间 包含在会话中的媒体信息，包括： 媒体类型(video, audio, etc) 传输协议(RTP/UDP/IP, H.320, etc) 媒体格式(H.261 video, MPEG video, etc) 多播或远端（单播）地址和端口 为接收媒体而需的信息(addresses, ports, formats and so on) 使用的带宽信息 可信赖的接洽信息（Contact information） 1.2.SDP协议格式SDP描述由许多文本行组成，文本行的格式为&lt;类型&gt;=&lt;值&gt;，&lt;类型&gt;是一个字母，&lt;值&gt;是结构化的文本串，其格式依&lt;类型&gt;而定。 ＜type＞=[CRLF] 1.2.1.fields分类 Seeesion Description v(Protocol Version),mnd,The current protocol version.Always “0” using RFC4566 o(Origin),Mnd,The session originator’s name and session identifiers. s(Session Name), Mnd,The textural session Name i(Session Information), opt,Textural information about the session u(Uri),opt, A pointer to supplemental session Information e(Email Address), opt, Email contract information for the person responsible. P(phone Address),opt,Phone contract information for the person responsible c(Connection Data),C,The connection type and Address b(Bandwidth),opt,Proposed bandwidth limits. z(Time Zones), opt, Accounts for daylight saving information k(Encryption Keys),opt,A simple mechanism for exchanging keys, Rarely used. Timing Description t(Timing),mnd, start and end times. r(Repeat Times),opt, Specified the duration and intervals for any session repeats. Media Description m(Media Description),mnd, Media definitions including media type(e.g.”audio”),transport details and formats. i(Session Information),opt c(Connection Data),c b(Bandwidth):opt k( Encryption keys),opt a(Attributes),opt 1.2.2.典型格式1234567891011121314151617181920212223242526Session description v= (protocol version) o= (owner/creator and session identifier) s= (session name) i=* (session information) u=* (URI of description) e=* (email address) p=* (phone number) c=* (connection information - not required if included in all media) b=* (zero or more bandwidth information lines) One or more time descriptions (&quot;t=&quot; and &quot;r=&quot; lines, see below) z=* (time zone adjustments) k=* (encryption key) a=* (zero or more session attribute lines) Zero or more media descriptionsTime description t= (time the session is active) r=* (zero or more repeat times)Media description, if present m= (media name and transport address) i=* (media title) c=* (connection information - optional if included at session-level) b=* (zero or more bandwidth information lines) k=* (encryption key) a=* (zero or more media attribute lines) 带&quot;*&quot;号的是可选的,其余的是必须的。一般顺序也按照上面的顺序来排列。 1.2.3.各type对应值的结构化文本串 v= 其中：nettype是IN,代表internet,addrtype是IP4或IP6。unicast-address任务创建计算机的地址。 整个这个属性，是唯一表示一个任务。 e=123@126.com 或 p=+1 616 555-6011 对于一个任务只能两者之中的一个，表示会议控制者的联系方式。邮件地址可以是[email]j.doe@example.com[/email] (Jane Doe)形式，括号里面的是描述联系人的名称，或者Jane Doe &lt;[email]j.doe@example.com[/email]&gt;，前面的是联系人的名称。 c= 这个连接数据，可以是传话级别的连接数据，或者是单独一个媒体数据的连接数据。在是多播时，connection-address就该是一个多播组地址，当是单播时，connection-address就该是一个单播地址。对于addrtype是IP4的情况下，connection-address不仅包含IP地址，并且还要包含a time to live value(TTL 0-255)，如：c=IN IP4 224.2.36.42/128，IP6没有这个TTL值。还允许象这样的[/]/格式的connection-address。如：c=IN IP4 224.2.1.1/127/3等同于包含c=IN IP4 224.2.1.1/127, c=IN IP4 224.2.1.2/127, c=IN IP4 224.2.1.3/127三行内容。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 r= 重复次数在时间表示里面可以如下表示： d - days (86400 seconds) h - hours (3600 seconds) m - minutes (60 seconds) s - seconds (allowed for completeness) z=&lt;adjustment time&gt; &lt;offset&gt; &lt;adjustment time&gt; &lt;offset&gt; .... k=&lt;method&gt; k=&lt;method&gt;:&lt;encryption key&gt; a=&lt;attribute&gt; a=&lt;attribute&gt;:&lt;value&gt; m=&lt;media&gt; &lt;port&gt; &lt;proto&gt; &lt;fmt&gt; ... m=&lt;media&gt; &lt;port&gt;/&lt;number of ports&gt; &lt;proto&gt; &lt;fmt&gt; ... a=cat:分类，根据分类接收者隔离相应的会话 a=keywds:关键字，根据关键字隔离相应的会话 a=tool:创建任务描述的工具的名称及版本号 a=ptime:在一个包里面的以毫秒为单位的媒体长度 a=maxptime:以毫秒为单位，能够压缩进一个包的媒体量。 a=rtpmap: / [/] a=recvonly a=sendrecv a=sendonly a=inactive， a=orient:其可能的值，”portrait”, “landscape” and “seascape” 。 a=type:,建议值是，”broadcast”, “meeting”, “moderated”, “test” and “H332”。 a=charset: a=sdplang:指定会话或者是媒体级别使用的语言 a=framerate:设置最大视频帧速率 a=quality:值是0-10 a=fmtp: 在SIP协议的包含的内容是SDP时，应该把Content-Type设置成application/sdp。1.3.SDP协议例子1.3.1.helix流媒体服务器的RTSP协议中的SDP协议:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0 //SDP version// o field定义的源的一些信息。其格式为：o=&lt;username&gt; &lt;sess-id&gt; &lt;sess-version&gt; &lt;nettype&gt; &lt;addrtype&gt; &lt;unicast-address&gt;o=- 1271659412 1271659412 IN IP4 10.56.136.37 s=&lt;No title&gt;i=&lt;No author&gt; &lt;No copyright&gt; //session的信息c=IN IP4 0.0.0.0 //connect 的信息，分别描述了：网络协议，地址的类型，连接地址。c=IN IP4 0.0.0.0t=0 0 //时间信息，分别表示开始的时间和结束的时间，一般在流媒体的直播的时移中见的比较多。a=SdpplinVersion:1610641560 //描述性的信息a=StreamCount:integer;2 //用来描述媒体流的信息，表示有两个媒体流。integer表示信息的格式为整数。a=control:*a=DefaultLicenseValue:integer;0 //License信息a=FileType:string;&quot;MPEG4&quot; ////用来描述媒体流的信息说明当前协商的文件是mpeg4格式的文件a=LicenseKey:string;&quot;license.Summary.Datatypes.RealMPEG4.Enabled&quot;a=range:npt=0-72.080000 //用来表示媒体流的长度m=audio 0 RTP/AVP 96 //做为媒体描述信息的重要组成部分描述了媒体信息的详细内容：表示session的audio是通过RTP来格式传送的，其payload值为96传送的端口还没有定。b=as:24 //audio 的bitrateb=RR:1800b=RS:600a=control:streamid=1 //通过媒体流1来发送音频a=range:npt=0-72.080000 //说明媒体流的长度。a=length:npt=72.080000a=rtpmap:96 MPEG4-GENERIC/32000/2 //rtpmap的信息，表示音频为AAC的其sample为32000a=fmtp:96 profile-level-id=15;mode=AAC-hbr;sizelength=13;indexlength=3;indexdeltalength=3;config=1210 //config为AAC的详细格式信息a=mimetype:string;&quot;audio/MPEG4-GENERIC&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;48000a=HasOutOfOrderTS:integer;1a=MaxBitRate:integer;48000a=Preroll:integer;1000a=OpaqueData:buffer;&quot;A4CAgCIAAAAEgICAFEAVABgAAAC7gAAAu4AFgICAAhKIBoCAgAEC&quot;a=StreamName:string;&quot;Audio Track&quot;下面是video的信息基本和audio的信息相对称，这里就不再说了。m=video 0 RTP/AVP 97b=as:150b=RR:11250b=RS:3750a=control:streamid=2a=range:npt=0-72.080000a=length:npt=72.080000a=rtpmap:97 MP4V-ES/2500a=fmtp:97 profile-level-id=1;a=mimetype:string;&quot;video/MP4V-ES&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;300000a=HasOutOfOrderTS:integer;1a=Height:integer;240 //影片的长度a=MaxBitRate:integer;300000a=MaxPacketSize:integer;1400a=Preroll:integer;1000a=Width:integer;320 //影片的宽度a=OpaqueData:buffer;&quot;AzcAAB8ELyARAbd0AAST4AAEk+AFIAAAAbDzAAABtQ7gQMDPAAABAAAAASAAhED6KFAg8KIfBgEC&quot;a=StreamName:string;&quot;Video Track&quot; 1.3.2.Webrtc SDP示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0o=- 0 0 IN IP4 127.0.0.1s=WX-RTC-SERVERt=0 0a=group:BUNDLE audio videoa=msid-semantic: WMS ryODEhTpFzm=audio 1 UDP/TLS/RTP/SAVPF 0 126c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-levela=mid:audioa=rtcp-muxa=rtpmap:0 PCMU/8000a=rtpmap:126 telephone-event/8000m=video 1 UDP/TLS/RTP/SAVPF 124 125 96c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=extmap:2 urn:ietf:params:rtp-hdrext:toffseta=extmap:3 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-timea=extmap:4 urn:3gpp:video-orientationa=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/playout-delaya=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=mid:videoa=rtcp-muxa=rtpmap:124 H264/90000a=rtcp-fb:124 ccm fira=rtcp-fb:124 nacka=rtcp-fb:124 nack plia=rtcp-fb:124 goog-remba=fmtp:124 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:125 H264/90000a=rtcp-fb:125 ccm fira=rtcp-fb:125 nacka=rtcp-fb:125 nack plia=rtcp-fb:125 goog-remba=fmtp:125 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:96 VP8/90000a=rtcp-fb:96 ccm fira=rtcp-fb:96 nacka=rtcp-fb:96 nack plia=rtcp-fb:96 goog-remb 2.RFC3264An Offer/Answer Model with the Session Description Protocol (SDP) 2.1情态动词定义在RFC2119: “MUST”，必须、一定要； “MUST NOT”，禁止； “REQUIRED”，需要； “SHALL”、”SHOULD”，应该； “SHALL NOT”、”SHOULD NOT”，不应该； “RECOMMENDED”，推荐； “MAY”，可以2.2术语 媒体流（Media Stream），或称为媒体类型（Media Type），即我们通常所说的音频流、视频流等，所有通信实体要进行媒体交互之前都必须进行媒体注的协商 媒体格式（Media Format），每种媒体流都有不同的编码格式，像音频有G711、G712编码，视频有H261、H264等，像现在所谓的高清视频采用是720P、1070P等。 单一会话（Unitcast Session） 多会话（Multicast Sessions） 单一媒体流（Unitcast Streams） 多媒体流（Multicast Streams）2.3offer/answerrfc3264协议[1]主要概述一个请求/响应模型（offer/answer，以下叙述采用英文），包括请求/响应的实体和不同阶段的操作行为，如初始协商过程和重协商过程，并简单介绍消息中各种参数的含义。具体各个参数的详细说明见rfc2327协议[2]2.3.1.实体,消息Offer/Answer模型包括两个实体，一个是请求主体Offerer，另外一个是响应实体Answerer，两个实体只是在逻辑上进行区分，在一定条件可以转换。例如，手机A发起媒体协商请求，那么A就是Offerer，反之如果A为接收请求则为Offerer。 Offerer发给Answerer的请求消息称为请求offer，内容包括媒体流类型、各个媒体流使用的编码集，以及将要用于接收媒体流的IP和端口。 Answerer收到offer之后，回复给Offerer的消息称为响应，内容包括要使用的媒体编码，是否接收该媒体流以及告诉Offerer其用于接收媒体流的IP和端口。2.3.2.SDP各个参数简单介绍下面示例摘自3264协议[1] v=0 o=carol 28908764872 28908764872 IN IP4 100.3.6.6 //会话ID号和版本 s=- //用于传递会话主题 t=0 0 //会话时间，一般由其它信令消息控制，因此填0 c=IN IP4 192.0.2.4 //描述本端将用于传输媒体流的IP m=audio 0 RTP/AVP 0 1 3 //媒体类型 端口号 本端媒体使用的编码标识（Payload）集 a=rtpmap:0 PCMU/8000 //rtpmap映射表，各种编码详细描述参数，包括使用带宽（bandwidth） a=rtpmap:1 1016/8000 a=rtpmap:3 GSM/8000 a=sendonly //说明本端媒体流的方向，取值包括sendonly/recvonly/sendrecv/inactive a=ptime:20 //说明媒体流打包时长 m=video 0 RTP/AVP 31 34 a=rtpmap:31 H261/90000 a=rtpmap:34 H263/900002.3.3.实体行为、操作过程2.3.3.1.初始协商的Offer请求实体A &lt;-&gt; 实体B，实体首先发起Offer请求，内容如2节所示，对于作何一个媒体流/媒体通道，这时实体A必须： 如果媒体流方向标为recvonly/sendrecv，即a=recvonly或a=sendrecv，则A必须（MUST）准备好在这个IP和端口上接收实体B发来的媒体流； 如果媒体流方向标为sendonly/inactive，即a=recvonly或a=sendrecv，则A不需要进行准备。2.3.3.1.Answer响应实体B收到A的请求offer后，根据自身支持的媒体类型和编码策略，回复响应。 如果实体B回复的响应中的媒体流数量和顺序必须（MUST）和请求offer一致，以便实体A进行甄别和决策。即m行的数量和顺序必须一致，B不能（MUST NOT）擅自增加或删除媒体流。如果B不支持某个媒体流，可以在对应的端口置0，但不能不带这个m行描述。 对于某种媒体，实体B必须（MUST）从请求offer中选出A支持且自己也支持的该媒体的编码标识集，并且可以（MAY）附带自己支持的其它类型编码。 对于响应消息中各个媒体的方向： 如果请求某媒体流的方向为sendonly，那么响应中对应媒体的方向必须为recvonly； 如果请求某媒体流的方向为recvonly，那么响应中对应媒体的方向必须为sendonly； 如果请求某媒体流的方向为sendrecv，那么响应中对应媒体的方向可以为sendrecv/sendonly/recvonly/inactive中的一种； 如果请求某媒体流的方向为inactive，那么响应中对应媒体的方向必须为inactive； 响应answer里提供IP和端口，指示Offerer本端期望用于接收媒体流的IP和端口，一旦响应发出之后，Offerer必须（MUST）准备好在这个IP和端口上接收实体A发来的媒体流。 如果请求offer中带了ptime（媒体流打包间隔）的a行或带宽的a行，则响应answer也应该（SHOULD）相应的携带。 实体B Offerer应该（SHOULD）使用实体A比较期望的编码生成媒体流发送。一般来说对于m行，如m=video 0 RTP/AVP 31 34，排充越靠前的编码表示该实体越希望以这个编码作为载体，这里示例31(H261)，34（H263）中H261为A更期望使用的编码类型。同理，当实体A收到响应answer后也是这样理解的。2.3.3.2.实体收到响应后的处理当实体A收到B回复的响应后，可以（MAY）开始发送媒体流，如果媒体流方向为sendonly/sendrecv， 必须（MUST）使用answer列举的媒体类型/编码生成媒体发送； 应该（SHOULD）使用answer中的ptime和bandwidth来打包发送媒体流； 可以（MAY）立即停止监听端口，该端口为offer支持answer不支持的媒体所使用的端口。 2.3.4.修改媒体流（会话）修改媒体流的offer-answer操作必须基于之前协商的媒体形式（音频、视频等），不能（MUST NOT）对已有媒体流进行删减。 2.3.4.1.删除媒体流如果实体认定新的会话不支持之前媒商的某个媒体，新的offer只须对这种媒体所在m行的端口置0，但不能不描述这种媒体，即不带对应m行。当answerer收到响应之后，处理同初始协商一样。 2.3.4.2.增加媒体流如果实体打算新增媒体流，在offer里只须加上描述即可或者占用之前端口被置0的媒体流，即用新的媒体描述m行替换旧的。当answerer收到offer请求后，发现有新增媒体描述，或者过于端口被置0的媒体行被新的媒体描述替换，即知道当前为新增媒体流，处理同初始协商。 2.3.4.3.修改媒体流修改媒体注主要是针对初始协商结果，如果有变更即进入修改流程处理，可能的变更包括IP地址、端口，媒体格式（编码），媒体类型（音、视频），媒体属性（ptime，bandwidth，媒体流方向变更等）。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之入门]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-introduce%2F</url>
    <content type="text"><![CDATA[webrtc developersThe WebRTC APIsThree main tasks Acquiring audio and video Communicating audio and video Communicating arbitrary data Three main JavaScript APIs MediaStream(aka getUserMedia) RTCPeerConnection RTCDataChannel MediaStream(Acquiring audio and video) MediaStream Pepresent a stream of audio and/or video Can contain multiple ‘tracks’ Obtain a MediaStream with navigator.getUserMedia() Constraints Controls the contents of the MediaStream Media type, resolution, frame rateRTCPeerConnection(Audio and video communication between peers)RTCPeerConnection does a lot Signal processing Codec handling Peer to peer communication Security Bandwidth managementWebRTC architecture RTCDataChannel(Bidirectional communication of arbitrary data between peers) RTCDataChannel Same API as WebSockets Ultra-low latency Unreliable or reliable Secure Servers and Protocols(Peer to peer — but we need servers :) Abstract Signaling Need to exchange ‘session description’ objects: What formats I support, what I want to send Network information for peer-to-peer setup Can use any messaging mechanism Can use any messaging protocol STUN and TRUN(P2P in the age of firewalls and NATs) An ideal world The real world STUN Tell me what my public IP address is Simple server, cheap to run Data flows peer-to-peer TURN Provide a cloud fallback if peer-to-peer communication fails Data is sent through server, uses server bandwidth Ensures the call works in almost all environments ICE ICE: a framework for connecting peers Tries to find the best path for each call Vast majority of calls can use STUN (webrtcstats.com): Deploying STUN/TURN stun.l.google.com:19302 WebRTC stunserver, turnserver rfc5766-turn-server restund SecuritySecurity throughout WebRTC Mandatory encryption for media and data Secure UI, explicit opt-in Sandboxed, no plugins WebRTC Security Architecture ArchitecturesPeer to Peer : one-to-one callclientA &lt;——–&gt; clientB Mesh: small N-way call123456clientA &lt;-------------&gt; clientB /|\ \ / /|\ | \ / | | / \ | \|/ / \|/clientC &lt;--------------&gt; clientD Star: medium N-way call123clientA &lt;---------&gt; clientBclientA &lt;---------&gt; clientCclientA &lt;---------&gt; clientD MCU: large N-way call1234567MCU &lt;--------------&gt;clientAMCU &lt;--------------&gt;clientBMCU &lt;--------------&gt;clientCMCU &lt;--------------&gt;clientDMCU &lt;--------------&gt;clientEMCU &lt;--------------&gt;clientFMCU &lt;--------------&gt;clientG]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之源码管理工具gclient]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-gclient%2F</url>
    <content type="text"><![CDATA[google的chromium项目是用gclient来管理源码的checkout, update等。 gclient是google专门为这种多源项目编写的脚本，它可以将多个源码管理系统中的代码放在一起管理。甚至包括将Git和svn代码放在一起。 webrtc也是使用gclient管理代码. gclient的sync，update等命令密切相关的两类文件.gclient和DEPS。 .gclient文件是gclient的控制文件，该文件放在工作目录的最上层(webrtc环境下与src统计目录)。”.gclient”文件是一个Python的脚本，定义了一组”solutions”，格式类似如下 1234567891011solutions = [ &#123; &quot;name&quot; : &quot;src&quot;, &quot;url&quot; : &quot;svn://svnserver/component/trunk/src&quot;, &quot;custom_deps&quot; : &#123; # To use the trunk of a component instead of what&apos;s in DEPS: #&quot;component&quot;: &quot;https://svnserver/component/trunk/&quot;, # To exclude a component from your working copy: #&quot;data/really_large_component&quot;: None, &#125; &#125;, ] name:checkout出源码的名字 url:源码所在的目录,gclient希望checkout出的源码中包括一个DEPS的文件,这个文件包含了必须checkout到工作目录的源码信息; deps_file:这是一个文件名(不包括路径),指在工程目录中包含依赖列表的文件,该项可选,默认值为”DEPS” custom_deps:这是一个可选的字典对象,会覆盖工程的”DEPS”文件定义的条目.一般它用作本地目录中,那些不用checkout的代码,或者让本地目录从不同位置checkout一个新的代码出来,或者checkout不同的分支,版本等.也可以用于增加在DEPS中不存在的新的项目.如: 12345678&quot;custom_deps&quot;: &#123; &quot;src/content/test/data/layout_tests/LayoutTests&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome_frame/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_linux&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_mac&quot;: None, &quot;src/third_party/hunspell_dictionaries&quot;: None, &#125;, target_os:这个可选的条目可以指出特殊的平台,根据平台类checkout出不同代码,如: 1target_os = [&apos;android&apos;] 如果target_os_only值为True的话,那么,仅仅checkout出对应的代码,如: 12target_os = [ &quot;ios&quot; ] target_os_only = True 在每个checkout出的工程中，gclient期望发现一个DEPS文件（由deps_file来给定），它定义了工程不同部分都是如何checkout出来。 “DEPS”也是一个python脚本，最简单的，如下： 12345deps = &#123; &quot;src/outside&quot; : &quot;http://outside-server/trunk@1234&quot;, &quot;src/component&quot; : &quot;svn://svnserver/component/trunk/src@77829&quot;, &quot;src/relative&quot; : &quot;/trunk/src@77829&quot;, &#125; deps的每个条目都包含一个key-value对，key是被checkout的本地目录，而value就是对应的远程URL。如果路径是以’/‘开头的，那么它是一个相对URL，相对与.gclient中URL地址。 URL通常包含一个版本号，以便锁定源码在特定版本上。当然，这是可选的。如果没有，那么它将获取指定分支上最新的版本。 DEPS还可以包含其他类型的数据，如vars, 12345678910111213vars = &#123; &apos;pymox&apos;: &apos;http://pymox.googlecode.com/svn&apos;, &apos;sfntly&apos;: &apos;http://sfntly.googlecode.com/svn&apos;, &apos;eyes-free&apos;: &apos;http://eyes-free.googlecode.com/svn&apos;, &apos;rlz&apos;: &apos;http://rlz.googlecode.com/svn&apos;, &apos;smhasher&apos;: &apos;http://smhasher.googlecode.com/svn&apos;,...&#125; vars定义了一组变量，在后面，可以通过Var(xxx)来访问。Var(xxx)返回一个字符串，故此，也可以进行操作，如 1234&apos;src/third_party/cros_dbus_cplusplus/source&apos;:Var(&quot;git.chromium.org&quot;) + &apos;/chromiumos/third_party/dbus-cplusplus.git@5e8f6d9db5c2abfb91d91f751184f25bb5cd0900&apos;,&apos;src/third_party/WebKit&apos;:Var(&quot;webkit_trunk&quot;)[:-6] + &apos;/branches/chromium/1548@153044&apos;, 第二个自立，Var(“webkit_trunk”)[:-6]是一个python表达式，表示取得”webkit_trunk”表示的字符串的最后6个 Hooks：DEPS包含可选的内容 hooks，也有重要的作用，它表示在sync, update或者recert后，执行一个hook操作。 如果使用 –nohooks选项（hook默认执行），那么在gclient sync或者其他操作后，不会执行hook。你可以通过gclient runhooks来单独执行； 如果有 gclient sync –force，那么，无论sync是否成功，都会执行hook。 hook在DEPS中的写法，一般是： 1234567hooks = [ &#123; &quot;pattern&quot;: &quot;\\.(gif|jpe?g|pr0n|png)$&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;image_indexer.py&quot;, &quot;--all&quot;]&#125;, &#123; &quot;pattern&quot;: &quot;.&quot;, &quot;name&quot;: &quot;gyp&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;src/build/gyp_chromium&quot;]&#125;,] hooks包含一组hook，每个hook有几个重要项: pattern 是一个正则表达式，用来匹配工程目录下的文件，一旦匹配成功，action项就会执行 action 描述一个根据特定参数运行的命令行。这个命令在每次gclient时，无论多少文件匹配，至多运行一次。这个命令和.gclient在同一目录下运行。如果第一个参数是”python”，那么，当前的python解释器将被使用。如果包含字符串 “$matching_files”，它将该字符串扩展为匹配出的文件列表。 name 可选，标记出hook所属的组，可以被用来覆盖和重新组织。 deps_os： DEPS中定义不同平台依赖关系的项目，如 1234567891011121314151617181920212223deps_os = &#123; &quot;win&quot;: &#123; &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: &quot;/trunk/deps/reference_builds/chrome_win@197743&quot;, &quot;src/third_party/cygwin&quot;: &quot;/trunk/deps/third_party/cygwin@133786&quot;,..... &#125;, &quot;ios&quot;: &#123; &quot;src/third_party/GTM&quot;: (Var(&quot;googlecode_url&quot;) % &quot;google-toolbox-for-mac&quot;) + &quot;/trunk@&quot; + Var(&quot;gtm_revision&quot;), &quot;src/third_party/nss&quot;: &quot;/trunk/deps/third_party/nss@&quot; + Var(&quot;nss_revision&quot;),.... &#125;,...&#125; deps_os指定不同平台的依赖，它可以包含多种平台，和.gclient中的target_os对应。这种对应关系如下： 12345678910111213DEPS_OS_CHOICES = &#123; &quot;win32&quot;: &quot;win&quot;, &quot;win&quot;: &quot;win&quot;, &quot;cygwin&quot;: &quot;win&quot;, &quot;darwin&quot;: &quot;mac&quot;, &quot;mac&quot;: &quot;mac&quot;, &quot;unix&quot;: &quot;unix&quot;, &quot;linux&quot;: &quot;unix&quot;, &quot;linux2&quot;: &quot;unix&quot;, &quot;linux3&quot;: &quot;unix&quot;, &quot;android&quot;: &quot;android&quot;,&#125; 下载webrtc android代码的.gclient文件(与src同级目录): 12345678910solutions = [ &#123; &quot;url&quot;: &quot;https://chromium.googlesource.com/external/webrtc.git&quot;, &quot;managed&quot;: False, &quot;name&quot;: &quot;src&quot;, &quot;deps_file&quot;: &quot;DEPS&quot;, &quot;custom_deps&quot;: &#123;&#125;, &#125;,]target_os = [&quot;android&quot;, &quot;unix&quot;] src同级目录下.gclient_entries定义了各模块及对应地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344entries = &#123; &apos;src&apos;: &apos;https://chromium.googlesource.com/external/webrtc.git&apos;, &apos;src/base&apos;: &apos;https://chromium.googlesource.com/chromium/src/base@413df39df4640665d7ee1e8c198be1e91cedb4d9&apos;, &apos;src/build&apos;: &apos;https://chromium.googlesource.com/chromium/src/build@98f2769027214c848094d0d58156474eada3bc1b&apos;, &apos;src/buildtools&apos;: &apos;https://chromium.googlesource.com/chromium/buildtools.git@98f00fa10dbad2cdbb2e297a66c3d6d5bc3994f3&apos;, &apos;src/testing&apos;: &apos;https://chromium.googlesource.com/chromium/src/testing@3eab1a4b0951ac1fcb2be8bf9cb24143b509ea52&apos;, &apos;src/testing/gmock&apos;: &apos;https://chromium.googlesource.com/external/googlemock.git@0421b6f358139f02e102c9c332ce19a33faf75be&apos;, &apos;src/testing/gtest&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/googletest.git@6f8a66431cb592dad629028a50b3dd418a408c87&apos;, &apos;src/third_party&apos;: &apos;https://chromium.googlesource.com/chromium/src/third_party@939f3a2eae486dd7cf3b31eae38642d2bc243737&apos;, &apos;src/third_party/android_tools&apos;: &apos;https://chromium.googlesource.com/android_tools.git@b65c4776dac2cf1b80e969b3b2d4e081b9c84f29&apos;, &apos;src/third_party/boringssl/src&apos;: &apos;https://boringssl.googlesource.com/boringssl.git@777fdd6443d5f01420b67137118febdf56a1c8e4&apos;, &apos;src/third_party/catapult&apos;: &apos;https://chromium.googlesource.com/external/github.com/catapult-project/catapult.git@6939b1db033bf35f4adf1ee55824b6edb3e324d6&apos;, &apos;src/third_party/ced/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/compact_enc_det.git@e21eb6aed10b9f6e2727f136c52420033214d458&apos;, &apos;src/third_party/colorama/src&apos;: &apos;https://chromium.googlesource.com/external/colorama.git@799604a1041e9b3bc5d2789ecbd7e8db2e18e6b8&apos;, &apos;src/third_party/ffmpeg&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ffmpeg.git@28a5cdde5c32bcf66715343c10f74e85713f7aaf&apos;, &apos;src/third_party/gflags&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/gflags@892576179b45861b53e04a112996a738309cf364&apos;, &apos;src/third_party/gflags/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/gflags/gflags@03bebcb065c83beff83d50ae025a55a4bf94dfca&apos;, &apos;src/third_party/gtest-parallel&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/gtest-parallel@7eb02a6415979ea59e765c34fe9da6c792f53e26&apos;, &apos;src/third_party/icu&apos;: &apos;https://chromium.googlesource.com/chromium/deps/icu.git@b34251f8b762f8e2112a89c587855ca4297fed96&apos;, &apos;src/third_party/jsoncpp/source&apos;: &apos;https://chromium.googlesource.com/external/github.com/open-source-parsers/jsoncpp.git@f572e8e42e22cfcf5ab0aea26574f408943edfa4&apos;, &apos;src/third_party/jsr-305/src&apos;: &apos;https://chromium.googlesource.com/external/jsr-305.git@642c508235471f7220af6d5df2d3210e3bfc0919&apos;, &apos;src/third_party/junit/src&apos;: &apos;https://chromium.googlesource.com/external/junit.git@64155f8a9babcfcf4263cf4d08253a1556e75481&apos;, &apos;src/third_party/libFuzzer/src&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer.git@16f5f743c188c836d32cdaf349d5d3effb8a3518&apos;, &apos;src/third_party/libjpeg_turbo&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libjpeg_turbo.git@7260e4d8b8e1e40b17f03fafdf1cd83296900f76&apos;, &apos;src/third_party/libsrtp&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libsrtp.git@ccf84786f8ef803cb9c75e919e5a3976b9f5a672&apos;, &apos;src/third_party/libvpx/source/libvpx&apos;: &apos;https://chromium.googlesource.com/webm/libvpx.git@f22b828d685adee4c7a561990302e2d21b5e0047&apos;, &apos;src/third_party/libyuv&apos;: &apos;https://chromium.googlesource.com/libyuv/libyuv.git@fc02cc3806a394a6b887979ba74aa49955f3199b&apos;, &apos;src/third_party/lss&apos;: &apos;https://chromium.googlesource.com/linux-syscall-support.git@63f24c8221a229f677d26ebe8f3d1528a9d787ac&apos;, &apos;src/third_party/mockito/src&apos;: &apos;https://chromium.googlesource.com/external/mockito/mockito.git@de83ad4598ad4cf5ea53c69a8a8053780b04b850&apos;, &apos;src/third_party/openh264/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/cisco/openh264@0fd88df93c5dcaf858c57eb7892bd27763f0f0ac&apos;, &apos;src/third_party/openmax_dl&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/openmax.git@7acede9c039ea5d14cf326f44aad1245b9e674a7&apos;, &apos;src/third_party/requests/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/kennethreitz/requests.git@f172b30356d821d180fa4ecfa3e71c7274a32de4&apos;, &apos;src/third_party/robolectric/robolectric&apos;: &apos;https://chromium.googlesource.com/external/robolectric.git@2a0b6ba221c14f3371813a676ce06143353e448d&apos;, &apos;src/third_party/ub-uiautomator/lib&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ub-uiautomator.git@00270549ce3161ae72ceb24712618ea28b4f9434&apos;, &apos;src/third_party/usrsctp/usrsctplib&apos;: &apos;https://chromium.googlesource.com/external/github.com/sctplab/usrsctp@8679f2b0bf063ac894dc473debefd61dbbebf622&apos;, &apos;src/third_party/yasm/source/patched-yasm&apos;: &apos;https://chromium.googlesource.com/chromium/deps/yasm/patched-yasm.git@7da28c6c7c6a1387217352ce02b31754deb54d2a&apos;, &apos;src/tools&apos;: &apos;https://chromium.googlesource.com/chromium/src/tools@4718dd2b6d53fb68819b3fd23676b40935f4f31e&apos;, &apos;src/tools/gyp&apos;: &apos;https://chromium.googlesource.com/external/gyp.git@eb296f67da078ec01f5e3a9ea9cdc6d26d680161&apos;, &apos;src/tools/swarming_client&apos;: &apos;https://chromium.googlesource.com/external/swarming.client.git@11e31afa5d330756ff87aa12064bb5d032896cb5&apos;, &apos;src/buildtools/clang_format/script&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/cfe/tools/clang-format.git@c09c8deeac31f05bd801995c475e7c8070f9ecda&apos;, &apos;src/buildtools/third_party/libc++/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxx.git@b1ece9c037d879843b0b0f5a2802e1e9d443b75a&apos;, &apos;src/buildtools/third_party/libc++abi/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxxabi.git@0edb61e2e581758fc4cd4cd09fc588b3fc91a653&apos;, &apos;src/third_party/android_tools/ndk&apos;: &apos;https://chromium.googlesource.com/android_ndk.git@26d93ec07f3ce2ec2cdfeae1b21ee6f12ff868d8&apos;,&#125;]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之信令交互流程]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-signalling%2F</url>
    <content type="text"><![CDATA[无论是使用前端JS的WebRTC API接口，还是在WebRTC源码上构建自己的对聊框架，都需要遵循以下执行流程： 上述序列中，WebRTC并不提供Stun服务器和Signal服务器，服务器端需要自己实现。Stun服务器可以用google提供的实现stun协议的测试服务器（stun:stun.l.google.com:19302），Signal服务器则完全需要自己实现了，它需要在ClientA和ClientB之间传送彼此的SDP信息和candidate信息，ClientA和ClientB通过这些信息建立P2P连接来传送音视频数据。 stun/turn、relay服务器的实现在WebRTC源码中都有示例。 上述序列中，标注的场景是ClientA向ClientB发起对聊请求，调用描述如下： ClientA首先创建PeerConnection对象，然后打开本地音视频设备，将音视频数据封装成MediaStream添加到PeerConnection中。 ClientA调用PeerConnection的CreateOffer方法创建一个用于offer的SDP对象，SDP对象中保存当前音视频的相关参数。ClientA通过PeerConnection的SetLocalDescription方法将该SDP对象保存起来，并通过Signal服务器发送给ClientB。 ClientB接收到ClientA发送过的offer SDP对象，通过PeerConnection的SetRemoteDescription方法将其保存起来，并调用PeerConnection的CreateAnswer方法创建一个应答的SDP对象，通过PeerConnection的SetLocalDescription的方法保存该应答SDP对象并将它通过Signal服务器发送给ClientA。 ClientA接收到ClientB发送过来的应答SDP对象，将其通过PeerConnection的SetRemoteDescription方法保存起来。 在SDP信息的offer/answer流程中，ClientA和ClientB已经根据SDP信息创建好相应的音频Channel和视频Channel并开启Candidate数据的收集，Candidate数据可以简单地理解成Client端的IP地址信息（本地IP地址、公网IP地址、Relay服务端分配的地址）。 当ClientA收集到Candidate信息后，PeerConnection会通过OnIceCandidate接口给ClientA发送通知，ClientA将收到的Candidate信息通过Signal服务器发送给ClientB，ClientB通过PeerConnection的AddIceCandidate方法保存起来。同样的操作ClientB对ClientA再来一次。 这样ClientA和ClientB就已经建立了音视频传输的P2P通道，ClientB接收到ClientA传送过来的音视频流，会通过PeerConnection的OnAddStream回调接口返回一个标识ClientA端音视频流的MediaStream对象，在ClientB端渲染出来即可。同样操作也适应ClientB到ClientA的音视频流的传输。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git服务搭建]]></title>
    <url>%2F2017%2F04%2F25%2Fserver-git%2F</url>
    <content type="text"><![CDATA[纯git server软件安装环境:ubuntu16.0.4 安装Git-Core:sudo apt-get install python-setuptools 安装openssh-server和openssh-client:sudo apt-get install openssh-server openssh-client 安装python tool:sudo apt-get install python-setuptools 安装gitosis:12345git clone https://github.com/res0nat0r/gitosis.gitcd gitosis/sudo python setup.py install 添加管理账号12345678sudo adduser \ --system \ --shell /bin/sh \ --gecos &apos;git version control&apos; \ --group \ --disabled-password \ --home /home/git \ git 如果已有git账户,可以替换成gitmanager 创建链接映射由于gitosis默认状态下会将仓库放在用户的repositories目录下，例如gitmanager用户的仓库地址默认在 /home/gitmanager/repositories/目录下，这里我们需要创建一个链接映射。让他指向我们前面创建的专门用于存放项目的仓库目录/home/gitrepository。 1sudo ln -s /home/gitrepository /home/gitmanager/repositories 初始化管理用户 拷贝管理用户公钥到/tmp/下,如: 1scp ~/.ssh/id_rsa.pub gitmanager@192.168.0.68:/tmp/ 使用拷贝来的公钥初始化gitosis: 12sudo -H -u gitmanager gitosis-init &lt; /tmp/id_ras.pubsudo chmod 755 /home/gitmanager/repositories/gitosis-admin.git/hooks/post-update 配置账号 验证ssh1234ssh gitmanager@192.168.0.68TY allocation request failed on channel 0ERROR:gitosis.serve.main:Need SSH_ORIGINAL_COMMAND in environment. Connection to gitserver closed. 说明 Gitosis 认出了该用户的身份，但由于没有运行任何 Git 命令，所以它切断了连接。 克隆gitosis管理仓库:1git clone gitmanager@192.168.0.68:gitosis-admin.git 这会得到一个名为 gitosis-admin 的工作目录，主要由两部分组成： 12./gitosis.conf./keydir gitosis.conf 文件是用来设置用户、仓库和权限的控制文件。keydir 目录则是保存所有具有访问权限用户公钥的地方— 每人一个。在 keydir 里的文件名（比如上面的 qingkouwei.pub） 会自动从使用 gitosis-init 脚本导入的公钥尾部的描述中获取该名字。 看一下 gitosis.conf 文件的内容，它应该只包含与刚刚克隆的 gitosis-admin 相关的信息： 12345[gitosis][group gitosis-admin]members = qingkouweiwritable = gitosis-admin 要创建项目demo,在里面加入: 123[group demo]members = qingkouweiwritable = demo 要为demo项目添加用户user1: 123[group demo]members = qingkouwei user1writable = demo 并将用户user1的公钥计入到keydir,并且公钥名.pub和members里面的名字对应. 要添加对demo项目只读的用户: 1234567[group demo]members = qingkouwei user1writable = demo[group demo]members = user2readonly = demo 修改完配置文件和keydir,使用git push到gitosis-admin服务器.即可直接git add remote add suervename gitmanager@192.168.0.68:demo.git,然后直接将本地目录推送到demo仓库,不需要再服务器手动创建demo仓库,gitosis会帮忙自动创建. 常见问题 ERROR:gitosis.serve.main:Repository read access denied 原因: gitosis.conf中的members与keydir中的用户名不一致，如gitosis中的members = foo@bar，但keydir中的公密名却叫foo.pub 解决方法: 使keydir的名称与gitosis中members所指的名称一致。 改为members = foo 或 公密名称改为foo@bar.pub clone时报does not appear to be a git repository 原因: clone时不能用绝对路径，直接写gitosis-admin.git即可. 参考:https://git-scm.com/book/zh/v1/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84-Git-Gitosis gitlab服务搭建]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware中Bridged,NAT,host-only三种网络连接模式的原理和区别]]></title>
    <url>%2F2017%2F04%2F22%2Fvmware-network-mode%2F</url>
    <content type="text"><![CDATA[不同虚拟交换机应用在不同的联网模式Bridged、NAT、host-only、custom四种模式，下面分别介绍其具体分配： VMnet0：这是VMware用于虚拟桥接网络下的虚拟交换机； VMnet1：这是VMware用于虚拟Host-Only网络下的虚拟交换机； VMnet8：这是VMware用于虚拟NAT网络下的虚拟交换机； VMnet2~VMnet7及VMnet9：是VMware用于虚拟自定义custom网络下的虚拟交换机； VMware Network Adapter VMnet1：这是宿主机用于与Host-Only虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet8：这是宿主机用于与NAT虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet1与VMware Network Adapter VMnet8可以在宿主机网络连接中看到. 1.Bridged桥接模式VMware在桥接模式下，虚拟机使用VMware为该虚拟机分配的虚拟网卡，宿主机使用自身的物理网卡（有线或无线都行），并且默认使用虚拟交换机VMnet0来连接虚拟机的虚拟网卡和宿主机的物理网卡。在此模式下没有局域网动态地址分配DHCP服务器，也没有网络地址转换ＮＡＴ服务器，虚拟交换机没有连接DHCP服务器和ＮＡＴ服务器。宿主机的网口（插网线的那个口）与宿主机物理网卡相连，同时也就和虚拟机的虚拟网卡相连，也就是和虚拟交换机相连，所以虚拟机相当于在宿主机所在局域网内的一个单独的主机，他的行为和宿主机是同等地位的，没有依存关系。所有桥接下的网卡与网卡都是交换模式的，相互可以访问而不干扰。在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关与DNS需要与主机网卡一致原理图如下： 配置虚拟机网卡,编辑/etc/sysconfig/network-scripts/ifcfg-eth0: 1234567891011DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=noneIPADDR=192.168.31.128 #设置虚拟机ip地址,与主机ip地址在同一网段NETMASK=255.255.255.0 #设置子网掩码GATEWAY=192.168.31.1#设置虚拟网关,与主机相同DNS1=192.168.31.1 #设置虚拟机DNS,与主机相同 执行/etc/init.d/network restart重启虚拟机网卡,ping内网与外网测试. 2.NAT网络地址转换模式： 注意：红色的方框是nat服务器，nat服务器有两个网卡一个是虚拟内网网卡，一个是宿主机的物理网卡。禁用VmNet8，虚拟机仍然可以上网，ping通主机，但是主机ping不通虚拟机的网卡。在NAT模式中，主机网卡直接与虚拟NAT设备相连，然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上，这样就实现了虚拟机联网。那么我们会觉得很奇怪，为什么需要虚拟网卡VMware Network Adapter VMnet8呢？原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。弥补了NAT协议中外网不能访问局域网的缺点。 具体配置: 123456789101112DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=dhcp #动态获取ip地址,如果此处设置为静态,则下面手动配置ip需要在DHCP地址范围内#NAT模式也可以设置静态ip,但需要在DHCP地址范围内IPADDR=192.168.31.128NETMASK=255.255.255.0GATEWAY=192.168.31.1DNS1=192.168.31.1 3.Host-Only方式 注意：上图中的VmNet8应该为VmNet1。其实跟nat模式的图片是类似的，只是少了nat服务。 所以host-only上不了外网，只能实现主机的VmNet1网卡和虚拟机的虚拟网卡通信。 NAT介绍NAT（Network Address Translation，网络地址转换）是1994年提出的。当在专用网内部的一些主机本来已经分配到了本地IP地址（即仅在本专用网内使用的专用地址），但现在又想和因特网上的主机通信（并不需要加密）时，可使用NAT方法。 这种方法需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球IP地址。这样，所有使用本地地址的主机在和外界通信时，都要在NAT路由器上将其本地地址转换成全球IP地址，才能和因特网连接。 另外，这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用的IP地址空间的枯竭。 功能NAT不仅能解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。 宽带分享：这是 NAT 主机的最大功能。 安全防护：NAT 之内的 PC 联机到 Internet 上面时，他所显示的 IP 是 NAT 主机的公共 IP，所以 Client 端的 PC 当然就具有一定程度的安全了，外界在进行 portscan（端口扫描） 的时候，就侦测不到源Client 端的 PC 。 实现方式NAT的实现方式有三种，即静态转换Static Nat、动态转换Dynamic Nat和端口多路复用OverLoad。 静态转换是指将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一成不变的，某个私有IP地址只转换为某个公有IP地址。借助于静态转换，可以实现外部网络对内部网络中某些特定设备（如服务器）的访问。 动态转换是指将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定的，是随机的，所有被授权访问上Internet的私有IP地址可随机转换为任何指定的合法IP地址。也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态转换。动态转换可以使用多个合法外部地址集。当ISP提供的合法IP地址略少于网络内部的计算机数量时。可以采用动态转换的方式。 端口多路复用（Port address Translation,PAT)是指改变外出数据包的源端口并进行端口转换，即端口地址转换（PAT，Port Address Translation).采用端口多路复用方式。内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，从而可以最大限度地节约IP地址资源。同时，又可隐藏网络内部的所有主机，有效避免来自internet的攻击。因此，目前网络中应用最多的就是端口多路复用方式。 ALG（Application Level Gateway），即应用程序级网关技术：传统的NAT技术只对IP层和传输层头部进行转换处理，但是一些应用层协议，在协议数据报文中包含了地址信息。为了使得这些应用也能透明地完成NAT转换，NAT使用一种称作ALG的技术，它能对这些应用程序在通信时所包含的地址信息也进行相应的NAT转换。例如：对于FTP协议的PORT/PASV命令、DNS协议的 “A” 和 “PTR” queries命令和部分ICMP消息类型等都需要相应的ALG来支持。 如果协议数据报文中不包含地址信息，则很容易利用传统的NAT技术来完成透明的地址转换功能，通常我们使用的如下应用就可以直接利用传统的NAT技术：HTTP、TELNET、FINGER、NTP、NFS、ARCHIE、RLOGIN、RSH、RCP等。 工作原理借助于NAT，私有（保留）地址的”内部”网络通过路由器发送数据包时，私有地址被转换成合法的IP地址，一个局域网只需使用少量IP地址（甚至是1个）即可实现私有地址网络内所有计算机与Internet的通信需求。 NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。 NAPTNAPT（Network Address Port Translation），即网络端口地址转换，可将多个内部地址映射为一个合法公网地址，但以不同的协议端口号与不同的内部地址相对应，也就是&lt;内部地址+内部端口&gt;与&lt;外部地址+外部端口&gt;之间的转换。NAPT普遍用于接入设备中，它可以将中小型的网络隐藏在一个合法的IP地址后面。NAPT也被称为“多对一”的NAT，或者叫PAT（Port Address Translations，端口地址转换）、地址超载（address overloading）。 NAPT与动态地址NAT不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的TCP端口号。NAPT算得上是一种较流行的NAT变体，通过转换TCP或UDP协议端口号以及地址来提供并发性。除了一对源和目的IP地址以外，这个表还包括一对源和目的协议端口号，以及NAT盒使用的一个协议端口号。 NAPT的主要优势在于，能够使用一个全球有效IP地址获得通用性。主要缺点在于其通信仅限于TCP或UDP。当所有通信都采用TCP或UDP，NAPT允许一台内部计算机访问多台外部计算机，并允许多台内部主机访问同一台外部计算机，相互之间不会发生冲突。 NAT穿透方法目前常用的针对UDP的NAT 穿透（NAT Traversal）方法主要有：STUN、TURN、ICE、uPnP等。其中ICE方式由于其结合了STUN和TURN的特点，所以使用最为广泛。针对TCP的NAT穿透技术目前仍为难点。实用的技术仍然不多。 配置在配置NAT(网络地址转换)之前，首先需要了解内部本地地址和内部全局地址的分配情况。根据不同的需求，执行以下不同的配置任务。 内部源地址NAT配置 内部源地址NAPT配置 重叠地址NAT配置 TCP负载均衡]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网卡配置]]></title>
    <url>%2F2017%2F04%2F22%2Flinux-networkcard%2F</url>
    <content type="text"><![CDATA[linux网卡可以通过命令和配置文件配置,如果是桌面环境还可以通过图形化界面配置. 1.ifconfig(interfaces config)命令方式通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置(用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在)。 1.1命令格式1ifconfig [网络设备] [参数] 1.2命令功能ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 1.3命令参数 up 启动指定网络设备/网卡。 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。 arp 设置指定网卡是否支持ARP协议。 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 1.4使用实例1.4.1显示网络设备信息（激活状态的）命令:ifcofig 输出: 12345678910111213141516[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 说明 eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 1.4.2启动关闭指定网卡命令： ifconfig eth0 up ifconfig eth0 down 输出： 说明： ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.3为网卡配置和删除IPv6地址命令： ifconfig eth0 add 33ffe:3240:800:1005::2/64 ifconfig eth0 del 33ffe:3240:800:1005::2/64 输出： 说明： ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址； ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址； 练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.4用ifconfig修改MAC地址命令： ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 down //关闭网卡[root@localhost ~]# ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE //修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:AA:BB:CC:DD:EE inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB)[root@localhost ~]# ifconfig eth0 hw ether 00:50:56:BF:26:20 //关闭网卡并修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 1.4.5配置IP地址输出: 123[root@localhost ~]# ifconfig eth0 192.168.120.56[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 说明: ifconfig eth0 192.168.120.56 给eth0网卡配置IP地：192.168.120.56 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 /给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255 1.4.6启用和关闭ARP协议命令： ifconfig eth0 arp ifconfig eth0 -arp 输出： 12[root@localhost ~]# ifconfig eth0 arp[root@localhost ~]# ifconfig eth0 -arp 说明 ifconfig eth0 arp 开启网卡eth0 的arp协议； ifconfig eth0 -arp 关闭网卡eth0 的arp协议； 1.4.7 设置最大传输单元命令： ifconfig eth0 mtu 1500 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 mtu 1480[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1480 Metric:1 RX packets:8712395 errors:0 dropped:0 overruns:0 frame:0 TX packets:36631 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597062089 (569.4 MiB) TX bytes:2643973 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# ifconfig eth0 mtu 1500[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8712548 errors:0 dropped:0 overruns:0 frame:0 TX packets:36685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597072333 (569.4 MiB) TX bytes:2650581 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# 说明: 设置能通过的最大数据包大小为1500bytes 2.配置文件方式ubuntu配置文件:/etc/network/interfaces 1234567auto loiface lo inet loopbackauto eth0 #配置静态ipiface eth0 inet staticaddress 192.168.1.100netmask 255.255.255.0gateway 192.168.1.1 centos配置文件:/etc/sysconfig/network-scripts/ifcfg-eth0 123456789101112DEVICE=eth0(默认)HWADDR=00:0C:29:2E:36:16(默认)TYPE=Ethernet(默认)UUID=XXXXXXX(默认)ONBOOT=yes(默认为no,修改为yes意为每次reboot后 ifup eth0)MM_CONTROLLED=yes(默认)#BOOTPROTO=dhcp(dhcp为自动分配ip地址,我们把他注释了，在下面另外加)BOOTPROTO=static(新添加)IPV6INIT=no(新添加)USERCTL=no(新添加)IPADDR=192.168.164.100(新添加)NETMASK=255.255.255.0(新添加) service network restart重启网卡服务 3.图形界面方式添加虚拟网卡一台服务器需要设置多个ip,但又不想添加多块网卡,那就需要设置虚拟网卡.这里介绍几种方式在linux服务器上添加虚拟网卡. 比如向eth0中添加一块虚拟网卡: 1.快速创建删除虚拟网卡sudo ifconfig eth0: 192.168.10.10 up 以上的命令就可以在eth0网卡上创建一个叫eth0:0的虚拟网卡,他的地址是:192.168.1.63 如果不想要这个虚拟网卡了,可以使用如下命令删除: 1sudo ifconfig eth0:0 down 重启服务器或者网络后,虚拟网卡就没有了. 2.修改网卡配置文件在ubuntu下,网卡的配置文件是/etc/network/interfaces,所以我们修改它: sudo vim /etc/network/interfaces 在这个文件中增加如下内容并保存: 123456auto eth0:0iface eth0:0 inet staticaddress 192.168.10.10netmask 255.255.255.0#network 192.168.10.1#broadcast 192.168.1.255 保存后,我们需要重启网卡(重新加载配置文件)才会生效,使用如下命令重启:sudo /etc/init.d/networking restart 他的优点是重启服务器或者网卡配置不会丢失。 3.创建tag前两种方法都有一个特点，创建的网卡可有不同的ip地址，但是Mac地址相同。无法用来创建虚拟机。 添加虚拟网卡tap 1tunctl -b 其他配置命令: 显示网桥信息:brctl show 添加网桥:brctl addbr virbr0 激活网桥:ip link set virbr0 up 添加虚拟网卡tap:tunctl -b tap0 ——-&gt; 执行上面使命就会生成一个tap,后缀从0，1，2依次递增激活创建的tap:ip link set tap0 up 将tap0虚拟网卡添加到指定网桥上:brctl addif br0 tap0给网桥配制ip地址:ifconfig virbr1 169.254.251.4 up 将virbr1网桥上绑定的网卡eth5解除: brctl delif virb1 eth5 给virbr1网桥添加网卡eth6:brctl addif virbr1 eth6]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android声音播放与录制]]></title>
    <url>%2F2017%2F04%2F19%2Fissues-android-audio%2F</url>
    <content type="text"><![CDATA[AudioTrackAudioTrack类说明:123456789101112131415161718192021222324252627282930313233343536373839/** * The AudioTrack class manages and plays a single audio resource for Java applications. * It allows streaming of PCM audio buffers to the audio sink for playback. This is * achieved by &quot;pushing&quot; the data to the AudioTrack object using one of the * &#123;@link #write(byte[], int, int)&#125;, &#123;@link #write(short[], int, int)&#125;, * and &#123;@link #write(float[], int, int, int)&#125; methods. * * &lt;p&gt;An AudioTrack instance can operate under two modes: static or streaming.&lt;br&gt; * In Streaming mode, the application writes a continuous stream of data to the AudioTrack, using * one of the &#123;@code write()&#125; methods. These are blocking and return when the data has been * transferred from the Java layer to the native layer and queued for playback. The streaming * mode is most useful when playing blocks of audio data that for instance are: * * &lt;ul&gt; * &lt;li&gt;too big to fit in memory because of the duration of the sound to play,&lt;/li&gt; * &lt;li&gt;too big to fit in memory because of the characteristics of the audio data * (high sampling rate, bits per sample ...)&lt;/li&gt; * &lt;li&gt;received or generated while previously queued audio is playing.&lt;/li&gt; * &lt;/ul&gt; * * The static mode should be chosen when dealing with short sounds that fit in memory and * that need to be played with the smallest latency possible. The static mode will * therefore be preferred for UI and game sounds that are played often, and with the * smallest overhead possible. * * &lt;p&gt;Upon creation, an AudioTrack object initializes its associated audio buffer. * The size of this buffer, specified during the construction, determines how long an AudioTrack * can play before running out of data.&lt;br&gt; * For an AudioTrack using the static mode, this size is the maximum size of the sound that can * be played from it.&lt;br&gt; * For the streaming mode, data will be written to the audio sink in chunks of * sizes less than or equal to the total buffer size. * * AudioTrack is not final and thus permits subclasses, but such use is not recommended. */public class AudioTrack extends PlayerBase implements AudioRouting&#123; &#125; 构造方法说明1234567891011121314151617//根据采样率，采样精度，单双声道来得到frame的大小。int bufsize = AudioTrack.getMinBufferSize(8000,//每秒8K个点 AudioFormat.CHANNEL_CONFIGURATION_STEREO,//双声道AudioFormat.ENCODING_PCM_16BIT);//一个采样点16比特-2个字节//注意，按照数字音频的知识，这个算出来的是一秒钟buffer的大小。//创建AudioTrackAudioTrack trackplayer = new AudioTrack(AudioManager.STREAM_MUSIC, 8000, AudioFormat.CHANNEL_CONFIGURATION_ STEREO, AudioFormat.ENCODING_PCM_16BIT, bufsize,AudioTrack.MODE_STREAM);// trackplayer.play() ;//开始trackplayer.write(bytes_pkg, 0, bytes_pkg.length) ;//往track中写数据….trackplayer.stop();//停止播放trackplayer.release();//释放底层资源。 参数说明1. AudioTrack.MODE_STREAM的意思：AudioTrack中有MODE_STATIC和MODE_STREAM两种分类。 STREAM的意思是由用户在应用程序通过write方式把数据一次一次得写到audiotrack中。这个和我们在socket中发送数据一样，应用层从某个地方获取数据，例如通过编解码得到PCM数据，然后write到audiotrack。这种方式的坏处就是总是在JAVA层和Native层交互，效率损失较大。 而STATIC的意思是一开始创建的时候，就把音频数据放到一个固定的buffer，然后直接传给audiotrack，后续就不用一次次得write了。AudioTrack会自己播放这个buffer中的数据。 这种方法对于铃声等内存占用较小，延时要求较高的声音来说很适用。 2. StreamType这个在构造AudioTrack的第一个参数中使用。这个参数和Android中的AudioManager有关系，涉及到手机上的音频管理策略。 Android将系统的声音分为以下几类常见的（定义在AudioManager)： 1234567891011121314151617181920/** The audio stream for phone calls */public static final int STREAM_VOICE_CALL = AudioSystem.STREAM_VOICE_CALL;/** The audio stream for system sounds */public static final int STREAM_SYSTEM = AudioSystem.STREAM_SYSTEM;/** The audio stream for the phone ring */public static final int STREAM_RING = AudioSystem.STREAM_RING;/** The audio stream for music playback */public static final int STREAM_MUSIC = AudioSystem.STREAM_MUSIC;/** The audio stream for alarms */public static final int STREAM_ALARM = AudioSystem.STREAM_ALARM;/** The audio stream for notifications */public static final int STREAM_NOTIFICATION = AudioSystem.STREAM_NOTIFICATION;/** @hide The audio stream for phone calls when connected to bluetooth */public static final int STREAM_BLUETOOTH_SCO = AudioSystem.STREAM_BLUETOOTH_SCO;/** @hide The audio stream for enforced system sounds in certain countries (e.g camera in Japan) */public static final int STREAM_SYSTEM_ENFORCED = AudioSystem.STREAM_SYSTEM_ENFORCED;/** The audio stream for DTMF Tones */public static final int STREAM_DTMF = AudioSystem.STREAM_DTMF;/** @hide The audio stream for text to speech (TTS) */public static final int STREAM_TTS = AudioSystem.STREAM_TTS; 常用说明: STREAM_ALARM：警告声 STREAM_MUSCI：音乐声，例如music等 STREAM_RING：铃声 STREAM_SYSTEM：系统声音 STREAM_VOCIE_CALL：电话声音 为什么要分这么多呢？以前在台式机上开发的时候很少知道有这么多的声音类型，不过仔细思考下，发现这样做是有道理的。例如你在听music的时候接到电话，这个时候music播放肯定会停止，此时你只能听到电话，如果你调节音量的话，这个调节肯定只对电话起作用。当电话打完了，再回到music，你肯定不用再调节音量了。 其实系统将这几种声音的数据分开管理，所以，这个参数对AudioTrack来说，它的含义就是告诉系统，我现在想使用的是哪种类型的声音，这样系统就可以对应管理他们了。 AudioRecordAudioRecord说明The AudioRecord class manages the audio resources for Java applications to record audio from the audio input hardware of the platform. This is achieved by “pulling” (reading) the data from the AudioRecord object. The application is responsible for polling the AudioRecord object in time using one of the following three methods: read(byte[], int, int), read(short[], int, int) or read(ByteBuffer, int). The choice of which method to use will be based on the audio data storage format that is the most convenient for the user of AudioRecord. Upon creation, an AudioRecord object initializes its associated audio buffer that it will fill with the new audio data. The size of this buffer, specified during the construction, determines how long an AudioRecord can record before “over-running” data that has not been read yet. Data should be read from the audio hardware in chunks of sizes inferior to the total recording buffer size. audiosource类型定义在MediaRecorder中 1234567891011121314151617181920212223242526272829/** Default audio source **/ public static final int DEFAULT = 0; /** Microphone audio source */ public static final int MIC = 1; /** Voice call uplink (Tx) audio source */ public static final int VOICE_UPLINK = 2; /** Voice call downlink (Rx) audio source */ public static final int VOICE_DOWNLINK = 3; /** Voice call uplink + downlink audio source */ public static final int VOICE_CALL = 4; /** Microphone audio source with same orientation as camera if available, the main * device microphone otherwise */ public static final int CAMCORDER = 5; /** Microphone audio source tuned for voice recognition if available, behaves like * &#123;@link #DEFAULT&#125; otherwise. */ public static final int VOICE_RECOGNITION = 6; /** Microphone audio source tuned for voice communications such as VoIP. It * will for instance take advantage of echo cancellation or automatic gain control * if available. It otherwise behaves like &#123;@link #DEFAULT&#125; if no voice processing * is applied. */ public static final int VOICE_COMMUNICATION = 7; AudioManager获取系统音量代码 1234567891011121314151617181920212223242526272829//初始化AudioManager:AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE);//通话音量int max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_VOICE_CALL );int current = mAudioManager.getStreamVolume( AudioManager.STREAM_VOICE_CALL );Log.d(“VIOCE_CALL”, “max : ” + max + ” current : ” + current);//系统音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_SYSTEM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_SYSTEM );Log.d(“SYSTEM”, “max : ” + max + ” current : ” + current);//铃声音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_RING );current = mAudioManager.getStreamVolume( AudioManager.STREAM_RING );Log.d(“RING”, “max : ” + max + ” current : ” + current);//音乐音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_MUSIC );current = mAudioManager.getStreamVolume( AudioManager.STREAM_MUSIC );Log.d(“MUSIC”, “max : ” + max + ” current : ” + current);//提示声音音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_ALARM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_ALARM );Log.d(“ALARM”, “max : ” + max + ” current : ” + current); ps： 游戏过程中只允许调整多媒体音量，而不允许调整通话音量。 1setVolumeControlStream(AudioManager.STREAM_MUSIC); 控制音量AudioManager提供了设置音量的方法： 1public void setStreamVolume(intstreamType,intindex,intflags) 其中streamType有内置的常量，去文档里面就可以看到。 使用示例: 12345678910111213141516171819202122232425//音量控制,初始化定义 AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE); //最大音量 int maxVolume = mAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC); //当前音量 int currentVolume = mAudioManager.getStreamVolume(AudioManager.STREAM_MUSIC);//直接控制音量if(isSilent)&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0); &#125;else&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, tempVolume, 0); //tempVolume:音量绝对值 &#125; //以一步步长控制音量的增减，并弹出系统默认音量控制条：//降低音量，调出系统音量控制 if(flag == 0)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_LOWER, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; //增加音量，调出系统音量控制 else if(flag == 1)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_RAISE, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; 监听按键手动控制音量 123456789101112131415161718192021AudioManager audio = (AudioManager) getSystemService(Service.AUDIO_SERVICE);@Overridepublic boolean onKeyDown(int keyCode, KeyEvent event) &#123; switch (keyCode) &#123; case KeyEvent.KEYCODE_VOLUME_UP: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_RAISE, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; case KeyEvent.KEYCODE_VOLUME_DOWN: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_LOWER, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; default: break; &#125; return super.onKeyDown(keyCode, event); 插入耳机状态仍使用扬声器外放音乐插入耳机的时候也可以选择使用扬声器播放音乐，来电铃声就是这么用的。但是只能用MediaPlayer，播放音频文件。 使用AudioTrack.write播放是行不通的(有待验证)。按理说AudioRecord、AudioTrack类相对于MediaRecorder mediaPlayer来说，更加接近底层，应该也行得通的。 插入耳机，选择外放的代码如下(兼容性验证)： 123456789AudioManager audioManager = (AudioManager) this.getSystemService(Context.AUDIO_SERVICE); audioManager.setMicrophoneMute(false); audioManager.setSpeakerphoneOn(true);//使用扬声器外放，即使已经插入耳机 setVolumeControlStream(AudioManager.STREAM_MUSIC);//控制声音的大小 audioManager.setMode(AudioManager.STREAM_MUSIC); //播放一段声音，查看效果 MediaPlayer playerSound = MediaPlayer.create(this, Uri.parse(&quot;file:///system/media/audio/ui/camera_click.ogg&quot;)); playerSound.start(); 使用STREAM_VOCIE_CALL播放声音与耳机冲突使用STREAM_VOCIE_CALL播放声音在某些手机,比如魅蓝等上面会导致声音仍外放,耳机没声音现象. WebRtc使用STREAM_VOCIE_CALL播放声音,导致某些手机声音低,没法使用音量键调节,插入耳机声音仍外放等问题.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>issue</tag>
        <tag>Audio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown中嵌入LaTex]]></title>
    <url>%2F2017%2F04%2F16%2Flatex%2F</url>
    <content type="text"><![CDATA[MarkDown中使用标识符$$和$$$$即可引入LaTeX语法,前者使用时不换行,即在所使用位置使用LaTeX的格式,后者会换行后居中 部分希腊字母 命令 显示 命令 显示 \alpha α A A \beta β B B \gamma γ \Gamma \varGamma Γ Γ delta δ \Delta \varDelta Δ Δ \epsilon ϵ E E \eta η H H \theta θ \Theta \varTheta Θ Θ \kappa κ K K \lambda λ \Lambda \varLambda Λ Λ \mu μ M M \nu ν N N \pi π \Pi \varPi Π Π \rho ρ P P \sigma σ \Sigma \varSigma Σ Σ \tau τ T T \phi \varphi ϕ φ \Phi \varPhi Φ Φ \omega ω \Omega \varOmega Ω Ω 全部24个字母: 名称 大写 Tex 小写 Tex alpha A A α \alpha beta B B β\ beta gamma Γ \Gamma γ \gamma delta Δ \Delta δ \delta epsilon E E ϵ \epsilon zeta Z Z ζ \zeta eta H H η \eta theta Θ \Theta θ \theta iota I I ι \iota kappa K K κ \kappa lambda Λ \Lambda λ \lambda mu M M μ \mu nu N N ν \nu xi Ξ \Xi ξ \xi omicron O O ο \omicron pi Π \Pi π \pi rho P P ρ \rho sigma Σ \Sigma σ \sigma tau T T τ \tau upsilon Υ \Upsilon υ \upsilon phi Φ \Phi ϕ \phi chi X X χ \chi psi Ψ \Psi ψ \psi omega Ω \Omega ω \omega 部分运算符 命令 显示 命令 显示 \pm ± \mp ∓ \times × \div ÷ \circ ∘ \bullet ∙ \cdot ⋅ \cup ∪ \cap ∩ \subset ⊂ \supset ⊃ \subseteq ⊆ \supseteq ⊇ \leq ≤ \geq ≥ \propto ∝ 其他符号 命令 显示 命令 显示 \cdotp ⋅ \cdots ⋯ \ddots ⋱ \infty ∞ \partial ∂ \bot ⊥ \hat{a} â \tilde{a} ã \bar{a} a¯ \vec{a} a⃗ \dot{a} a˙ \sqrt{a} a‾‾√ \sqrt[3]{2} a‾‾√3 a^{3} a3 \frac{1}{a} 1a \lim_{x \to 0} lima→0 集合关系符号 说明 命令 集合的大括号 { … }\ 集合中的竖线$\mid$ \mid 属于 \in 不属于 \not\in A包含于B A\subset B A真包含于B A\subsetneqq B A包含B A\supset B A真包含B A\supsetneqq B A不包含于B A\not\subset B A交B A\cap B A并B A\cup B A的闭包 \overline{A} A减去B A\setminus B 实数集合 \mathbb{R} 空集 \emptyset 表格中竖线用&amp;#124; 括号总结 功能 语法 显示 不好看 ( \frac{1}{2} ) $(\frac{1}{2})$ 好一点 \left( \frac{1}{2} \right) $\left ( \frac{1}{2} \right )$ 可以使用\left和\right来显示不同的括号： 功能 语法 显示 圆括号，小括号 \left( \frac{a}{b} \right) $\left( \frac{a}{b} \right)$ 方括号，中括号 \left[ \frac{a}{b} \right] $\left[ \frac{a}{b} \right]$ 花括号，大括号 \left\{ \frac{a}{b} \right\} $ \left{ \frac{a}{b} \right}$ 角括号 \left \langle \frac{a}{b} \right \rangle $\left\langle \frac{a}{b} \right \rangle$ 单竖线，绝对值 \left 竖线 \frac{a}{b} \right 竖线 双竖线，范 \left \ 竖线 \frac{a}{b} \right \ 竖线 取整函数 （Floor function） \left \lfloor \frac{a}{b} \right \rfloor $ \left \lfloor \frac{a}{b} \right \rfloor$ 取顶函数 （Ceiling function) \left \lceil \frac{c}{d} \right \rceil $ \left \lceil \frac{c}{d} \right \rceil$ 斜线与反斜线 \left / \frac{a}{b} \right \backslash $ \left / \frac{a}{b} \right \backslash$ 上下箭头 \left \uparrow \frac{a}{b} \right \downarrow \left \Uparrow \frac{a}{b} \right \Downarrow \left \updownarrow \frac{a}{b} \right \Updownarrow $\left \uparrow \frac{a}{b} \right \downarrow$ $\left \Uparrow \frac{a}{b} \right \Downarrow$ $\left \updownarrow \frac{a}{b} \right \Updownarrow$ 混合括号 \left [ 0,1 \right ) \left \langle \psi ) $\left [ 0,1 \right )$ $ \left \langle \psi \right)$ 单左括号 \left \{ \frac{a}{b} \right . $\left { \frac{a}{b} \right .$ 单右括号 \left . \frac{a}{b} \right \} $\left . \frac{a}{b} \right }$ 备注： 可以使用\big, \Big, \bigg, \Bigg控制括号的大小，比如代码\Bigg ( \bigg [ \Big \{ \big \langle \left | \| \frac{a}{b} \| \right | \big \rangle \Big \} \bigg ] \Bigg )显示 $$\Bigg ( \bigg [ \Big { \big \langle \left | | x | \right | \big \rangle \Big } \bigg ] \Bigg )$$ 矩阵基本用法使用$$\begin{matrix}…\end{matrix}$$这样的形式来表示矩阵，在\begin与\end之间加入矩阵中的元素即可。矩阵的行之间使用\\分隔，列之间使用&amp;分隔。 1234567$$ \begin&#123;matrix&#125; 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \end&#123;matrix&#125;$$ $$ \begin{matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \ \end{matrix} $$ 加括号如果要对矩阵加括号，可以像上文中提到的一样，使用\left与\right配合表示括号符号。也可以使用特殊的matrix。即替换\begin{matrix}…\end{matrix}中的matrix为pmatrix，bmatrix，Bmatrix，vmatrix,Vmatrix. 省略元素可以使用\cdots ⋯ \ddots ⋱ \vdots ⋮ 来省略矩阵中的元素 增广矩阵增广矩阵需要使用前面的array来实现 1234567$$ \left[ \begin&#123;array&#125;&#123;cc|c&#125; 1&amp;2&amp;3\\ 4&amp;5&amp;6 \end&#123;array&#125; \right]$$ $$ \left[ \begin{array}{cc|c} 1&amp;2&amp;3\ 4&amp;5&amp;6 \end{array} \right] $$ 表格使用$$\begin{array}{列样式}…\end{array}$$这样的形式来创建表格，列样式可以是clr表示居中，左，右对齐，还可以使用|表示一条竖线。表格中 各行使用\\分隔，各列使用&amp;分隔。使用\hline在本行前加入一条直线。 例如， 123456789$$\begin&#123;array&#125;&#123;c|lcr&#125;n &amp; \text&#123;Left&#125; &amp; \text&#123;Center&#125; &amp; \text&#123;Right&#125; \\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i \\\end&#123;array&#125;$$ 上标与下标上标和下标分别使用^与_，例如x_i^2：$x_i^2$ 。默认情况下，上下标符号仅仅对下一个组起作用。一个组即单个字符或者使用{..}包裹起来的内容。也就是说，如果使用10^10，会得到$10^10$ ，而10^{10}才是$10^{10}$ 。同时，大括号还能消除二义性，如x^5^6将得到一个错误，必须使用大括号来界定^的结合性，如{x^5}^6：${x^5}^6$ 或者 x^{5^6}：$x^{5^6}$ 。 对齐的公式分类表达式定义函数的时候经常需要分情况给出表达式，可使用\begin{cases}…\end{cases}。其中，使用\来分类，使用&amp;指示需要对齐的位置。如： 多重积分连分数方程组颜色公式标记与引用求和与积分分式与根式特殊函数与符号空间顶部符号 参考 http://mlworks.cn/posts/introduction-to-mathjax-and-latex-expression/]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高数1.函数与极限]]></title>
    <url>%2F2017%2F04%2F13%2Fam-function-and-limitaion%2F</url>
    <content type="text"><![CDATA[1.映射与函数1.1 集合1.1.1 集合的概念集合(集)是指具有某种特定性质的事物的总体,组成这个集合的事物成为该集合的元素(简称元) 表示:用大写拉丁字母A,B,C…表示集合,小写拉丁字母表示集合的元素 分类: 有限集 无限集 表示数集的字母的右上角标*表示该数集内排除0的集,标上+来表示数集内排除0和负数的集 常用表示 N={0, 1, 2, 3…};全体非负整数即自然数的集合 N+={1,2,3,…n,….};全体正整数的集合 Z={…,-n,…-3, -2,-1, 0, 1, 2, 3,…,n…};全体整数的集合 $Q=\lbrace \frac{p}{q}|p \in Z,q \in N^{+} \rbrace$;全体有理数集 全体实数记做R,R*为排除0的实数集,R+为全体正实数集. 子集概念: 子集 真子集 集合相等:互为子集 空集 $\emptyset$1.1.2 集合的运算 1.1.3 区间和领域]]></content>
      <categories>
        <category>高数</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android线程使用总结]]></title>
    <url>%2F2017%2F04%2F10%2Ftips-android-thread%2F</url>
    <content type="text"><![CDATA[1. Threading Performance在程序开发的实践当中，为了让程序表现得更加流畅，我们肯定会需要使用到多线程来提升程序的并发执行性能。但是编写多线程并发的代码一直以来都是一个相对棘手的问题，所以想要获得更佳的程序性能，我们非常有必要掌握多线程并发编程的基础技能。 众所周知，Android 程序的大多数代码操作都必须执行在主线程，例如系统事件(例如设备屏幕发生旋转)，输入事件(例如用户点击滑动等)，程序回调服务，UI 绘制以及闹钟事件等等。那么我们在上述事件或者方法中插入的代码也将执行在主线程。 一旦我们在主线程里面添加了操作复杂的代码，这些代码就很可能阻碍主线程去响应点击/滑动事件，阻碍主线程的 UI 绘制等等。我们知道，为了让屏幕的刷新帧率达到 60fps，我们需要确保 16ms 内完成单次刷新的操作。一旦我们在主线程里面执行的任务过于繁重就可能导致接收到刷新信号的时候因为资源被占用而无法完成这次刷新操作，这样就会产生掉帧的现象，刷新帧率自然也就跟着下降了(一旦刷新帧率降到 20fps 左右，用户就可以明显感知到卡顿不流畅了)。 为了避免上面提到的掉帧问题，我们需要使用多线程的技术方案，把那些操作复杂的任务移动到其他线程当中执行，这样就不容易阻塞主线程的操作，也就减小了出现掉帧的可能性。 为主线程减轻负的多线程方案有哪些呢？这些方案分别适合在什么场景下使用？Android 系统为我们提供了若干组工具类来帮助解决这个问题。 AsyncTask: 为 UI 线程与工作线程之间进行快速的切换提供一种简单便捷的机制。适用于当下立即需要启动，但是异步执行的生命周期短暂的使用场景。 HandlerThread: 为某些回调方法或者等待某些任务的执行设置一个专属的线程，并提供线程任务的调度机制。 ThreadPool: 把任务分解成不同的单元，分发到各个不同的线程上，进行同时并发处理。 IntentService: 适合于执行由 UI 触发的后台 Service 任务，并可以把后台任务执行的情况通过一定的机制反馈给 UI。 了解这些系统提供的多线程工具类分别适合在什么场景下，可以帮助我们选择合适的解决方案，避免出现不可预期的麻烦。虽然使用多线程可以提高程序的并发量，但是我们需要特别注意因为引入多线程而可能伴随而来的内存问题。举个例子，在 Activity 内部定义的一个 AsyncTask，它属于一个内部类，该类本身和外面的 Activity 是有引用关系的，如果 Activity 要销毁的时候，AsyncTask 还仍然在运行，这会导致 Activity 没有办法完全释放，从而引发内存泄漏。所以说，多线程是提升程序性能的有效手段之一，但是使用多线程却需要十分谨慎小心，如果不了解背后的执行机制以及使用的注意事项，很可能引起严重的问题。 2. Understanding Android Threading通常来说，一个线程需要经历三个生命阶段：开始，执行，结束。线程会在任务执行完毕之后结束，那么为了确保线程的存活，我们会在执行阶段给线程赋予不同的任务，然后在里面添加退出的条件从而确保任务能够执行完毕后退出。 在很多时候，线程不仅仅是线性执行一系列的任务就结束那么简单的，我们会需要增加一个任务队列，让线程不断的从任务队列中获取任务去进行执行，另外我们还可能在线程执行的任务过程中与其他的线程进行协作。如果这些细节都交给我们自己来处理，这将会是件极其繁琐又容易出错的事情。 所幸的是，Android 系统为我们提供了 Looper，Handler，MessageQueue 来帮助实现上面的线程任务模型： Looper: 能够确保线程持续存活并且可以不断的从任务队列中获取任务并进行执行。 Handler: 能够帮助实现队列任务的管理，不仅仅能够把任务插入到队列的头部，尾部，还可以按照一定的时间延迟来确保任务从队列中能够来得及被取消掉。 MessageQueue: 使用 Intent，Message，Runnable 作为任务的载体在不同的线程之间进行传递。 把上面三个组件打包到一起进行协作，这就是 HandlerThread 我们知道，当程序被启动，系统会帮忙创建进程以及相应的主线程，而这个主线程其实就是一个 HandlerThread。这个主线程会需要处理系统事件，输入事件，系统回调的任务，UI绘制等等任务，为了避免主线程任务过重，我们就会需要不断的开启新的工作线程来处理那些子任务。 3. Memory &amp; Threading增加并发的线程数会导致内存消耗的增加，平衡好这两者的关系是非常重要的。我们知道，多线程并发访问同一块内存区域有可能带来很多问题，例如读写的权限争夺问题，ABA 问题等等。为了解决这些问题，我们会需要引入锁的概念。 在 Android 系统中也无法避免因为多线程的引入而导致出现诸如上文提到的种种问题。Android UI 对象的创建，更新，销毁等等操作都默认是执行在主线程，但是如果我们在非主线程对UI对象进行操作，程序将可能出现异常甚至是崩溃。 另外，在非 UI 线程中直接持有 UI 对象的引用也很可能出现问题。例如Work线程中持有某个 UI 对象的引用，在 Work 线程执行完毕之前，UI 对象在主线程中被从 ViewHierarchy 中移除了，这个时候 UI 对象的任何属性都已经不再可用了，另外对这个 UI 对象的更新操作也都没有任何意义了，因为它已经从 ViewHierarchy 中被移除，不再绘制到画面上了。 不仅如此，View 对象本身对所属的 Activity 是有引用关系的，如果工作线程持续保有 View 的引用，这就可能导致 Activity 无法完全释放。除了直接显式的引用关系可能导致内存泄露之外，我们还需要特别留意隐式的引用关系也可能导致泄露。例如通常我们会看到在 Activity 里面定义的一个 AsyncTask，这种类型的 AsyncTask 与外部的 Activity 是存在隐式引用关系的，只要 Task 没有结束，引用关系就会一直存在，这很容易导致 Activity 的泄漏。更糟糕的情况是，它不仅仅发生了内存泄漏，还可能导致程序异常或者崩溃。 为了解决上面的问题，我们需要谨记的原则就是：不要在任何非 UI 线程里面去持有 UI 对象的引用。系统为了确保所有的 UI 对象都只会被 UI 线程所进行创建，更新，销毁的操作，特地设计了对应的工作机制(当 Activity 被销毁的时候，由该 Activity 所触发的非 UI 线程都将无法对UI对象进行操作，否者就会抛出程序执行异常的错误)来防止 UI 对象被错误的使用。 4. Good AsyncTask HuntingAsyncTask 是一个让人既爱又恨的组件，它提供了一种简便的异步处理机制，但是它又同时引入了一些令人厌恶的麻烦。一旦对 AsyncTask 使用不当，很可能对程序的性能带来负面影响，同时还可能导致内存泄露。 举个例子，常遇到的一个典型的使用场景：用户切换到某个界面，触发了界面上的图片的加载操作，因为图片的加载相对来说耗时比较长，我们需要在子线程中处理图片的加载，当图片在子线程中处理完成之后，再把处理好的图片返回给主线程，交给 UI 更新到画面上。 AsyncTask 的出现就是为了快速的实现上面的使用场景，AsyncTask 把在主线程里面的准备工作放到 onPreExecute()方法里面进行执行，doInBackground()方法执行在工作线程中，用来处理那些繁重的任务，一旦任务执行完毕，就会调用 onPostExecute()方法返回到主线程。 使用 AsyncTask 需要注意的问题有哪些呢？请关注以下几点： 首先，默认情况下，所有的 AsyncTask 任务都是被线性调度执行的，他们处在同一个任务队列当中，按顺序逐个执行。假设你按照顺序启动20个 AsyncTask，一旦其中的某个 AsyncTask 执行时间过长，队列中的其他剩余 AsyncTask 都处于阻塞状态，必须等到该任务执行完毕之后才能够有机会执行下一个任务。 为了解决上面提到的线性队列等待的问题，我们可以使用 AsyncTask.executeOnExecutor()强制指定 AsyncTask 使用线程池并发调度任务。 其次，如何才能够真正的取消一个 AsyncTask 的执行呢？我们知道 AsyncTaks 有提供 cancel()的方法，但是这个方法实际上做了什么事情呢？线程本身并不具备中止正在执行的代码的能力，为了能够让一个线程更早的被销毁，我们需要在 doInBackground()的代码中不断的添加程序是否被中止的判断逻辑. 一旦任务被成功中止，AsyncTask 就不会继续调用 onPostExecute()，而是通过调用 onCancelled()的回调方法反馈任务执行取消的结果。我们可以根据任务回调到哪个方法（是 onPostExecute 还是 onCancelled）来决定是对 UI 进行正常的更新还是把对应的任务所占用的内存进行销毁等。 最后，使用 AsyncTask 很容易导致内存泄漏，一旦把 AsyncTask 写成 Activity 的内部类的形式就很容易因为 AsyncTask 生命周期的不确定而导致 Activity 发生泄漏。 综上所述，AsyncTask 虽然提供了一种简单便捷的异步机制，但是我们还是很有必要特别关注到他的缺点，避免出现因为使用错误而导致的严重系统性能问题。 5. Getting a HandlerThread大多数情况下，AsyncTask 都能够满足多线程并发的场景需要（在工作线程执行任务并返回结果到主线程），但是它并不是万能的。例如打开相机之后的预览帧数据是通过 onPreviewFrame()的方法进行回调的，onPreviewFrame()和 open()相机的方法是执行在同一个线程的。 如果这个回调方法执行在 UI 线程，那么在 onPreviewFrame()里面将要执行的数据转换操作将和主线程的界面绘制，事件传递等操作争抢系统资源，这就有可能影响到主界面的表现性能。 我们需要确保 onPreviewFrame()执行在工作线程。如果使用 AsyncTask，会因为 AsyncTask 默认的线性执行的特性(即使换成并发执行)会导致因为无法把任务及时传递给工作线程而导致任务在主线程中被延迟，直到工作线程空闲，才可以把任务切换到工作线程中进行执行。 所以我们需要的是一个执行在工作线程，同时又能够处理队列中的复杂任务的功能，而 HandlerThread 的出现就是为了实现这个功能的，它组合了 Handler，MessageQueue，Looper 实现了一个长时间运行的线程，不断的从队列中获取任务进行执行的功能。 回到刚才的处理相机回调数据的例子，使用 HandlerThread 我们可以把 open()操作与 onPreviewFrame()的操作执行在同一个线程，同时还避免了 AsyncTask 的弊端。如果需要在 onPreviewFrame()里面更新 UI，只需要调用 runOnUiThread()方法把任务回调给主线程就够了。 HandlerThread 比较合适处理那些在工作线程执行，需要花费时间偏长的任务。我们只需要把任务发送给 HandlerThread，然后就只需要等待任务执行结束的时候通知返回到主线程就好了。 另外很重要的一点是，一旦我们使用了 HandlerThread，需要特别注意给 HandlerThread 设置不同的线程优先级，CPU 会根据设置的不同线程优先级对所有的线程进行调度优化。 掌握 HandlerThread 与 AsyncTask 之间的优缺点，可以帮助我们选择合适的方案。 6. Swimming in Threadpools线程池适合用在把任务进行分解，并发进行执行的场景。通常来说，系统里面会针对不同的任务设置一个单独的守护线程用来专门处理这项任务。例如使用 Networking Thread 用来专门处理网络请求的操作，使用 IO Thread 用来专门处理系统的 I\O 操作。针对那些场景，这样设计是没有问题的，因为对应的任务单次执行的时间并不长而且可以是顺序执行的。但是这种专属的单线程并不能满足所有的情况，例如我们需要一次性 decode 40张图片，每个线程需要执行 4ms 的时间，如果我们使用专属单线程的方案，所有图片执行完毕会需要花费 160ms(40*4)，但是如果我们创建10个线程，每个线程执行4个任务，那么我们就只需要16ms就能够把所有的图片处理完毕。 为了能够实现上面的线程池模型，系统为我们提供了 ThreadPoolExecutor 帮助类来简化实现，剩下需要做的就只是对任务进行分解就好了。 使用线程池需要特别注意同时并发线程数量的控制，理论上来说，我们可以设置任意你想要的并发数量，但是这样做非常的不好。因为 CPU 只能同时执行固定数量的线程数，一旦同时并发的线程数量超过 CPU 能够同时执行的阈值，CPU 就需要花费精力来判断到底哪些线程的优先级比较高，需要在不同的线程之间进行调度切换。 一旦同时并发的线程数量达到一定的量级，这个时候 CPU 在不同线程之间进行调度的时间就可能过长，反而导致性能严重下降。另外需要关注的一点是，每开一个新的线程，都会耗费至少 64K+ 的内存。为了能够方便的对线程数量进行控制，ThreadPoolExecutor 为我们提供了初始化的并发线程数量，以及最大的并发数量进行设置。 另外需要关注的一个问题是：Runtime.getRuntime().availableProcesser()方法并不可靠，他返回的值并不是真实的 CPU 核心数，因为 CPU 会在某些情况下选择对部分核心进行睡眠处理，在这种情况下，返回的数量就只能是激活的 CPU 核心数。 7. The Zen of IntentService默认的 Service 是执行在主线程的，可是通常情况下，这很容易影响到程序的绘制性能(抢占了主线程的资源)。除了前面介绍过的 AsyncTask 与 HandlerThread，我们还可以选择使用 IntentService 来实现异步操作。IntentService 继承自普通 Service 同时又在内部创建了一个 HandlerThread，在 onHandlerIntent()的回调里面处理扔到 IntentService 的任务。所以 IntentService 就不仅仅具备了异步线程的特性，还同时保留了 Service 不受主页面生命周期影响的特点。 如此一来，我们可以在 IntentService 里面通过设置闹钟间隔性的触发异步任务，例如刷新数据，更新缓存的图片或者是分析用户操作行为等等，当然处理这些任务需要小心谨慎。 使用 IntentService 需要特别留意以下几点： 首先，因为 IntentService 内置的是 HandlerThread 作为异步线程，所以每一个交给 IntentService 的任务都将以队列的方式逐个被执行到，一旦队列中有某个任务执行时间过长，那么就会导致后续的任务都会被延迟处理。 其次，通常使用到 IntentService 的时候，我们会结合使用 BroadcastReceiver 把工作线程的任务执行结果返回给主 UI 线程。使用广播容易引起性能问题，我们可以使用 LocalBroadcastManager 来发送只在程序内部传递的广播，从而提升广播的性能。我们也可以使用 runOnUiThread() 快速回调到主 UI 线程。 最后，包含正在运行的 IntentService 的程序相比起纯粹的后台程序更不容易被系统杀死，该程序的优先级是介于前台程序与纯后台程序之间的。 8. Threading and Loaders当启动工作线程的 Activity 被销毁的时候，我们应该做点什么呢？为了方便的控制工作线程的启动与结束，Android 为我们引入了 Loader 来解决这个问题。我们知道 Activity 有可能因为用户的主动切换而频繁的被创建与销毁，也有可能是因为类似屏幕发生旋转等被动原因而销毁再重建。在 Activity 不停的创建与销毁的过程当中，很有可能因为工作线程持有 Activity 的 View 而导致内存泄漏(因为工作线程很可能持有 View 的强引用，另外工作线程的生命周期还无法保证和 Activity 的生命周期一致，这样就容易发生内存泄漏了)。除了可能引起内存泄漏之外，在 Activity 被销毁之后，工作线程还继续更新视图是没有意义的，因为此时视图已经不在界面上显示了。 Loader 的出现就是为了确保工作线程能够和 Activity 的生命周期保持一致，同时避免出现前面提到的问题。 LoaderManager 会对查询的操作进行缓存，只要对应 Cursor 上的数据源没有发生变化，在配置信息发生改变的时候(例如屏幕的旋转)，Loader 可以直接把缓存的数据回调到 onLoadFinished()，从而避免重新查询数据。另外系统会在 Loader 不再需要使用到的时候(例如使用 Back 按钮退出当前页面)回调 onLoaderReset()方法，我们可以在这里做数据的清除等等操作。 在 Activity 或者 Fragment 中使用 Loader 可以方便的实现异步加载的框架，Loader 有诸多优点。但是实现 Loader 的这套代码还是稍微有点点复杂，Android 官方为我们提供了使用 Loader 的示例代码进行参考学习。 9. The Importance of Thread Priority理论上来说，我们的程序可以创建出非常多的子线程一起并发执行的，可是基于 CPU 时间片轮转调度的机制，不可能所有的线程都可以同时被调度执行，CPU 需要根据线程的优先级赋予不同的时间片。 Android 系统会根据当前运行的可见的程序和不可见的后台程序对线程进行归类，划分为 forground 的那部分线程会大致占用掉 CPU 的90%左右的时间片，background 的那部分线程就总共只能分享到5%-10%左右的时间片。之所以设计成这样是因为 forground 的程序本身的优先级就更高，理应得到更多的执行时间。 默认情况下，新创建的线程的优先级默认和创建它的母线程保持一致。如果主 UI 线程创建出了几十个工作线程，这些工作线程的优先级就默认和主线程保持一致了，为了不让新创建的工作线程和主线程抢占 CPU 资源，需要把这些线程的优先级进行降低处理，这样才能给帮组 CPU 识别主次，提高主线程所能得到的系统资源。 在 Android 系统里面，我们可以通过 android.os.Process.setThreadPriority(int) 设置线程的优先级，参数范围从-20到19，数值越小优先级越高。Android 系统还为我们提供了以下的一些预设值，我们可以通过给不同的工作线程设置不同数值的优先级来达到更细粒度的控制。 大多数情况下，新创建的线程优先级会被设置为默认的0，主线程设置为0的时候，新创建的线程还可以利用 THREAD_PRIORITY_LESS_FAVORABLE 或者 THREAD_PRIORITY_MORE_FAVORABLE 来控制线程的优先级。 Android 系统里面的 AsyncTask 与 IntentService已经默认帮助我们设置线程的优先级，但是对于那些非官方提供的多线程工具类，我们需要特别留意根据需要自己手动来设置线程的优先级。 10. Profile GPU Rendering : M Update从 Android M 系统开始，系统更新了 GPU Profiling 的工具来帮助我们定位 UI 的渲染性能问题。早期的 CPU Profiling 工具只能粗略的显示出 Process，Execute，Update 三大步骤的时间耗费情况。 但是仅仅显示三大步骤的时间耗费情况，还是不太能够清晰帮助我们定位具体的程序代码问题，所以在 Android M 版本开始，GPU Profiling 工具把渲染操作拆解成如下8个详细的步骤进行显示。 旧版本中提到的 Proces，Execute，Update 还是继续得到了保留，他们的对应关系如下： 接下去我们看下其他五个步骤分别代表了什么含义： Sync &amp; Upload：通常表示的是准备当前界面上有待绘制的图片所耗费的时间，为了减少该段区域的执行时间，我们可以减少屏幕上的图片数量或者是缩小图片本身的大小。 Measure &amp; Layout：这里表示的是布局的 onMeasure 与 onLayout 所花费的时间，一旦时间过长，就需要仔细检查自己的布局是不是存在严重的性能问题。 Animation：表示的是计算执行动画所需要花费的时间，包含的动画有 ObjectAnimator，ViewPropertyAnimator，Transition 等等。一旦这里的执行时间过长，就需要检查是不是使用了非官方的动画工具或者是检查动画执行的过程中是不是触发了读写操作等等。 Input Handling：表示的是系统处理输入事件所耗费的时间，粗略等于对于的事件处理方法所执行的时间。一旦执行时间过长，意味着在处理用户的输入事件的地方执行了复杂的操作。 Misc/Vsync Delay：如果稍加注意，我们可以在开发应用的 Log 日志里面看到这样一行提示：I/Choreographer(691): Skipped XXX frames! The application may be doing too much work on its main thread。这意味着我们在主线程执行了太多的任务，导致 UI 渲染跟不上 vSync 的信号而出现掉帧的情况。 上面八种不同的颜色区分了不同的操作所耗费的时间，为了便于我们迅速找出那些有问题的步骤，GPU Profiling 工具会显示 16ms 的阈值线，这样就很容易找出那些不合理的性能问题，再仔细看对应具体哪个步骤相对来说耗费时间比例更大，结合上面介绍的细化步骤，从而快速定位问题，修复问题。 http://bugly.qq.com/bbs/forum.php?mod=viewthread&amp;tid=1022]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>tips</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MP4格式解析]]></title>
    <url>%2F2017%2F04%2F09%2Fm-f-mp4%2F</url>
    <content type="text"><![CDATA[目前MP4的概念被炒得很火，也很乱。最开始MP4指的是音频（MP3的升级版），即MPEG-2 AAC标准。随后MP4概念被转移到视频上，对应的是MPEG-4标准。而现在我们流行的叫法，多半是指能播放MPEG-4标准编码格式视频的播放器。但是这篇文章介绍的内容跟上面这些都无关，我们要讨论的是MP4文件封装格式，对应的标准为ISO/IEC 14496-12，即信息技术 视听对象编码的第12部分：ISO 基本媒体文件格式（Information technology Coding of audio-visual objects Part 12: ISO base media file format）。ISO/IEC组织指定的标准一般用数字表示，ISO/IEC 14496即MPEG-4标准。 MP4视频文件封装格式是基于QuickTime容器格式定义的，因此参考QuickTime的格式定义对理解MP4文件格式很有帮助。MP4文件格式是一个十分开放的容器，几乎可以用来描述所有的媒体结构，MP4文件中的媒体描述与媒体数据是分开的，并且媒体数据的组织也很自由，不一定要按照时间顺序排列，甚至媒体数据可以直接引用其他文件。同时，MP4也支持流媒体。MP4目前被广泛用于封装h.264视频和AAC音频，是高清视频的代表。MP4格式的官方文件后缀名是“.mp4”，还有其他的以mp4为基础进行的扩展或者是缩水版本的格式，包括：M4V, 3GP, F4V等。 1.概述MP4文件中的所有数据都装在box（QuickTime中为atom）中，也就是说MP4文件由若干个box组成，每个box有类型和长度，可以将box理解为一个数据对象块。box中可以包含另一个box，这种box称为container box。一个MP4文件首先会有且只有一个“ftyp”类型的box，作为MP4格式的标志并包含关于文件的一些信息；之后会有且只有一个“moov”类型的box（Movie Box），它是一种container box，子box包含了媒体的metadata信息；MP4文件的媒体数据包含在“mdat”类型的box（Midia Data Box）中，该类型的box也是container box，可以有多个，也可以没有（当媒体数据全部引用其他文件时），媒体数据的结构由metadata进行描述。 下面是一些概念： track 表示一些sample的集合，对于媒体数据来说，track表示一个视频或音频序列。 hint track 这个特殊的track并不包含媒体数据，而是包含了一些将其他数据track打包成流媒体的指示信息。 sample 对于非hint track来说，video sample即为一帧视频，或一组连续视频帧，audio sample即为一段连续的压缩音频，它们统称sample。对于hint track，sample定义一个或多个流媒体包的格式。 sample table 指明sampe时序和物理布局的表。 chunk 一个track的几个sample组成的单元。 不讨论涉及hint的内容，只关注包含媒体数据的本地MP4文件。下图为一个典型的MP4文件的结构树。 2.Boxbox中的字节序为网络字节序，也就是大端字节序（Big-Endian），简单的说，就是一个32位的4字节整数存储方式为高位字节在内存的低端。Box由header和body组成，其中header统一指明box的大小和类型，body根据类型有不同的意义和格式。 标准的box开头的4个字节（32位）为box size，该大小包括box header和box body整个box的大小，这样我们就可以在文件中定位各个box。如果size为1，则表示这个box的大小为large size，真正的size值要在largesize域上得到。（实际上只有“mdat”类型的box才有可能用到large size。）如果size为0，表示该box为文件的最后一个box，文件结尾即为该box结尾。（同样只存在于“mdat”类型的box中。）size后面紧跟的32位为box type，一般是4个字符，如“ftyp”、“moov”等，这些box type都是已经预定义好的，分别表示固定的意义。如果是“uuid”，表示该box为用户扩展类型。如果box type是未定义的，应该将其忽略。 3.File Type Box(ftyp)该box有且只有1个，并且只能被包含在文件层，而不能被其他box包含。该box应该被放在文件的最开始，指示该MP4文件应用的相关信息。 “ftyp” body依次包括1个32位的major brand（4个字符），1个32位的minor version（整数）和1个以32位（4个字符）为单位元素的数组compatible brands。这些都是用来指示文件应用级别的信息。该box的字节实例如下： 1200000000h: 00 00 00 18 66 74 79 70 6D 70 34 32 00 00 00 01 ; ....ftypmp42....00000010h: 6D 70 34 32 6D 70 34 31 00 00 5A EB 6D 6F 6F 76 ; mp42mp41..Zmoov 4.Movie Box(moov)该box包含了文件媒体的metadata信息，“moov”是一个container box，具体内容信息由子box诠释。同File Type Box一样，该box有且只有一个，且只被包含在文件层。一般情况下，“moov”会紧随“ftyp”出现。 一般情况下（限于篇幅，本文只讲解常见的MP4文件结构），“moov”中会包含1个“mvhd”和若干个“trak”。其中“mvhd”为header box，一般作为“moov”的第一个子box出现（对于其他container box来说，header box都应作为首个子box出现）。“trak”包含了一个track的相关信息，是一个container box。下图为部分“moov”的字节实例，其中红色部分为box header，绿色为“mvhd”，黄色为一部分“trak”。 4.1 Movie Header Box(mvhd)“mvhd”接口如下表: 字段 字节数 意义 box size 4 box大小 box type 4 box类型 version 1 box版本，0或1，一般为0。（以下字节数均按version=0） flags 3 creation time 4 创建时间（相对于UTC时间1904-01-01零点的秒数） modification time 4 修改时间 time scale 4 文件媒体在1秒时间内的刻度值，可以理解为1秒长度的时间单元数 duration 4 该track的时间长度，用duration和time scale值可以计算track时长，比如audio track的time scale = 8000, duration = 560128，时长为70.016，video track的time scale = 600, duration = 42000，时长为70 rate 4 推荐播放速率，高16位和低16位分别为小数点整数部分和小数部分，即[16.16] 格式，该值为1.0（0x00010000）表示正常前向播放 volume 2 与rate类似，[8.8] 格式，1.0（0x0100）表示最大音量 reserved 10 保留位 matrix 36 视频变换矩阵 pre-defined 24 next track id 4 下一个track使用的id号 4.2Track Box(trak)“trak”也是一个container box，其子box包含了该track的媒体数据引用和描述（hint track除外）。一个MP4文件中的媒体可以包含多个track，且至少有一个track，这些track之间彼此独立，有自己的时间和空间信息。“trak”必须包含一个“tkhd”和一个“mdia”，此外还有很多可选的box（略）。其中“tkhd”为track header box，“mdia”为media box，该box是一个包含一些track媒体数据信息box的container box。 box类型说明 ftypefile type,说明文件类型 moovmetadata container,存放媒体信息的地方 mvhdmovie header,文件的总体信息,如时长,创建时间等 mvhdmovie header,文件的总体信息,如时长,创建时间等 traktrack or stream container,存放视频/音频流的容器 tkhdtrack header,track的总体信息,如时长,宽高等 mediatrak media information container mdhdmedia header,定义TimeScale,trak需要通过TimeScale转换成真实时间 hdlrhandler,表明本trak类型,指明是video/audio/还是hint minfmedia information container,数据在子box中 stblsample table box,存放时间/偏移的映射关系表,数据在子box中 stsdsample descriptions stts(decoding)time-to-sample,”时戳-sample序号”的映射表 stscsample-to-chunk,sample和chunk的映射表,这里的算法比较巧妙 stszsample size,每个sample的大小 stz2sample size,另一种sample size的存储算法,更节省空间 stsssync sample table,可随机访问的sample列表(关键帧列表) stcochunk offset,每个chunk的偏移,sample的偏移可根据其他box推算出来 co6464-bit chunk offset mdatmedia data container,具体的媒体数据 Mdat Box引用 http://xhelmboyx.tripod.com/formats/mp4-layout.txt]]></content>
      <categories>
        <category>音视频封装</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>format</tag>
      </tags>
  </entry>
</search>