<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[webrtc之Native APIs]]></title>
    <url>%2F2017%2F05%2F03%2Fwebrtc-nativeapis%2F</url>
    <content type="text"><![CDATA[Block diagram Calling sequencesSet up a call Receive a call Close down a call Threading modelWebRTC native APIs use two globally available threads: the signaling thread and the worker thread. Depending on how the PeerConnection factory is created, the application can either provide those 2 threads or just let them be created internally. The calls to the Stream APIs and the PeerConnection APIs will be proxied to the signaling thread which means that the application can call those APIs from whatever thread. All callbacks will be made on the signaling thread. The application should return the callback as quickly as possible to avoid blocking the signaling thread. Resource intensive processes should be posted to a different thread. The worker thread is used to handle more resource intensive processes such as data streaming. https://sites.google.com/site/webrtc/native-code/native-apis]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之api]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-api%2F</url>
    <content type="text"><![CDATA[api目录下封装了webrtc相关的供外部调用接口. 123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! peerconnection接口关于peerconnectioninterface.h说明: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// This file contains the PeerConnection interface as defined in// http://dev.w3.org/2011/webrtc/editor/webrtc.html#peer-to-peer-connections.//// The PeerConnectionFactory class provides factory methods to create// PeerConnection, MediaStream and MediaStreamTrack objects.//// The following steps are needed to setup a typical call using WebRTC://// 1. Create a PeerConnectionFactoryInterface. Check constructors for more// information about input parameters.//// 2. Create a PeerConnection object. Provide a configuration struct which// points to STUN and/or TURN servers used to generate ICE candidates, and// provide an object that implements the PeerConnectionObserver interface,// which is used to receive callbacks from the PeerConnection.//// 3. Create local MediaStreamTracks using the PeerConnectionFactory and add// them to PeerConnection by calling AddTrack (or legacy method, AddStream).//// 4. Create an offer, call SetLocalDescription with it, serialize it, and send// it to the remote peer//// 5. Once an ICE candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. The candidates must also be serialized and// sent to the remote peer.//// 6. Once an answer is received from the remote peer, call// SetRemoteDescription with the remote answer.//// 7. Once a remote candidate is received from the remote peer, provide it to// the PeerConnection by calling AddIceCandidate.//// The receiver of a call (assuming the application is &quot;call&quot;-based) can decide// to accept or reject the call; this decision will be taken by the application,// not the PeerConnection.//// If the application decides to accept the call, it should://// 1. Create PeerConnectionFactoryInterface if it doesn&apos;t exist.//// 2. Create a new PeerConnection.//// 3. Provide the remote offer to the new PeerConnection object by calling// SetRemoteDescription.//// 4. Generate an answer to the remote offer by calling CreateAnswer and send it// back to the remote peer.//// 5. Provide the local answer to the new PeerConnection by calling// SetLocalDescription with the answer.//// 6. Provide the remote ICE candidates by calling AddIceCandidate.//// 7. Once a candidate has been gathered, the PeerConnection will call the// observer function OnIceCandidate. Send these candidates to the remote peer.]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc源码走读之base]]></title>
    <url>%2F2017%2F05%2F02%2Fwebrtc-source-base%2F</url>
    <content type="text"><![CDATA[src/webrtc/base是webrtc基础平台库，包括线程、锁、socket,智能指针等. 智能指针refcount.h定义了rtc::RefCountInterface: 123456789101112131415#include &quot;webrtc/base/refcountedobject.h&quot;namespace rtc &#123;// Reference count interface.class RefCountInterface &#123; public: virtual int AddRef() const = 0; virtual int Release() const = 0; protected: virtual ~RefCountInterface() &#123;&#125;&#125;;&#125; // namespace rtc refcountedobject.h下定义了RefCountedObject: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;utility&gt;#include &quot;webrtc/base/atomicops.h&quot;namespace rtc &#123;template &lt;class T&gt;class RefCountedObject : public T &#123; public: RefCountedObject() &#123;&#125; template &lt;class P0&gt; explicit RefCountedObject(P0&amp;&amp; p0) : T(std::forward&lt;P0&gt;(p0)) &#123;&#125; template &lt;class P0, class P1, class... Args&gt; RefCountedObject(P0&amp;&amp; p0, P1&amp;&amp; p1, Args&amp;&amp;... args) : T(std::forward&lt;P0&gt;(p0), std::forward&lt;P1&gt;(p1), std::forward&lt;Args&gt;(args)...) &#123;&#125; virtual int AddRef() const &#123; return AtomicOps::Increment(&amp;ref_count_); &#125; virtual int Release() const &#123; int count = AtomicOps::Decrement(&amp;ref_count_); if (!count) &#123; delete this; &#125; return count; &#125; // Return whether the reference count is one. If the reference count is used // in the conventional way, a reference count of 1 implies that the current // thread owns the reference and no other thread shares it. This call // performs the test for a reference count of one, and performs the memory // barrier needed for the owning thread to act on the object, knowing that it // has exclusive access to the object. virtual bool HasOneRef() const &#123; return AtomicOps::AcquireLoad(&amp;ref_count_) == 1; &#125; protected: virtual ~RefCountedObject() &#123;&#125; mutable volatile int ref_count_ = 0;&#125;;&#125; // namespace rtc 线程Thread网络Socket]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之sdp协议]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-sdp%2F</url>
    <content type="text"><![CDATA[Session Description Protocol(会话描述协议)RFC定义SDP的协议有两个: RFC3264: An Offer/Answer Model with the session Description Protocol(SDP),用来概述一个请求/响应模型 RFC2327: SDP:Session Description Protocol,描述数据格式. 1.RFC23271.1.概述SDP 完全是一种会话描述格式 ― 它不属于传输协议 ― 它只使用不同的适当的传输协议，包括会话通知协议（SAP）、会话初始协议（SIP）、实时流协议（RTSP）、MIME 扩展协议的电子邮件以及超文本传输协议（HTTP）。SDP协议是也是基于文本的协议，这样就能保证协议的可扩展性比较强，这样就使其具有广泛的应用范围。SDP 不支持会话内容或媒体编码的协商，所以在流媒体中只用来描述媒体信息。媒体协商这一块要用RTSP来实现． SDP包括以下一些方面： 会话的名称和目的 会话存活时间 包含在会话中的媒体信息，包括： 媒体类型(video, audio, etc) 传输协议(RTP/UDP/IP, H.320, etc) 媒体格式(H.261 video, MPEG video, etc) 多播或远端（单播）地址和端口 为接收媒体而需的信息(addresses, ports, formats and so on) 使用的带宽信息 可信赖的接洽信息（Contact information） 1.2.SDP协议格式SDP描述由许多文本行组成，文本行的格式为&lt;类型&gt;=&lt;值&gt;，&lt;类型&gt;是一个字母，&lt;值&gt;是结构化的文本串，其格式依&lt;类型&gt;而定。 ＜type＞=[CRLF] 1.2.1.fields分类 Seeesion Description v(Protocol Version),mnd,The current protocol version.Always “0” using RFC4566 o(Origin),Mnd,The session originator’s name and session identifiers. s(Session Name), Mnd,The textural session Name i(Session Information), opt,Textural information about the session u(Uri),opt, A pointer to supplemental session Information e(Email Address), opt, Email contract information for the person responsible. P(phone Address),opt,Phone contract information for the person responsible c(Connection Data),C,The connection type and Address b(Bandwidth),opt,Proposed bandwidth limits. z(Time Zones), opt, Accounts for daylight saving information k(Encryption Keys),opt,A simple mechanism for exchanging keys, Rarely used. Timing Description t(Timing),mnd, start and end times. r(Repeat Times),opt, Specified the duration and intervals for any session repeats. Media Description m(Media Description),mnd, Media definitions including media type(e.g.”audio”),transport details and formats. i(Session Information),opt c(Connection Data),c b(Bandwidth):opt k( Encryption keys),opt a(Attributes),opt 1.2.2.典型格式1234567891011121314151617181920212223242526Session description v= (protocol version) o= (owner/creator and session identifier) s= (session name) i=* (session information) u=* (URI of description) e=* (email address) p=* (phone number) c=* (connection information - not required if included in all media) b=* (zero or more bandwidth information lines) One or more time descriptions (&quot;t=&quot; and &quot;r=&quot; lines, see below) z=* (time zone adjustments) k=* (encryption key) a=* (zero or more session attribute lines) Zero or more media descriptionsTime description t= (time the session is active) r=* (zero or more repeat times)Media description, if present m= (media name and transport address) i=* (media title) c=* (connection information - optional if included at session-level) b=* (zero or more bandwidth information lines) k=* (encryption key) a=* (zero or more media attribute lines) 带&quot;*&quot;号的是可选的,其余的是必须的。一般顺序也按照上面的顺序来排列。 1.2.3.各type对应值的结构化文本串 v= 其中：nettype是IN,代表internet,addrtype是IP4或IP6。unicast-address任务创建计算机的地址。 整个这个属性，是唯一表示一个任务。 e=123@126.com 或 p=+1 616 555-6011 对于一个任务只能两者之中的一个，表示会议控制者的联系方式。邮件地址可以是[email]j.doe@example.com[/email] (Jane Doe)形式，括号里面的是描述联系人的名称，或者Jane Doe &lt;[email]j.doe@example.com[/email]&gt;，前面的是联系人的名称。 c= 这个连接数据，可以是传话级别的连接数据，或者是单独一个媒体数据的连接数据。在是多播时，connection-address就该是一个多播组地址，当是单播时，connection-address就该是一个单播地址。对于addrtype是IP4的情况下，connection-address不仅包含IP地址，并且还要包含a time to live value(TTL 0-255)，如：c=IN IP4 224.2.36.42/128，IP6没有这个TTL值。还允许象这样的[/]/格式的connection-address。如：c=IN IP4 224.2.1.1/127/3等同于包含c=IN IP4 224.2.1.1/127, c=IN IP4 224.2.1.2/127, c=IN IP4 224.2.1.3/127三行内容。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 b=: bwtype可以是CT或AS，CT方式是设置整个会议的带宽，AS是设置单个会话的带宽。缺省带宽是千比特每秒。 t= ，这个可以有行，指定多个不规则时间段，如果是规则的时间段，则r=属性可以使用。start-time和stop- time都遵从NTP(Network Time Protocol),是以秒为单位，自从1900以来的时间。要转换为UNIX时间，减去2208988800。如果stop-time设置为0,则会话没有时间限制。如果start-time也设置为0，则会话被认为是永久的。 r= 重复次数在时间表示里面可以如下表示： d - days (86400 seconds) h - hours (3600 seconds) m - minutes (60 seconds) s - seconds (allowed for completeness) z=&lt;adjustment time&gt; &lt;offset&gt; &lt;adjustment time&gt; &lt;offset&gt; .... k=&lt;method&gt; k=&lt;method&gt;:&lt;encryption key&gt; a=&lt;attribute&gt; a=&lt;attribute&gt;:&lt;value&gt; m=&lt;media&gt; &lt;port&gt; &lt;proto&gt; &lt;fmt&gt; ... m=&lt;media&gt; &lt;port&gt;/&lt;number of ports&gt; &lt;proto&gt; &lt;fmt&gt; ... a=cat:分类，根据分类接收者隔离相应的会话 a=keywds:关键字，根据关键字隔离相应的会话 a=tool:创建任务描述的工具的名称及版本号 a=ptime:在一个包里面的以毫秒为单位的媒体长度 a=maxptime:以毫秒为单位，能够压缩进一个包的媒体量。 a=rtpmap: / [/] a=recvonly a=sendrecv a=sendonly a=inactive， a=orient:其可能的值，”portrait”, “landscape” and “seascape” 。 a=type:,建议值是，”broadcast”, “meeting”, “moderated”, “test” and “H332”。 a=charset: a=sdplang:指定会话或者是媒体级别使用的语言 a=framerate:设置最大视频帧速率 a=quality:值是0-10 a=fmtp: 在SIP协议的包含的内容是SDP时，应该把Content-Type设置成application/sdp。1.3.SDP协议例子1.3.1.helix流媒体服务器的RTSP协议中的SDP协议:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0 //SDP version// o field定义的源的一些信息。其格式为：o=&lt;username&gt; &lt;sess-id&gt; &lt;sess-version&gt; &lt;nettype&gt; &lt;addrtype&gt; &lt;unicast-address&gt;o=- 1271659412 1271659412 IN IP4 10.56.136.37 s=&lt;No title&gt;i=&lt;No author&gt; &lt;No copyright&gt; //session的信息c=IN IP4 0.0.0.0 //connect 的信息，分别描述了：网络协议，地址的类型，连接地址。c=IN IP4 0.0.0.0t=0 0 //时间信息，分别表示开始的时间和结束的时间，一般在流媒体的直播的时移中见的比较多。a=SdpplinVersion:1610641560 //描述性的信息a=StreamCount:integer;2 //用来描述媒体流的信息，表示有两个媒体流。integer表示信息的格式为整数。a=control:*a=DefaultLicenseValue:integer;0 //License信息a=FileType:string;&quot;MPEG4&quot; ////用来描述媒体流的信息说明当前协商的文件是mpeg4格式的文件a=LicenseKey:string;&quot;license.Summary.Datatypes.RealMPEG4.Enabled&quot;a=range:npt=0-72.080000 //用来表示媒体流的长度m=audio 0 RTP/AVP 96 //做为媒体描述信息的重要组成部分描述了媒体信息的详细内容：表示session的audio是通过RTP来格式传送的，其payload值为96传送的端口还没有定。b=as:24 //audio 的bitrateb=RR:1800b=RS:600a=control:streamid=1 //通过媒体流1来发送音频a=range:npt=0-72.080000 //说明媒体流的长度。a=length:npt=72.080000a=rtpmap:96 MPEG4-GENERIC/32000/2 //rtpmap的信息，表示音频为AAC的其sample为32000a=fmtp:96 profile-level-id=15;mode=AAC-hbr;sizelength=13;indexlength=3;indexdeltalength=3;config=1210 //config为AAC的详细格式信息a=mimetype:string;&quot;audio/MPEG4-GENERIC&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;48000a=HasOutOfOrderTS:integer;1a=MaxBitRate:integer;48000a=Preroll:integer;1000a=OpaqueData:buffer;&quot;A4CAgCIAAAAEgICAFEAVABgAAAC7gAAAu4AFgICAAhKIBoCAgAEC&quot;a=StreamName:string;&quot;Audio Track&quot;下面是video的信息基本和audio的信息相对称，这里就不再说了。m=video 0 RTP/AVP 97b=as:150b=RR:11250b=RS:3750a=control:streamid=2a=range:npt=0-72.080000a=length:npt=72.080000a=rtpmap:97 MP4V-ES/2500a=fmtp:97 profile-level-id=1;a=mimetype:string;&quot;video/MP4V-ES&quot;a=Helix-Adaptation-Support:1a=AvgBitRate:integer;300000a=HasOutOfOrderTS:integer;1a=Height:integer;240 //影片的长度a=MaxBitRate:integer;300000a=MaxPacketSize:integer;1400a=Preroll:integer;1000a=Width:integer;320 //影片的宽度a=OpaqueData:buffer;&quot;AzcAAB8ELyARAbd0AAST4AAEk+AFIAAAAbDzAAABtQ7gQMDPAAABAAAAASAAhED6KFAg8KIfBgEC&quot;a=StreamName:string;&quot;Video Track&quot; 1.3.2.Webrtc SDP示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152v=0o=- 0 0 IN IP4 127.0.0.1s=WX-RTC-SERVERt=0 0a=group:BUNDLE audio videoa=msid-semantic: WMS ryODEhTpFzm=audio 1 UDP/TLS/RTP/SAVPF 0 126c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-levela=mid:audioa=rtcp-muxa=rtpmap:0 PCMU/8000a=rtpmap:126 telephone-event/8000m=video 1 UDP/TLS/RTP/SAVPF 124 125 96c=IN IP4 0.0.0.0a=rtcp:1 IN IP4 0.0.0.0a=candidate:1 1 udp 2013266431 192.168.0.68 42739 typ host generation 0a=ice-ufrag:T+0ca=ice-pwd:FzV1T/5PiBI78s630cwSb6a=extmap:2 urn:ietf:params:rtp-hdrext:toffseta=extmap:3 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-timea=extmap:4 urn:3gpp:video-orientationa=extmap:6 http://www.webrtc.org/experiments/rtp-hdrext/playout-delaya=fingerprint:sha-256 2D:38:ED:09:73:36:F9:18:A6:CB:BC:ED:FB:C5:60:B3:F1:6C:FC:BD:97:57:AD:A6:38:11:9D:D4:8F:77:D6:C3a=setup:activea=recvonlya=mid:videoa=rtcp-muxa=rtpmap:124 H264/90000a=rtcp-fb:124 ccm fira=rtcp-fb:124 nacka=rtcp-fb:124 nack plia=rtcp-fb:124 goog-remba=fmtp:124 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:125 H264/90000a=rtcp-fb:125 ccm fira=rtcp-fb:125 nacka=rtcp-fb:125 nack plia=rtcp-fb:125 goog-remba=fmtp:125 x-google-max-bitrate=800;x-google-min-bitrate=150;x-google-start-bitrate=300a=rtpmap:96 VP8/90000a=rtcp-fb:96 ccm fira=rtcp-fb:96 nacka=rtcp-fb:96 nack plia=rtcp-fb:96 goog-remb 2.RFC3264An Offer/Answer Model with the Session Description Protocol (SDP) 2.1情态动词定义在RFC2119: “MUST”，必须、一定要； “MUST NOT”，禁止； “REQUIRED”，需要； “SHALL”、”SHOULD”，应该； “SHALL NOT”、”SHOULD NOT”，不应该； “RECOMMENDED”，推荐； “MAY”，可以2.2术语 媒体流（Media Stream），或称为媒体类型（Media Type），即我们通常所说的音频流、视频流等，所有通信实体要进行媒体交互之前都必须进行媒体注的协商 媒体格式（Media Format），每种媒体流都有不同的编码格式，像音频有G711、G712编码，视频有H261、H264等，像现在所谓的高清视频采用是720P、1070P等。 单一会话（Unitcast Session） 多会话（Multicast Sessions） 单一媒体流（Unitcast Streams） 多媒体流（Multicast Streams）2.3offer/answerrfc3264协议[1]主要概述一个请求/响应模型（offer/answer，以下叙述采用英文），包括请求/响应的实体和不同阶段的操作行为，如初始协商过程和重协商过程，并简单介绍消息中各种参数的含义。具体各个参数的详细说明见rfc2327协议[2]2.3.1.实体,消息Offer/Answer模型包括两个实体，一个是请求主体Offerer，另外一个是响应实体Answerer，两个实体只是在逻辑上进行区分，在一定条件可以转换。例如，手机A发起媒体协商请求，那么A就是Offerer，反之如果A为接收请求则为Offerer。 Offerer发给Answerer的请求消息称为请求offer，内容包括媒体流类型、各个媒体流使用的编码集，以及将要用于接收媒体流的IP和端口。 Answerer收到offer之后，回复给Offerer的消息称为响应，内容包括要使用的媒体编码，是否接收该媒体流以及告诉Offerer其用于接收媒体流的IP和端口。2.3.2.SDP各个参数简单介绍下面示例摘自3264协议[1] v=0 o=carol 28908764872 28908764872 IN IP4 100.3.6.6 //会话ID号和版本 s=- //用于传递会话主题 t=0 0 //会话时间，一般由其它信令消息控制，因此填0 c=IN IP4 192.0.2.4 //描述本端将用于传输媒体流的IP m=audio 0 RTP/AVP 0 1 3 //媒体类型 端口号 本端媒体使用的编码标识（Payload）集 a=rtpmap:0 PCMU/8000 //rtpmap映射表，各种编码详细描述参数，包括使用带宽（bandwidth） a=rtpmap:1 1016/8000 a=rtpmap:3 GSM/8000 a=sendonly //说明本端媒体流的方向，取值包括sendonly/recvonly/sendrecv/inactive a=ptime:20 //说明媒体流打包时长 m=video 0 RTP/AVP 31 34 a=rtpmap:31 H261/90000 a=rtpmap:34 H263/900002.3.3.实体行为、操作过程2.3.3.1.初始协商的Offer请求实体A &lt;-&gt; 实体B，实体首先发起Offer请求，内容如2节所示，对于作何一个媒体流/媒体通道，这时实体A必须： 如果媒体流方向标为recvonly/sendrecv，即a=recvonly或a=sendrecv，则A必须（MUST）准备好在这个IP和端口上接收实体B发来的媒体流； 如果媒体流方向标为sendonly/inactive，即a=recvonly或a=sendrecv，则A不需要进行准备。2.3.3.1.Answer响应实体B收到A的请求offer后，根据自身支持的媒体类型和编码策略，回复响应。 如果实体B回复的响应中的媒体流数量和顺序必须（MUST）和请求offer一致，以便实体A进行甄别和决策。即m行的数量和顺序必须一致，B不能（MUST NOT）擅自增加或删除媒体流。如果B不支持某个媒体流，可以在对应的端口置0，但不能不带这个m行描述。 对于某种媒体，实体B必须（MUST）从请求offer中选出A支持且自己也支持的该媒体的编码标识集，并且可以（MAY）附带自己支持的其它类型编码。 对于响应消息中各个媒体的方向： 如果请求某媒体流的方向为sendonly，那么响应中对应媒体的方向必须为recvonly； 如果请求某媒体流的方向为recvonly，那么响应中对应媒体的方向必须为sendonly； 如果请求某媒体流的方向为sendrecv，那么响应中对应媒体的方向可以为sendrecv/sendonly/recvonly/inactive中的一种； 如果请求某媒体流的方向为inactive，那么响应中对应媒体的方向必须为inactive； 响应answer里提供IP和端口，指示Offerer本端期望用于接收媒体流的IP和端口，一旦响应发出之后，Offerer必须（MUST）准备好在这个IP和端口上接收实体A发来的媒体流。 如果请求offer中带了ptime（媒体流打包间隔）的a行或带宽的a行，则响应answer也应该（SHOULD）相应的携带。 实体B Offerer应该（SHOULD）使用实体A比较期望的编码生成媒体流发送。一般来说对于m行，如m=video 0 RTP/AVP 31 34，排充越靠前的编码表示该实体越希望以这个编码作为载体，这里示例31(H261)，34（H263）中H261为A更期望使用的编码类型。同理，当实体A收到响应answer后也是这样理解的。2.3.3.2.实体收到响应后的处理当实体A收到B回复的响应后，可以（MAY）开始发送媒体流，如果媒体流方向为sendonly/sendrecv， 必须（MUST）使用answer列举的媒体类型/编码生成媒体发送； 应该（SHOULD）使用answer中的ptime和bandwidth来打包发送媒体流； 可以（MAY）立即停止监听端口，该端口为offer支持answer不支持的媒体所使用的端口。 2.3.4.修改媒体流（会话）修改媒体流的offer-answer操作必须基于之前协商的媒体形式（音频、视频等），不能（MUST NOT）对已有媒体流进行删减。 2.3.4.1.删除媒体流如果实体认定新的会话不支持之前媒商的某个媒体，新的offer只须对这种媒体所在m行的端口置0，但不能不描述这种媒体，即不带对应m行。当answerer收到响应之后，处理同初始协商一样。 2.3.4.2.增加媒体流如果实体打算新增媒体流，在offer里只须加上描述即可或者占用之前端口被置0的媒体流，即用新的媒体描述m行替换旧的。当answerer收到offer请求后，发现有新增媒体描述，或者过于端口被置0的媒体行被新的媒体描述替换，即知道当前为新增媒体流，处理同初始协商。 2.3.4.3.修改媒体流修改媒体注主要是针对初始协商结果，如果有变更即进入修改流程处理，可能的变更包括IP地址、端口，媒体格式（编码），媒体类型（音、视频），媒体属性（ptime，bandwidth，媒体流方向变更等）。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
        <tag>协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之入门]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-introduce%2F</url>
    <content type="text"><![CDATA[webrtc developersThe WebRTC APIsThree main tasks Acquiring audio and video Communicating audio and video Communicating arbitrary data Three main JavaScript APIs MediaStream(aka getUserMedia) RTCPeerConnection RTCDataChannel MediaStream(Acquiring audio and video) MediaStream Pepresent a stream of audio and/or video Can contain multiple ‘tracks’ Obtain a MediaStream with navigator.getUserMedia() Constraints Controls the contents of the MediaStream Media type, resolution, frame rateRTCPeerConnection(Audio and video communication between peers)RTCPeerConnection does a lot Signal processing Codec handling Peer to peer communication Security Bandwidth managementWebRTC architecture RTCDataChannel(Bidirectional communication of arbitrary data between peers) RTCDataChannel Same API as WebSockets Ultra-low latency Unreliable or reliable Secure Servers and Protocols(Peer to peer — but we need servers :) Abstract Signaling Need to exchange ‘session description’ objects: What formats I support, what I want to send Network information for peer-to-peer setup Can use any messaging mechanism Can use any messaging protocol STUN and TRUN(P2P in the age of firewalls and NATs) An ideal world The real world STUN Tell me what my public IP address is Simple server, cheap to run Data flows peer-to-peer TURN Provide a cloud fallback if peer-to-peer communication fails Data is sent through server, uses server bandwidth Ensures the call works in almost all environments ICE ICE: a framework for connecting peers Tries to find the best path for each call Vast majority of calls can use STUN (webrtcstats.com): Deploying STUN/TURN stun.l.google.com:19302 WebRTC stunserver, turnserver rfc5766-turn-server restund SecuritySecurity throughout WebRTC Mandatory encryption for media and data Secure UI, explicit opt-in Sandboxed, no plugins WebRTC Security Architecture ArchitecturesPeer to Peer : one-to-one callclientA &lt;——–&gt; clientB Mesh: small N-way call123456clientA &lt;-------------&gt; clientB /|\ \ / /|\ | \ / | | / \ | \|/ / \|/clientC &lt;--------------&gt; clientD Star: medium N-way call123clientA &lt;---------&gt; clientBclientA &lt;---------&gt; clientCclientA &lt;---------&gt; clientD MCU: large N-way call1234567MCU &lt;--------------&gt;clientAMCU &lt;--------------&gt;clientBMCU &lt;--------------&gt;clientCMCU &lt;--------------&gt;clientDMCU &lt;--------------&gt;clientEMCU &lt;--------------&gt;clientFMCU &lt;--------------&gt;clientG]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之源码管理工具gclient]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-gclient%2F</url>
    <content type="text"><![CDATA[google的chromium项目是用gclient来管理源码的checkout, update等。 gclient是google专门为这种多源项目编写的脚本，它可以将多个源码管理系统中的代码放在一起管理。甚至包括将Git和svn代码放在一起。 webrtc也是使用gclient管理代码. gclient的sync，update等命令密切相关的两类文件.gclient和DEPS。 .gclient文件是gclient的控制文件，该文件放在工作目录的最上层(webrtc环境下与src统计目录)。”.gclient”文件是一个Python的脚本，定义了一组”solutions”，格式类似如下 1234567891011solutions = [ &#123; &quot;name&quot; : &quot;src&quot;, &quot;url&quot; : &quot;svn://svnserver/component/trunk/src&quot;, &quot;custom_deps&quot; : &#123; # To use the trunk of a component instead of what&apos;s in DEPS: #&quot;component&quot;: &quot;https://svnserver/component/trunk/&quot;, # To exclude a component from your working copy: #&quot;data/really_large_component&quot;: None, &#125; &#125;, ] name:checkout出源码的名字 url:源码所在的目录,gclient希望checkout出的源码中包括一个DEPS的文件,这个文件包含了必须checkout到工作目录的源码信息; deps_file:这是一个文件名(不包括路径),指在工程目录中包含依赖列表的文件,该项可选,默认值为”DEPS” custom_deps:这是一个可选的字典对象,会覆盖工程的”DEPS”文件定义的条目.一般它用作本地目录中,那些不用checkout的代码,或者让本地目录从不同位置checkout一个新的代码出来,或者checkout不同的分支,版本等.也可以用于增加在DEPS中不存在的新的项目.如: 12345678&quot;custom_deps&quot;: &#123; &quot;src/content/test/data/layout_tests/LayoutTests&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome_frame/tools/test/reference_build/chrome_win&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_linux&quot;: None, &quot;src/chrome/tools/test/reference_build/chrome_mac&quot;: None, &quot;src/third_party/hunspell_dictionaries&quot;: None, &#125;, target_os:这个可选的条目可以指出特殊的平台,根据平台类checkout出不同代码,如: 1target_os = [&apos;android&apos;] 如果target_os_only值为True的话,那么,仅仅checkout出对应的代码,如: 12target_os = [ &quot;ios&quot; ] target_os_only = True 在每个checkout出的工程中，gclient期望发现一个DEPS文件（由deps_file来给定），它定义了工程不同部分都是如何checkout出来。 “DEPS”也是一个python脚本，最简单的，如下： 12345deps = &#123; &quot;src/outside&quot; : &quot;http://outside-server/trunk@1234&quot;, &quot;src/component&quot; : &quot;svn://svnserver/component/trunk/src@77829&quot;, &quot;src/relative&quot; : &quot;/trunk/src@77829&quot;, &#125; deps的每个条目都包含一个key-value对，key是被checkout的本地目录，而value就是对应的远程URL。如果路径是以’/‘开头的，那么它是一个相对URL，相对与.gclient中URL地址。 URL通常包含一个版本号，以便锁定源码在特定版本上。当然，这是可选的。如果没有，那么它将获取指定分支上最新的版本。 DEPS还可以包含其他类型的数据，如vars, 12345678910111213vars = &#123; &apos;pymox&apos;: &apos;http://pymox.googlecode.com/svn&apos;, &apos;sfntly&apos;: &apos;http://sfntly.googlecode.com/svn&apos;, &apos;eyes-free&apos;: &apos;http://eyes-free.googlecode.com/svn&apos;, &apos;rlz&apos;: &apos;http://rlz.googlecode.com/svn&apos;, &apos;smhasher&apos;: &apos;http://smhasher.googlecode.com/svn&apos;,...&#125; vars定义了一组变量，在后面，可以通过Var(xxx)来访问。Var(xxx)返回一个字符串，故此，也可以进行操作，如 1234&apos;src/third_party/cros_dbus_cplusplus/source&apos;:Var(&quot;git.chromium.org&quot;) + &apos;/chromiumos/third_party/dbus-cplusplus.git@5e8f6d9db5c2abfb91d91f751184f25bb5cd0900&apos;,&apos;src/third_party/WebKit&apos;:Var(&quot;webkit_trunk&quot;)[:-6] + &apos;/branches/chromium/1548@153044&apos;, 第二个自立，Var(“webkit_trunk”)[:-6]是一个python表达式，表示取得”webkit_trunk”表示的字符串的最后6个 Hooks：DEPS包含可选的内容 hooks，也有重要的作用，它表示在sync, update或者recert后，执行一个hook操作。 如果使用 –nohooks选项（hook默认执行），那么在gclient sync或者其他操作后，不会执行hook。你可以通过gclient runhooks来单独执行； 如果有 gclient sync –force，那么，无论sync是否成功，都会执行hook。 hook在DEPS中的写法，一般是： 1234567hooks = [ &#123; &quot;pattern&quot;: &quot;\\.(gif|jpe?g|pr0n|png)$&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;image_indexer.py&quot;, &quot;--all&quot;]&#125;, &#123; &quot;pattern&quot;: &quot;.&quot;, &quot;name&quot;: &quot;gyp&quot;, &quot;action&quot;: [&quot;python&quot;, &quot;src/build/gyp_chromium&quot;]&#125;,] hooks包含一组hook，每个hook有几个重要项: pattern 是一个正则表达式，用来匹配工程目录下的文件，一旦匹配成功，action项就会执行 action 描述一个根据特定参数运行的命令行。这个命令在每次gclient时，无论多少文件匹配，至多运行一次。这个命令和.gclient在同一目录下运行。如果第一个参数是”python”，那么，当前的python解释器将被使用。如果包含字符串 “$matching_files”，它将该字符串扩展为匹配出的文件列表。 name 可选，标记出hook所属的组，可以被用来覆盖和重新组织。 deps_os： DEPS中定义不同平台依赖关系的项目，如 1234567891011121314151617181920212223deps_os = &#123; &quot;win&quot;: &#123; &quot;src/chrome/tools/test/reference_build/chrome_win&quot;: &quot;/trunk/deps/reference_builds/chrome_win@197743&quot;, &quot;src/third_party/cygwin&quot;: &quot;/trunk/deps/third_party/cygwin@133786&quot;,..... &#125;, &quot;ios&quot;: &#123; &quot;src/third_party/GTM&quot;: (Var(&quot;googlecode_url&quot;) % &quot;google-toolbox-for-mac&quot;) + &quot;/trunk@&quot; + Var(&quot;gtm_revision&quot;), &quot;src/third_party/nss&quot;: &quot;/trunk/deps/third_party/nss@&quot; + Var(&quot;nss_revision&quot;),.... &#125;,...&#125; deps_os指定不同平台的依赖，它可以包含多种平台，和.gclient中的target_os对应。这种对应关系如下： 12345678910111213DEPS_OS_CHOICES = &#123; &quot;win32&quot;: &quot;win&quot;, &quot;win&quot;: &quot;win&quot;, &quot;cygwin&quot;: &quot;win&quot;, &quot;darwin&quot;: &quot;mac&quot;, &quot;mac&quot;: &quot;mac&quot;, &quot;unix&quot;: &quot;unix&quot;, &quot;linux&quot;: &quot;unix&quot;, &quot;linux2&quot;: &quot;unix&quot;, &quot;linux3&quot;: &quot;unix&quot;, &quot;android&quot;: &quot;android&quot;,&#125; 下载webrtc android代码的.gclient文件(与src同级目录): 12345678910solutions = [ &#123; &quot;url&quot;: &quot;https://chromium.googlesource.com/external/webrtc.git&quot;, &quot;managed&quot;: False, &quot;name&quot;: &quot;src&quot;, &quot;deps_file&quot;: &quot;DEPS&quot;, &quot;custom_deps&quot;: &#123;&#125;, &#125;,]target_os = [&quot;android&quot;, &quot;unix&quot;] src同级目录下.gclient_entries定义了各模块及对应地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344entries = &#123; &apos;src&apos;: &apos;https://chromium.googlesource.com/external/webrtc.git&apos;, &apos;src/base&apos;: &apos;https://chromium.googlesource.com/chromium/src/base@413df39df4640665d7ee1e8c198be1e91cedb4d9&apos;, &apos;src/build&apos;: &apos;https://chromium.googlesource.com/chromium/src/build@98f2769027214c848094d0d58156474eada3bc1b&apos;, &apos;src/buildtools&apos;: &apos;https://chromium.googlesource.com/chromium/buildtools.git@98f00fa10dbad2cdbb2e297a66c3d6d5bc3994f3&apos;, &apos;src/testing&apos;: &apos;https://chromium.googlesource.com/chromium/src/testing@3eab1a4b0951ac1fcb2be8bf9cb24143b509ea52&apos;, &apos;src/testing/gmock&apos;: &apos;https://chromium.googlesource.com/external/googlemock.git@0421b6f358139f02e102c9c332ce19a33faf75be&apos;, &apos;src/testing/gtest&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/googletest.git@6f8a66431cb592dad629028a50b3dd418a408c87&apos;, &apos;src/third_party&apos;: &apos;https://chromium.googlesource.com/chromium/src/third_party@939f3a2eae486dd7cf3b31eae38642d2bc243737&apos;, &apos;src/third_party/android_tools&apos;: &apos;https://chromium.googlesource.com/android_tools.git@b65c4776dac2cf1b80e969b3b2d4e081b9c84f29&apos;, &apos;src/third_party/boringssl/src&apos;: &apos;https://boringssl.googlesource.com/boringssl.git@777fdd6443d5f01420b67137118febdf56a1c8e4&apos;, &apos;src/third_party/catapult&apos;: &apos;https://chromium.googlesource.com/external/github.com/catapult-project/catapult.git@6939b1db033bf35f4adf1ee55824b6edb3e324d6&apos;, &apos;src/third_party/ced/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/compact_enc_det.git@e21eb6aed10b9f6e2727f136c52420033214d458&apos;, &apos;src/third_party/colorama/src&apos;: &apos;https://chromium.googlesource.com/external/colorama.git@799604a1041e9b3bc5d2789ecbd7e8db2e18e6b8&apos;, &apos;src/third_party/ffmpeg&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ffmpeg.git@28a5cdde5c32bcf66715343c10f74e85713f7aaf&apos;, &apos;src/third_party/gflags&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/gflags@892576179b45861b53e04a112996a738309cf364&apos;, &apos;src/third_party/gflags/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/gflags/gflags@03bebcb065c83beff83d50ae025a55a4bf94dfca&apos;, &apos;src/third_party/gtest-parallel&apos;: &apos;https://chromium.googlesource.com/external/github.com/google/gtest-parallel@7eb02a6415979ea59e765c34fe9da6c792f53e26&apos;, &apos;src/third_party/icu&apos;: &apos;https://chromium.googlesource.com/chromium/deps/icu.git@b34251f8b762f8e2112a89c587855ca4297fed96&apos;, &apos;src/third_party/jsoncpp/source&apos;: &apos;https://chromium.googlesource.com/external/github.com/open-source-parsers/jsoncpp.git@f572e8e42e22cfcf5ab0aea26574f408943edfa4&apos;, &apos;src/third_party/jsr-305/src&apos;: &apos;https://chromium.googlesource.com/external/jsr-305.git@642c508235471f7220af6d5df2d3210e3bfc0919&apos;, &apos;src/third_party/junit/src&apos;: &apos;https://chromium.googlesource.com/external/junit.git@64155f8a9babcfcf4263cf4d08253a1556e75481&apos;, &apos;src/third_party/libFuzzer/src&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer.git@16f5f743c188c836d32cdaf349d5d3effb8a3518&apos;, &apos;src/third_party/libjpeg_turbo&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libjpeg_turbo.git@7260e4d8b8e1e40b17f03fafdf1cd83296900f76&apos;, &apos;src/third_party/libsrtp&apos;: &apos;https://chromium.googlesource.com/chromium/deps/libsrtp.git@ccf84786f8ef803cb9c75e919e5a3976b9f5a672&apos;, &apos;src/third_party/libvpx/source/libvpx&apos;: &apos;https://chromium.googlesource.com/webm/libvpx.git@f22b828d685adee4c7a561990302e2d21b5e0047&apos;, &apos;src/third_party/libyuv&apos;: &apos;https://chromium.googlesource.com/libyuv/libyuv.git@fc02cc3806a394a6b887979ba74aa49955f3199b&apos;, &apos;src/third_party/lss&apos;: &apos;https://chromium.googlesource.com/linux-syscall-support.git@63f24c8221a229f677d26ebe8f3d1528a9d787ac&apos;, &apos;src/third_party/mockito/src&apos;: &apos;https://chromium.googlesource.com/external/mockito/mockito.git@de83ad4598ad4cf5ea53c69a8a8053780b04b850&apos;, &apos;src/third_party/openh264/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/cisco/openh264@0fd88df93c5dcaf858c57eb7892bd27763f0f0ac&apos;, &apos;src/third_party/openmax_dl&apos;: &apos;https://chromium.googlesource.com/external/webrtc/deps/third_party/openmax.git@7acede9c039ea5d14cf326f44aad1245b9e674a7&apos;, &apos;src/third_party/requests/src&apos;: &apos;https://chromium.googlesource.com/external/github.com/kennethreitz/requests.git@f172b30356d821d180fa4ecfa3e71c7274a32de4&apos;, &apos;src/third_party/robolectric/robolectric&apos;: &apos;https://chromium.googlesource.com/external/robolectric.git@2a0b6ba221c14f3371813a676ce06143353e448d&apos;, &apos;src/third_party/ub-uiautomator/lib&apos;: &apos;https://chromium.googlesource.com/chromium/third_party/ub-uiautomator.git@00270549ce3161ae72ceb24712618ea28b4f9434&apos;, &apos;src/third_party/usrsctp/usrsctplib&apos;: &apos;https://chromium.googlesource.com/external/github.com/sctplab/usrsctp@8679f2b0bf063ac894dc473debefd61dbbebf622&apos;, &apos;src/third_party/yasm/source/patched-yasm&apos;: &apos;https://chromium.googlesource.com/chromium/deps/yasm/patched-yasm.git@7da28c6c7c6a1387217352ce02b31754deb54d2a&apos;, &apos;src/tools&apos;: &apos;https://chromium.googlesource.com/chromium/src/tools@4718dd2b6d53fb68819b3fd23676b40935f4f31e&apos;, &apos;src/tools/gyp&apos;: &apos;https://chromium.googlesource.com/external/gyp.git@eb296f67da078ec01f5e3a9ea9cdc6d26d680161&apos;, &apos;src/tools/swarming_client&apos;: &apos;https://chromium.googlesource.com/external/swarming.client.git@11e31afa5d330756ff87aa12064bb5d032896cb5&apos;, &apos;src/buildtools/clang_format/script&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/cfe/tools/clang-format.git@c09c8deeac31f05bd801995c475e7c8070f9ecda&apos;, &apos;src/buildtools/third_party/libc++/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxx.git@b1ece9c037d879843b0b0f5a2802e1e9d443b75a&apos;, &apos;src/buildtools/third_party/libc++abi/trunk&apos;: &apos;https://chromium.googlesource.com/chromium/llvm-project/libcxxabi.git@0edb61e2e581758fc4cd4cd09fc588b3fc91a653&apos;, &apos;src/third_party/android_tools/ndk&apos;: &apos;https://chromium.googlesource.com/android_ndk.git@26d93ec07f3ce2ec2cdfeae1b21ee6f12ff868d8&apos;,&#125;]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webrtc之信令交互流程]]></title>
    <url>%2F2017%2F04%2F27%2Fwebrtc-signalling%2F</url>
    <content type="text"><![CDATA[无论是使用前端JS的WebRTC API接口，还是在WebRTC源码上构建自己的对聊框架，都需要遵循以下执行流程： 上述序列中，WebRTC并不提供Stun服务器和Signal服务器，服务器端需要自己实现。Stun服务器可以用google提供的实现stun协议的测试服务器（stun:stun.l.google.com:19302），Signal服务器则完全需要自己实现了，它需要在ClientA和ClientB之间传送彼此的SDP信息和candidate信息，ClientA和ClientB通过这些信息建立P2P连接来传送音视频数据。 stun/turn、relay服务器的实现在WebRTC源码中都有示例。 上述序列中，标注的场景是ClientA向ClientB发起对聊请求，调用描述如下： ClientA首先创建PeerConnection对象，然后打开本地音视频设备，将音视频数据封装成MediaStream添加到PeerConnection中。 ClientA调用PeerConnection的CreateOffer方法创建一个用于offer的SDP对象，SDP对象中保存当前音视频的相关参数。ClientA通过PeerConnection的SetLocalDescription方法将该SDP对象保存起来，并通过Signal服务器发送给ClientB。 ClientB接收到ClientA发送过的offer SDP对象，通过PeerConnection的SetRemoteDescription方法将其保存起来，并调用PeerConnection的CreateAnswer方法创建一个应答的SDP对象，通过PeerConnection的SetLocalDescription的方法保存该应答SDP对象并将它通过Signal服务器发送给ClientA。 ClientA接收到ClientB发送过来的应答SDP对象，将其通过PeerConnection的SetRemoteDescription方法保存起来。 在SDP信息的offer/answer流程中，ClientA和ClientB已经根据SDP信息创建好相应的音频Channel和视频Channel并开启Candidate数据的收集，Candidate数据可以简单地理解成Client端的IP地址信息（本地IP地址、公网IP地址、Relay服务端分配的地址）。 当ClientA收集到Candidate信息后，PeerConnection会通过OnIceCandidate接口给ClientA发送通知，ClientA将收到的Candidate信息通过Signal服务器发送给ClientB，ClientB通过PeerConnection的AddIceCandidate方法保存起来。同样的操作ClientB对ClientA再来一次。 这样ClientA和ClientB就已经建立了音视频传输的P2P通道，ClientB接收到ClientA传送过来的音视频流，会通过PeerConnection的OnAddStream回调接口返回一个标识ClientA端音视频流的MediaStream对象，在ClientB端渲染出来即可。同样操作也适应ClientB到ClientA的音视频流的传输。]]></content>
      <categories>
        <category>webrtc</category>
      </categories>
      <tags>
        <tag>webrtc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git服务搭建]]></title>
    <url>%2F2017%2F04%2F25%2Fserver-git%2F</url>
    <content type="text"><![CDATA[纯git server软件安装环境:ubuntu16.0.4 安装Git-Core:sudo apt-get install python-setuptools 安装openssh-server和openssh-client:sudo apt-get install openssh-server openssh-client 安装python tool:sudo apt-get install python-setuptools 安装gitosis:12345git clone https://github.com/res0nat0r/gitosis.gitcd gitosis/sudo python setup.py install 添加管理账号12345678sudo adduser \ --system \ --shell /bin/sh \ --gecos &apos;git version control&apos; \ --group \ --disabled-password \ --home /home/git \ git 如果已有git账户,可以替换成gitmanager 创建链接映射由于gitosis默认状态下会将仓库放在用户的repositories目录下，例如gitmanager用户的仓库地址默认在 /home/gitmanager/repositories/目录下，这里我们需要创建一个链接映射。让他指向我们前面创建的专门用于存放项目的仓库目录/home/gitrepository。 1sudo ln -s /home/gitrepository /home/gitmanager/repositories 初始化管理用户 拷贝管理用户公钥到/tmp/下,如: 1scp ~/.ssh/id_rsa.pub gitmanager@192.168.0.68:/tmp/ 使用拷贝来的公钥初始化gitosis: 12sudo -H -u gitmanager gitosis-init &lt; /tmp/id_ras.pubsudo chmod 755 /home/gitmanager/repositories/gitosis-admin.git/hooks/post-update 配置账号 验证ssh1234ssh gitmanager@192.168.0.68TY allocation request failed on channel 0ERROR:gitosis.serve.main:Need SSH_ORIGINAL_COMMAND in environment. Connection to gitserver closed. 说明 Gitosis 认出了该用户的身份，但由于没有运行任何 Git 命令，所以它切断了连接。 克隆gitosis管理仓库:1git clone gitmanager@192.168.0.68:gitosis-admin.git 这会得到一个名为 gitosis-admin 的工作目录，主要由两部分组成： 12./gitosis.conf./keydir gitosis.conf 文件是用来设置用户、仓库和权限的控制文件。keydir 目录则是保存所有具有访问权限用户公钥的地方— 每人一个。在 keydir 里的文件名（比如上面的 qingkouwei.pub） 会自动从使用 gitosis-init 脚本导入的公钥尾部的描述中获取该名字。 看一下 gitosis.conf 文件的内容，它应该只包含与刚刚克隆的 gitosis-admin 相关的信息： 12345[gitosis][group gitosis-admin]members = qingkouweiwritable = gitosis-admin 要创建项目demo,在里面加入: 123[group demo]members = qingkouweiwritable = demo 要为demo项目添加用户user1: 123[group demo]members = qingkouwei user1writable = demo 并将用户user1的公钥计入到keydir,并且公钥名.pub和members里面的名字对应. 要添加对demo项目只读的用户: 1234567[group demo]members = qingkouwei user1writable = demo[group demo]members = user2readonly = demo 修改完配置文件和keydir,使用git push到gitosis-admin服务器.即可直接git add remote add suervename gitmanager@192.168.0.68:demo.git,然后直接将本地目录推送到demo仓库,不需要再服务器手动创建demo仓库,gitosis会帮忙自动创建. 常见问题 ERROR:gitosis.serve.main:Repository read access denied 原因: gitosis.conf中的members与keydir中的用户名不一致，如gitosis中的members = foo@bar，但keydir中的公密名却叫foo.pub 解决方法: 使keydir的名称与gitosis中members所指的名称一致。 改为members = foo 或 公密名称改为foo@bar.pub clone时报does not appear to be a git repository 原因: clone时不能用绝对路径，直接写gitosis-admin.git即可. 参考:https://git-scm.com/book/zh/v1/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84-Git-Gitosis gitlab服务搭建]]></content>
      <categories>
        <category>server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware中Bridged,NAT,host-only三种网络连接模式的原理和区别]]></title>
    <url>%2F2017%2F04%2F22%2Fvmware-network-mode%2F</url>
    <content type="text"><![CDATA[不同虚拟交换机应用在不同的联网模式Bridged、NAT、host-only、custom四种模式，下面分别介绍其具体分配： VMnet0：这是VMware用于虚拟桥接网络下的虚拟交换机； VMnet1：这是VMware用于虚拟Host-Only网络下的虚拟交换机； VMnet8：这是VMware用于虚拟NAT网络下的虚拟交换机； VMnet2~VMnet7及VMnet9：是VMware用于虚拟自定义custom网络下的虚拟交换机； VMware Network Adapter VMnet1：这是宿主机用于与Host-Only虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet8：这是宿主机用于与NAT虚拟网络进行通信的宿主机使用的虚拟网卡； VMware Network Adapter VMnet1与VMware Network Adapter VMnet8可以在宿主机网络连接中看到. 1.Bridged桥接模式VMware在桥接模式下，虚拟机使用VMware为该虚拟机分配的虚拟网卡，宿主机使用自身的物理网卡（有线或无线都行），并且默认使用虚拟交换机VMnet0来连接虚拟机的虚拟网卡和宿主机的物理网卡。在此模式下没有局域网动态地址分配DHCP服务器，也没有网络地址转换ＮＡＴ服务器，虚拟交换机没有连接DHCP服务器和ＮＡＴ服务器。宿主机的网口（插网线的那个口）与宿主机物理网卡相连，同时也就和虚拟机的虚拟网卡相连，也就是和虚拟交换机相连，所以虚拟机相当于在宿主机所在局域网内的一个单独的主机，他的行为和宿主机是同等地位的，没有依存关系。所有桥接下的网卡与网卡都是交换模式的，相互可以访问而不干扰。在桥接模式下，虚拟机ip地址需要与主机在同一个网段，如果需要联网，则网关与DNS需要与主机网卡一致原理图如下： 配置虚拟机网卡,编辑/etc/sysconfig/network-scripts/ifcfg-eth0: 1234567891011DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=noneIPADDR=192.168.31.128 #设置虚拟机ip地址,与主机ip地址在同一网段NETMASK=255.255.255.0 #设置子网掩码GATEWAY=192.168.31.1#设置虚拟网关,与主机相同DNS1=192.168.31.1 #设置虚拟机DNS,与主机相同 执行/etc/init.d/network restart重启虚拟机网卡,ping内网与外网测试. 2.NAT网络地址转换模式： 注意：红色的方框是nat服务器，nat服务器有两个网卡一个是虚拟内网网卡，一个是宿主机的物理网卡。禁用VmNet8，虚拟机仍然可以上网，ping通主机，但是主机ping不通虚拟机的网卡。在NAT模式中，主机网卡直接与虚拟NAT设备相连，然后虚拟NAT设备与虚拟DHCP服务器一起连接在虚拟交换机VMnet8上，这样就实现了虚拟机联网。那么我们会觉得很奇怪，为什么需要虚拟网卡VMware Network Adapter VMnet8呢？原来我们的VMware Network Adapter VMnet8虚拟网卡主要是为了实现主机与虚拟机之间的通信。弥补了NAT协议中外网不能访问局域网的缺点。 具体配置: 123456789101112DEVICE=eth0HWADDR=00:0C:29:DA:E9:99TYPE=EthernetUUID=0711466f-ae1f-aa83-825cb3dfb5f7ONBOOT=yesMM_CONTROLLED=yesBOOTPROTO=dhcp #动态获取ip地址,如果此处设置为静态,则下面手动配置ip需要在DHCP地址范围内#NAT模式也可以设置静态ip,但需要在DHCP地址范围内IPADDR=192.168.31.128NETMASK=255.255.255.0GATEWAY=192.168.31.1DNS1=192.168.31.1 3.Host-Only方式 注意：上图中的VmNet8应该为VmNet1。其实跟nat模式的图片是类似的，只是少了nat服务。 所以host-only上不了外网，只能实现主机的VmNet1网卡和虚拟机的虚拟网卡通信。 NAT介绍NAT（Network Address Translation，网络地址转换）是1994年提出的。当在专用网内部的一些主机本来已经分配到了本地IP地址（即仅在本专用网内使用的专用地址），但现在又想和因特网上的主机通信（并不需要加密）时，可使用NAT方法。 这种方法需要在专用网连接到因特网的路由器上安装NAT软件。装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球IP地址。这样，所有使用本地地址的主机在和外界通信时，都要在NAT路由器上将其本地地址转换成全球IP地址，才能和因特网连接。 另外，这种通过使用少量的公有IP 地址代表较多的私有IP 地址的方式，将有助于减缓可用的IP地址空间的枯竭。 功能NAT不仅能解决了lP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。 宽带分享：这是 NAT 主机的最大功能。 安全防护：NAT 之内的 PC 联机到 Internet 上面时，他所显示的 IP 是 NAT 主机的公共 IP，所以 Client 端的 PC 当然就具有一定程度的安全了，外界在进行 portscan（端口扫描） 的时候，就侦测不到源Client 端的 PC 。 实现方式NAT的实现方式有三种，即静态转换Static Nat、动态转换Dynamic Nat和端口多路复用OverLoad。 静态转换是指将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一成不变的，某个私有IP地址只转换为某个公有IP地址。借助于静态转换，可以实现外部网络对内部网络中某些特定设备（如服务器）的访问。 动态转换是指将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定的，是随机的，所有被授权访问上Internet的私有IP地址可随机转换为任何指定的合法IP地址。也就是说，只要指定哪些内部地址可以进行转换，以及用哪些合法地址作为外部地址时，就可以进行动态转换。动态转换可以使用多个合法外部地址集。当ISP提供的合法IP地址略少于网络内部的计算机数量时。可以采用动态转换的方式。 端口多路复用（Port address Translation,PAT)是指改变外出数据包的源端口并进行端口转换，即端口地址转换（PAT，Port Address Translation).采用端口多路复用方式。内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，从而可以最大限度地节约IP地址资源。同时，又可隐藏网络内部的所有主机，有效避免来自internet的攻击。因此，目前网络中应用最多的就是端口多路复用方式。 ALG（Application Level Gateway），即应用程序级网关技术：传统的NAT技术只对IP层和传输层头部进行转换处理，但是一些应用层协议，在协议数据报文中包含了地址信息。为了使得这些应用也能透明地完成NAT转换，NAT使用一种称作ALG的技术，它能对这些应用程序在通信时所包含的地址信息也进行相应的NAT转换。例如：对于FTP协议的PORT/PASV命令、DNS协议的 “A” 和 “PTR” queries命令和部分ICMP消息类型等都需要相应的ALG来支持。 如果协议数据报文中不包含地址信息，则很容易利用传统的NAT技术来完成透明的地址转换功能，通常我们使用的如下应用就可以直接利用传统的NAT技术：HTTP、TELNET、FINGER、NTP、NFS、ARCHIE、RLOGIN、RSH、RCP等。 工作原理借助于NAT，私有（保留）地址的”内部”网络通过路由器发送数据包时，私有地址被转换成合法的IP地址，一个局域网只需使用少量IP地址（甚至是1个）即可实现私有地址网络内所有计算机与Internet的通信需求。 NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。 NAPTNAPT（Network Address Port Translation），即网络端口地址转换，可将多个内部地址映射为一个合法公网地址，但以不同的协议端口号与不同的内部地址相对应，也就是&lt;内部地址+内部端口&gt;与&lt;外部地址+外部端口&gt;之间的转换。NAPT普遍用于接入设备中，它可以将中小型的网络隐藏在一个合法的IP地址后面。NAPT也被称为“多对一”的NAT，或者叫PAT（Port Address Translations，端口地址转换）、地址超载（address overloading）。 NAPT与动态地址NAT不同，它将内部连接映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的TCP端口号。NAPT算得上是一种较流行的NAT变体，通过转换TCP或UDP协议端口号以及地址来提供并发性。除了一对源和目的IP地址以外，这个表还包括一对源和目的协议端口号，以及NAT盒使用的一个协议端口号。 NAPT的主要优势在于，能够使用一个全球有效IP地址获得通用性。主要缺点在于其通信仅限于TCP或UDP。当所有通信都采用TCP或UDP，NAPT允许一台内部计算机访问多台外部计算机，并允许多台内部主机访问同一台外部计算机，相互之间不会发生冲突。 NAT穿透方法目前常用的针对UDP的NAT 穿透（NAT Traversal）方法主要有：STUN、TURN、ICE、uPnP等。其中ICE方式由于其结合了STUN和TURN的特点，所以使用最为广泛。针对TCP的NAT穿透技术目前仍为难点。实用的技术仍然不多。 配置在配置NAT(网络地址转换)之前，首先需要了解内部本地地址和内部全局地址的分配情况。根据不同的需求，执行以下不同的配置任务。 内部源地址NAT配置 内部源地址NAPT配置 重叠地址NAT配置 TCP负载均衡]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux网卡配置]]></title>
    <url>%2F2017%2F04%2F22%2Flinux-networkcard%2F</url>
    <content type="text"><![CDATA[linux网卡可以通过命令和配置文件配置,如果是桌面环境还可以通过图形化界面配置. 1.ifconfig(interfaces config)命令方式通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置(用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在)。 1.1命令格式1ifconfig [网络设备] [参数] 1.2命令功能ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 1.3命令参数 up 启动指定网络设备/网卡。 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。 arp 设置指定网卡是否支持ARP协议。 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 1.4使用实例1.4.1显示网络设备信息（激活状态的）命令:ifcofig 输出: 12345678910111213141516[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 说明 eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 1.4.2启动关闭指定网卡命令： ifconfig eth0 up ifconfig eth0 down 输出： 说明： ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.3为网卡配置和删除IPv6地址命令： ifconfig eth0 add 33ffe:3240:800:1005::2/64 ifconfig eth0 del 33ffe:3240:800:1005::2/64 输出： 说明： ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址； ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址； 练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 1.4.4用ifconfig修改MAC地址命令： ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 down //关闭网卡[root@localhost ~]# ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE //修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:AA:BB:CC:DD:EE inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB)[root@localhost ~]# ifconfig eth0 hw ether 00:50:56:BF:26:20 //关闭网卡并修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 1.4.5配置IP地址输出: 123[root@localhost ~]# ifconfig eth0 192.168.120.56[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0[root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 说明: ifconfig eth0 192.168.120.56 给eth0网卡配置IP地：192.168.120.56 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0 ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 /给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255 1.4.6启用和关闭ARP协议命令： ifconfig eth0 arp ifconfig eth0 -arp 输出： 12[root@localhost ~]# ifconfig eth0 arp[root@localhost ~]# ifconfig eth0 -arp 说明 ifconfig eth0 arp 开启网卡eth0 的arp协议； ifconfig eth0 -arp 关闭网卡eth0 的arp协议； 1.4.7 设置最大传输单元命令： ifconfig eth0 mtu 1500 输出： 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 mtu 1480[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1480 Metric:1 RX packets:8712395 errors:0 dropped:0 overruns:0 frame:0 TX packets:36631 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597062089 (569.4 MiB) TX bytes:2643973 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# ifconfig eth0 mtu 1500[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8712548 errors:0 dropped:0 overruns:0 frame:0 TX packets:36685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597072333 (569.4 MiB) TX bytes:2650581 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# 说明: 设置能通过的最大数据包大小为1500bytes 2.配置文件方式ubuntu配置文件:/etc/network/interfaces 1234567auto loiface lo inet loopbackauto eth0 #配置静态ipiface eth0 inet staticaddress 192.168.1.100netmask 255.255.255.0gateway 192.168.1.1 centos配置文件:/etc/sysconfig/network-scripts/ifcfg-eth0 123456789101112DEVICE=eth0(默认)HWADDR=00:0C:29:2E:36:16(默认)TYPE=Ethernet(默认)UUID=XXXXXXX(默认)ONBOOT=yes(默认为no,修改为yes意为每次reboot后 ifup eth0)MM_CONTROLLED=yes(默认)#BOOTPROTO=dhcp(dhcp为自动分配ip地址,我们把他注释了，在下面另外加)BOOTPROTO=static(新添加)IPV6INIT=no(新添加)USERCTL=no(新添加)IPADDR=192.168.164.100(新添加)NETMASK=255.255.255.0(新添加) service network restart重启网卡服务 3.图形界面方式添加虚拟网卡一台服务器需要设置多个ip,但又不想添加多块网卡,那就需要设置虚拟网卡.这里介绍几种方式在linux服务器上添加虚拟网卡. 比如向eth0中添加一块虚拟网卡: 1.快速创建删除虚拟网卡sudo ifconfig eth0: 192.168.10.10 up 以上的命令就可以在eth0网卡上创建一个叫eth0:0的虚拟网卡,他的地址是:192.168.1.63 如果不想要这个虚拟网卡了,可以使用如下命令删除: 1sudo ifconfig eth0:0 down 重启服务器或者网络后,虚拟网卡就没有了. 2.修改网卡配置文件在ubuntu下,网卡的配置文件是/etc/network/interfaces,所以我们修改它: sudo vim /etc/network/interfaces 在这个文件中增加如下内容并保存: 123456auto eth0:0iface eth0:0 inet staticaddress 192.168.10.10netmask 255.255.255.0#network 192.168.10.1#broadcast 192.168.1.255 保存后,我们需要重启网卡(重新加载配置文件)才会生效,使用如下命令重启:sudo /etc/init.d/networking restart 他的优点是重启服务器或者网卡配置不会丢失。 3.创建tag前两种方法都有一个特点，创建的网卡可有不同的ip地址，但是Mac地址相同。无法用来创建虚拟机。 添加虚拟网卡tap 1tunctl -b 其他配置命令: 显示网桥信息:brctl show 添加网桥:brctl addbr virbr0 激活网桥:ip link set virbr0 up 添加虚拟网卡tap:tunctl -b tap0 ——-&gt; 执行上面使命就会生成一个tap,后缀从0，1，2依次递增激活创建的tap:ip link set tap0 up 将tap0虚拟网卡添加到指定网桥上:brctl addif br0 tap0给网桥配制ip地址:ifconfig virbr1 169.254.251.4 up 将virbr1网桥上绑定的网卡eth5解除: brctl delif virb1 eth5 给virbr1网桥添加网卡eth6:brctl addif virbr1 eth6]]></content>
      <categories>
        <category>linux管理</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android声音播放与录制]]></title>
    <url>%2F2017%2F04%2F19%2Fissues-android-audio%2F</url>
    <content type="text"><![CDATA[AudioTrackAudioTrack类说明:123456789101112131415161718192021222324252627282930313233343536373839/** * The AudioTrack class manages and plays a single audio resource for Java applications. * It allows streaming of PCM audio buffers to the audio sink for playback. This is * achieved by &quot;pushing&quot; the data to the AudioTrack object using one of the * &#123;@link #write(byte[], int, int)&#125;, &#123;@link #write(short[], int, int)&#125;, * and &#123;@link #write(float[], int, int, int)&#125; methods. * * &lt;p&gt;An AudioTrack instance can operate under two modes: static or streaming.&lt;br&gt; * In Streaming mode, the application writes a continuous stream of data to the AudioTrack, using * one of the &#123;@code write()&#125; methods. These are blocking and return when the data has been * transferred from the Java layer to the native layer and queued for playback. The streaming * mode is most useful when playing blocks of audio data that for instance are: * * &lt;ul&gt; * &lt;li&gt;too big to fit in memory because of the duration of the sound to play,&lt;/li&gt; * &lt;li&gt;too big to fit in memory because of the characteristics of the audio data * (high sampling rate, bits per sample ...)&lt;/li&gt; * &lt;li&gt;received or generated while previously queued audio is playing.&lt;/li&gt; * &lt;/ul&gt; * * The static mode should be chosen when dealing with short sounds that fit in memory and * that need to be played with the smallest latency possible. The static mode will * therefore be preferred for UI and game sounds that are played often, and with the * smallest overhead possible. * * &lt;p&gt;Upon creation, an AudioTrack object initializes its associated audio buffer. * The size of this buffer, specified during the construction, determines how long an AudioTrack * can play before running out of data.&lt;br&gt; * For an AudioTrack using the static mode, this size is the maximum size of the sound that can * be played from it.&lt;br&gt; * For the streaming mode, data will be written to the audio sink in chunks of * sizes less than or equal to the total buffer size. * * AudioTrack is not final and thus permits subclasses, but such use is not recommended. */public class AudioTrack extends PlayerBase implements AudioRouting&#123; &#125; 构造方法说明1234567891011121314151617//根据采样率，采样精度，单双声道来得到frame的大小。int bufsize = AudioTrack.getMinBufferSize(8000,//每秒8K个点 AudioFormat.CHANNEL_CONFIGURATION_STEREO,//双声道AudioFormat.ENCODING_PCM_16BIT);//一个采样点16比特-2个字节//注意，按照数字音频的知识，这个算出来的是一秒钟buffer的大小。//创建AudioTrackAudioTrack trackplayer = new AudioTrack(AudioManager.STREAM_MUSIC, 8000, AudioFormat.CHANNEL_CONFIGURATION_ STEREO, AudioFormat.ENCODING_PCM_16BIT, bufsize,AudioTrack.MODE_STREAM);// trackplayer.play() ;//开始trackplayer.write(bytes_pkg, 0, bytes_pkg.length) ;//往track中写数据….trackplayer.stop();//停止播放trackplayer.release();//释放底层资源。 参数说明1. AudioTrack.MODE_STREAM的意思：AudioTrack中有MODE_STATIC和MODE_STREAM两种分类。 STREAM的意思是由用户在应用程序通过write方式把数据一次一次得写到audiotrack中。这个和我们在socket中发送数据一样，应用层从某个地方获取数据，例如通过编解码得到PCM数据，然后write到audiotrack。这种方式的坏处就是总是在JAVA层和Native层交互，效率损失较大。 而STATIC的意思是一开始创建的时候，就把音频数据放到一个固定的buffer，然后直接传给audiotrack，后续就不用一次次得write了。AudioTrack会自己播放这个buffer中的数据。 这种方法对于铃声等内存占用较小，延时要求较高的声音来说很适用。 2. StreamType这个在构造AudioTrack的第一个参数中使用。这个参数和Android中的AudioManager有关系，涉及到手机上的音频管理策略。 Android将系统的声音分为以下几类常见的（定义在AudioManager)： 1234567891011121314151617181920/** The audio stream for phone calls */public static final int STREAM_VOICE_CALL = AudioSystem.STREAM_VOICE_CALL;/** The audio stream for system sounds */public static final int STREAM_SYSTEM = AudioSystem.STREAM_SYSTEM;/** The audio stream for the phone ring */public static final int STREAM_RING = AudioSystem.STREAM_RING;/** The audio stream for music playback */public static final int STREAM_MUSIC = AudioSystem.STREAM_MUSIC;/** The audio stream for alarms */public static final int STREAM_ALARM = AudioSystem.STREAM_ALARM;/** The audio stream for notifications */public static final int STREAM_NOTIFICATION = AudioSystem.STREAM_NOTIFICATION;/** @hide The audio stream for phone calls when connected to bluetooth */public static final int STREAM_BLUETOOTH_SCO = AudioSystem.STREAM_BLUETOOTH_SCO;/** @hide The audio stream for enforced system sounds in certain countries (e.g camera in Japan) */public static final int STREAM_SYSTEM_ENFORCED = AudioSystem.STREAM_SYSTEM_ENFORCED;/** The audio stream for DTMF Tones */public static final int STREAM_DTMF = AudioSystem.STREAM_DTMF;/** @hide The audio stream for text to speech (TTS) */public static final int STREAM_TTS = AudioSystem.STREAM_TTS; 常用说明: STREAM_ALARM：警告声 STREAM_MUSCI：音乐声，例如music等 STREAM_RING：铃声 STREAM_SYSTEM：系统声音 STREAM_VOCIE_CALL：电话声音 为什么要分这么多呢？以前在台式机上开发的时候很少知道有这么多的声音类型，不过仔细思考下，发现这样做是有道理的。例如你在听music的时候接到电话，这个时候music播放肯定会停止，此时你只能听到电话，如果你调节音量的话，这个调节肯定只对电话起作用。当电话打完了，再回到music，你肯定不用再调节音量了。 其实系统将这几种声音的数据分开管理，所以，这个参数对AudioTrack来说，它的含义就是告诉系统，我现在想使用的是哪种类型的声音，这样系统就可以对应管理他们了。 AudioRecordAudioRecord说明The AudioRecord class manages the audio resources for Java applications to record audio from the audio input hardware of the platform. This is achieved by “pulling” (reading) the data from the AudioRecord object. The application is responsible for polling the AudioRecord object in time using one of the following three methods: read(byte[], int, int), read(short[], int, int) or read(ByteBuffer, int). The choice of which method to use will be based on the audio data storage format that is the most convenient for the user of AudioRecord. Upon creation, an AudioRecord object initializes its associated audio buffer that it will fill with the new audio data. The size of this buffer, specified during the construction, determines how long an AudioRecord can record before “over-running” data that has not been read yet. Data should be read from the audio hardware in chunks of sizes inferior to the total recording buffer size. audiosource类型定义在MediaRecorder中 1234567891011121314151617181920212223242526272829/** Default audio source **/ public static final int DEFAULT = 0; /** Microphone audio source */ public static final int MIC = 1; /** Voice call uplink (Tx) audio source */ public static final int VOICE_UPLINK = 2; /** Voice call downlink (Rx) audio source */ public static final int VOICE_DOWNLINK = 3; /** Voice call uplink + downlink audio source */ public static final int VOICE_CALL = 4; /** Microphone audio source with same orientation as camera if available, the main * device microphone otherwise */ public static final int CAMCORDER = 5; /** Microphone audio source tuned for voice recognition if available, behaves like * &#123;@link #DEFAULT&#125; otherwise. */ public static final int VOICE_RECOGNITION = 6; /** Microphone audio source tuned for voice communications such as VoIP. It * will for instance take advantage of echo cancellation or automatic gain control * if available. It otherwise behaves like &#123;@link #DEFAULT&#125; if no voice processing * is applied. */ public static final int VOICE_COMMUNICATION = 7; AudioManager获取系统音量代码 1234567891011121314151617181920212223242526272829//初始化AudioManager:AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE);//通话音量int max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_VOICE_CALL );int current = mAudioManager.getStreamVolume( AudioManager.STREAM_VOICE_CALL );Log.d(“VIOCE_CALL”, “max : ” + max + ” current : ” + current);//系统音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_SYSTEM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_SYSTEM );Log.d(“SYSTEM”, “max : ” + max + ” current : ” + current);//铃声音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_RING );current = mAudioManager.getStreamVolume( AudioManager.STREAM_RING );Log.d(“RING”, “max : ” + max + ” current : ” + current);//音乐音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_MUSIC );current = mAudioManager.getStreamVolume( AudioManager.STREAM_MUSIC );Log.d(“MUSIC”, “max : ” + max + ” current : ” + current);//提示声音音量max = mAudioManager.getStreamMaxVolume( AudioManager.STREAM_ALARM );current = mAudioManager.getStreamVolume( AudioManager.STREAM_ALARM );Log.d(“ALARM”, “max : ” + max + ” current : ” + current); ps： 游戏过程中只允许调整多媒体音量，而不允许调整通话音量。 1setVolumeControlStream(AudioManager.STREAM_MUSIC); 控制音量AudioManager提供了设置音量的方法： 1public void setStreamVolume(intstreamType,intindex,intflags) 其中streamType有内置的常量，去文档里面就可以看到。 使用示例: 12345678910111213141516171819202122232425//音量控制,初始化定义 AudioManager mAudioManager = (AudioManager) getSystemService(Context.AUDIO_SERVICE); //最大音量 int maxVolume = mAudioManager.getStreamMaxVolume(AudioManager.STREAM_MUSIC); //当前音量 int currentVolume = mAudioManager.getStreamVolume(AudioManager.STREAM_MUSIC);//直接控制音量if(isSilent)&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, 0, 0); &#125;else&#123; mAudioManager.setStreamVolume(AudioManager.STREAM_MUSIC, tempVolume, 0); //tempVolume:音量绝对值 &#125; //以一步步长控制音量的增减，并弹出系统默认音量控制条：//降低音量，调出系统音量控制 if(flag == 0)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_LOWER, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; //增加音量，调出系统音量控制 else if(flag == 1)&#123; mAudioManager.adjustStreamVolume(AudioManager.STREAM_MUSIC,AudioManager.ADJUST_RAISE, AudioManager.FX_FOCUS_NAVIGATION_UP); &#125; 监听按键手动控制音量 123456789101112131415161718192021AudioManager audio = (AudioManager) getSystemService(Service.AUDIO_SERVICE);@Overridepublic boolean onKeyDown(int keyCode, KeyEvent event) &#123; switch (keyCode) &#123; case KeyEvent.KEYCODE_VOLUME_UP: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_RAISE, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; case KeyEvent.KEYCODE_VOLUME_DOWN: audio.adjustStreamVolume( AudioManager.STREAM_MUSIC, AudioManager.ADJUST_LOWER, AudioManager.FLAG_PLAY_SOUND | AudioManager.FLAG_SHOW_UI); return true; default: break; &#125; return super.onKeyDown(keyCode, event); 插入耳机状态仍使用扬声器外放音乐插入耳机的时候也可以选择使用扬声器播放音乐，来电铃声就是这么用的。但是只能用MediaPlayer，播放音频文件。 使用AudioTrack.write播放是行不通的(有待验证)。按理说AudioRecord、AudioTrack类相对于MediaRecorder mediaPlayer来说，更加接近底层，应该也行得通的。 插入耳机，选择外放的代码如下(兼容性验证)： 123456789AudioManager audioManager = (AudioManager) this.getSystemService(Context.AUDIO_SERVICE); audioManager.setMicrophoneMute(false); audioManager.setSpeakerphoneOn(true);//使用扬声器外放，即使已经插入耳机 setVolumeControlStream(AudioManager.STREAM_MUSIC);//控制声音的大小 audioManager.setMode(AudioManager.STREAM_MUSIC); //播放一段声音，查看效果 MediaPlayer playerSound = MediaPlayer.create(this, Uri.parse(&quot;file:///system/media/audio/ui/camera_click.ogg&quot;)); playerSound.start(); 使用STREAM_VOCIE_CALL播放声音与耳机冲突使用STREAM_VOCIE_CALL播放声音在某些手机,比如魅蓝等上面会导致声音仍外放,耳机没声音现象. WebRtc使用STREAM_VOCIE_CALL播放声音,导致某些手机声音低,没法使用音量键调节,插入耳机声音仍外放等问题.]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Audio</tag>
        <tag>issue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown中嵌入LaTex]]></title>
    <url>%2F2017%2F04%2F16%2Flatex%2F</url>
    <content type="text"><![CDATA[MarkDown中使用标识符$$和$$$$即可引入LaTeX语法,前者使用时不换行,即在所使用位置使用LaTeX的格式,后者会换行后居中 部分希腊字母 命令 显示 命令 显示 \alpha α A A \beta β B B \gamma γ \Gamma \varGamma Γ Γ delta δ \Delta \varDelta Δ Δ \epsilon ϵ E E \eta η H H \theta θ \Theta \varTheta Θ Θ \kappa κ K K \lambda λ \Lambda \varLambda Λ Λ \mu μ M M \nu ν N N \pi π \Pi \varPi Π Π \rho ρ P P \sigma σ \Sigma \varSigma Σ Σ \tau τ T T \phi \varphi ϕ φ \Phi \varPhi Φ Φ \omega ω \Omega \varOmega Ω Ω 全部24个字母: 名称 大写 Tex 小写 Tex alpha A A α \alpha beta B B β\ beta gamma Γ \Gamma γ \gamma delta Δ \Delta δ \delta epsilon E E ϵ \epsilon zeta Z Z ζ \zeta eta H H η \eta theta Θ \Theta θ \theta iota I I ι \iota kappa K K κ \kappa lambda Λ \Lambda λ \lambda mu M M μ \mu nu N N ν \nu xi Ξ \Xi ξ \xi omicron O O ο \omicron pi Π \Pi π \pi rho P P ρ \rho sigma Σ \Sigma σ \sigma tau T T τ \tau upsilon Υ \Upsilon υ \upsilon phi Φ \Phi ϕ \phi chi X X χ \chi psi Ψ \Psi ψ \psi omega Ω \Omega ω \omega 部分运算符 命令 显示 命令 显示 \pm ± \mp ∓ \times × \div ÷ \circ ∘ \bullet ∙ \cdot ⋅ \cup ∪ \cap ∩ \subset ⊂ \supset ⊃ \subseteq ⊆ \supseteq ⊇ \leq ≤ \geq ≥ \propto ∝ 其他符号 命令 显示 命令 显示 \cdotp ⋅ \cdots ⋯ \ddots ⋱ \infty ∞ \partial ∂ \bot ⊥ \hat{a} â \tilde{a} ã \bar{a} a¯ \vec{a} a⃗ \dot{a} a˙ \sqrt{a} a‾‾√ \sqrt[3]{2} a‾‾√3 a^{3} a3 \frac{1}{a} 1a \lim_{x \to 0} lima→0 集合关系符号 说明 命令 集合的大括号 { … }\ 集合中的竖线$\mid$ \mid 属于 \in 不属于 \not\in A包含于B A\subset B A真包含于B A\subsetneqq B A包含B A\supset B A真包含B A\supsetneqq B A不包含于B A\not\subset B A交B A\cap B A并B A\cup B A的闭包 \overline{A} A减去B A\setminus B 实数集合 \mathbb{R} 空集 \emptyset 表格中竖线用&amp;#124; 括号总结 功能 语法 显示 不好看 ( \frac{1}{2} ) $(\frac{1}{2})$ 好一点 \left( \frac{1}{2} \right) $\left ( \frac{1}{2} \right )$ 可以使用\left和\right来显示不同的括号： 功能 语法 显示 圆括号，小括号 \left( \frac{a}{b} \right) $\left( \frac{a}{b} \right)$ 方括号，中括号 \left[ \frac{a}{b} \right] $\left[ \frac{a}{b} \right]$ 花括号，大括号 \left\{ \frac{a}{b} \right\} $ \left{ \frac{a}{b} \right}$ 角括号 \left \langle \frac{a}{b} \right \rangle $\left\langle \frac{a}{b} \right \rangle$ 单竖线，绝对值 \left 竖线 \frac{a}{b} \right 竖线 双竖线，范 \left \ 竖线 \frac{a}{b} \right \ 竖线 取整函数 （Floor function） \left \lfloor \frac{a}{b} \right \rfloor $ \left \lfloor \frac{a}{b} \right \rfloor$ 取顶函数 （Ceiling function) \left \lceil \frac{c}{d} \right \rceil $ \left \lceil \frac{c}{d} \right \rceil$ 斜线与反斜线 \left / \frac{a}{b} \right \backslash $ \left / \frac{a}{b} \right \backslash$ 上下箭头 \left \uparrow \frac{a}{b} \right \downarrow \left \Uparrow \frac{a}{b} \right \Downarrow \left \updownarrow \frac{a}{b} \right \Updownarrow $\left \uparrow \frac{a}{b} \right \downarrow$ $\left \Uparrow \frac{a}{b} \right \Downarrow$ $\left \updownarrow \frac{a}{b} \right \Updownarrow$ 混合括号 \left [ 0,1 \right ) \left \langle \psi ) $\left [ 0,1 \right )$ $ \left \langle \psi \right)$ 单左括号 \left \{ \frac{a}{b} \right . $\left { \frac{a}{b} \right .$ 单右括号 \left . \frac{a}{b} \right \} $\left . \frac{a}{b} \right }$ 备注： 可以使用\big, \Big, \bigg, \Bigg控制括号的大小，比如代码\Bigg ( \bigg [ \Big \{ \big \langle \left | \| \frac{a}{b} \| \right | \big \rangle \Big \} \bigg ] \Bigg )显示 $$\Bigg ( \bigg [ \Big { \big \langle \left | | x | \right | \big \rangle \Big } \bigg ] \Bigg )$$ 矩阵基本用法使用$$\begin{matrix}…\end{matrix}$$这样的形式来表示矩阵，在\begin与\end之间加入矩阵中的元素即可。矩阵的行之间使用\\分隔，列之间使用&amp;分隔。 1234567$$ \begin&#123;matrix&#125; 1 &amp; x &amp; x^2 \\ 1 &amp; y &amp; y^2 \\ 1 &amp; z &amp; z^2 \\ \end&#123;matrix&#125;$$ $$ \begin{matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \ \end{matrix} $$ 加括号如果要对矩阵加括号，可以像上文中提到的一样，使用\left与\right配合表示括号符号。也可以使用特殊的matrix。即替换\begin{matrix}…\end{matrix}中的matrix为pmatrix，bmatrix，Bmatrix，vmatrix,Vmatrix. 省略元素可以使用\cdots ⋯ \ddots ⋱ \vdots ⋮ 来省略矩阵中的元素 增广矩阵增广矩阵需要使用前面的array来实现 1234567$$ \left[ \begin&#123;array&#125;&#123;cc|c&#125; 1&amp;2&amp;3\\ 4&amp;5&amp;6 \end&#123;array&#125; \right]$$ $$ \left[ \begin{array}{cc|c} 1&amp;2&amp;3\ 4&amp;5&amp;6 \end{array} \right] $$ 表格使用$$\begin{array}{列样式}…\end{array}$$这样的形式来创建表格，列样式可以是clr表示居中，左，右对齐，还可以使用|表示一条竖线。表格中 各行使用\\分隔，各列使用&amp;分隔。使用\hline在本行前加入一条直线。 例如， 123456789$$\begin&#123;array&#125;&#123;c|lcr&#125;n &amp; \text&#123;Left&#125; &amp; \text&#123;Center&#125; &amp; \text&#123;Right&#125; \\\hline1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i \\\end&#123;array&#125;$$ 上标与下标上标和下标分别使用^与_，例如x_i^2：$x_i^2$ 。默认情况下，上下标符号仅仅对下一个组起作用。一个组即单个字符或者使用{..}包裹起来的内容。也就是说，如果使用10^10，会得到$10^10$ ，而10^{10}才是$10^{10}$ 。同时，大括号还能消除二义性，如x^5^6将得到一个错误，必须使用大括号来界定^的结合性，如{x^5}^6：${x^5}^6$ 或者 x^{5^6}：$x^{5^6}$ 。 对齐的公式分类表达式定义函数的时候经常需要分情况给出表达式，可使用\begin{cases}…\end{cases}。其中，使用\来分类，使用&amp;指示需要对齐的位置。如： 多重积分连分数方程组颜色公式标记与引用求和与积分分式与根式特殊函数与符号空间顶部符号 参考 http://mlworks.cn/posts/introduction-to-mathjax-and-latex-expression/]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高数1.函数与极限]]></title>
    <url>%2F2017%2F04%2F13%2Fam-function-and-limitaion%2F</url>
    <content type="text"><![CDATA[1.映射与函数1.1 集合1.1.1 集合的概念集合(集)是指具有某种特定性质的事物的总体,组成这个集合的事物成为该集合的元素(简称元) 表示:用大写拉丁字母A,B,C…表示集合,小写拉丁字母表示集合的元素 分类: 有限集 无限集 表示数集的字母的右上角标*表示该数集内排除0的集,标上+来表示数集内排除0和负数的集 常用表示 N={0, 1, 2, 3…};全体非负整数即自然数的集合 N+={1,2,3,…n,….};全体正整数的集合 Z={…,-n,…-3, -2,-1, 0, 1, 2, 3,…,n…};全体整数的集合 $Q=\lbrace \frac{p}{q}|p \in Z,q \in N^{+} \rbrace$;全体有理数集 全体实数记做R,R*为排除0的实数集,R+为全体正实数集. 子集概念: 子集 真子集 集合相等:互为子集 空集 $\emptyset$1.1.2 集合的运算 1.1.3 区间和领域]]></content>
      <categories>
        <category>高数</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android线程使用总结]]></title>
    <url>%2F2017%2F04%2F10%2Ftips-android-thread%2F</url>
    <content type="text"><![CDATA[1. Threading Performance在程序开发的实践当中，为了让程序表现得更加流畅，我们肯定会需要使用到多线程来提升程序的并发执行性能。但是编写多线程并发的代码一直以来都是一个相对棘手的问题，所以想要获得更佳的程序性能，我们非常有必要掌握多线程并发编程的基础技能。 众所周知，Android 程序的大多数代码操作都必须执行在主线程，例如系统事件(例如设备屏幕发生旋转)，输入事件(例如用户点击滑动等)，程序回调服务，UI 绘制以及闹钟事件等等。那么我们在上述事件或者方法中插入的代码也将执行在主线程。 一旦我们在主线程里面添加了操作复杂的代码，这些代码就很可能阻碍主线程去响应点击/滑动事件，阻碍主线程的 UI 绘制等等。我们知道，为了让屏幕的刷新帧率达到 60fps，我们需要确保 16ms 内完成单次刷新的操作。一旦我们在主线程里面执行的任务过于繁重就可能导致接收到刷新信号的时候因为资源被占用而无法完成这次刷新操作，这样就会产生掉帧的现象，刷新帧率自然也就跟着下降了(一旦刷新帧率降到 20fps 左右，用户就可以明显感知到卡顿不流畅了)。 为了避免上面提到的掉帧问题，我们需要使用多线程的技术方案，把那些操作复杂的任务移动到其他线程当中执行，这样就不容易阻塞主线程的操作，也就减小了出现掉帧的可能性。 为主线程减轻负的多线程方案有哪些呢？这些方案分别适合在什么场景下使用？Android 系统为我们提供了若干组工具类来帮助解决这个问题。 AsyncTask: 为 UI 线程与工作线程之间进行快速的切换提供一种简单便捷的机制。适用于当下立即需要启动，但是异步执行的生命周期短暂的使用场景。 HandlerThread: 为某些回调方法或者等待某些任务的执行设置一个专属的线程，并提供线程任务的调度机制。 ThreadPool: 把任务分解成不同的单元，分发到各个不同的线程上，进行同时并发处理。 IntentService: 适合于执行由 UI 触发的后台 Service 任务，并可以把后台任务执行的情况通过一定的机制反馈给 UI。 了解这些系统提供的多线程工具类分别适合在什么场景下，可以帮助我们选择合适的解决方案，避免出现不可预期的麻烦。虽然使用多线程可以提高程序的并发量，但是我们需要特别注意因为引入多线程而可能伴随而来的内存问题。举个例子，在 Activity 内部定义的一个 AsyncTask，它属于一个内部类，该类本身和外面的 Activity 是有引用关系的，如果 Activity 要销毁的时候，AsyncTask 还仍然在运行，这会导致 Activity 没有办法完全释放，从而引发内存泄漏。所以说，多线程是提升程序性能的有效手段之一，但是使用多线程却需要十分谨慎小心，如果不了解背后的执行机制以及使用的注意事项，很可能引起严重的问题。 2. Understanding Android Threading通常来说，一个线程需要经历三个生命阶段：开始，执行，结束。线程会在任务执行完毕之后结束，那么为了确保线程的存活，我们会在执行阶段给线程赋予不同的任务，然后在里面添加退出的条件从而确保任务能够执行完毕后退出。 在很多时候，线程不仅仅是线性执行一系列的任务就结束那么简单的，我们会需要增加一个任务队列，让线程不断的从任务队列中获取任务去进行执行，另外我们还可能在线程执行的任务过程中与其他的线程进行协作。如果这些细节都交给我们自己来处理，这将会是件极其繁琐又容易出错的事情。 所幸的是，Android 系统为我们提供了 Looper，Handler，MessageQueue 来帮助实现上面的线程任务模型： Looper: 能够确保线程持续存活并且可以不断的从任务队列中获取任务并进行执行。 Handler: 能够帮助实现队列任务的管理，不仅仅能够把任务插入到队列的头部，尾部，还可以按照一定的时间延迟来确保任务从队列中能够来得及被取消掉。 MessageQueue: 使用 Intent，Message，Runnable 作为任务的载体在不同的线程之间进行传递。 把上面三个组件打包到一起进行协作，这就是 HandlerThread 我们知道，当程序被启动，系统会帮忙创建进程以及相应的主线程，而这个主线程其实就是一个 HandlerThread。这个主线程会需要处理系统事件，输入事件，系统回调的任务，UI绘制等等任务，为了避免主线程任务过重，我们就会需要不断的开启新的工作线程来处理那些子任务。 3. Memory &amp; Threading增加并发的线程数会导致内存消耗的增加，平衡好这两者的关系是非常重要的。我们知道，多线程并发访问同一块内存区域有可能带来很多问题，例如读写的权限争夺问题，ABA 问题等等。为了解决这些问题，我们会需要引入锁的概念。 在 Android 系统中也无法避免因为多线程的引入而导致出现诸如上文提到的种种问题。Android UI 对象的创建，更新，销毁等等操作都默认是执行在主线程，但是如果我们在非主线程对UI对象进行操作，程序将可能出现异常甚至是崩溃。 另外，在非 UI 线程中直接持有 UI 对象的引用也很可能出现问题。例如Work线程中持有某个 UI 对象的引用，在 Work 线程执行完毕之前，UI 对象在主线程中被从 ViewHierarchy 中移除了，这个时候 UI 对象的任何属性都已经不再可用了，另外对这个 UI 对象的更新操作也都没有任何意义了，因为它已经从 ViewHierarchy 中被移除，不再绘制到画面上了。 不仅如此，View 对象本身对所属的 Activity 是有引用关系的，如果工作线程持续保有 View 的引用，这就可能导致 Activity 无法完全释放。除了直接显式的引用关系可能导致内存泄露之外，我们还需要特别留意隐式的引用关系也可能导致泄露。例如通常我们会看到在 Activity 里面定义的一个 AsyncTask，这种类型的 AsyncTask 与外部的 Activity 是存在隐式引用关系的，只要 Task 没有结束，引用关系就会一直存在，这很容易导致 Activity 的泄漏。更糟糕的情况是，它不仅仅发生了内存泄漏，还可能导致程序异常或者崩溃。 为了解决上面的问题，我们需要谨记的原则就是：不要在任何非 UI 线程里面去持有 UI 对象的引用。系统为了确保所有的 UI 对象都只会被 UI 线程所进行创建，更新，销毁的操作，特地设计了对应的工作机制(当 Activity 被销毁的时候，由该 Activity 所触发的非 UI 线程都将无法对UI对象进行操作，否者就会抛出程序执行异常的错误)来防止 UI 对象被错误的使用。 4. Good AsyncTask HuntingAsyncTask 是一个让人既爱又恨的组件，它提供了一种简便的异步处理机制，但是它又同时引入了一些令人厌恶的麻烦。一旦对 AsyncTask 使用不当，很可能对程序的性能带来负面影响，同时还可能导致内存泄露。 举个例子，常遇到的一个典型的使用场景：用户切换到某个界面，触发了界面上的图片的加载操作，因为图片的加载相对来说耗时比较长，我们需要在子线程中处理图片的加载，当图片在子线程中处理完成之后，再把处理好的图片返回给主线程，交给 UI 更新到画面上。 AsyncTask 的出现就是为了快速的实现上面的使用场景，AsyncTask 把在主线程里面的准备工作放到 onPreExecute()方法里面进行执行，doInBackground()方法执行在工作线程中，用来处理那些繁重的任务，一旦任务执行完毕，就会调用 onPostExecute()方法返回到主线程。 使用 AsyncTask 需要注意的问题有哪些呢？请关注以下几点： 首先，默认情况下，所有的 AsyncTask 任务都是被线性调度执行的，他们处在同一个任务队列当中，按顺序逐个执行。假设你按照顺序启动20个 AsyncTask，一旦其中的某个 AsyncTask 执行时间过长，队列中的其他剩余 AsyncTask 都处于阻塞状态，必须等到该任务执行完毕之后才能够有机会执行下一个任务。 为了解决上面提到的线性队列等待的问题，我们可以使用 AsyncTask.executeOnExecutor()强制指定 AsyncTask 使用线程池并发调度任务。 其次，如何才能够真正的取消一个 AsyncTask 的执行呢？我们知道 AsyncTaks 有提供 cancel()的方法，但是这个方法实际上做了什么事情呢？线程本身并不具备中止正在执行的代码的能力，为了能够让一个线程更早的被销毁，我们需要在 doInBackground()的代码中不断的添加程序是否被中止的判断逻辑. 一旦任务被成功中止，AsyncTask 就不会继续调用 onPostExecute()，而是通过调用 onCancelled()的回调方法反馈任务执行取消的结果。我们可以根据任务回调到哪个方法（是 onPostExecute 还是 onCancelled）来决定是对 UI 进行正常的更新还是把对应的任务所占用的内存进行销毁等。 最后，使用 AsyncTask 很容易导致内存泄漏，一旦把 AsyncTask 写成 Activity 的内部类的形式就很容易因为 AsyncTask 生命周期的不确定而导致 Activity 发生泄漏。 综上所述，AsyncTask 虽然提供了一种简单便捷的异步机制，但是我们还是很有必要特别关注到他的缺点，避免出现因为使用错误而导致的严重系统性能问题。 5. Getting a HandlerThread大多数情况下，AsyncTask 都能够满足多线程并发的场景需要（在工作线程执行任务并返回结果到主线程），但是它并不是万能的。例如打开相机之后的预览帧数据是通过 onPreviewFrame()的方法进行回调的，onPreviewFrame()和 open()相机的方法是执行在同一个线程的。 如果这个回调方法执行在 UI 线程，那么在 onPreviewFrame()里面将要执行的数据转换操作将和主线程的界面绘制，事件传递等操作争抢系统资源，这就有可能影响到主界面的表现性能。 我们需要确保 onPreviewFrame()执行在工作线程。如果使用 AsyncTask，会因为 AsyncTask 默认的线性执行的特性(即使换成并发执行)会导致因为无法把任务及时传递给工作线程而导致任务在主线程中被延迟，直到工作线程空闲，才可以把任务切换到工作线程中进行执行。 所以我们需要的是一个执行在工作线程，同时又能够处理队列中的复杂任务的功能，而 HandlerThread 的出现就是为了实现这个功能的，它组合了 Handler，MessageQueue，Looper 实现了一个长时间运行的线程，不断的从队列中获取任务进行执行的功能。 回到刚才的处理相机回调数据的例子，使用 HandlerThread 我们可以把 open()操作与 onPreviewFrame()的操作执行在同一个线程，同时还避免了 AsyncTask 的弊端。如果需要在 onPreviewFrame()里面更新 UI，只需要调用 runOnUiThread()方法把任务回调给主线程就够了。 HandlerThread 比较合适处理那些在工作线程执行，需要花费时间偏长的任务。我们只需要把任务发送给 HandlerThread，然后就只需要等待任务执行结束的时候通知返回到主线程就好了。 另外很重要的一点是，一旦我们使用了 HandlerThread，需要特别注意给 HandlerThread 设置不同的线程优先级，CPU 会根据设置的不同线程优先级对所有的线程进行调度优化。 掌握 HandlerThread 与 AsyncTask 之间的优缺点，可以帮助我们选择合适的方案。 6. Swimming in Threadpools线程池适合用在把任务进行分解，并发进行执行的场景。通常来说，系统里面会针对不同的任务设置一个单独的守护线程用来专门处理这项任务。例如使用 Networking Thread 用来专门处理网络请求的操作，使用 IO Thread 用来专门处理系统的 I\O 操作。针对那些场景，这样设计是没有问题的，因为对应的任务单次执行的时间并不长而且可以是顺序执行的。但是这种专属的单线程并不能满足所有的情况，例如我们需要一次性 decode 40张图片，每个线程需要执行 4ms 的时间，如果我们使用专属单线程的方案，所有图片执行完毕会需要花费 160ms(40*4)，但是如果我们创建10个线程，每个线程执行4个任务，那么我们就只需要16ms就能够把所有的图片处理完毕。 为了能够实现上面的线程池模型，系统为我们提供了 ThreadPoolExecutor 帮助类来简化实现，剩下需要做的就只是对任务进行分解就好了。 使用线程池需要特别注意同时并发线程数量的控制，理论上来说，我们可以设置任意你想要的并发数量，但是这样做非常的不好。因为 CPU 只能同时执行固定数量的线程数，一旦同时并发的线程数量超过 CPU 能够同时执行的阈值，CPU 就需要花费精力来判断到底哪些线程的优先级比较高，需要在不同的线程之间进行调度切换。 一旦同时并发的线程数量达到一定的量级，这个时候 CPU 在不同线程之间进行调度的时间就可能过长，反而导致性能严重下降。另外需要关注的一点是，每开一个新的线程，都会耗费至少 64K+ 的内存。为了能够方便的对线程数量进行控制，ThreadPoolExecutor 为我们提供了初始化的并发线程数量，以及最大的并发数量进行设置。 另外需要关注的一个问题是：Runtime.getRuntime().availableProcesser()方法并不可靠，他返回的值并不是真实的 CPU 核心数，因为 CPU 会在某些情况下选择对部分核心进行睡眠处理，在这种情况下，返回的数量就只能是激活的 CPU 核心数。 7. The Zen of IntentService默认的 Service 是执行在主线程的，可是通常情况下，这很容易影响到程序的绘制性能(抢占了主线程的资源)。除了前面介绍过的 AsyncTask 与 HandlerThread，我们还可以选择使用 IntentService 来实现异步操作。IntentService 继承自普通 Service 同时又在内部创建了一个 HandlerThread，在 onHandlerIntent()的回调里面处理扔到 IntentService 的任务。所以 IntentService 就不仅仅具备了异步线程的特性，还同时保留了 Service 不受主页面生命周期影响的特点。 如此一来，我们可以在 IntentService 里面通过设置闹钟间隔性的触发异步任务，例如刷新数据，更新缓存的图片或者是分析用户操作行为等等，当然处理这些任务需要小心谨慎。 使用 IntentService 需要特别留意以下几点： 首先，因为 IntentService 内置的是 HandlerThread 作为异步线程，所以每一个交给 IntentService 的任务都将以队列的方式逐个被执行到，一旦队列中有某个任务执行时间过长，那么就会导致后续的任务都会被延迟处理。 其次，通常使用到 IntentService 的时候，我们会结合使用 BroadcastReceiver 把工作线程的任务执行结果返回给主 UI 线程。使用广播容易引起性能问题，我们可以使用 LocalBroadcastManager 来发送只在程序内部传递的广播，从而提升广播的性能。我们也可以使用 runOnUiThread() 快速回调到主 UI 线程。 最后，包含正在运行的 IntentService 的程序相比起纯粹的后台程序更不容易被系统杀死，该程序的优先级是介于前台程序与纯后台程序之间的。 8. Threading and Loaders当启动工作线程的 Activity 被销毁的时候，我们应该做点什么呢？为了方便的控制工作线程的启动与结束，Android 为我们引入了 Loader 来解决这个问题。我们知道 Activity 有可能因为用户的主动切换而频繁的被创建与销毁，也有可能是因为类似屏幕发生旋转等被动原因而销毁再重建。在 Activity 不停的创建与销毁的过程当中，很有可能因为工作线程持有 Activity 的 View 而导致内存泄漏(因为工作线程很可能持有 View 的强引用，另外工作线程的生命周期还无法保证和 Activity 的生命周期一致，这样就容易发生内存泄漏了)。除了可能引起内存泄漏之外，在 Activity 被销毁之后，工作线程还继续更新视图是没有意义的，因为此时视图已经不在界面上显示了。 Loader 的出现就是为了确保工作线程能够和 Activity 的生命周期保持一致，同时避免出现前面提到的问题。 LoaderManager 会对查询的操作进行缓存，只要对应 Cursor 上的数据源没有发生变化，在配置信息发生改变的时候(例如屏幕的旋转)，Loader 可以直接把缓存的数据回调到 onLoadFinished()，从而避免重新查询数据。另外系统会在 Loader 不再需要使用到的时候(例如使用 Back 按钮退出当前页面)回调 onLoaderReset()方法，我们可以在这里做数据的清除等等操作。 在 Activity 或者 Fragment 中使用 Loader 可以方便的实现异步加载的框架，Loader 有诸多优点。但是实现 Loader 的这套代码还是稍微有点点复杂，Android 官方为我们提供了使用 Loader 的示例代码进行参考学习。 9. The Importance of Thread Priority理论上来说，我们的程序可以创建出非常多的子线程一起并发执行的，可是基于 CPU 时间片轮转调度的机制，不可能所有的线程都可以同时被调度执行，CPU 需要根据线程的优先级赋予不同的时间片。 Android 系统会根据当前运行的可见的程序和不可见的后台程序对线程进行归类，划分为 forground 的那部分线程会大致占用掉 CPU 的90%左右的时间片，background 的那部分线程就总共只能分享到5%-10%左右的时间片。之所以设计成这样是因为 forground 的程序本身的优先级就更高，理应得到更多的执行时间。 默认情况下，新创建的线程的优先级默认和创建它的母线程保持一致。如果主 UI 线程创建出了几十个工作线程，这些工作线程的优先级就默认和主线程保持一致了，为了不让新创建的工作线程和主线程抢占 CPU 资源，需要把这些线程的优先级进行降低处理，这样才能给帮组 CPU 识别主次，提高主线程所能得到的系统资源。 在 Android 系统里面，我们可以通过 android.os.Process.setThreadPriority(int) 设置线程的优先级，参数范围从-20到19，数值越小优先级越高。Android 系统还为我们提供了以下的一些预设值，我们可以通过给不同的工作线程设置不同数值的优先级来达到更细粒度的控制。 大多数情况下，新创建的线程优先级会被设置为默认的0，主线程设置为0的时候，新创建的线程还可以利用 THREAD_PRIORITY_LESS_FAVORABLE 或者 THREAD_PRIORITY_MORE_FAVORABLE 来控制线程的优先级。 Android 系统里面的 AsyncTask 与 IntentService已经默认帮助我们设置线程的优先级，但是对于那些非官方提供的多线程工具类，我们需要特别留意根据需要自己手动来设置线程的优先级。 10. Profile GPU Rendering : M Update从 Android M 系统开始，系统更新了 GPU Profiling 的工具来帮助我们定位 UI 的渲染性能问题。早期的 CPU Profiling 工具只能粗略的显示出 Process，Execute，Update 三大步骤的时间耗费情况。 但是仅仅显示三大步骤的时间耗费情况，还是不太能够清晰帮助我们定位具体的程序代码问题，所以在 Android M 版本开始，GPU Profiling 工具把渲染操作拆解成如下8个详细的步骤进行显示。 旧版本中提到的 Proces，Execute，Update 还是继续得到了保留，他们的对应关系如下： 接下去我们看下其他五个步骤分别代表了什么含义： Sync &amp; Upload：通常表示的是准备当前界面上有待绘制的图片所耗费的时间，为了减少该段区域的执行时间，我们可以减少屏幕上的图片数量或者是缩小图片本身的大小。 Measure &amp; Layout：这里表示的是布局的 onMeasure 与 onLayout 所花费的时间，一旦时间过长，就需要仔细检查自己的布局是不是存在严重的性能问题。 Animation：表示的是计算执行动画所需要花费的时间，包含的动画有 ObjectAnimator，ViewPropertyAnimator，Transition 等等。一旦这里的执行时间过长，就需要检查是不是使用了非官方的动画工具或者是检查动画执行的过程中是不是触发了读写操作等等。 Input Handling：表示的是系统处理输入事件所耗费的时间，粗略等于对于的事件处理方法所执行的时间。一旦执行时间过长，意味着在处理用户的输入事件的地方执行了复杂的操作。 Misc/Vsync Delay：如果稍加注意，我们可以在开发应用的 Log 日志里面看到这样一行提示：I/Choreographer(691): Skipped XXX frames! The application may be doing too much work on its main thread。这意味着我们在主线程执行了太多的任务，导致 UI 渲染跟不上 vSync 的信号而出现掉帧的情况。 上面八种不同的颜色区分了不同的操作所耗费的时间，为了便于我们迅速找出那些有问题的步骤，GPU Profiling 工具会显示 16ms 的阈值线，这样就很容易找出那些不合理的性能问题，再仔细看对应具体哪个步骤相对来说耗费时间比例更大，结合上面介绍的细化步骤，从而快速定位问题，修复问题。 http://bugly.qq.com/bbs/forum.php?mod=viewthread&amp;tid=1022]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>多线程</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MP4格式解析]]></title>
    <url>%2F2017%2F04%2F09%2Fm-f-mp4%2F</url>
    <content type="text"><![CDATA[目前MP4的概念被炒得很火，也很乱。最开始MP4指的是音频（MP3的升级版），即MPEG-2 AAC标准。随后MP4概念被转移到视频上，对应的是MPEG-4标准。而现在我们流行的叫法，多半是指能播放MPEG-4标准编码格式视频的播放器。但是这篇文章介绍的内容跟上面这些都无关，我们要讨论的是MP4文件封装格式，对应的标准为ISO/IEC 14496-12，即信息技术 视听对象编码的第12部分：ISO 基本媒体文件格式（Information technology Coding of audio-visual objects Part 12: ISO base media file format）。ISO/IEC组织指定的标准一般用数字表示，ISO/IEC 14496即MPEG-4标准。 MP4视频文件封装格式是基于QuickTime容器格式定义的，因此参考QuickTime的格式定义对理解MP4文件格式很有帮助。MP4文件格式是一个十分开放的容器，几乎可以用来描述所有的媒体结构，MP4文件中的媒体描述与媒体数据是分开的，并且媒体数据的组织也很自由，不一定要按照时间顺序排列，甚至媒体数据可以直接引用其他文件。同时，MP4也支持流媒体。MP4目前被广泛用于封装h.264视频和AAC音频，是高清视频的代表。MP4格式的官方文件后缀名是“.mp4”，还有其他的以mp4为基础进行的扩展或者是缩水版本的格式，包括：M4V, 3GP, F4V等。 1.概述MP4文件中的所有数据都装在box（QuickTime中为atom）中，也就是说MP4文件由若干个box组成，每个box有类型和长度，可以将box理解为一个数据对象块。box中可以包含另一个box，这种box称为container box。一个MP4文件首先会有且只有一个“ftyp”类型的box，作为MP4格式的标志并包含关于文件的一些信息；之后会有且只有一个“moov”类型的box（Movie Box），它是一种container box，子box包含了媒体的metadata信息；MP4文件的媒体数据包含在“mdat”类型的box（Midia Data Box）中，该类型的box也是container box，可以有多个，也可以没有（当媒体数据全部引用其他文件时），媒体数据的结构由metadata进行描述。 下面是一些概念： track 表示一些sample的集合，对于媒体数据来说，track表示一个视频或音频序列。 hint track 这个特殊的track并不包含媒体数据，而是包含了一些将其他数据track打包成流媒体的指示信息。 sample 对于非hint track来说，video sample即为一帧视频，或一组连续视频帧，audio sample即为一段连续的压缩音频，它们统称sample。对于hint track，sample定义一个或多个流媒体包的格式。 sample table 指明sampe时序和物理布局的表。 chunk 一个track的几个sample组成的单元。 不讨论涉及hint的内容，只关注包含媒体数据的本地MP4文件。下图为一个典型的MP4文件的结构树。 2.Boxbox中的字节序为网络字节序，也就是大端字节序（Big-Endian），简单的说，就是一个32位的4字节整数存储方式为高位字节在内存的低端。Box由header和body组成，其中header统一指明box的大小和类型，body根据类型有不同的意义和格式。 标准的box开头的4个字节（32位）为box size，该大小包括box header和box body整个box的大小，这样我们就可以在文件中定位各个box。如果size为1，则表示这个box的大小为large size，真正的size值要在largesize域上得到。（实际上只有“mdat”类型的box才有可能用到large size。）如果size为0，表示该box为文件的最后一个box，文件结尾即为该box结尾。（同样只存在于“mdat”类型的box中。）size后面紧跟的32位为box type，一般是4个字符，如“ftyp”、“moov”等，这些box type都是已经预定义好的，分别表示固定的意义。如果是“uuid”，表示该box为用户扩展类型。如果box type是未定义的，应该将其忽略。 3.File Type Box(ftyp)该box有且只有1个，并且只能被包含在文件层，而不能被其他box包含。该box应该被放在文件的最开始，指示该MP4文件应用的相关信息。 “ftyp” body依次包括1个32位的major brand（4个字符），1个32位的minor version（整数）和1个以32位（4个字符）为单位元素的数组compatible brands。这些都是用来指示文件应用级别的信息。该box的字节实例如下： 1200000000h: 00 00 00 18 66 74 79 70 6D 70 34 32 00 00 00 01 ; ....ftypmp42....00000010h: 6D 70 34 32 6D 70 34 31 00 00 5A EB 6D 6F 6F 76 ; mp42mp41..Zmoov 4.Movie Box(moov)该box包含了文件媒体的metadata信息，“moov”是一个container box，具体内容信息由子box诠释。同File Type Box一样，该box有且只有一个，且只被包含在文件层。一般情况下，“moov”会紧随“ftyp”出现。 一般情况下（限于篇幅，本文只讲解常见的MP4文件结构），“moov”中会包含1个“mvhd”和若干个“trak”。其中“mvhd”为header box，一般作为“moov”的第一个子box出现（对于其他container box来说，header box都应作为首个子box出现）。“trak”包含了一个track的相关信息，是一个container box。下图为部分“moov”的字节实例，其中红色部分为box header，绿色为“mvhd”，黄色为一部分“trak”。 4.1 Movie Header Box(mvhd)“mvhd”接口如下表: 字段 字节数 意义 box size 4 box大小 box type 4 box类型 version 1 box版本，0或1，一般为0。（以下字节数均按version=0） flags 3 creation time 4 创建时间（相对于UTC时间1904-01-01零点的秒数） modification time 4 修改时间 time scale 4 文件媒体在1秒时间内的刻度值，可以理解为1秒长度的时间单元数 duration 4 该track的时间长度，用duration和time scale值可以计算track时长，比如audio track的time scale = 8000, duration = 560128，时长为70.016，video track的time scale = 600, duration = 42000，时长为70 rate 4 推荐播放速率，高16位和低16位分别为小数点整数部分和小数部分，即[16.16] 格式，该值为1.0（0x00010000）表示正常前向播放 volume 2 与rate类似，[8.8] 格式，1.0（0x0100）表示最大音量 reserved 10 保留位 matrix 36 视频变换矩阵 pre-defined 24 next track id 4 下一个track使用的id号 4.2Track Box(trak)“trak”也是一个container box，其子box包含了该track的媒体数据引用和描述（hint track除外）。一个MP4文件中的媒体可以包含多个track，且至少有一个track，这些track之间彼此独立，有自己的时间和空间信息。“trak”必须包含一个“tkhd”和一个“mdia”，此外还有很多可选的box（略）。其中“tkhd”为track header box，“mdia”为media box，该box是一个包含一些track媒体数据信息box的container box。 box类型说明 ftypefile type,说明文件类型 moovmetadata container,存放媒体信息的地方 mvhdmovie header,文件的总体信息,如时长,创建时间等 mvhdmovie header,文件的总体信息,如时长,创建时间等 traktrack or stream container,存放视频/音频流的容器 tkhdtrack header,track的总体信息,如时长,宽高等 mediatrak media information container mdhdmedia header,定义TimeScale,trak需要通过TimeScale转换成真实时间 hdlrhandler,表明本trak类型,指明是video/audio/还是hint minfmedia information container,数据在子box中 stblsample table box,存放时间/偏移的映射关系表,数据在子box中 stsdsample descriptions stts(decoding)time-to-sample,”时戳-sample序号”的映射表 stscsample-to-chunk,sample和chunk的映射表,这里的算法比较巧妙 stszsample size,每个sample的大小 stz2sample size,另一种sample size的存储算法,更节省空间 stsssync sample table,可随机访问的sample列表(关键帧列表) stcochunk offset,每个chunk的偏移,sample的偏移可根据其他box推算出来 co6464-bit chunk offset mdatmedia data container,具体的媒体数据 Mdat Box]]></content>
      <categories>
        <category>音视频封装</category>
      </categories>
      <tags>
        <tag>多媒体</tag>
        <tag>音视频</tag>
        <tag>format</tag>
      </tags>
  </entry>
</search>