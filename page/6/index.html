<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="老司机种菜" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="老司机种菜">
<meta property="og:url" content="http://wodekouwei.com/page/6/index.html">
<meta property="og:site_name" content="老司机种菜">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="老司机种菜">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wodekouwei.com/page/6/"/>





  <title> 老司机种菜 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2021aa5f03a4203621d42ef374e0d5f7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">老司机种菜</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-graphic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-graphic/" itemprop="url">
                  多媒体技术(一)之图形图像
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:07:54+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-图形与图像的基本概念"><a href="#1-图形与图像的基本概念" class="headerlink" title="1.图形与图像的基本概念"></a>1.图形与图像的基本概念</h2><h3 id="1-1图形与图像的颜色模型"><a href="#1-1图形与图像的颜色模型" class="headerlink" title="1.1图形与图像的颜色模型"></a>1.1图形与图像的颜色模型</h3><h4 id="1-1-1颜色的基本概念"><a href="#1-1-1颜色的基本概念" class="headerlink" title="1.1.1颜色的基本概念"></a>1.1.1颜色的基本概念</h4><h5 id="1-1-1-1-物体的颜色"><a href="#1-1-1-1-物体的颜色" class="headerlink" title="1.1.1.1 物体的颜色"></a>1.1.1.1 物体的颜色</h5><p>物体的颜色不同是因为他们对光的吸收和反射的属性不同.物体的颜色是由该物体所反射的光的波长来决定的.</p>
<p>人眼看到的物体的颜色不仅取决于该物体所反射的光的波长,还与照射它的光源有关.如果用单一蓝色去照射绿色的树叶,
则此时的树叶只能是黑色的.因为蓝色光源中没有绿色成分,树叶吸收了全部蓝色而呈现黑色.</p>
<p>在彩色显示器中,为了使颜色具有较好的还原度和真实感,通常采用类似自然光作为照明光源.</p>
<h5 id="1-1-1-2-彩色三要素"><a href="#1-1-1-2-彩色三要素" class="headerlink" title="1.1.1.2 彩色三要素"></a>1.1.1.2 彩色三要素</h5><p>颜色信息对人的视觉反应,可通过色调,色饱和度和亮度这三个参量来表示:</p>
<ul>
<li>色调:用来描述颜色的不同类别的物理量称为色调,如红,橙,黄,绿,青,蓝,紫.色调取决于该种颜色的主要波长.</li>
<li>色饱和度:色饱和度则是描述颜色的深浅程度的物理量,它按该种颜色混入白光的比例来表示,当某色光的饱和度为100%时,就是表示该色光是完全没有混入白色光的单色光饱和度越高则颜色也越浓.如果大量混入白色光使饱和度降低,人视觉会感到颜色变淡.例如,在浓的的红色光中混入大量的白光,由于饱和度降低就变成了粉红色,但是因为红色是基本色,所以色调并不改变.在某颜色中混入白光与增强白光对某颜色物体的照射是不同的.前者是在摄入人眼的眸色光中混入白光,而后者的结果则是加强了某色物体的反射光的强度,在摄入人眼的反射光中并没有混入白光,因此它并没有改变该色的饱和度.</li>
<li>亮度:用来描述色光的明暗变化的强度的物理量成为亮度.亮度是色光能量的一种描述,是指色调和色饱和度已经固定的光,当它的全部能量增强时感觉明亮,否则感觉暗淡.</li>
</ul>
<p>色调和色饱和度统称为色度.</p>
<h5 id="1-1-1-3-三基色原理"><a href="#1-1-1-3-三基色原理" class="headerlink" title="1.1.1.3 三基色原理"></a>1.1.1.3 三基色原理</h5><p>三基色原理认为自然界中景物的绝大多数的彩色光,能分解为互相独立的红(R),绿(G),蓝(B)三种基色光;反之,用互相独立的红,绿,蓝3种基色光以不同的比例混合,可模拟出自然界中绝大多数景色的光.RGB三基色相互独立的含义是指,任一种基色都不能由另外两种基色混合而产生.三基色的选择并不是唯一的.</p>
<h5 id="1-1-1-4-像素-pixel"><a href="#1-1-1-4-像素-pixel" class="headerlink" title="1.1.1.4 像素(pixel)"></a>1.1.1.4 像素(pixel)</h5><p>像素是计算机图形与图像中能被单独处理的最小基本单元.
从像素的视觉属性看,它是一个最小可是单位.一幅彩色图像可以看成是由许多很小的可是点组成的,这个点就是像素.每个像素点都有确定的颜色和亮度,这个颜色就是有互相独立的红,绿,蓝三种基色光以不同的比例混合而成的.
从像素的量值属性看,它的数据结构应同时显示地址,色彩,亮度等数据信息,这些数据就称为像素值.</p>
<h4 id="1-1-2-颜色模型"><a href="#1-1-2-颜色模型" class="headerlink" title="1.1.2 颜色模型"></a>1.1.2 颜色模型</h4><p>颜色模型(或称色彩模型)就是定量颜色方法.在不同的领域应用于图像时,为了尽可能多地,有效地描述各种颜色,往往采用不同的颜色模型,例如,用显示器这类发光物体显示时采用的是RGB模型,用打印机这类吸光物体输出图像时用CMY模型,进行彩色电视信号的显示与传输时采用YUV模型,从事艺术绘画时习惯采用HSL模型.</p>
<h5 id="1-1-2-1-RGB模型"><a href="#1-1-2-1-RGB模型" class="headerlink" title="1.1.2.1 RGB模型"></a>1.1.2.1 RGB模型</h5><p>RGB模型也称为加色法混色模型.其混色规律是:以等量的红,绿,蓝基色光混合时:</p>
<ul>
<li>红 + 绿 = 黄色</li>
<li>红 + 蓝 = 品红色</li>
<li>绿 + 蓝 = 青色</li>
<li>红 + 绿 + 蓝 = 白色</li>
<li>3种基色光全无 = 黑色</li>
</ul>
<p>加色法的混色规律可以使用下图表示,3个圆分别红绿蓝3种基色,圆与圆的叠加区域表示以等量的基色相混合时所合成的颜色,其色调如该区域的文字表示.当3种基色等量相加时,就会得到白色.其中,又尝尝把品红色成为绿色的补色,青色称为红色的补色,黄色称为蓝色的补色.
<img src="http://images.wodekouwei.com/media/rgb.png" alt="image">
物体的颜色是丰富多彩的,任何一种颜色和这3种基色之间的关系可以用下面的配色方程式来描述:
F(物体颜色)=R(红色的百分比) + G(绿色的百分比) + B(蓝色的百分比)</p>
<p>由于人类的视觉特性,两种或3种基色产生混色效果,不一定要同时和同一空间位置混合.例如,在心理学实验中有一个色轮实验,它是在可旋转的圆盘上按扇形面积均等的分成3部分,并涂上3种基色,当圆盘慢慢旋转时能够分辨出3中基色,但当圆盘旋转的频率提高到闪光融合频率以上时,人眼不再能分辨出3种基色,而产生白颜色的感觉,以达到混色的效果.这就是 <strong>“时间混色法”</strong> .最初的顺序制彩色电视就应用了人的这一视觉效果.例如,很细小的红点和旅店均匀间置互相靠的很近,只有在近距离仔细观看才能区分出来,当观看距离很远时就只感觉到黄色的一篇了,这就是 <strong>“空间混色法”</strong> .目前广泛使用的彩色显像管以及大型LED真彩色广告屏就是利用了这一混色视觉效应.</p>
<p>在多媒体技术中,RGB颜色模型是最基本的模型,因为彩色显示器只有按RGB分量式输入,才能在显示屏幕上合成任意颜色.</p>
<h5 id="1-1-2-2-CMY模型"><a href="#1-1-2-2-CMY模型" class="headerlink" title="1.1.2.2 CMY模型"></a>1.1.2.2 CMY模型</h5><p>CMY(Cyan Magenta Yellow)模型是采用青,品红,黄色3种基本颜色按一定比例合成颜色的方法.CMY模型又称为减色法混色模型,因为色彩的显示不是直接来自于光线的色彩,而是光线被物体吸收掉一部分之后发射回来的剩余光线所产生的.光线都被吸收时称为黑色,当光线都被反射时成为白色.这种模式适合于彩色打印机等用彩色墨水或颜料进行混合显示的情况.</p>
<p>在相减混色中,当3种基本颜色等量相减时得到黑色;等量黄色(Y)和品红(M)相减而青色为0时,等到红色(R);等量青色(C)和品红(M)相减而黄色为0时,得到蓝色(B);等量黄色(Y)和青色(C)相减而品红(M)为0时,得到绿色(G).</p>
<p>由于颜料的化学特性,实际上等量的CMY混合后并不能产生真正的黑色,因此在印刷时通常再加上黑色(Black),这样又称为CMYK模式,四色印刷便是由此而来.</p>
<p>显然,RGB与CMY模型是颜色互补的模型,它们之间可以互相转换.如果按每个像素每种颜色用一位二进制数表示的话,RGB与CMY模型之间的颜色关系如下表所示.利用它们之间的关系,可以把显示器显示的颜色转换成打印的颜色.但实际上因为发射光与反射光的性质完全不同,显示器上的颜色不可能精确地在打印机上复制出来,因此实际的转换过程会利用一定的算法进行一定程度上的失真补偿.
|RGB|CMY|颜色|
|—|—|—|
|000|111|黑|
|001|110|蓝|
|010|101|绿|
|011|100|青|
|100|011|红|
|101|010|品红|
|110|001|黄|
|111|000|白|</p>
<h5 id="1-1-2-3-YUV与YIQ模型"><a href="#1-1-2-3-YUV与YIQ模型" class="headerlink" title="1.1.2.3 YUV与YIQ模型"></a>1.1.2.3 YUV与YIQ模型</h5><p>在彩色电视系统中不采用RGB颜色模型,而采用YUV或YIQ模型表示彩色图像.YUV适用于PAL(Phase Altermation Line,同行倒相制式)和SECAM(法文)(Sequential C欧了让Memo,顺序传送彩色与存储制式)彩色电视制式,而YIQ适用于美国国家电视标准委员会(NTSC,National Television System Committee)彩色电视制式.</p>
<p>Y是亮度信号,U和V则是两个色差信号,分别传送红基色分量和蓝基色分量与亮度分量的差值信号.</p>
<p>采用YUV颜色模型的好处是:其一,亮度信号Y解决了彩色电视与黑白电视的兼容性问题;其二,由于人眼对颜色细节的分辨率低于对亮度细节的分辨率,所以可以用一个通道来传送,Y,U,V这3个信号,给亮度信号较大的带宽(6MHz)来传送图像的细节,而给色差信号较小的带宽(1.3MHz)来进行大面积涂色.这样,总的传输数据量和RGB模型相比,要明显小一些,起到了一种数据压缩节省存储空间的作用,而对于这种数据压缩带来的画面变化人眼一般是感觉不到的.</p>
<p>电视系统通常采用摄像机把摄得的彩色图像信号经分色,放大和校正分成RGB这3个分量的信号,再经过矩阵变换电路将彩色信号分解成亮度信号Y和色差信号,U,V,而后对其进行编码,用同一信道发送出去.接收端再通过编码及矩阵逆变换还原成3个基色显示.</p>
<p>在NTSC彩色电视制式中使用YIQ模型,其特性与YUV模型相近.其中的Y表示亮度,I,Q也是两个色差分量,但它们在色度矢量图中与U,V的位置不同.Q,I正交坐标轴与U,V正交坐标轴之间有33度夹角,如图所示:</p>
<p><img src="http://images.wodekouwei.com/media/yuv_yiq.bmp" alt="image"></p>
<p>I,Q与U,V之间的关系如下:
I = Vcos33 - Usin33
Q = Vsin33 + Ucos33</p>
<p>人眼的彩色视觉特性表明,人眼分辨红与黄之间的颜色变化的能力最强,而分辨蓝,紫之间颜色变化的能力最弱.因此YIQ模型在色度矢量图中,选择I轴正好处于夹角123度处,即人眼具有最大彩色分辨率的红与黄之间的橙色和青色(相角为303度)处,选择与I轴正交的色度信号轴为Q轴(相角为33度),正是人眼最不敏感的色轴位置.因而YIQ模型传送分辨力较强的I信号时,用较宽的频带(1.3MHz~1.5MHz),传送分辨力弱的Q信号时,可用较窄的频带(0.5MHz),这就可以在保证较好的颜色传输特性情况下,最大限度地节省存储空间.</p>
<h5 id="1-1-2-4-HSI颜色模型"><a href="#1-1-2-4-HSI颜色模型" class="headerlink" title="1.1.2.4 HSI颜色模型"></a>1.1.2.4 HSI颜色模型</h5><p>HSI或HSL是Hue Saturation Intensity(Lightness)的英文缩写,颜色模型用H,S,I这三个参数描述颜色特性,其中H定义颜色的波长,称为色调;S表示颜色的深浅程度,称为饱和度;I表示强度或亮度,这正是颜色的三要素.</p>
<p>HSI模型更接近人对颜色更接近人对彩色的认识,符合人眼对颜色的感知方式,是一种从事艺术绘画的画家们习惯使用的描述色彩的方法.它比RGB模型使用更方便,从而能减少彩色图像处理的复杂性,增加快速性,因此一般的图像处理软件中,都提供了这种定量色彩的方式.</p>
<h4 id="1-1-3-颜色模型的转换"><a href="#1-1-3-颜色模型的转换" class="headerlink" title="1.1.3 颜色模型的转换"></a>1.1.3 颜色模型的转换</h4><p>无论采用什么颜色模型来表示彩色图形与图像,由于所有的显示器都需要RGB值来驱动,所以在显示每个像素之前,必须要把彩色分量值转换成RGB值.</p>
<h5 id="1-1-3-1-YUV与RGB颜色模型变换"><a href="#1-1-3-1-YUV与RGB颜色模型变换" class="headerlink" title="1.1.3.1 YUV与RGB颜色模型变换"></a>1.1.3.1 YUV与RGB颜色模型变换</h5><p>RGB与YUV的对应关系可以近似地用下面的方程表示:</p>
<ul>
<li>Y = 0.299R + 0.587G + 0.114B</li>
<li>U = -0.147R - 0.289G + 0.436B</li>
<li>V = 0.615R - 0.515G - 0.096B<h5 id="1-1-3-2-YIQ与RGB颜色模型变换"><a href="#1-1-3-2-YIQ与RGB颜色模型变换" class="headerlink" title="1.1.3.2 YIQ与RGB颜色模型变换"></a>1.1.3.2 YIQ与RGB颜色模型变换</h5>YIQ与RGB的对应关系可以近似地用下面的方程表示:</li>
<li>Y = 0.229R + 0.587G + 0.114B</li>
<li>I = 0.596R - 0.275G - 0.321B</li>
<li>Q = 0.212R - 0.523G + 0.311B</li>
</ul>
<h5 id="HSI-与-RGB颜色变换"><a href="#HSI-与-RGB颜色变换" class="headerlink" title="HSI 与 RGB颜色变换"></a>HSI 与 RGB颜色变换</h5><p>HSI与RGB空间的转换关系可以用下面的方程表示:</p>
<ul>
<li>H = [90 - arctan(F/sqr(3)) + [0, G&gt;B;180,G&lt;B]]/360</li>
<li>S = 1 - min(R,G,B)/I</li>
<li>I = (R+G+B)/3
其中,F=(2R-G-B)/(G-B),sqr为求平方根</li>
</ul>
<h3 id="1-2图形与图像的基本属性"><a href="#1-2图形与图像的基本属性" class="headerlink" title="1.2图形与图像的基本属性"></a>1.2图形与图像的基本属性</h3><p>一幅彩色图像可以看成二维连续函数f(x,y),其彩色幅度是位置(x,y)的函数.计算机多媒体技术从其图像的生成,显示,处理和存储的机制出发,需要对彩色图像数字化.数字化一幅彩色图像就是要把连续函数f(x,y)在空间的坐标和彩色幅度进行离散和量化.空间坐标x,y的离散化通常以分辨率来表征,而彩色幅度的离散化则由像素的颜色深度来表征.</p>
<h4 id="1-2-1分辨率"><a href="#1-2-1分辨率" class="headerlink" title="1.2.1分辨率"></a>1.2.1分辨率</h4><p>分辨率是一个统称,分为显示分辨率,图像分辨率,扫描分辨率和打印分辨率等.</p>
<h5 id="1-2-1-1显示分辨率"><a href="#1-2-1-1显示分辨率" class="headerlink" title="1.2.1.1显示分辨率"></a>1.2.1.1显示分辨率</h5><p>是指某一种显示方式下,显示屏上能够显示出的像素数目,以水平和垂直的像素表示.例如,显示分辨率为640*480表示显示屏分成480行,每行显示640个像素,整个显示屏就含有307200个显像点.屏幕上的像素越多,分辨率就越高,显示出来的图像也就越细腻,显示的图像质量也就约高.屏幕能够显示的最大像素数目越多,也说明显示设备的最大分辨率越高.显示屏上的每个彩色像素由代表R,G,B这3种模拟信号的相对强度决定,这些彩色像素点就构成一幅彩色图像.</p>
<h5 id="1-2-1-2图像分辨率"><a href="#1-2-1-2图像分辨率" class="headerlink" title="1.2.1.2图像分辨率"></a>1.2.1.2图像分辨率</h5><p>图像分辨率指数字化图像的大小,以水平和垂直的像素数表示.如果组成图像的像素数目越多,则说明图像的分辨率越高,看起来就越逼真,图像分辨率实际上决定了图像的显示质量,也就是说,即使提高了显示分辨率,也无法真正改善图像的质量.图像分辨率与显示分辨率是两个不同的概念.图像分辨率的确定组成一幅图像的像素数目,而显示分辨率是确定显示图像的区域大小.当图像分辨率与屏幕分辨率一致时,图像正好占据满屏;当图像分辨率小于屏幕分辨率时,图像占据屏幕的一部分;当图像分辨率大于屏幕分辨率时,则屏幕仅能显示图像的一部分.</p>
<h5 id="1-2-1-3扫描分辨率和打印分辨率"><a href="#1-2-1-3扫描分辨率和打印分辨率" class="headerlink" title="1.2.1.3扫描分辨率和打印分辨率"></a>1.2.1.3扫描分辨率和打印分辨率</h5><p>在用于扫描仪扫描图像时,通常要指定扫描的分辨率,用每英寸包含的点(d/i,dots per inch)表示.如果用300d/i来扫描一幅8<em>6的彩色图像,就得到一幅2400</em>1800个像素的图像.分辨率越高,像素就越多.</p>
<p>打印分辨率是指图像打印时每英寸可识别的点数,也使用d/i(dots per inch)为衡量单位.两种分辨率之间是有区别的,扫描分辨率反映了扫描后的图像与原始图像之间的差异程度,分辨率越高,差异越小.打印分辨率反映了打印的图像与原数字图像之间的差异程度,分辨率越接近原图像的分辨率,打印质量越高.两种分辨率的最高值都受到设备的限制.</p>
<h4 id="1-2-2颜色深度"><a href="#1-2-2颜色深度" class="headerlink" title="1.2.2颜色深度"></a>1.2.2颜色深度</h4><p>颜色深度是指图像中每个像素的颜色(或亮度)信息所占的二进制数位数,记做位/像素(b/p,bits per pixel).屏幕上的每一个像素都占有一个或多个位,用于存放与它相关的颜色信息.颜色深度决定了构成图像的每个像素可能出现的最大颜色数,因而颜色深度值越高,显示的图像色彩越丰富.反之,颜色深度太浅,会影响图像的质量,图像看起来让人觉得很粗糙和很不自然.常见颜色深度有一下5种:</p>
<ol>
<li>4bit:这是VGA标准支持的颜色深度,共2的四次方16种颜色;</li>
<li>8bit:这是多媒体应用中的最低颜色深度,共2的8次方256种颜色,称为索引彩色图(由颜色查找决定);</li>
<li>16bit:在16bit中,用其中的15bit表示RGB这3种颜色,每种颜色5bit,用剩余的以为表示图像的其他属性,如透明度.所以16bit的颜色深度实际可以表示为2的15次方32<em>32</em>32共32768种颜色.称为HI-Color(高彩色)图像.</li>
<li>24bit:用3个8bit分别表示RGB,可生成的颜色数2的24次16777216种,约16M种颜色,这已经成为真彩色;</li>
<li>32bit:同24bit颜色深度一样,也是用3个bit分别表示RGB这三种颜色,剩余的8bit用来表示图像的其他属性,如透明度等.</li>
</ol>
<p>虽然像素的颜色颜色深度值越大图像色彩越丰富,但由于设备的限制,人眼分辨率的限制,不一定要追求特别深的颜色深度,一般来说,32bit的颜色深度已经足够.此外,像素颜色深度越深,所占用的存储空间越大.</p>
<p>一个像素的颜色深度位数除R,G,B分量占用固定bit数表示颜色外,一般要腾出1bit或几bit作为属性(Attribute)位.属性位用来指定该像素应具有的性质.例如,像素的颜色深度为32bit时,R,G,B分别用8bit表示,那么余下的8bit常称为a通道(Alpha Channel)位,或称为覆盖(Overlay)位,中断位,属性位,它用来控制该像素点的透明度.假如定义一个像素值(A,R,G,B)的4个分量(其中A为Alpha属性位数值)都用归一化的数值表示,那么像素91,1,0,0)时显示红色.当像素为(0.5,1,0,0)时,预乘的结果就变成了(0.5.0.5,0,0),这表示现在显示的红色的强度减低一半.用这种定义像素属性的办法可以实现两幅彩色图像之间的透明叠加效果.当Alpha数值很小时,渲染出来的效果是几乎透明的,如玻璃;当Alpha数值处于中间的位置时,则可以得到一种半透明的效果;当Alpha数值接近255时,是几乎不透明的效果.这种属性位的加入为实现透明和半透明的显示掉过带来了方便.</p>
<h4 id="1-2-3文件的大小"><a href="#1-2-3文件的大小" class="headerlink" title="1.2.3文件的大小"></a>1.2.3文件的大小</h4><p>图形和图像文件的大小(也称为数据量)是指在磁盘上存储整幅图像所有点的字节数(Bytes),反映了图像所需数据存储空间的大小,可按下面的公式计算:
<strong>文件字节数 = 图像分辨率 * 图像深度/8</strong></p>
<p>从公式看,图像文件的大小与图像的颜色和内容无关.其实在实际应用中,为了节省存储空间,总要对图像应用某种压缩文件格式.这样,不同的图像会因为内容的不同而使文件的大小有所不同.相对于颜色层次多,图形复杂的图像文件较大.但各种图像文件的最大值(文件字节数)都不会超越由上式决定的字节数.</p>
<h4 id="1-2-4-真彩色-伪彩色与直接色"><a href="#1-2-4-真彩色-伪彩色与直接色" class="headerlink" title="1.2.4 真彩色,伪彩色与直接色"></a>1.2.4 真彩色,伪彩色与直接色</h4><ol>
<li>真彩色(True Color):真彩色是指在组成一幅彩色图像的每个像素值中,有R,G,B这3个基色分量,每个基色分量直接决定显示设备的基色强度,这样产生的彩色称为真彩色.例如,用RGB的8:8:8方式表示一幅彩色图像,就是R,G,B都用8bit来表示,每个基色分量占一个字节,共3个字节,每个像素的颜色就是由这3字节中的数值直接决定,可生成的颜色数就是2的24次中,共计16777216中.</li>
<li>伪彩色(Pseudo Color)
伪彩色图像是每个像素的颜色不是由每个基色分量的数值直接决定,而是把像素值当做彩色查找表(CLUT,Color-Look-Up Table)的表项入口地址,去查找一个显示图像时使用的RGB强度值,用查找出的R,G,B强度值产生的彩色称为伪彩色.彩色查找表是一个事先制作好的表,表项入口地址也称为索引号.彩色图像本身的像素值和彩色查找表中的索引号有一个变换关系,也可以是用自己定义的变换关系.使用查找得到的数值在显示器上显示的颜色是真的,但不是图像本身真正的颜色,因此称其为伪彩色;</li>
<li>直接色(Direct Color):把像素值的R,G,B分量作为单独的索引值,通过相应的彩色变换表找出R,G,B各自的基色程度,用这个强度值产生的彩色称其为直接色.真彩色系统虽然也是采用R,G,B分量来决定基色强度,但这是由R,G,B经变换后决定的,这与直接用R,G,B决定基色基色强度产生的颜色就有差别.比较而言,直接色在显示器上显示彩色图像看起来更真实,更自然.</li>
</ol>
<p>伪彩色系统是把整个像素当做查找表的索引值进行彩色变换,而直接色系统是对R,G,B分量分别采用查找表进行变换,因此伪彩色系统色彩还原度自然就查多了.</p>
<h3 id="1-3图形与图像的基本类型"><a href="#1-3图形与图像的基本类型" class="headerlink" title="1.3图形与图像的基本类型"></a>1.3图形与图像的基本类型</h3><h4 id="1-3-1位图与矢量图"><a href="#1-3-1位图与矢量图" class="headerlink" title="1.3.1位图与矢量图"></a>1.3.1位图与矢量图</h4><ol>
<li><p>位图(Bit-mapped Graphics)</p>
</li>
<li><p>矢量图(Vector Graphic)</p>
</li>
<li><p>位图和矢量图的关系</p>
</li>
</ol>
<h4 id="1-3-2-图形与图像的区别与联系"><a href="#1-3-2-图形与图像的区别与联系" class="headerlink" title="1.3.2 图形与图像的区别与联系"></a>1.3.2 图形与图像的区别与联系</h4><h2 id="2-图形与图像的处理"><a href="#2-图形与图像的处理" class="headerlink" title="2.图形与图像的处理"></a>2.图形与图像的处理</h2><h3 id="2-1图形与图像的获取"><a href="#2-1图形与图像的获取" class="headerlink" title="2.1图形与图像的获取"></a>2.1图形与图像的获取</h3><h4 id="2-1-1-图形与图像的数字化"><a href="#2-1-1-图形与图像的数字化" class="headerlink" title="2.1.1 图形与图像的数字化"></a>2.1.1 图形与图像的数字化</h4><h4 id="2-1-2-图形的获取"><a href="#2-1-2-图形的获取" class="headerlink" title="2.1.2 图形的获取"></a>2.1.2 图形的获取</h4><h4 id="2-1-3-图像的获取"><a href="#2-1-3-图像的获取" class="headerlink" title="2.1.3 图像的获取"></a>2.1.3 图像的获取</h4><h3 id="2-2图形与图像的存储"><a href="#2-2图形与图像的存储" class="headerlink" title="2.2图形与图像的存储"></a>2.2图形与图像的存储</h3><h4 id="2-2-1静态图形与图像常见文件存储格式"><a href="#2-2-1静态图形与图像常见文件存储格式" class="headerlink" title="2.2.1静态图形与图像常见文件存储格式"></a>2.2.1静态图形与图像常见文件存储格式</h4><h4 id="2-2-2-动态图形与图像常见文件存储格式"><a href="#2-2-2-动态图形与图像常见文件存储格式" class="headerlink" title="2.2.2 动态图形与图像常见文件存储格式"></a>2.2.2 动态图形与图像常见文件存储格式</h4><h4 id="2-2-3-文件存储格式的数据结构"><a href="#2-2-3-文件存储格式的数据结构" class="headerlink" title="2.2.3 文件存储格式的数据结构"></a>2.2.3 文件存储格式的数据结构</h4><h3 id="2-3图形与图像的显示"><a href="#2-3图形与图像的显示" class="headerlink" title="2.3图形与图像的显示"></a>2.3图形与图像的显示</h3><h4 id="2-3-1映射显示原理"><a href="#2-3-1映射显示原理" class="headerlink" title="2.3.1映射显示原理"></a>2.3.1映射显示原理</h4><h4 id="2-3-2硬复制设备"><a href="#2-3-2硬复制设备" class="headerlink" title="2.3.2硬复制设备"></a>2.3.2硬复制设备</h4><h3 id="2-4图形与图像的处理"><a href="#2-4图形与图像的处理" class="headerlink" title="2.4图形与图像的处理"></a>2.4图形与图像的处理</h3><h4 id="2-4-1-图形与图像处理的基本内容"><a href="#2-4-1-图形与图像处理的基本内容" class="headerlink" title="2.4.1 图形与图像处理的基本内容"></a>2.4.1 图形与图像处理的基本内容</h4><h4 id="2-4-2-图像处理实例分析-图像识别"><a href="#2-4-2-图像处理实例分析-图像识别" class="headerlink" title="2.4.2 图像处理实例分析-图像识别"></a>2.4.2 图像处理实例分析-图像识别</h4><h4 id="2-4-3-图形与图像处理软件"><a href="#2-4-3-图形与图像处理软件" class="headerlink" title="2.4.3 图形与图像处理软件"></a>2.4.3 图形与图像处理软件</h4><h2 id="3-计算机动画"><a href="#3-计算机动画" class="headerlink" title="3.计算机动画"></a>3.计算机动画</h2><h3 id="3-1计算机动画的原理"><a href="#3-1计算机动画的原理" class="headerlink" title="3.1计算机动画的原理"></a>3.1计算机动画的原理</h3><h3 id="3-2计算机动画的类型"><a href="#3-2计算机动画的类型" class="headerlink" title="3.2计算机动画的类型"></a>3.2计算机动画的类型</h3><h3 id="3-3计算机动画的制作"><a href="#3-3计算机动画的制作" class="headerlink" title="3.3计算机动画的制作"></a>3.3计算机动画的制作</h3><h3 id="3-4虚拟现实动画技术"><a href="#3-4虚拟现实动画技术" class="headerlink" title="3.4虚拟现实动画技术"></a>3.4虚拟现实动画技术</h3>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/18/tips-qt-pack/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/18/tips-qt-pack/" itemprop="url">
                  mac下打包qt程序成dmg
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-18T19:06:08+08:00">
                2017-06-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/QT/" itemprop="url" rel="index">
                    <span itemprop="name">QT</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>参考<a href="http://doc.qt.digia.com/4.7-snapshot/appicon.html" target="_blank" rel="external">http://doc.qt.digia.com/4.7-snapshot/appicon.html</a></li>
<li>图片格式在线转换<a href="http://iconverticons.com/，可以生成icns格式图片。" target="_blank" rel="external">http://iconverticons.com/，可以生成icns格式图片。</a></li>
<li>Test.pro中添加macx{ICON = Test.icns} （记得把Test.icns添加到工程中）</li>
<li>发布dmb包</li>
</ol>
<ul>
<li>QT在mac下有个发布命令：<code>macdeployqt</code></li>
<li>我的mac上macdeployqt目录如下：<code>/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin</code></li>
<li>将macdeployqt的路径添加到环境变量里面
终端里 <code>vim /etc/profile</code>（如果在保存时有问题，可以用 <code>sudo vim /etc/profile</code>）<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#在最后添加一行，如下所示：</div><div class="line"># System-wide .profile for sh(1)</div><div class="line"></div><div class="line">if [ -x /usr/libexec/path_helper ]; then</div><div class="line"></div><div class="line">        eval `/usr/libexec/path_helper -s`</div><div class="line"></div><div class="line">fi</div><div class="line"></div><div class="line">if [ &quot;$&#123;BASH-no&#125;&quot; != &quot;no&quot; ]; then</div><div class="line"></div><div class="line">        [ -r /etc/bashrc ] &amp;&amp; . /etc/bashrc</div><div class="line"></div><div class="line">fi</div></pre></td></tr></table></figure>
</li>
</ul>
<p><code>export PATH=/Users/duobianxing/QtSDK/Desktop/Qt/4.8.1/gcc/bin:$PATH</code></p>
<ul>
<li>cd进入到Test.app所在目录，然后执行<code>macdeployqt extractor.app -verbose=1 -dmg</code>，即可生成Test.dmg包。</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/18/tips-seekto/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/18/tips-seekto/" itemprop="url">
                  mpeg编码seekto方法精确定位到指定帧
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-18T18:11:40+08:00">
                2017-06-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://developer.android.com/intl/es/reference/android/media/MediaExtractor.html" target="_blank" rel="external">MediaExtractor</a>有一个方法如下:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">//All selected tracks seek near the requested time according to the specified mode.</div><div class="line">public void seekTo (long timeUs, int mode)</div></pre></td></tr></table></figure></p>
<p>timeUs是要seek的时间戳，mode是seek的模式，可以是SEEK_TO_PREVIOUS_SYNC, SEEK_TO_CLOSEST_SYNC, SEEK_TO_NEXT_SYNC，分别是seek指定帧的上一帧，最近帧和下一帧。
此方法可用于视频播放时动态定位播放帧，用于动态改变视频播放进度，比如使用seekBar来跟踪视频播放进度，同时可拖动来动态改变播放进度。</p>
<p>mpeg编码决定seekTo方法无法精确定位到指定帧。即使使用的是某一帧精确的时间戳作为seekTo方法的输入参数也无法实现精确定位。</p>
<p>在google, stackoverlfow查询得出的结论是：在每次seekTo方法调用后，MediaCodec必须从关键帧开始解码。因此seekTo方法只会seek到最近的／上一个／下一个关键帧，也就是I-Frame(key frame = I frame = sync frame)。之所以要从关键帧开始解码，是因为每一帧不一定是单独编码的，只有I frame才是帧内编码，而P, B frame都是要参考别的帧来进行编码，因此单独拿出来是不完整的一帧。</p>
<p>stackoverflow上有人对此的做法是：seekTo的输入参数mode设置为SEEK_TO_PREVIOUS_SYNC,即seek的是指定帧的上一个关键帧。然后判断当前的时间戳是否小于定位关键帧的时间戳，如果是就调用MediaExtractor的advance方法，“快进”到指定帧。
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">extractor.seekTo(expectedPts, MediaExtractor.SEEK_TO_PREVIOUS_SYNC);  </div><div class="line">while (currentPts &lt; expectedPts) &#123;  </div><div class="line">    extractor.advance();  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>但是这个方法仍不理想，如果seek的位置和当前位置比较远的话，会有一定延迟。而且视频内容偶尔会出现不完整的帧的闪现。
经过一段时间的研究，终于解决了这个问题，现在播放时可以根据seekBar随时拖动到视频任何一帧，不会有任何延迟，甚至可以实现倒播了。
因为之前播放视频的是自己用MediaCodec, MediaMuxer等编码合成的视频文件，在编码参数设置的时候，将关键帧间隔KEY_I_FRAME_INTERVAL设置为了1（因为要求参数为整数）。注意这个参数的单位是秒，而不是帧数！网上看到很多例子包括fadden的bigflake和Grafika上都将这里设置为了20几。搞得我一开始还以为是每隔二十几帧就有一个关键帧。如果设置为20几，那么就是说你用MediaCodec编码录制一段20多秒的视频，只有开头的一个关键帧！剩下的都是P或者B帧。
这显然是不合理的。一般来说是每隔1秒有一个关键帧，这样就可以seek到对应秒的关键帧。或者说1秒内如果有30帧，那么这30帧至少有一个关键帧。因此我将KEY_I_FRAME_INTERVAL设置为了1。
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 1);</div></pre></td></tr></table></figure></p>
<p>这也是为什么我在播放用这种参数编码的视频的时候，使用seekTo方法不能准确定位帧了。之前有讲，seekTo是定位到关键帧的，如果不是关键帧，那么它会去找上一个／最近一个／下一个关键帧，这取决于你输入参数mode的设置。
因此如果想使用seekBar准确拖动定位到任何一帧播放，必须保证每一帧都是关键帧。
于是，我将KEY_I_FRAME_INTERVAL设置为了0：
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mediaFormat.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, 0);</div></pre></td></tr></table></figure></p>
<p>事实也证明这样可以保证录制的每一帧都是关键帧，因此在使用seekTo方法的时候终于可以准确定位任何一帧了。拖动seekBar的时候视频内容也会立刻改变，无论是往前还是往后，都不会有任何延迟和画面不完整的情况.
但是，把视频每一帧都设置为关键帧是否合理呢？是否会占太大空间呢？
带着这个疑问，我使用ffmpeg查看了我测试使用的手机（Lenovo X2)内置相机录制的视频。
只需一行代码：
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ffprobe -show_frames video.mp4  &gt; frames.txt</div></pre></td></tr></table></figure></p>
<p>打开frames.txt可以看到每一帧的key_frame=1，表示是关键帧</p>
<p>这说明了手机本来录像就是把每一帧都作为关键帧的。
当然，不能以偏概全，于是我使用iPhone 6s录制的一段普通视频和慢动作视频。使用ffmpeg查看，发现每一帧也都是关键帧（慢动作视频1秒有240帧也都全部作为关键帧也是蛮拼的）。</p>
<p>目前我测试的两部手机都是如此，具体为什么手机录的视频每一帧都是关键帧我也不明白。而视频文件体积大小和是否将每一帧设为关键帧似乎不成线性关系，所以将KEY_I_FRAME_INTERVAL设置为0的方案是可行的。
因此只要保证视频每帧都是关键帧，那么seekTo方法就可以精确定位指定帧了。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/07/media-intro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/07/media-intro/" itemprop="url">
                  多媒体技术简介
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-07T22:28:19+08:00">
                2017-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="关键帧间隔"><a href="#关键帧间隔" class="headerlink" title="关键帧间隔"></a>关键帧间隔</h4><p>关键帧包含了显示帧需要的所有信息</p>
<p>所有的视频都至少包含一个关键帧，作为文件的第一个帧。其它的关键帧可用来改善视频的质量，不过它们也会增加文件大小。一般而言，每一秒视频至少需要使用 1 个关键帧。若使用此公式，在每秒播放 25个帧的视频中，每 25 个帧就会有 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。</p>
<p>两种彩电视频制式：</p>
<ul>
<li>NTSC (525 lines @ 59.94 Hz)  29.97 fps</li>
<li>PAL (625 lines @ 50 Hz)  25 fps</li>
</ul>
<p>NTSC和PAL属于全球两大主要的电视广播制式，但是由于系统投射颜色影像的频率而有所不同。NTSC是National Television System Committee的缩写，其标准主要应用于日本、美国，加拿大、墨西哥等等，PAL 则是Phase Alternating Line的缩写，主要应用于中国，香港、中东地区和欧洲一带。</p>
<p>GOP最大可含帧数目：18 (NTSC) / 15 (PAL)</p>
<p>GOP是由固定模式的一系列I帧、P帧、B帧组成。
I帧编码是为了减少空间域冗余，P帧和B帧是为了减少时间域冗余。
常用的结构由15个帧组成，具有以下形式IBBPBBPBBPBBPBB。简称GOP(4,2)，指的是该图像组除了一个I帧外，包含了4个P帧，并且任何两个P帧或者I、P之间都有两个B帧。</p>
<p>GOP（Group of Pictures）策略影响编码质量：所谓GOP，意思是画面组，一个GOP就是一组连续的画面。MPEG编码将画面（即帧）分为I、P、B三种，I是内部编码帧，P是前向预测帧，B是双向内插帧。简单地讲，I帧是一个完整的画面，而P帧和B帧记录的是相对于I帧的变化。没有I帧，P帧和B帧就无法解码，这就是MPEG格式难以精确剪辑的原因，也是我们之所以要微调头和尾的原因。</p>
<p>MPEG-2 帧结构
　　MPEG-2压缩的帧结构有两个参数，一个是GOP（Group Of Picture）图像组的长度，一般可按编码方式从1－15；另一个是I帧和P帧之间B帧的数量，一般是1－2个。前者在理论上记录为N，即多少帧里面出现一次I帧；后者描述为多少帧里出现一次P帧，记录为M。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/07/jni-intro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/07/jni-intro/" itemprop="url">
                  jni介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-07T22:23:23+08:00">
                2017-06-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="NDK技巧"><a href="#NDK技巧" class="headerlink" title="NDK技巧"></a>NDK技巧</h3><ol>
<li>加快ndk-build编译速度
NDK编译时加上-j参数,如:<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ndk-build -j4 # -j4,让make最多允许4个编译命令同时执行</div></pre></td></tr></table></figure>
</li>
</ol>
<p>测试后编译速度至少可以提高一倍</p>
<h3 id="C回调JAVA"><a href="#C回调JAVA" class="headerlink" title="C回调JAVA"></a>C回调JAVA</h3><ol>
<li><p>c中返回一个字符串</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">（*env）-&gt;NewStringUTF(env,&quot;Huazi 华仔&quot;);</div></pre></td></tr></table></figure>
</li>
<li><p>c中返回一个数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">.....................  </div><div class="line">  int i = 0;  </div><div class="line">  jintArray array;  </div><div class="line">  array =(*env)-&gt;NewIntArray(env,8);  </div><div class="line">  for(;i&lt;8;i++)  </div><div class="line"></div><div class="line">// 赋值成 0 ~ 7  </div><div class="line">      (*env)-&gt;SetObjectArrayElement(env,array,i,i);  </div><div class="line">  &#125;  </div><div class="line">  return array;</div></pre></td></tr></table></figure>
</li>
<li><p>c中使用调用传入的参数是数组array 是传入的数组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">.........  </div><div class="line"> int sum =0, i;  </div><div class="line"> int len = (*env)-&gt;GetArrayLength(env,array);  </div><div class="line"> jint *element =(*env)-&gt;GetIntArrayElement(env,array,0);  </div><div class="line"> for(i=0;i&lt;len;i++)  </div><div class="line"> &#123;  </div><div class="line">     sum+= *(element+i);  </div><div class="line"> &#125;  </div><div class="line"> return sum;</div></pre></td></tr></table></figure>
</li>
<li><p>c中调用java中类的方法 没有参数 只有返回值String</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">//()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型  </div><div class="line">JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123;  </div><div class="line">  jmethodID mid;  </div><div class="line">  jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名  </div><div class="line"> mid =(*env)-&gt;GetMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);//TestMethod java中的方法名  </div><div class="line"> jstring msg =(*env)-&gt;CallObjectMethod(env,object,mid); //object 注意下是jni传过来的jobject  </div><div class="line"> return msg;</div></pre></td></tr></table></figure>
</li>
<li><p>c中调用java中类的静态方法 没有参数 只有返回值String</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">//@&quot;()Ljava/lang/String;&quot; 表示参数为空 返回值是String类型</div><div class="line">JNIEXPORT jstring JNICALLJava_com_huazi_Demo_getCallBack(JNIENV env,jobject object)&#123;  </div><div class="line">    jmethodID mid;  </div><div class="line">    jclass cls =(*env)-&gt;FindClass(env,&quot;com/huazi/Demo&quot;); //后面是包名+类名  </div><div class="line">   mid =(*env)-&gt;GeStatictMethodID(env,cls,&quot;TestMethod&quot;,&quot;()Ljava/lang/String;&quot;);// TestMethod java中的方法名  </div><div class="line">   jstring msg =(*env)-&gt;CallStaticObjectMethod(env,cls,mid); //object 注意下是jni传过来的jobject  </div><div class="line">   return msg;  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/07/ffmpeg-compile-mac/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/07/ffmpeg-compile-mac/" itemprop="url">
                  FFMPEG编译之Mac
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-07T21:28:32+08:00">
                2017-06-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/FFMPEG/" itemprop="url" rel="index">
                    <span itemprop="name">FFMPEG</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Mac下FFMPEG使用"><a href="#Mac下FFMPEG使用" class="headerlink" title="Mac下FFMPEG使用"></a>Mac下FFMPEG使用</h3><p>There are a few ways to get FFmpeg on OS X.</p>
<ol>
<li>One is to build it yourself. Compiling on Mac OS X is as easy as any other <code>*</code>nix machine, there are just a few caveats(警告). The general procedure is get the source, then ./configure <flags>; make &amp;&amp; sudo make install, though specific configure flags are possible.</flags></li>
<li>Another is to use some “build helper” tool, to install it for you. For example, homebrew or macports, see the homebrew section in this document.</li>
<li>Alternatively, if you are unable to compile, or do not want to install homebrew, you can simply download a static build for OS X, but it may not contain the features you want. Typically this involves unzipping an FFmpeg distribution file [like .zip file], then running it from within the newly extracted files/directories.</li>
</ol>
<h3 id="手动编译FFMPEG"><a href="#手动编译FFMPEG" class="headerlink" title="手动编译FFMPEG"></a>手动编译FFMPEG</h3><h4 id="1-下载FFMPEG源码"><a href="#1-下载FFMPEG源码" class="headerlink" title="1.下载FFMPEG源码"></a>1.下载FFMPEG源码</h4><p>使用<code>git clone https://github.com/FFmpeg/FFmpeg</code>从github下载ffmpeg源码,切换到要使用的目标分支(这里使用release/3.3):<code>git checkout -b r3.3 origin/release/3.3</code>,或者直接从github下载分支<code>release/3.3</code>的压缩包,解压.</p>
<h4 id="2-准备Xcode"><a href="#2-准备Xcode" class="headerlink" title="2.准备Xcode"></a>2.准备Xcode</h4><p>Starting with Lion 10.7, Xcode is available for free from the Mac App Store and is required to compile anything on your Mac. Make sure you install the Command Line Tools from Preferences &gt; Downloads &gt; Components. Older versions are still available with an AppleID and free Developer account at ​developer.apple.com.</p>
<h4 id="3-准备HomeBrew工具"><a href="#3-准备HomeBrew工具" class="headerlink" title="3.准备HomeBrew工具"></a>3.准备HomeBrew工具</h4><p>To get ffmpeg for OS X, you first have to install ​Homebrew. If you don’t want to use Homebrew, see the section below.
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</div></pre></td></tr></table></figure></p>
<p>Then:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">brew install automake fdk-aac git lame libass libtool libvorbis libvpx \</div><div class="line">opus sdl shtool texi2html theora wget x264 x265 xvid yasm</div></pre></td></tr></table></figure></p>
<p>Mac OS X Lion comes with Freetype already installed (older versions may need ‘X11’ selected during installation), but in an atypical location: /usr/X11. Running freetype-config in Terminal can give the locations of the individual folders, like headers, and libraries, so be prepared to add lines like CFLAGS=<code>freetype-config --cflags</code> LDFLAGS=<code>freetype-config --libs</code> PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig:/usr/lib/pkgconfig:/usr/X11/lib/pkgconfig before ./configure or add them to your $HOME/.profile file.</p>
<h4 id="4-编译"><a href="#4-编译" class="headerlink" title="4.编译"></a>4.编译</h4><p>Once you have compiled all of the codecs/libraries you want, you can now download the FFmpeg source either with Git or the from release tarball links on the website. Study the output of ./configure –help and make sure you’ve enabled all the features you want, remembering that –enable-nonfree and –enable-gpl will be necessary for some of the dependencies above. A sample command is:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">git clone http://source.ffmpeg.org/git/ffmpeg.git ffmpeg</div><div class="line">cd ffmpeg</div><div class="line">./configure  --prefix=/usr/local/ffmpeg --enable-gpl --enable-nonfree --enable-libass \</div><div class="line">--enable-libfdk-aac --enable-libfreetype --enable-libmp3lame \</div><div class="line">--enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libopus --enable-libxvid</div><div class="line">make &amp;&amp; sudo make install</div></pre></td></tr></table></figure></p>
<p><code>--prefix</code>指定编译完成后安装路径,这里指定到<code>/usr/local/ffmpeg</code>,安装完成会在<code>/usr/local/ffmpeg</code>下生成:bin,include,lib,share四个目录</p>
<h3 id="安装环境介绍"><a href="#安装环境介绍" class="headerlink" title="安装环境介绍"></a>安装环境介绍</h3><p>A package consists of several related files which are installed in several directories. The configure step usually allows the user to specify the so-called install prefix, and is usually specified through the configure option configure –prefix=PREFIX, where PREFIX usually is by default /usr/local. The prefix specifies the common directory where all the components are installed.</p>
<p>The following directories are usually involved in the installation:</p>
<ul>
<li><code>PREFIX/bin</code>: contains the generated binaries (e.g. ffmpeg, ffplay, ffprobe etc. in the case of FFmpeg)</li>
<li><code>PREFIX/include</code>: contains the library headers (e.g. libavutil/avstring.h, libavcodec/avcodec.h, libavformat/avformat.h etc. in case of FFmpeg) required to compile applications linked against the package libraries</li>
<li><code>PREFIX/lib</code>: contains the generated libraries (e.g. libavutil, libavcodec, libavformat etc. in the case of FFmpeg)</li>
<li><code>PREFIX/share</code>: contains various system-independent components; especially documentation files and examples
By specifying the prefix it is possible to define the installation layout.</li>
</ul>
<p>By using a shared prefix like /usr/local/, different packages will be installed in the same directory, so in general it will be more difficult to revert the installation.</p>
<p>Using a prefix like /opt/PROJECT/, the project will be installed in a dedicated directory, and to remove from the system you can simply remove the /opt/PREFIX path. On the other hand, such installation will require to edit all the environment variables to point to the custom path.</p>
<h3 id="Environment-variables"><a href="#Environment-variables" class="headerlink" title="Environment variables"></a>Environment variables</h3><p>Several variables defined in the environment affect your package install. In particular, depending on your installation prefix, you may need to update some of these variables in order to make sure that the installed components can be found by the system tools.</p>
<p>The list of environment variables can be shown through the command env.</p>
<p>A list of the affected variables follows:</p>
<ul>
<li>PATH: defines the list of :-separated paths where the system looks for binaries. For example if you install your package in /usr/local/, you should update the PATH so that it will contain /usr/local/bin. This can be done for example through the command export PATH=/usr/local/bin:$PATH.</li>
<li>LD_LIBRARY_PATH: contains the :-separated paths where the system looks for libraries. For example if you install your package in /usr/local/, you should update the LD_LIBRARY_PATH so that it will contain /usr/local/lib. This can be done for example through the command export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH. This variable is sometimes deprecated in favor of the use of ldconfig.</li>
<li>CFLAGS: contains flags used by the C compiler, and usually includes preprocessing directives like -IPREFIX/include or compilation flags. Custom CFLAGS are usually prefixed to the source package compiler flags by the source package build system. Alternatively many build systems allow to specify the configure option -extra-cflags.</li>
<li>LDFLAGS: these are directives used by the linker, and usually include linking directives like -LPREFIX/lib needed to find libraries installed in custom paths. Custom LDFLAGS are usually prefixed to the source package linker flags by the source package build system. Alternatively, many build systems allow to specify the configure option -extra-ldflags.</li>
<li>PKG_CONFIG_PATH: contains the :-separated paths used by pkg-config to detect the pkg-config files used by many build systems to detect the custom CFLAGS/LDFLAGS used by a specific library.
In case you installed a package in a non standard path, you need to update these environment libraries so that system tools will be able to detect the package components. This is especially required when running a configure script for a package relying on other installed libraries/headers/tools.</li>
</ul>
<p>Environment variables are usually defined in the profile file, for example .profile defined in the user directory for sh/bash users, and in /etc/profile. This file can be edited to permanently set the custom environment. Alternatively, the variables can be set in a script or in a particular shell session.</p>
<p>Remember to export the variables to the child process, e.g. using the export command. Read the fine documentation of your shell for more detailed information.</p>
<h3 id="MAC下的动态链接库"><a href="#MAC下的动态链接库" class="headerlink" title="MAC下的动态链接库"></a>MAC下的动态链接库</h3><h4 id="扩展名"><a href="#扩展名" class="headerlink" title="扩展名"></a>扩展名</h4><p>Windows下.DLL,Linux下.so,Mac OS X下的扩展名是.dylib。
.dylib是Mach-O格式，也就是Mac OS X下的二进制文件格式。Mac OS X提供了一系列
工具，用于创建和访问动态链接库。</p>
<ul>
<li>编译器/usr/bin/cc，也就是gcc了，Apple改过的。这个主要还是一个壳，去调用其他
的一些部件。当然同时还有/usr/bin/c++，等等。</li>
<li>汇编器/usr/bin/as</li>
<li>链接器/usr/bin/ld</li>
</ul>
<h4 id="MAC下创建动态链接库步骤"><a href="#MAC下创建动态链接库步骤" class="headerlink" title="MAC下创建动态链接库步骤:"></a>MAC下创建动态链接库步骤:</h4><ol>
<li>首先是生成module文件，也就是.o文件。这跟一般的unix没什么区别。例如<code>cc -c a.c b.c</code>,就得到a.o和b.o</li>
<li>可以用ld来合并.o文件，比如<code>ld -r -o c.o a.o b.o</code></li>
<li>然后可以用libtool来创建动态链接库:<code>libtool -dynamic -o c.dylib a.o b.o</code>.（ 这里也可以用<code>libtool -static -o c.a a.o b.o</code>就创建静态库）</li>
</ol>
<p>如果用gcc直接编译，我记得linux下一般是可以:
<code>gcc -shared -o c.so a.c b.c</code>
而在Mac OS X下需要:
<code>gcc -dynamiclib -o c.dylib a.c b.c</code></p>
<h4 id="动态链接库的工具"><a href="#动态链接库的工具" class="headerlink" title="动态链接库的工具"></a>动态链接库的工具</h4><p>nm是最常用的，这个用法跟linux下差不多:<code>nm c.dylib</code>,可以看到导出符号表，等等。
另一个常用的工具是otool，这个是Mac OS X独有的。比如想看看c.dylib的依赖关系<code>otool -L c.dylib</code></p>
<h3 id="官网方法"><a href="#官网方法" class="headerlink" title="官网方法"></a>官网方法</h3><ul>
<li><a href="https://trac.ffmpeg.org/wiki/CompilationGuide/Generic" target="_blank" rel="external">CompilationGuide-Generic</a></li>
<li><a href="https://trac.ffmpeg.org/wiki/CompilationGuide/MacOSX" target="_blank" rel="external">CompilationGuide-MacOSX</a></li>
</ul>
<h3 id="编译ffmpeg3-3结果没有ffplay"><a href="#编译ffmpeg3-3结果没有ffplay" class="headerlink" title="编译ffmpeg3.3结果没有ffplay"></a>编译ffmpeg3.3结果没有ffplay</h3><p>因为系统没有sdl环境或sdl版本不匹配,ffmpeg3.3需要sdl2</p>
<p><a href="http://www.libsdl.org/download-2.0.php" target="_blank" rel="external">http://www.libsdl.org/download-2.0.php</a> 下载Source Code SDL2-2.0.5.zip - GPG signed,解压缩,执行命令:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">./configure  </div><div class="line">make  </div><div class="line">sudo make install</div></pre></td></tr></table></figure></p>
<p>进行编译</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/03/gl-fbo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/03/gl-fbo/" itemprop="url">
                  OpenGL Frame Buffer Object(FBO)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-03T18:57:30+08:00">
                2017-06-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenGL/" itemprop="url" rel="index">
                    <span itemprop="name">OpenGL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Update: Framebuffer object extension is promoted as a core feature of OpenGL version 3.0, and is approved by ARB combining the following extensions;</p>
<ul>
<li>EXT_framebuffer_object</li>
<li>EXT_framebuffer_blit</li>
<li>EXT_framebuffer_multisample</li>
<li>EXT_packed_depth_stencil</li>
</ul>
<hr>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>In <a href="http://www.songho.ca/opengl/gl_pipeline.html" target="_blank" rel="external">OpenGL rendering pipeline</a>, the geometry data and textures are transformed and passed several tests, and then finally rendered onto a screen as 2D pixels. The final rendering destination of the OpenGL pipeline is called framebuffer. Framebuffer is a collection of 2D arrays or storages utilized by OpenGL; colour buffers, depth buffer, stencil buffer and accumulation buffer. By default, OpenGL uses the framebuffer as a rendering destination that is created and managed entirely by the window system. This default framebuffer is called window-system-provided framebuffer.
在OpenGL渲染管线中，几何数据和纹理经过多次转化和多次测试，最后以二维像素的形式显示在屏幕上。OpenGL管线的最终渲染目的地被称作帧缓存（framebuffer）。帧缓冲是一些二维数组和OpenG所使用的存储区的集合：颜色缓存、深度缓存、模板缓存和累计缓存。一般情况下，帧缓存完全由window系统生成和管理，由OpenGL使用。这个默认的帧缓存被称作“window系统生成”（window-system-provided）的帧缓存。</p>
<p>The OpenGL extension, GL_ARB_framebuffer_object provides an interface to create additional non-displayable framebuffer objects (FBO). This framebuffer is called application-created framebuffer in order to distinguish from the default window-system-provided framebuffer. By using framebuffer object (FBO), an OpenGL application can redirect the rendering output to the application-created framebuffer object (FBO) other than the traditional window-system-provided framebuffer. And, it is fully controlled by OpenGL.
在OpenGL扩展中，GL_EXT_framebuffer_object提供了一种创建额外的不能显示的帧缓存对象的接口。为了和默认的“window系统生成”的帧缓存区别，这种帧缓冲成为应用程序帧缓存（application-createdframebuffer）。通过使用帧缓存对象（FBO），OpenGL可以将显示输出到引用程序帧缓存对象，而不是传统的“window系统生成”帧缓存。而且，它完全受OpenGL控制。</p>
<p>Similar to window-system-provided framebuffer, a FBO contains a collection of rendering destinations; color, depth and stencil buffer. (Note that accumulation buffer is not defined in FBO.) These logical buffers in a FBO are called framebuffer-attachable images, which are 2D arrays of pixels that can be attached to a framebuffer object.
相似于window系统提供的帧缓存，一个FBO也包含一些存储颜色、深度和模板数据的区域。（注意：没有累积缓存）我们把FBO中这些逻辑缓存称之为“帧缓存关联图像”，它们是一些能够和一个帧缓存对象关联起来的二维数组像素。</p>
<p>There are two types of framebuffer-attachable images; texture images and renderbuffer images. If an image of a texture object is attached to a framebuffer, OpenGL performs “render to texture”. And if an image of a renderbuffer object is attached to a framebuffer, then OpenGL performs “offscreen rendering”.
有两种类型的“帧缓存关联图像”：纹理图像（texture images）和渲染缓存图像（renderbuffer images）。如果纹理对象的图像数据关联到帧缓存，OpenGL执行的是“渲染到纹理”（render to texture）操作。如果渲染缓存的图像数据关联到帧缓存，OpenGL执行的是离线渲染（offscreen rendering）。</p>
<p>By the way, renderbuffer object is a new type of storage object defined in GL_ARB_framebuffer_object extension. It is used as a rendering destination for a single 2D image during rendering process.
这里要提到的是，渲染缓存对象是在GL_EXT_framebuffer_object扩展中定义的一种新的存储类型。在渲染过程中它被用作存储单幅二维图像。</p>
<p>The following diagram shows the connectivity among the framebuffer object, texture object and renderbuffer object. Multiple texture objects or renderbuffer objects can be attached to a framebuffer object through the attachment points.
下面这幅图显示了帧缓存对象、纹理对象和渲染缓存对象之间的联系。多多个纹理对象或者渲染缓存对象能够通过关联点关联到一个帧缓存对象上。</p>
<p><img src="http://images.wodekouwei.com/gl/gl_fbo01.png" alt="image">
There are multiple color attachment points (GL_COLOR_ATTACHMENT0,…, GL_COLOR_ATTACHMENTn), one depth attachment point (GL_DEPTH_ATTACHMENT), and one stencil attachment point (GL_STENCIL_ATTACHMENT) in a framebuffer object. The number of color attachment points is implementation dependent, but each FBO must have at least one color attachement point. You can query the maximum number of color attachement points with GL_MAX_COLOR_ATTACHMENTS, which are supported by a graphics card. The reason that a FBO has multiple color attachement points is to allow to render the color buffer to multiple destinations at the same time. This “multiple render targets” (MRT) can be accomplished by GL_ARB_draw_buffers extension. Notice that the framebuffer object itself does not have any image storage(array) in it, but, it has only multiple attachment points.
在一个帧缓存对象中有多个颜色关联点（GL_COLOR_ATTACHMENT0_EXT,…,GL_COLOR_ATTACHMENTn_EXT），一个深度关联点（GL_DEPTH_ATTACHMENT_EXT），和一个模板关联点（GL_STENCIL_ATTACHMENT_EXT）。每个FBO中至少有一个颜色关联点，其数目与实体显卡相关。可以通过GL_MAX_COLOR_ATTACHMENTS_EXT来查询颜色关联点的最大数目。FBO有多个颜色关联点的原因是这样可以同时将颜色而换成渲染到多个FBO关联区。这种“多渲染目标”（multiple rendertargets,MRT）可以通过GL_ARB_draw_buffers扩展实现。需要注意的是：FBO本身并没有任何图像存储区，只有多个关联点。</p>
<p>Framebuffer object (FBO) provides an efficient switching mechanism; detach the previous framebuffer-attachable image from a FBO, and attach a new framebuffer-attachable image to the FBO. Switching framebuffer-attachable images is much faster than switching between FBOs. FBO provides glFramebufferTexture2D() to switch 2D texture objects, and glFramebufferRenderbuffer() to switch renderbuffer objects.
FBO提供了一种高效的切换机制；将前面的帧缓存关联图像从FBO分离，然后把新的帧缓存关联图像关联到FBO。在帧缓存关联图像之间切换比在FBO之间切换要快得多。FBO提供了glFramebufferTexture2DEXT()来切换2D纹理对象和glFramebufferRenderbufferEXT()来切换渲染缓存对象。</p>
<hr>
<h3 id="Creating-Frame-Buffer-Object-FBO"><a href="#Creating-Frame-Buffer-Object-FBO" class="headerlink" title="Creating Frame Buffer Object (FBO)"></a>Creating Frame Buffer Object (FBO)</h3><p>Creating framebuffer objects is similar to generating <a href="http://www.songho.ca/opengl/gl_vbo.html" target="_blank" rel="external">vertex buffer objects (VBO)</a>.
创建FBO和产生VBO类似。
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">void glGenFramebuffers(GLsizei n, GLuint* ids)</div><div class="line">void glDeleteFramebuffers(GLsizei n, const GLuint* ids)</div></pre></td></tr></table></figure></p>
<p>glGenFramebuffers() requires 2 parameters; the first one is the number of framebuffers to create, and the second parameter is the pointer to a GLuint variable or an array to store a single ID or multiple IDs. It returns the IDs of unused framebuffer objects. ID 0 means the default framebuffer, which is the window-system-provided framebuffer.
glGenFramebuffersEXT()需要两个参数：第一个是要创建的帧缓存的数目，第二个是指向存储一个或者多个ID的变量或数组的指针。它返回未使用的FBO的ID。ID为0表示默认帧缓存，即window系统提供的帧缓存。</p>
<p>And, FBO may be deleted by calling glDeleteFramebuffers() when it is not used anymore.
当FBO不再被使用时，FBO可以通过调用glDeleteFrameBuffersEXT()来删除。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">glBindFramebuffer()</div></pre></td></tr></table></figure>
<p>Once a FBO is created, it has to be bound before using it.
一旦一个FBO被创建，在使用它之前必须绑定。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">void glBindFramebuffer(GLenum target, GLuint id)</div></pre></td></tr></table></figure>
<p>The first parameter, target, should be GL_FRAMEBUFFER, and the second parameter is the ID of a framebuffer object. Once a FBO is bound, all OpenGL operations affect onto the current bound framebuffer object. The object ID 0 is reserved for the default window-system provided framebuffer. Therefore, in order to unbind the current framebuffer (FBO), use ID 0 in glBindFramebuffer().
第一个参数target应该是GL_FRAMEBUFFER_EXT，第二个参数是FBO的ID号。一旦FBO被绑定，之后的所有的OpenGL操作都会对当前所绑定的FBO造成影响。ID号为0表示缺省帧缓存，即默认的window提供的帧缓存。因此，在glBindFramebufferEXT()中将ID号设置为0可以解绑定当前FBO。</p>
<hr>
<h3 id="Renderbuffer-Object"><a href="#Renderbuffer-Object" class="headerlink" title="Renderbuffer Object"></a>Renderbuffer Object</h3><p>In addition, renderbuffer object is newly introduced for offscreen rendering. It allows to render a scene directly to a renderbuffer object, instead of rendering to a texture object. Renderbuffer is simply a data storage object containing a single image of a renderable internal format. It is used to store OpenGL logical buffers that do not have corresponding texture format, such as stencil or depth buffer.</p>
<p>另外，渲染缓存是为离线渲染而新引进的。它允许将一个场景直接渲染到一个渲染缓存对象中，而不是渲染到纹理对象中。渲染缓存对象是用于存储单幅图像的数据存储区域。该图像按照一种可渲染的内部格式存储。它用于存储没有相关纹理格式的OpenGL逻辑缓存，比如模板缓存或者深度缓存。</p>
<h4 id="glGenRenderbuffers"><a href="#glGenRenderbuffers" class="headerlink" title="glGenRenderbuffers()"></a>glGenRenderbuffers()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">void glGenRenderbuffers(GLsizei n, GLuint* ids)</div><div class="line">void glDeleteRenderbuffers(GLsizei n, const Gluint* ids)</div></pre></td></tr></table></figure>
<p>Once a renderbuffer is created, it returns non-zero positive integer. ID 0 is reserved for OpenGL.
一旦一个渲染缓存被创建，它返回一个非零的正整数。ID为0是OpenGL保留值。</p>
<h4 id="glBindRenderbuffer"><a href="#glBindRenderbuffer" class="headerlink" title="glBindRenderbuffer()"></a>glBindRenderbuffer()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">void glBindRenderbuffer(GLenum target, GLuint id)</div></pre></td></tr></table></figure>
<p>Same as other OpenGL objects, you have to bind the current renderbuffer object before referencing it. The target parameter should be GL_RENDERBUFFER for renderbuffer object.
和OpenGL中其他对象一样，在引用渲染缓存之前必须绑定当前渲染缓存对象。他target参数应该是GL_RENDERBUFFER_EXT。</p>
<h4 id="glRenderbufferStorage"><a href="#glRenderbufferStorage" class="headerlink" title="glRenderbufferStorage()"></a>glRenderbufferStorage()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">void glRenderbufferStorage(GLenum  target,</div><div class="line">                           GLenum  internalFormat,</div><div class="line">                           GLsizei width,</div><div class="line">                           GLsizei height)</div></pre></td></tr></table></figure>
<p>When a renderbuffer object is created, it does not have any data storage, so we have to allocate a memory space for it. This can be done by using glRenderbufferStorage(). The first parameter must be GL_RENDERBUFFER. The second parameter would be color-renderable (GL_RGB, GL_RGBA, etc.), depth-renderable (GL_DEPTH_COMPONENT), or stencil-renderable formats (GL_STENCIL_INDEX). The width and height are the dimension of the renderbuffer image in pixels.
当一个渲染缓存被创建，它没有任何数据存储区域，所以我们还要为他分配空间。这可以通过用glRenderbufferStorageEXT()实现。第一个参数必须是GL_RENDERBUFFER_EXT。第二个参数可以是用于颜色的（GL_RGB，GL_RGBA，etc.），用于深度的（GL_DEPTH_COMPONENT），或者是用于模板的格式（GL_STENCIL_INDEX）。Width和height是渲染缓存图像的像素维度。
The width and height should be less than GL_MAX_RENDERBUFFER_SIZE, otherwise, it generates GL_INVALID_VALUE error.
width和height必须比GL_MAX_RENDERBUFFER_SIZE_EXT小，否则将会产生GL_UNVALID_VALUE错误。</p>
<h4 id="glGetRenderbufferParameteriv"><a href="#glGetRenderbufferParameteriv" class="headerlink" title="glGetRenderbufferParameteriv()"></a>glGetRenderbufferParameteriv()</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">void glGetRenderbufferParameteriv(GLenum target,</div><div class="line">                                  GLenum param,</div><div class="line">                                  GLint* value)</div></pre></td></tr></table></figure>
<p>You also get various parameters of the currently bound renderbuffer object. target should be GL_RENDERBUFFER, and the second parameter is the name of parameter. The last is the pointer to an integer variable to store the returned value. The available names of the renderbuffer parameters are;
我们也可以得到当前绑定的渲染缓存对象的一些参数。Target应该是GL_RENDERBUFFER_EXT，第二个参数是所要得到的参数名字。最后一个是指向存储返回值的整型量的指针。渲染缓存的变量名有如下:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">GL_RENDERBUFFER_WIDTH</div><div class="line">GL_RENDERBUFFER_HEIGHT</div><div class="line">GL_RENDERBUFFER_INTERNAL_FORMAT</div><div class="line">GL_RENDERBUFFER_RED_SIZE</div><div class="line">GL_RENDERBUFFER_GREEN_SIZE</div><div class="line">GL_RENDERBUFFER_BLUE_SIZE</div><div class="line">GL_RENDERBUFFER_ALPHA_SIZE</div><div class="line">GL_RENDERBUFFER_DEPTH_SIZE</div><div class="line">GL_RENDERBUFFER_STENCIL_SIZE</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="Attaching-images-to-FBO"><a href="#Attaching-images-to-FBO" class="headerlink" title="Attaching images to FBO"></a>Attaching images to FBO</h3><p>FBO itself does not have any image storage(buffer) in it. Instead, we must attach framebuffer-attachable images (texture or renderbuffer objects) to the FBO. This mechanism allows that FBO quickly switch (detach and attach) the framebuffer-attachable images in a FBO. It is much faster to switch framebuffer-attachable images than to switch between FBOs. And, it saves unnecessary data copies and memory consumption. For example, a texture can be attached to multiple FBOs, and its image storage can be shared by multiple FBOs.
FBO本身没有图像存储区。我们必须帧缓存关联图像（纹理或渲染对象）关联到FBO。这种机制允许FBO快速地切换（分离和关联）帧缓存关联图像。切换帧缓存关联图像比在FBO之间切换要快得多。而且，它节省了不必要的数据拷贝和内存消耗。比如，一个纹理可以被关联到多个FBO上，图像存储区可以被多个FBO共享。</p>
<h4 id="Attaching-a-2D-texture-image-to-FBO"><a href="#Attaching-a-2D-texture-image-to-FBO" class="headerlink" title="Attaching a 2D texture image to FBO"></a>Attaching a 2D texture image to FBO</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">glFramebufferTexture2D(GLenum target,</div><div class="line">                       GLenum attachmentPoint,</div><div class="line">                       GLenum textureTarget,</div><div class="line">                       GLuint textureId,</div><div class="line">                       GLint  level)</div></pre></td></tr></table></figure>
<p>glFramebufferTexture2D() is to attach a 2D texture image to a FBO. The first parameter must be GL_FRAMEBUFFER, and the second parameter is the attachment point where to connect the texture image. A FBO has multiple color attachment points (GL_COLOR_ATTACHMENT0, …, GL_COLOR_ATTACHMENTn), GL_DEPTH_ATTACHMENT, and GL_STENCIL_ATTACHMENT. The third parameter, “textureTarget” is GL_TEXTURE_2D in most cases. The fourth parameter is the identifier of the texture object. The last parameter is the mipmap level of the texture to be attached.
glFramebufferTexture2DEXT()把一幅纹理图像关联到一个FBO。第一个参数一定是GL_FRAMEBUFFER_EXT，第二个参数是关联纹理图像的关联点。第三个参数textureTarget在多数情况下是GL_TEXTURE_2D。第四个参数是纹理对象的ID号。最后一个参数是要被关联的纹理的mipmap等级
If the textureId parameter is set to 0, then, the texture image will be detached from the FBO. If a texture object is deleted while it is still attached to a FBO, then, the texture image will be automatically detached from the currently bound FBO. However, if it is attached to multiple FBOs and deleted, then it will be detached from only the bound FBO, but will not be detached from any other un-bound FBOs.
如果参数textureId被设置为0，那么纹理图像将会被从FBO分离。如果纹理对象在依然关联在FBO上时被删除，那么纹理对象将会自动从当前帮的FBO上分离。然而，如果它被关联到多个FBO上然后被删除，那么它将只被从绑定的FBO上分离，而不会被从其他非绑定的FBO上分离。</p>
<h4 id="Attaching-a-Renderbuffer-image-to-FBO"><a href="#Attaching-a-Renderbuffer-image-to-FBO" class="headerlink" title="Attaching a Renderbuffer image to FBO"></a>Attaching a Renderbuffer image to FBO</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">void glFramebufferRenderbuffer(GLenum target,</div><div class="line">                               GLenum attachmentPoint,</div><div class="line">                               GLenum renderbufferTarget,</div><div class="line">                               GLuint renderbufferId)</div></pre></td></tr></table></figure>
<p>A renderbuffer image can be attached by calling glFramebufferRenderbuffer(). The first and second parameters are same as glFramebufferTexture2D(). The third parameter must be GL_RENDERBUFFER, and the last parameter is the ID of the renderbuffer object.
通过调用glFramebufferRenderbufferEXT()可以关联渲染缓存图像。前两个参数和glFramebufferTexture2DEXT()一样。第三个参数只能是GL_RENDERBUFFER_EXT，最后一个参数是渲染缓存对象的ID号。
If renderbufferId parameter is set to 0, the renderbuffer image will be detached from the attachment point in the FBO. If a renderbuffer object is deleted while it is still attached in a FBO, then it will be automatically detached from the bound FBO. However, it will not be detached from any other non-bound FBOs.
如果参数renderbufferId被设置为0，渲染缓存图像将会从FBO的关联点分离。如果渲染缓存图像在依然关联在FBO上时被删除，那么纹理对象将会自动从当前绑定的FBO上分离，而不会从其他非绑定的FBO上分离。</p>
<hr>
<h3 id="FBO-with-MSAA-Multi-Sample-Anti-Aliasing"><a href="#FBO-with-MSAA-Multi-Sample-Anti-Aliasing" class="headerlink" title="FBO with MSAA (Multi Sample Anti Aliasing)"></a>FBO with MSAA (Multi Sample Anti Aliasing)</h3><p>When you render to a FBO, anti-aliasing is not automatically enabled even if you properly create a OpenGL rendering context with the multisampling attribute (SAMPLEBUFFERS_ARB) for window-system-provided framebuffer.</p>
<p>In order to activate multisample anti-aliasing mode for rendering to a FBO, you need to prepare and attach multisample images to a FBO’s color and/or depth attachement points.</p>
<p>FBO extension provides glRenderbufferStorageMultisample() to create a renderbuffer image for multisample anti-aliasing rendering mode.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">void glRenderbufferStorageMultisample(GLenum  target,</div><div class="line">                                      GLsizei samples,</div><div class="line">                                      GLenum  internalFormat,</div><div class="line">                                      GLsizei width,</div><div class="line">                                      GLsizei height)</div></pre></td></tr></table></figure>
<p>It adds new parameter, samples on top of glRenderbufferStorage(), which is the number of multisamples for anti-aliased rendering mode. If it is 0, then no MSAA mode is enabled and glRenderbufferStorage() is called instead. You can query the maximum number of samples with GL_MAX_SAMPLES token in glGetIntegerv().</p>
<p>The following code is to create a FBO with multisample colorbuffer and depthbuffer images. Note that if multiple images are attached to a FBO, then all images must have the same number of multisamples. Otherwise, the FBO status is incomplete.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">// create a 4x MSAA renderbuffer object for colorbuffer</div><div class="line">int msaa = 4;</div><div class="line">GLuint rboColorId;</div><div class="line">glGenRenderbuffers(1, &amp;rboColorId);</div><div class="line">glBindRenderbuffer(GL_RENDERBUFFER, rboColorId);</div><div class="line">glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_RGB8, width, height);</div><div class="line"></div><div class="line">// create a 4x MSAA renderbuffer object for depthbuffer</div><div class="line">GLuint rboDepthId;</div><div class="line">glGenRenderbuffers(1, &amp;rboDepthId);</div><div class="line">glBindRenderbuffer(GL_RENDERBUFFER, rboDepthId);</div><div class="line">glRenderbufferStorageMultisample(GL_RENDERBUFFER, msaa, GL_DEPTH_COMPONENT, width, height);</div><div class="line"></div><div class="line">// create a 4x MSAA framebuffer object</div><div class="line">GLuint fboId;</div><div class="line">glGenFramebuffers(1, &amp;fboMsaaId);</div><div class="line">glBindFramebuffer(GL_FRAMEBUFFER, fboMsaaId);</div><div class="line"></div><div class="line">// attach colorbuffer image to FBO</div><div class="line">glFramebufferRenderbuffer(GL_FRAMEBUFFER,       // 1. fbo target: GL_FRAMEBUFFER</div><div class="line">                          GL_COLOR_ATTACHMENT0, // 2. color attachment point</div><div class="line">                          GL_RENDERBUFFER,      // 3. rbo target: GL_RENDERBUFFER</div><div class="line">                          rboColorId);          // 4. rbo ID</div><div class="line"></div><div class="line">// attach depthbuffer image to FBO</div><div class="line">glFramebufferRenderbuffer(GL_FRAMEBUFFER,       // 1. fbo target: GL_FRAMEBUFFER</div><div class="line">                          GL_DEPTH_ATTACHMENT,  // 2. depth attachment point</div><div class="line">                          GL_RENDERBUFFER,      // 3. rbo target: GL_RENDERBUFFER</div><div class="line">                          rboDepthId);          // 4. rbo ID</div><div class="line"></div><div class="line">// check FBO status</div><div class="line">GLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);</div><div class="line">if(status != GL_FRAMEBUFFER_COMPLETE)</div><div class="line">    fboUsed = false;</div></pre></td></tr></table></figure>
<p>It is important to know that glRenderbufferStorageMultisample() only enables MSAA rendering to FBO. However, you cannot directly use the result from MSAA FBO. If you need to transfer the result to a texture or other non-multisampled framebuffer, you have to convert (downsample) the result to single-sample image using glBlitFramebuffer().</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">void glBlitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, // source rectangle</div><div class="line">                       GLint dstX0, GLint dstY0, GLint dstX1, GLint dstY1, // destination rect</div><div class="line">                       GLbitfield mask,</div><div class="line">                       GLenum filter)</div></pre></td></tr></table></figure>
<p>glBlitFramebuffer() copies a rectangle of images from the source (GL_READ_BUFFER) to the destination framebuffer (GL_DRAW_BUFFER). The “mask” parameter is to specify which buffers are copied, GL_COLOR_BUFFER_BIT, GL_DEPTH_BUFFER_BIT and/or GL_STENCIL_BUFFER_BIT. The last parameter, “filter” is to specify the interpolation mode if the source and destination rectangles are not same. It is either GL_NEAREST or GL_LINEAR.</p>
<p>The following code is to transfer a multisampled image from a FBO to another non-multisampled FBO. Notice it requires an additional FBO to get the result of MSAA rendering. Please see fboMsaa.zip for details to perform render-to-texture with MSAA.
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">// copy rendered image from MSAA (multi-sample) to normal (single-sample)</div><div class="line">// NOTE: The multi samples at a pixel in read buffer will be converted</div><div class="line">// to a single sample at the target pixel in draw buffer.</div><div class="line">glBindFramebuffer(GL_READ_FRAMEBUFFER, fboMsaaId); // src FBO (multi-sample)</div><div class="line">glBindFramebuffer(GL_DRAW_FRAMEBUFFER, fboId);     // dst FBO (single-sample)</div><div class="line"></div><div class="line">glBlitFramebuffer(0, 0, width, height,             // src rect</div><div class="line">                  0, 0, width, height,             // dst rect</div><div class="line">                  GL_COLOR_BUFFER_BIT,             // buffer mask</div><div class="line">                  GL_LINEAR);                      // scale filter</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="Checking-FBO-Status"><a href="#Checking-FBO-Status" class="headerlink" title="Checking FBO Status"></a>Checking FBO Status</h3><p>Once attachable images (textures and renderbuffers) are attached to a FBO and before performing FBO operation, you must validate if the FBO status is complete or incomplete by using glCheckFramebufferStatus(). If the FBO is not complete, then any drawing and reading command (glBegin(), glCopyTexImage2D(), etc) will be failed.</p>
<p>一旦关联图像（纹理和渲染缓存）被关联到FBO上，在执行FBO的操作之前，你必须检查FBO的状态，这可以通过调用glCheckFramebufferStatusEXT()实现。如果这个FBObuilding完整，那么任何绘制和读取命令（glBegin(),glCopyTexImage2D(), etc）都会失败。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">GLenum glCheckFramebufferStatus(GLenum target)</div></pre></td></tr></table></figure>
<p>glCheckFramebufferStatus() validates all its attached images and framebuffer parameters on the currently bound FBO. And, this function cannot be called within glBegin()/glEnd() pair. The target parameter should be GL_FRAMEBUFFER. It returns non-zero value after checking the FBO. If all requirements and rules are satisfied, then it returns GL_FRAMEBUFFER_COMPLETE. Otherwise, it returns a relevant error value, which tells what rule is violated.
glCheckFramebufferStatusEXT()检查当前帧缓存的关联图像和帧缓存参数。这个函数不能在glBegin()/glEnd()之间调用。Target参数必须为GL_FRAMEBUFFER_EXT。它返回一个非零值。如果所有要求和准则都满足，它返回GL_FRAMEBUFFER_COMPLETE_EXT。否则，返回一个相关错误代码告诉我们哪条准则没有满足。</p>
<p>The rules of FBO completeness are:</p>
<ul>
<li>The width and height of framebuffer-attachable image must be not zero.</li>
<li>If an image is attached to a color attachment point, then the image must have a color-renderable internal format. (GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc)</li>
<li>If an image is attached to GL_DEPTH_ATTACHMENT, then the image must have a depth-renderable internal format. (GL_DEPTH_COMPONENT, GL_DEPTH_COMPONENT24, etc)</li>
<li>If an image is attached to GL_STENCIL_ATTACHMENT, then the image must have a stencil-renderable internal format. (GL_STENCIL_INDEX, GL_STENCIL_INDEX8, etc)</li>
<li>FBO must have at least one image attached.</li>
<li>All images attached a FBO must have the same width and height.</li>
<li>All images attached the color attachment points must have the same internal format.</li>
</ul>
<p>FBO完整性准则有：</p>
<ol>
<li>帧缓存关联图像的宽度和高度必须非零。</li>
<li>如果一幅图像被关联到一个颜色关联点，那么这幅图像必须有颜色可渲染的内部格式（GL_RGBA, GL_DEPTH_COMPONENT, GL_LUMINANCE, etc)。</li>
<li>如果一幅被图像关联到GL_DEPTH_ATTACHMENT_EXT，那么这幅图像必须有深度可渲染的内部格式(GL_DEPTH_COMPONENT,GL_DEPTH_COMPONENT24_EXT, etc)。</li>
<li>如果一幅被图像关联到GL_STENCIL_ATTACHMENT_EXT，那么这幅图像必须有模板可渲染的内部格式(GL_STENCIL_INDEX,GL_STENCIL_INDEX8_EXT, etc)。</li>
<li>FBO至少有一幅图像关联。</li>
<li>被关联到FBO的缩影图像必须有相同的宽度和高度。</li>
<li>被关联到颜色关联点上的所有图像必须有相同的内部格式。</li>
</ol>
<p>Note that even though all of the above conditions are satisfied, your OpenGL driver may not support some combinations of internal formats and parameters. If a particular implementation is not supported by OpenGL driver, then glCheckFramebufferStatus() returns GL_FRAMEBUFFER_UNSUPPORTED.
注意：即使以上所有条件都满足，你的OpenGL驱动也可能不支持某些格式和参数的组合。如果一种特别的实现不被OpenGL驱动支持，那么glCheckFramebufferStatusEXT()返回GL_FRAMEBUFFER_UNSUPPORTED_EXT。</p>
<p>The sample code provides some utility functions to report the information of the current FBO; printFramebufferInfo() and checkFramebufferStatus().</p>
<p><a href="http://www.programcreek.com/java-api-examples/index.php?class=javax.media.opengl.GL&amp;method=GL_FRAMEBUFFER_COMPLETE_EXT" target="_blank" rel="external">Java Code Examples for javax.media.opengl.GL.GL_FRAMEBUFFER_COMPLETE_EXT</a></p>
<hr>
<h3 id="GL-EXT-discard-framebuffer"><a href="#GL-EXT-discard-framebuffer" class="headerlink" title="GL_EXT_discard_framebuffer"></a>GL_EXT_discard_framebuffer</h3><h4 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h4><p>This extension provides a new command, DiscardFramebufferEXT, which causes the contents of the named framebuffer attachable images to become undefined.  The contents of the specified buffers are undefined until a subsequent operation modifies the content, and only the modified region is guaranteed to hold valid content.  Effective usage of this command may provide an implementation with new optimization opportunities.
Some OpenGL ES implementations cache framebuffer images in a small pool of fast memory.  Before rendering, these implementations must load the existing contents of one or more of the logical buffers (color, depth, stencil, etc.) into this memory.  After rendering, some or all of these buffers are likewise stored back to external memory so their contents can be used again in the future.  In many applications, some or all of the logical buffers  are cleared at the start of rendering.  If so, the effort to load or store those buffers is wasted.</p>
<p>Even without this extension, if a frame of rendering begins with a full-screen Clear, an OpenGL ES implementation may optimize away the loading of framebuffer contents prior to rendering the frame.  With this extension, an application can use DiscardFramebufferEXT to signal that framebuffer contents will no longer be needed.  In this case an OpenGL ES implementation may also optimize away the storing back of framebuffer contents after rendering the frame.</p>
<h4 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h4><p>1) Should DiscardFramebufferEXT’s argument be a list of COLOR_ATTACHMENTx enums, or should it use the same bitfield from Clear and BlitFramebuffer?</p>
<p>RESOLVED: We’ll use a sized list of framebuffer attachments.  This will give us some future-proofing for when MRTs and multisampled FBOs are supported.</p>
<p>2) What happens if the app discards only one of the depth and stencil attachments, but those are backed by the same packed_depth_stencil buffer?
  a) Generate an error
  b) Both images become undefined
  c) Neither image becomes undefined
  d) Only one of the images becomes undefined
  RESOLVED: (b) which sort of falls out of Issue 4.</p>
<p>3) How should DiscardFramebufferEXT interact with the default framebuffer?
  a) Generate an error
  b) Ignore the hint silently
  c) The contents of the specified attachments become undefined
  RESOLVED: (c), with appropriate wording to map FBO attachments to the corresponding default framebuffer’s logical buffers</p>
<p>4) What happens when you discard an attachment that doesn’t exist?  This is the case where a framebuffer is complete but doesn’t have, for example, a stencil attachment, yet the app tries to discard the stencil attachment.
  a) Generate an error
  b) Ignore the hint silently</p>
<p>  RESOLVED: (b) for two reasons.  First, this is just a hint anyway, and if we required error detection, then suddenly an implementation can’t trivially ignore it.  Second, this is consistent with Clear, which ignores specified buffers that aren’t present.</p>
<hr>
<h3 id="Example-Render-To-Texture"><a href="#Example-Render-To-Texture" class="headerlink" title="Example: Render To Texture"></a>Example: Render To Texture</h3><p>Sometimes, you need to generate dynamic textures on the fly. The most common examples are generating mirroring/reflection effects, dynamic cube/environment maps and shadow maps. Dynamic texturing can be accomplished by rendering the scene to a texture. A traditional way of render-to-texture is to draw a scene to the framebuffer as normal, and then copy the framebuffer image to a texture by using glCopyTexSubImage2D().
有时候，你需要产生动态纹理。比较常见的例子是产生镜面反射效果、动态环境贴图和阴影等效果。动态纹理可以通过把场景渲染到纹理来实现。渲染到纹理的一种传统方式是将场景绘制到普通的帧缓存上，然后调用glCopyTexSubImage2D()拷贝帧缓存图像至纹理。</p>
<p>Using FBO, we can render a scene directly onto a texture, so we don’t have to use the window-system-provided framebuffer at all. Further more, we can eliminate an additional data copy (from framebuffer to texture).
使用FBO，我们能够将场景直接渲染到纹理，所以我们不必使用window系统提供的帧缓存。并且，我们能够去除额外的数据拷贝（从帧缓存到纹理）；。</p>
<p>This demo program performs render to texture operation with/without FBO, and compares the performance difference. Other than performance gain, there is another advantage of using FBO. If the texture resolution is larger than the size of the rendering window in traditional render-to-texture mode (without FBO), then the area out of the window region will be clipped. However, FBO does not suffer from this clipping problem. You can create a framebuffer-renderable image larger than the display window.
这个demo实现了使用FBO和不使用FBO两种情况下渲染到纹理的操作，并且比较了性能差异。除了能够获得性能上的提升，使用FBO的还有另外一个优点。在传统的渲染到纹理的模式中（不使用FBO），如果纹理分辨率比渲染窗口的尺寸大，超出窗口区域的部分将被剪切掉。然后，使用FBO就不会有这个问题。你可以产生比显示窗口大的帧缓存渲染图像。</p>
<p>The following codes is to setup a FBO and framebuffer-attachable images before the rendering loop is started. Note that not only a texture image is attached to the FBO, but also, a renderbuffer image is attached to the depth attachment point of the FBO. We do not actually use this depth buffer, however, the FBO itself needs it for depth test. If we don’t attach this depth renderable image to the FBO, then the rendering output will be corrupted because of missing depth test. If stencil test is also required during FBO rendering, then additional renderbuffer image should be attached to GL_STENCIL_ATTACHMENT.
以下代码在渲染循环开始之前，对FBO和帧缓存关联图像进行了初始化。注意只有一幅纹理图像被关联到FBO，但是，一个深度渲染图像被关联到FBO的深度关联点。实际上我们并没有使用这个深度缓存，但是FBO本身需要它进行深度测试。如果我们不把这个深度可渲染的图像关联到FBO，那么由于缺少深度测试渲染输出结果是不正确的。如果在FBO渲染期间模板测试也是必要的，那么也需要把额外的渲染图像和GL_STENCIL_ATTACHMENT_EXT关联起来。
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">// create a texture object</div><div class="line">GLuint textureId;</div><div class="line">glGenTextures(1, &amp;textureId);</div><div class="line">glBindTexture(GL_TEXTURE_2D, textureId);</div><div class="line">glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</div><div class="line">glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);</div><div class="line">glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);</div><div class="line">glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);</div><div class="line">glTexParameteri(GL_TEXTURE_2D, GL_GENERATE_MIPMAP, GL_TRUE); // automatic mipmap</div><div class="line">glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, TEXTURE_WIDTH, TEXTURE_HEIGHT, 0,</div><div class="line">             GL_RGBA, GL_UNSIGNED_BYTE, 0);</div><div class="line">glBindTexture(GL_TEXTURE_2D, 0);</div><div class="line"></div><div class="line">// create a renderbuffer object to store depth info</div><div class="line">GLuint rboId;</div><div class="line">glGenRenderbuffers(1, &amp;rboId);</div><div class="line">glBindRenderbuffer(GL_RENDERBUFFER, rboId);</div><div class="line">glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT,</div><div class="line">                      TEXTURE_WIDTH, TEXTURE_HEIGHT);</div><div class="line">glBindRenderbuffer(GL_RENDERBUFFER, 0);</div><div class="line"></div><div class="line">// create a framebuffer object</div><div class="line">GLuint fboId;</div><div class="line">glGenFramebuffers(1, &amp;fboId);</div><div class="line">glBindFramebuffer(GL_FRAMEBUFFER, fboId);</div><div class="line"></div><div class="line">// attach the texture to FBO color attachment point</div><div class="line">glFramebufferTexture2D(GL_FRAMEBUFFER,        // 1. fbo target: GL_FRAMEBUFFER</div><div class="line">                       GL_COLOR_ATTACHMENT0,  // 2. attachment point</div><div class="line">                       GL_TEXTURE_2D,         // 3. tex target: GL_TEXTURE_2D</div><div class="line">                       textureId,             // 4. tex ID</div><div class="line">                       0);                    // 5. mipmap level: 0(base)</div><div class="line"></div><div class="line">// attach the renderbuffer to depth attachment point</div><div class="line">glFramebufferRenderbuffer(GL_FRAMEBUFFER,      // 1. fbo target: GL_FRAMEBUFFER</div><div class="line">                          GL_DEPTH_ATTACHMENT, // 2. attachment point</div><div class="line">                          GL_RENDERBUFFER,     // 3. rbo target: GL_RENDERBUFFER</div><div class="line">                          rboId);              // 4. rbo ID</div><div class="line"></div><div class="line">// check FBO status</div><div class="line">GLenum status = glCheckFramebufferStatus(GL_FRAMEBUFFER);</div><div class="line">if(status != GL_FRAMEBUFFER_COMPLETE)</div><div class="line">    fboUsed = false;</div><div class="line"></div><div class="line">// switch back to window-system-provided framebuffer</div><div class="line">glBindFramebuffer(GL_FRAMEBUFFER, 0);</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>The rendering procedure of render-to-texture is almost same as normal drawing. We only need to switch the rendering destination from the window-system-provided to the non-displayable, application-created framebuffer (FBO).
渲染到纹理的过程和普通的绘制过程基本一样。我们只需要把渲染的目的地由window系统提供的帧缓存改成不可显示的应用程序创建的帧缓存（FBO）就可以了。
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">// set rendering destination to FBO</div><div class="line">glBindFramebuffer(GL_FRAMEBUFFER, fboId);</div><div class="line"></div><div class="line">// clear buffers</div><div class="line">glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</div><div class="line"></div><div class="line">// draw a scene to a texture directly</div><div class="line">draw();</div><div class="line"></div><div class="line">// unbind FBO</div><div class="line">glBindFramebuffer(GL_FRAMEBUFFER, 0);</div><div class="line"></div><div class="line">// trigger mipmaps generation explicitly</div><div class="line">// NOTE: If GL_GENERATE_MIPMAP is set to GL_TRUE, then glCopyTexSubImage2D()</div><div class="line">// triggers mipmap generation automatically. However, the texture attached</div><div class="line">// onto a FBO should generate mipmaps manually via glGenerateMipmap().</div><div class="line">glBindTexture(GL_TEXTURE_2D, textureId);</div><div class="line">glGenerateMipmap(GL_TEXTURE_2D);</div><div class="line">glBindTexture(GL_TEXTURE_2D, 0);</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>Note that glGenerateMipmap() is also included as part of FBO extension in order to generate mipmaps explicitly after modifying the base level texture image. If GL_GENERATE_MIPMAP is set to GL_TRUE, then glTex{Sub}Image2D() and glCopyTex{Sub}Image2D() trigger automatic mipmap generation (in OpenGL version 1.4 or greater). However, FBO operation does not generate its mipmaps automatically when the base level texture is modified because FBO does not call glCopyTex{Sub}Image2D() to modify the texture. Therefore, glGenerateMipmap() must be explicitly called for mipmap generation.
注意到，glGenerateMipmapEXT()也是作为FBO扩展的一部分，用来在改变了纹理图像的基级之后显式生成mipmap的。如果GL_GENERATE_MIPMAP被设置为GL_TRUE，那么glTex{Sub}Image2D()和 glCopyTex{Sub}Image2D()将会启用自动mipmap生成（在OpenGL版本1.4或者更高版本中）。然后，当纹理基级被改变时，FBO操作不会自动产生mipmaps。因为FBO不会调用glCopyTex{Sub}Image2D()来修改纹理。因此，要产生mipmap，glGenerateMipmapEXT()必须被显示调用。</p>
<h2 id="If-you-need-to-a-post-processing-of-the-texture-it-is-possible-to-combine-with-Pixel-Buffer-Object-PBO-to-modify-the-texture-efficiently"><a href="#If-you-need-to-a-post-processing-of-the-texture-it-is-possible-to-combine-with-Pixel-Buffer-Object-PBO-to-modify-the-texture-efficiently" class="headerlink" title="If you need to a post processing of the texture, it is possible to combine with Pixel Buffer Object (PBO) to modify the texture efficiently."></a>If you need to a post processing of the texture, it is possible to combine with Pixel Buffer Object (PBO) to modify the texture efficiently.</h2><h3 id="PBuffer-vs-FBO"><a href="#PBuffer-vs-FBO" class="headerlink" title="PBuffer vs FBO"></a>PBuffer vs FBO</h3><p>opengles2.0渲染到纹理的方法有三种：</p>
<ol>
<li>使用glCopyTexImage2D或者glCopyTexSubImage2D，这两个函数，复制framebuffer中的像素到纹理缓存里面，但这两个函数性能比较低下，并且要求纹理的尺寸必须小于等于framebuffer的尺寸。</li>
<li>使用一个附加到纹理的pbuffer，来执行渲染到纹理的操作。我们知道，窗口系统为我们提供的surface必须添加到一个渲染环境里面，但是，在某些平台上要求每个pbuffer和窗口系统提供的surface都需要一个单独的context，所以如果要渲染到pbuffer里面的话，就会发生context的切换，这种切换操作时很耗时的。</li>
<li>使用fbo，rbo等，这种是最高效的。</li>
</ol>
<p>pbuffer跟framebuffer功能是一样的，都是用来做渲染到一个off-screen surface上的，但是如果要做的是渲染到一个纹理上，还是使用framebuffer，效率高些。pbuffer的用途是：渲染到纹理上，随后这个纹理可以给其他API用的，比如openVG。创建pbuffer的过程跟创建窗口surface差不多的：
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">EGLSurface eglCreatePbufferSurface(EGLDisplay display,EGLConfig config,const EGLint *attribList);</div></pre></td></tr></table></figure></p>
<p>需要在attribList指定一些pbuffer的属性。选择config的时候需要指定：EGL_SURFACE_TYPE：EGL_PBUFFER_BIT</p>
<p>频繁的在自己创建的fbo和窗口系统创建的vbo之间切换，比较影响性能。不要在每一帧都去创建，销毁fbo，vbo对象。要一次创建多次使用。如果一个纹理attach到一个fbo的attachment point，就要尽量避免调用glTexImage2D或glTexSubImage2D,glCopyTexImage2D等去修改纹理的值。</p>
<h2 id="Presumably-eglSwapBuffers-has-no-effect-on-PBufferSurface-since-it-is-not-double-buffer-surface-but-if-it-is-you-would-try-to-read-pixels-from-undefined-buffer-with-undefined-result"><a href="#Presumably-eglSwapBuffers-has-no-effect-on-PBufferSurface-since-it-is-not-double-buffer-surface-but-if-it-is-you-would-try-to-read-pixels-from-undefined-buffer-with-undefined-result" class="headerlink" title="Presumably eglSwapBuffers has no effect on PBufferSurface (since it is not double-buffer surface) but if it is you would try to read pixels from undefined buffer, with undefined result.."></a><a href="https://stackoverflow.com/questions/28817777/pbuffer-vs-fbo-in-egl-offscreen-rendering" target="_blank" rel="external">Presumably eglSwapBuffers has no effect on PBufferSurface (since it is not double-buffer surface) but if it is you would try to read pixels from undefined buffer, with undefined result..</a></h2><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><blockquote>
<p><a href="http://www.songho.ca/opengl/gl_fbo.html" target="_blank" rel="external">原文</a>
<a href="http://blog.csdn.net/xiajun07061225/article/details/7283929" target="_blank" rel="external">译文</a></p>
<p><a href="https://www.khronos.org/registry/OpenGL/extensions/EXT/EXT_discard_framebuffer.txt" target="_blank" rel="external">GL_EXT_discard_framebuffer</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/05/04/android-view-textureview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/04/android-view-textureview/" itemprop="url">
                  android textureview处理预览摄像头变形问题
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-05-04T20:03:05+08:00">
                2017-05-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Android/" itemprop="url" rel="index">
                    <span itemprop="name">Android</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>当TextureView的大小和匹配到的摄像头PreviewSize宽高比例不完全一致时,TextureView可通过setTransform函数对预览画面进行处理后再显示到TextureView,如下对图形居中裁剪:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">public void sizeNotify(Camera.Size size) &#123;</div><div class="line">            float viewWidth = getWidth();</div><div class="line">            float viewHeight = getHeight();</div><div class="line"></div><div class="line">            float scaleX = 1.0f;</div><div class="line">            float scaleY = 1.0f;</div><div class="line">            int mPreviewWidth = size.width;</div><div class="line">            int mPreviewHeight = size.height;</div><div class="line">            if(viewWidth &lt; viewHeight) &#123;</div><div class="line">                mPreviewWidth = size.height;</div><div class="line">                mPreviewHeight = size.width;</div><div class="line">            &#125;</div><div class="line"></div><div class="line"></div><div class="line">            if (mPreviewWidth &gt; viewWidth &amp;&amp; mPreviewHeight &gt; viewHeight) &#123;</div><div class="line">                scaleX = mPreviewWidth / viewWidth;</div><div class="line">                scaleY = mPreviewHeight / viewHeight;</div><div class="line">            &#125; else if (mPreviewWidth &lt; viewWidth &amp;&amp; mPreviewHeight &lt; viewHeight) &#123;</div><div class="line">                scaleY = viewWidth / mPreviewWidth;</div><div class="line">                scaleX = viewHeight / mPreviewHeight;</div><div class="line">            &#125; else if (viewWidth &gt; mPreviewWidth) &#123;</div><div class="line">                scaleY = (viewWidth / mPreviewWidth) / (viewHeight / mPreviewHeight);</div><div class="line">            &#125; else if (viewHeight &gt; mPreviewHeight) &#123;</div><div class="line">                scaleX = (viewHeight / mPreviewHeight) / (viewWidth / mPreviewWidth);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            // Calculate pivot points, in our case crop from center</div><div class="line">            int pivotPointX = (int) (viewWidth / 2);</div><div class="line">            int pivotPointY = (int) (viewHeight / 2);</div><div class="line"></div><div class="line">            Matrix matrix = new Matrix();</div><div class="line">            matrix.setScale(scaleX, scaleY, pivotPointX, pivotPointY);</div><div class="line">            /*Log.e(TAG, &quot;viewsize:&quot; + viewWidth + &quot; * &quot; + viewHeight +</div><div class="line">                    &quot;;prviewSize:&quot; + mPreviewWidth + &quot; * &quot; + mPreviewHeight +</div><div class="line">                    &quot;;scale:&quot; + scaleX + &quot; * &quot; + scaleY +</div><div class="line">                    &quot;;pivot:&quot; + pivotPointX + &quot; * &quot; + pivotPointY);*/</div><div class="line">            setTransform(matrix);</div><div class="line">        &#125;</div></pre></td></tr></table></figure></p>
<p>TextureView中setTransform函数说明:
Sets the transform to associate with this texture view. The specified transform applies to the underlying surface texture and does not affect the size or position of the view itself, only of its content.</p>
<p>Some transforms might prevent the content from drawing all the pixels contained within this view’s bounds. In such situations, make sure this texture view is not marked opaque.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/05/03/webrtc-nativeapis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/03/webrtc-nativeapis/" itemprop="url">
                  webrtc之Native APIs
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-05-03T11:51:59+08:00">
                2017-05-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/webrtc/" itemprop="url" rel="index">
                    <span itemprop="name">webrtc</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Block-diagram"><a href="#Block-diagram" class="headerlink" title="Block diagram"></a>Block diagram</h3><p><img src="http://images.wodekouwei.com/protocol/WebRTCNativeAPIsDocument1.png" alt="image"></p>
<h3 id="Calling-sequences"><a href="#Calling-sequences" class="headerlink" title="Calling sequences"></a>Calling sequences</h3><h4 id="Set-up-a-call"><a href="#Set-up-a-call" class="headerlink" title="Set up a call"></a>Set up a call</h4><p><img src="http://images.wodekouwei.com/protocol/WebRTCNativeAPIsDocument2.png" alt="image"></p>
<h4 id="Receive-a-call"><a href="#Receive-a-call" class="headerlink" title="Receive a call"></a>Receive a call</h4><p><img src="http://images.wodekouwei.com/protocol/WebRTCNativeAPIsDocument3.png" alt="image"></p>
<h4 id="Close-down-a-call"><a href="#Close-down-a-call" class="headerlink" title="Close down a call"></a>Close down a call</h4><p><img src="http://images.wodekouwei.com/protocol/WebRTCNativeAPIsDocument4.png" alt="image"></p>
<h3 id="Threading-model"><a href="#Threading-model" class="headerlink" title="Threading model"></a>Threading model</h3><p>WebRTC native APIs use two globally available threads: the signaling thread and the worker thread. Depending on how the PeerConnection factory is created, the application can either provide those 2 threads or just let them be created internally.</p>
<p>The calls to the Stream APIs and the PeerConnection APIs will be proxied to the signaling thread which means that the application can call those APIs from whatever thread.</p>
<p>All callbacks will be made on the signaling thread. The application should return the callback as quickly as possible to avoid blocking the signaling thread. Resource intensive processes should be posted to a different thread.</p>
<p>The worker thread is used to handle more resource intensive processes such as data streaming.</p>
<blockquote>
<p><a href="https://sites.google.com/site/webrtc/native-code/native-apis" target="_blank" rel="external">https://sites.google.com/site/webrtc/native-code/native-apis</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/05/02/webrtc-source-api/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/02/webrtc-source-api/" itemprop="url">
                  webrtc源码走读之api
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-05-02T16:23:59+08:00">
                2017-05-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/webrtc/" itemprop="url" rel="index">
                    <span itemprop="name">webrtc</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>api目录下封装了webrtc相关的供外部调用接口.</p>
<h5 id="datachannel-h"><a href="#datachannel-h" class="headerlink" title="datachannel.h"></a>datachannel.h</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// Including this file is deprecated. It is no longer part of the public API.</div><div class="line">// This only includes the file in its new location for backwards compatibility.</div><div class="line">#include &quot;webrtc/pc/datachannel.h&quot;</div></pre></td></tr></table></figure>
<h5 id="datachannelinterface-h"><a href="#datachannelinterface-h" class="headerlink" title="datachannelinterface.h"></a>datachannelinterface.h</h5><ul>
<li>DataChannelObserver:Used to implement RTCDataChannel events.The code responding to these callbacks should unwind the stack before using any other webrtc APIs; re-entrancy is not supported.</li>
<li>DataChannelInterface:</li>
</ul>
<h5 id="dtmfsenderinterface-h"><a href="#dtmfsenderinterface-h" class="headerlink" title="dtmfsenderinterface.h"></a>dtmfsenderinterface.h</h5><ul>
<li>DtmfSenderObserverInterface:DtmfSender callback interface, used to implement RTCDtmfSender events.Applications should implement this interface to get notifications from the DtmfSender.</li>
<li>DtmfSenderInterface:The interface of native implementation of the RTCDTMFSender defined by the WebRTC W3C Editor’s Draft.</li>
</ul>
<h5 id="fakemetricsobserver-h-cc"><a href="#fakemetricsobserver-h-cc" class="headerlink" title="fakemetricsobserver.h/cc"></a>fakemetricsobserver.h/cc</h5><ul>
<li>FakeMetricsObserver</li>
</ul>
<h5 id="jsep-h"><a href="#jsep-h" class="headerlink" title="jsep.h"></a>jsep.h</h5><ul>
<li>IceCandidateInterface:Class representation of an ICE candidate.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateIceCandidate.</li>
<li>IceCandidateCollection:This class represents a collection of candidates for a specific m= section.Used in SessionDescriptionInterface.</li>
<li>SessionDescriptionInterface:Class representation of an SDP session description.An instance of this interface is supposed to be owned by one class at a time and is therefore not expected to be thread safe.An instance can be created by CreateSessionDescription.</li>
<li>CreateSessionDescriptionObserver:CreateOffer and CreateAnswer callback interface.</li>
<li>SetSessionDescriptionObserver:SetLocalDescription and SetRemoteDescription callback interface.</li>
</ul>
<h5 id="jsepicecandidate-h"><a href="#jsepicecandidate-h" class="headerlink" title="jsepicecandidate.h"></a>jsepicecandidate.h</h5><ul>
<li>JsepIceCandidate:继承自IceCandidateInterface</li>
<li>JsepCandidateCollection:继承自IceCandidateCollection</li>
</ul>
<h5 id="jsepsessiondescription-h"><a href="#jsepsessiondescription-h" class="headerlink" title="jsepsessiondescription.h"></a>jsepsessiondescription.h</h5><ul>
<li>JsepSessionDescription:Implementation of SessionDescriptionInterface.</li>
</ul>
<h5 id="mediaconstraintsinterface-h-cc"><a href="#mediaconstraintsinterface-h-cc" class="headerlink" title="mediaconstraintsinterface.h/cc"></a>mediaconstraintsinterface.h/cc</h5><ul>
<li>MediaConstraintsInterface:Interface used for passing arguments about media constraints to the MediaStream and PeerConnection implementation.Constraints may be either “mandatory”, which means that unless satisfied,the method taking the constraints should fail, or “optional”, which means they may not be satisfied..</li>
</ul>
<h5 id="mediastream-h"><a href="#mediastream-h" class="headerlink" title="mediastream.h"></a>mediastream.h</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// Including this file is deprecated. It is no longer part of the public API.</div><div class="line">// This only includes the file in its new location for backwards compatibility.</div><div class="line">#include &quot;webrtc/pc/mediastream.h&quot;</div></pre></td></tr></table></figure>
<h5 id="mediastreaminterface-h-cc"><a href="#mediastreaminterface-h-cc" class="headerlink" title="mediastreaminterface.h/cc"></a>mediastreaminterface.h/cc</h5><ul>
<li>OberverInterface</li>
<li>NotifierInterface</li>
<li>MediaSourceInterface:Base class for sources. A MediaStreamTrack has an underlying source that provides media. A source can be shared by multiple tracks.继承自notifierInterface</li>
<li>MediaStreamTrackInterface:继承自notifierInterface</li>
<li>VideoTrackSourceInterface:VideoTrackSourceInterface is a reference counted source used for VideoTracks. The same source can be used by multiple VideoTracks.继承自MediaSourceinterface与VideoSourceInterface</li>
<li>VideoTrackInterface: 继承自MediaStreamTrackInterface与VideoSourceInterface</li>
<li>AudioTrackSinkinterface:</li>
<li>AudioSourceInterface:AudioSourceInterface is a reference counted source used for AudioTracks.The same source can be used by multiple AudioTracks.继承自MediaSourceInterface.</li>
<li>AudioProcessorInterface:Interface of the audio processor used by the audio track to collect statistics.</li>
<li>AudioTrackInterface:继承自MediaStreamTrackInterface</li>
<li><strong>MediaStreamInterface</strong>: A major difference is that remote audio/video tracks (received by a PeerConnection/RtpReceiver) are not synchronized simply by adding them to the same stream; a session description with the correct “a=msid” attributes
must be pushed down.Thus, this interface acts as simply a container for tracks.</li>
</ul>
<h5 id="mediastreamproxy-h"><a href="#mediastreamproxy-h" class="headerlink" title="mediastreamproxy.h"></a>mediastreamproxy.h</h5><p>Move this to .cc file and out of api/. What threads methods
// are called on is an implementation detail.</p>
<h5 id="mediastreamtrack-h"><a href="#mediastreamtrack-h" class="headerlink" title="mediastreamtrack.h"></a>mediastreamtrack.h</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// Including this file is deprecated. It is no longer part of the public API.</div><div class="line">// This only includes the file in its new location for backwards compatibility.</div><div class="line">#include &quot;webrtc/pc/mediastreamtrack.h&quot;</div></pre></td></tr></table></figure>
<h5 id="mediatypes-h-cc"><a href="#mediatypes-h-cc" class="headerlink" title="mediatypes.h/cc"></a>mediatypes.h/cc</h5><p>mediatype到string转换</p>
<h5 id="notifier-h"><a href="#notifier-h" class="headerlink" title="notifier.h"></a>notifier.h</h5><ul>
<li>Notifier:</li>
</ul>
<h5 id="peerconnectionfactoryproxy-h"><a href="#peerconnectionfactoryproxy-h" class="headerlink" title="peerconnectionfactoryproxy.h"></a>peerconnectionfactoryproxy.h</h5><h5 id="peerconnectioninterface-h"><a href="#peerconnectioninterface-h" class="headerlink" title="peerconnectioninterface.h"></a>peerconnectioninterface.h</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line">// This file contains the PeerConnection interface as defined in</div><div class="line">// http://dev.w3.org/2011/webrtc/editor/webrtc.html#peer-to-peer-connections.</div><div class="line">//</div><div class="line">// The PeerConnectionFactory class provides factory methods to create</div><div class="line">// PeerConnection, MediaStream and MediaStreamTrack objects.</div><div class="line">//</div><div class="line">// The following steps are needed to setup a typical call using WebRTC:</div><div class="line">//</div><div class="line">// 1. Create a PeerConnectionFactoryInterface. Check constructors for more</div><div class="line">// information about input parameters.</div><div class="line">//</div><div class="line">// 2. Create a PeerConnection object. Provide a configuration struct which</div><div class="line">// points to STUN and/or TURN servers used to generate ICE candidates, and</div><div class="line">// provide an object that implements the PeerConnectionObserver interface,</div><div class="line">// which is used to receive callbacks from the PeerConnection.</div><div class="line">//</div><div class="line">// 3. Create local MediaStreamTracks using the PeerConnectionFactory and add</div><div class="line">// them to PeerConnection by calling AddTrack (or legacy method, AddStream).</div><div class="line">//</div><div class="line">// 4. Create an offer, call SetLocalDescription with it, serialize it, and send</div><div class="line">// it to the remote peer</div><div class="line">//</div><div class="line">// 5. Once an ICE candidate has been gathered, the PeerConnection will call the</div><div class="line">// observer function OnIceCandidate. The candidates must also be serialized and</div><div class="line">// sent to the remote peer.</div><div class="line">//</div><div class="line">// 6. Once an answer is received from the remote peer, call</div><div class="line">// SetRemoteDescription with the remote answer.</div><div class="line">//</div><div class="line">// 7. Once a remote candidate is received from the remote peer, provide it to</div><div class="line">// the PeerConnection by calling AddIceCandidate.</div><div class="line">//</div><div class="line">// The receiver of a call (assuming the application is &quot;call&quot;-based) can decide</div><div class="line">// to accept or reject the call; this decision will be taken by the application,</div><div class="line">// not the PeerConnection.</div><div class="line">//</div><div class="line">// If the application decides to accept the call, it should:</div><div class="line">//</div><div class="line">// 1. Create PeerConnectionFactoryInterface if it doesn&apos;t exist.</div><div class="line">//</div><div class="line">// 2. Create a new PeerConnection.</div><div class="line">//</div><div class="line">// 3. Provide the remote offer to the new PeerConnection object by calling</div><div class="line">// SetRemoteDescription.</div><div class="line">//</div><div class="line">// 4. Generate an answer to the remote offer by calling CreateAnswer and send it</div><div class="line">// back to the remote peer.</div><div class="line">//</div><div class="line">// 5. Provide the local answer to the new PeerConnection by calling</div><div class="line">// SetLocalDescription with the answer.</div><div class="line">//</div><div class="line">// 6. Provide the remote ICE candidates by calling AddIceCandidate.</div><div class="line">//</div><div class="line">// 7. Once a candidate has been gathered, the PeerConnection will call the</div><div class="line">// observer function OnIceCandidate. Send these candidates to the remote peer.</div></pre></td></tr></table></figure>
<ul>
<li>StreamCollectionInterface</li>
<li>StatsObserver</li>
<li>PeerConnectionInterface</li>
<li>PeerConnectionObserver:PeerConnection callback interface, used for RTCPeerConnection events. Application should implement these methods.</li>
<li>PeerConnectionFactoryInterface:PeerConnectionFactoryInterface is the factory interface used for creating PeerConnection, MediaStream and MediaStreamTrack objects.The simplest method for obtaiing one, CreatePeerConnectionFactory will create the required libjingle threads, socket and network manager factory classes for networking if none are provided, though it requires that the application runs a message loop on the thread that called the method (see explanation below) If an application decides to provide its own threads and/or implementation of networking classes, it should use the alternate CreatePeerConnectionFactory method which accepts threads as input, and use the CreatePeerConnection version that takes a PortAllocator as an argument.</li>
</ul>
<h5 id="peerconnectionproxy-h"><a href="#peerconnectionproxy-h" class="headerlink" title="peerconnectionproxy.h"></a>peerconnectionproxy.h</h5><h5 id="proxy-h"><a href="#proxy-h" class="headerlink" title="proxy.h"></a>proxy.h</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">// This file contains Macros for creating proxies for webrtc MediaStream and</div><div class="line">// PeerConnection classes.</div><div class="line">// TODO(deadbeef): Move this to pc/; this is part of the implementation.</div><div class="line"></div><div class="line">//</div><div class="line">// Example usage:</div><div class="line">//</div><div class="line">// class TestInterface : public rtc::RefCountInterface &#123;</div><div class="line">//  public:</div><div class="line">//   std::string FooA() = 0;</div><div class="line">//   std::string FooB(bool arg1) const = 0;</div><div class="line">//   std::string FooC(bool arg1) = 0;</div><div class="line">//  &#125;;</div><div class="line">//</div><div class="line">// Note that return types can not be a const reference.</div><div class="line">//</div><div class="line">// class Test : public TestInterface &#123;</div><div class="line">// ... implementation of the interface.</div><div class="line">// &#125;;</div><div class="line">//</div><div class="line">// BEGIN_PROXY_MAP(Test)</div><div class="line">//   PROXY_SIGNALING_THREAD_DESTRUCTOR()</div><div class="line">//   PROXY_METHOD0(std::string, FooA)</div><div class="line">//   PROXY_CONSTMETHOD1(std::string, FooB, arg1)</div><div class="line">//   PROXY_WORKER_METHOD1(std::string, FooC, arg1)</div><div class="line">// END_PROXY_MAP()</div><div class="line">//</div><div class="line">// Where the destructor and first two methods are invoked on the signaling</div><div class="line">// thread, and the third is invoked on the worker thread.</div><div class="line">//</div><div class="line">// The proxy can be created using</div><div class="line">//</div><div class="line">//   TestProxy::Create(Thread* signaling_thread, Thread* worker_thread,</div><div class="line">//                     TestInterface*).</div><div class="line">//</div><div class="line">// The variant defined with BEGIN_SIGNALING_PROXY_MAP is unaware of</div><div class="line">// the worker thread, and invokes all methods on the signaling thread.</div><div class="line">//</div><div class="line">// The variant defined with BEGIN_OWNED_PROXY_MAP does not use</div><div class="line">// refcounting, and instead just takes ownership of the object being proxied.</div></pre></td></tr></table></figure>
<h5 id="rtcerror-h-cc"><a href="#rtcerror-h-cc" class="headerlink" title="rtcerror.h/cc"></a>rtcerror.h/cc</h5><h5 id="rtcerror-unittest-cc"><a href="#rtcerror-unittest-cc" class="headerlink" title="rtcerror_unittest.cc"></a>rtcerror_unittest.cc</h5><h5 id="rtpparameters-h"><a href="#rtpparameters-h" class="headerlink" title="rtpparameters.h"></a>rtpparameters.h</h5><h5 id="rtpreceiverinterface-h"><a href="#rtpreceiverinterface-h" class="headerlink" title="rtpreceiverinterface.h"></a>rtpreceiverinterface.h</h5><h5 id="rtpsender-h"><a href="#rtpsender-h" class="headerlink" title="rtpsender.h"></a>rtpsender.h</h5><h5 id="rtpsenderinterface-h"><a href="#rtpsenderinterface-h" class="headerlink" title="rtpsenderinterface.h"></a>rtpsenderinterface.h</h5><h5 id="statstypes-h-cc"><a href="#statstypes-h-cc" class="headerlink" title="statstypes.h/cc"></a>statstypes.h/cc</h5><h5 id="streamcollection-h"><a href="#streamcollection-h" class="headerlink" title="streamcollection.h"></a>streamcollection.h</h5><h5 id="umametrics-h"><a href="#umametrics-h" class="headerlink" title="umametrics.h"></a>umametrics.h</h5><h5 id="videosourceproxy-h"><a href="#videosourceproxy-h" class="headerlink" title="videosourceproxy.h"></a>videosourceproxy.h</h5><h5 id="videotracksource-h"><a href="#videotracksource-h" class="headerlink" title="videotracksource.h"></a>videotracksource.h</h5><h5 id="webrtcsdp-h"><a href="#webrtcsdp-h" class="headerlink" title="webrtcsdp.h"></a>webrtcsdp.h</h5><h5 id="audio-audio-mixer-h"><a href="#audio-audio-mixer-h" class="headerlink" title="audio/audio_mixer.h"></a>audio/audio_mixer.h</h5><ul>
<li>AudioMixer:This class is under development and is not yet intended for for use outside of WebRtc/Libjingle.</li>
</ul>
<h5 id="audio-codecs-audio-decoder-h-cc"><a href="#audio-codecs-audio-decoder-h-cc" class="headerlink" title="audio_codecs/audio_decoder.h/cc"></a>audio_codecs/audio_decoder.h/cc</h5><ul>
<li>AudioDecoder</li>
</ul>
<h5 id="audio-codecs-audio-decoder-factory-h"><a href="#audio-codecs-audio-decoder-factory-h" class="headerlink" title="audio_codecs/audio_decoder_factory.h"></a>audio_codecs/audio_decoder_factory.h</h5><ul>
<li>AudioDecoderFactory</li>
</ul>
<h5 id="audio-codecs-audio-encoder-h-cc"><a href="#audio-codecs-audio-encoder-h-cc" class="headerlink" title="audio_codecs/audio_encoder.h/cc"></a>audio_codecs/audio_encoder.h/cc</h5><p>-AudioEncoder: his is the interface class for encoders in AudioCoding module. Each codec type must have an implementation of this class.</p>
<h5 id="audio-codecs-audio-encoder-factory-h"><a href="#audio-codecs-audio-encoder-factory-h" class="headerlink" title="audio_codecs/audio_encoder_factory.h"></a>audio_codecs/audio_encoder_factory.h</h5><ul>
<li>AudioEncoderFactory</li>
</ul>
<h5 id="audio-codecs-audio-format-h-cc"><a href="#audio-codecs-audio-format-h-cc" class="headerlink" title="audio_codecs/audio_format.h/cc"></a>audio_codecs/audio_format.h/cc</h5><h5 id="audio-codecs-builtin-audio-encoder-factory-h-cc"><a href="#audio-codecs-builtin-audio-encoder-factory-h-cc" class="headerlink" title="audio_codecs/builtin_audio_encoder_factory.h/cc"></a>audio_codecs/builtin_audio_encoder_factory.h/cc</h5><h5 id="audio-codecs-builtin-audio-decoder-factory-h-cc"><a href="#audio-codecs-builtin-audio-decoder-factory-h-cc" class="headerlink" title="audio_codecs/builtin_audio_decoder_factory.h/cc"></a>audio_codecs/builtin_audio_decoder_factory.h/cc</h5><h5 id="call-audio-sink-h"><a href="#call-audio-sink-h" class="headerlink" title="call/audio_sink.h"></a>call/audio_sink.h</h5><h5 id="call-transport-h"><a href="#call-transport-h" class="headerlink" title="call/transport.h"></a>call/transport.h</h5><h5 id="ortc-mediadescription-h-cc"><a href="#ortc-mediadescription-h-cc" class="headerlink" title="ortc/mediadescription.h/cc"></a>ortc/mediadescription.h/cc</h5><h5 id="ortc-mediadescription-unittest-cc"><a href="#ortc-mediadescription-unittest-cc" class="headerlink" title="ortc/mediadescription_unittest.cc"></a>ortc/mediadescription_unittest.cc</h5><h5 id="ortc-ortcfactoryinterface-h"><a href="#ortc-ortcfactoryinterface-h" class="headerlink" title="ortc/ortcfactoryinterface.h"></a>ortc/ortcfactoryinterface.h</h5><h5 id="ortc-ortcrtpreceiverinterface-h"><a href="#ortc-ortcrtpreceiverinterface-h" class="headerlink" title="ortc/ortcrtpreceiverinterface.h"></a>ortc/ortcrtpreceiverinterface.h</h5><h5 id="ortc-ortcrtpsenderinterface-h"><a href="#ortc-ortcrtpsenderinterface-h" class="headerlink" title="ortc/ortcrtpsenderinterface.h"></a>ortc/ortcrtpsenderinterface.h</h5><h5 id="ortc-packettransportinterface-h"><a href="#ortc-packettransportinterface-h" class="headerlink" title="ortc/packettransportinterface.h"></a>ortc/packettransportinterface.h</h5><h5 id="ortc-rtptransportcontrollerinterface-h"><a href="#ortc-rtptransportcontrollerinterface-h" class="headerlink" title="ortc/rtptransportcontrollerinterface.h"></a>ortc/rtptransportcontrollerinterface.h</h5><h5 id="ortc-rtptransportinterface-h"><a href="#ortc-rtptransportinterface-h" class="headerlink" title="ortc/rtptransportinterface.h"></a>ortc/rtptransportinterface.h</h5><h5 id="ortc-sessiondecription-h-cc"><a href="#ortc-sessiondecription-h-cc" class="headerlink" title="ortc/sessiondecription.h/cc"></a>ortc/sessiondecription.h/cc</h5><h5 id="ortc-sessiondescription-unittest-cc"><a href="#ortc-sessiondescription-unittest-cc" class="headerlink" title="ortc/sessiondescription_unittest.cc"></a>ortc/sessiondescription_unittest.cc</h5><h5 id="ortc-srtptransportinerface-h"><a href="#ortc-srtptransportinerface-h" class="headerlink" title="ortc/srtptransportinerface.h"></a>ortc/srtptransportinerface.h</h5><h5 id="ortc-udptransportinterface-h"><a href="#ortc-udptransportinterface-h" class="headerlink" title="ortc/udptransportinterface.h"></a>ortc/udptransportinterface.h</h5>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg"
               alt="轻口味" />
          <p class="site-author-name" itemprop="name">轻口味</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">73</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">47</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/qingkouwei" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/LightTaste" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.douban.com/people/turnpp/" target="_blank" title="豆瓣">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  豆瓣
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/shen-jun-wei-9/" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/ossrs/srs" title="SRS" target="_blank">SRS</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">轻口味</span>
</div>

<div>
<a href="http://www.miitbeian.gov.cn/">京ICP备17018543号</a>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  
    
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "bb46b146831e4e34808d09cd94c85f50",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

</body>
</html>
