<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="老司机种菜" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="老司机种菜">
<meta property="og:url" content="http://wodekouwei.com/index.html">
<meta property="og:site_name" content="老司机种菜">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="老司机种菜">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wodekouwei.com/"/>





  <title> 老司机种菜 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2021aa5f03a4203621d42ef374e0d5f7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">老司机种菜</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/07/03/tips-android-performance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/03/tips-android-performance/" itemprop="url">
                  Android应用性能优化
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-03T22:53:59+08:00">
                2017-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Android/" itemprop="url" rel="index">
                    <span itemprop="name">Android</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Android手机由于其本身的后台机制和硬件特点，性能上一直被诟病，所以软件开发者对软件本身的性能优化就显得尤为重要；本文将对Android开发过程中性能优化的各个方面做一个回顾与总结。</p>
<h3 id="Cache优化"><a href="#Cache优化" class="headerlink" title="Cache优化"></a>Cache优化</h3><ul>
<li><p>ListView缓存：</p>
<ul>
<li>ListView中有一个回收器，Item滑出界面的时候View会回收到这里，需要显示新的Item的时候，就尽量重用回收器里面的View；每次在getView函数中inflate新的item之前会先判断回收器中是否有缓存的view，即判断convertView是否为null，是则inflate一个新的item View，否则重用回收器中的item。</li>
<li>此外，ListView还使用静态的ViewHolder减少findViewById的次数</li>
<li>ListView中有getViewTypeCount()函数用于获取列表有几种布局类型，getItemViewType(int position)用于获取在position位置上的布局类型; 我们可以利用ViewType来给不同类型的item创建不同的View，这样可以利于ListView的回收</li>
<li>对Item中图片进行适当压缩, 并进行异步加载；如果快速滑动，不加载图片；实现数据的分页加载</li>
</ul>
</li>
<li><p>IO缓存：在文件和网络IO中使用具有缓存策略的输入流，BufferedInputStream替代InputStream，BufferedReader替代Reader，BufferedReader替代BufferedInputStream</p>
</li>
<li><p>data缓存(空间换时间)：①缓存数据库的查询结果，比如缓存数据库表中的数据条数，这样就可以避免多次的select count查询 ②缓存磁盘文件中需要频繁访问的数据到内存中 ③缓存耗时计算的结果</p>
</li>
</ul>
<h3 id="Battery优化"><a href="#Battery优化" class="headerlink" title="Battery优化"></a>Battery优化</h3><ul>
<li>cpu的使用率和使用频率将直接或间接的影响电量的分配和使用，cpu降频可以节约电量</li>
<li><p>service优化</p>
<ul>
<li><p>service作为一个运行在主线程中的后台服务，应该尽量避免耗时动作，而应该尽量新开线程去处理耗时动作
监听系统广播看service是否存活，否则kill掉；降低service优先级使得系统内存吃紧时会被自动kill掉</p>
</li>
<li><p>使用Android提供的IntentService代替service，因为IntentService会在运行完成之后自动停止，而service需要手动调用stopService()才能停止运行</p>
</li>
<li><p>定时执行任务的Alarm机制：Android的定时任务有两种实现方式，Timer类和Alarm机制；Timer不适合长期后台运行的定时任务。因为每种手机都会有自己的休眠策略，Android手机就会在长时间不操作的情况下自动让CPU进入到睡眠状态，这就有可能导致Timer中的定时任务无法正常运行。而Alarm机制则不存在这种情况，它具有唤醒CPU的功能，即可以保证每次需要执行定时任务的时候CPU能正常工作。然而从Android4.4之后，Alarm任务的触发时间将会变得不准确，有可能会延迟一段时间后任务才能得到执行。这不是bug，而是系统在耗电性方面进行的优化。系统会自动检测目前有多少Alarm任务存在，然后将触发时间将近的几个任务放在一起执行，这就可以大幅度的减少CPU被唤醒的次数，从而有效延长电池的使用时间</p>
</li>
</ul>
</li>
</ul>
<h3 id="渲染层优化"><a href="#渲染层优化" class="headerlink" title="渲染层优化"></a>渲染层优化</h3><ul>
<li><p>Android 界面卡顿的原因？</p>
<ul>
<li>UI线程中做耗时操作，比如进行网络请求,磁盘读取，位图修改，更新UI等耗时操作，从而导致UI线程卡顿</li>
<li>布局Layout过于复杂，无法在16ms内完成渲染，或者嵌套层次过深</li>
<li>View过度绘制或者频繁的触发measure、layout，同一时间动画执行的次数过多，导致CPU或GPU负载过重</li>
<li>冗余资源及逻辑等导致加载和执行缓慢</li>
</ul>
</li>
<li>Android 界面卡顿怎么处理？<ul>
<li>xml布局优化：尽量使用include、merge、ViewStub标签，尽量不存在冗余嵌套及过于复杂布局（譬如10层就会直接异常），例如使用RelativeLayout代替LinearLayout可以减少布局层次和复杂性，View的嵌套层次不能过深，尽量使用GONE替换INVISIBLE，使用weight后尽量将width和heigh设置为0dp，减少运算，Item存在非常复杂的嵌套时考虑使用自定义Item View来取代，减少measure与layout次数等。</li>
<li>ListView及Adapter优化；尽量复用getView方法中的相关View，不重复获取实例导致卡顿，列表尽量在滑动过程中不进行UI元素刷新等。</li>
<li>背景和图片等内存分配优化；尽量减少不必要的背景设置，图片尽量压缩处理显示，尽量避免频繁内存抖动等问题出现；尽可能为不同分辨率创建资源，以减少不必要的硬件缩放</li>
<li>自定义View等绘图与布局优化；尽量避免在draw、measure、layout中做过于耗时及耗内存操作，尤其是draw方法中，尽量减少draw、measure、layout等执行次数，避免过度渲染和绘制；减少不必要的inflate，尽量使用全局变量缓存View</li>
<li>避免ANR，不要在UI线程中做耗时操作，譬如多次数据库操作等</li>
</ul>
</li>
<li><p>Layout常用的标签</p>
<ul>
<li><p>include标签：该标签可以用于将布局文件中的公共部分提取出来给其它布局文件复用，从而使得布局模块化，代码轻量化; 注意点: ①如果标签已经定义了id，而嵌入布局文件的root布局文件也定义了id，标签的id会覆盖掉嵌入布局文件root的id，如果include标签没有定义id则会使用嵌入文件root的id ②如果想使用标签覆盖嵌入布局root布局属性，必须同时覆盖layout_height和layout_width属性，否则会直接报编译时语法错误</p>
</li>
<li><p>viewstub标签：该标签与include一样用于引入布局模块，只是引入的布局默认不会扩张，既不会占用显示也不会占用位置，从而在解析layout时节省cpu和内存，只有通过调用setVisibility函数或者Inflate函数才会将其要装载的目标布局给加载出来，从而达到延迟加载的效果；例如条目详情、进度条标识或者未读消息等，这些情况如果在一开始初始化，虽然设置可见性View.GONE,但是在Inflate的时候View仍然会被Inflate，仍然会创建对象。</p>
</li>
<li><p>merge标签：该标签在layout中会被自动忽略，从而减少一层布局嵌套，其主要用处是当一个布局作为子布局被其他布局include时，使用merge当作该布局的顶节点来代替layout顶节点就可以减少一层嵌套</p>
</li>
<li><p>hierarchy viewer：该工具可以方便的查看Activity的布局，各个View的属性、measure、layout、draw的时间，如果耗时较多会用红色标记，否则显示绿色</p>
</li>
</ul>
</li>
</ul>
<h3 id="网络优化"><a href="#网络优化" class="headerlink" title="网络优化"></a>网络优化</h3><ul>
<li>异步请求网络数据，避免频繁请求数据（例如如果某个页面内请求过多，可以考虑做一定的请求合并），尽可能的减少网络请求次数和减小网络请求时间间隔</li>
<li>网络应用传输中使用高效率的数据格式，譬如使用JSON代替XML，使用WebP代替其他图片格式,并对数据进行Gzip压缩数据，比如post请求的body和header内容</li>
<li>及时缓存数据到内存/文件/数据库</li>
<li><p>执行某些操作前尽量先进行网络状态判断，比如wifi传输数据比蜂窝数据更省电，所以尽量在wifi下进行数据的预加载</p>
</li>
<li><p>httpClient和httpUrlConnection对比：</p>
<ul>
<li>httpClient是apache的开源实现，API数量多，非常稳定</li>
<li>httpUrlConnection是java自带的模块: ①可以直接支持GZIP压缩,而HttpClient虽然也支持GZIP，但要自己写代码处理 ②httpUrlConnection直接在系统层面做了缓存策略处理，加快重复请求的速度 ③API简单，体积较小,而且直接支持系统级连接池，即打开的连接不会直接关闭，在一段时间内所有程序可共用</li>
<li>HttpURLConnection在Android2.2之前有个重大Bug，调用close()函数会影响连接池，导致连接复用失效，需要关闭keepAlive;因此在2.2之前http请求都是用httpClient，2.2之后则是使用HttpURLConnection</li>
<li>但是!!!现在!!!Android不再推荐这两种方式！二是直接使用OKHttp这种成熟方案！支持Android 2.3及其以上版本</li>
</ul>
</li>
</ul>
<h3 id="数据结构优化"><a href="#数据结构优化" class="headerlink" title="数据结构优化"></a>数据结构优化</h3><ul>
<li><p>ArrayList和LinkedList的选择：ArrayList根据index取值更快，LinkedList更占内存、随机插入删除更快速、扩容效率更高</p>
</li>
<li><p>ArrayList、HashMap、LinkedHashMap、HashSet的选择：hash系列数据结构查询速度更优，ArrayList存储有序元素，HashMap为键值对数据结构，LinkedHashMap可以记住加入次序的hashMap，HashSet不允许重复元素</p>
</li>
<li><p>HashMap、WeakHashMap选择：WeakHashMap中元素可在适当时候被系统垃圾回收器自动回收，所以适合在内存紧张时使用</p>
</li>
<li><p>Collections.synchronizedMap和ConcurrentHashMap的选择：ConcurrentHashMap为细分锁，锁粒度更小，并发性能更优；Collections.synchronizedMap为对象锁，自己添加函数进行锁控制更方便</p>
</li>
<li><p>Android中性能更优的数据类型：如SparseArray、SparseBooleanArray、SparseIntArray、Pair；Sparse系列的数据结构是为key为int情况的特殊处理，采用二分查找及简单的数组存储，加上不需要泛型转换的开销，相对Map来说性能更优</p>
</li>
</ul>
<h3 id="内存优化"><a href="#内存优化" class="headerlink" title="内存优化"></a>内存优化</h3><ul>
<li>Android应用内存溢出OOM<ul>
<li>内存溢出的主要导致原因有如下几类：①应用代码存在内存泄露，长时间积累无法释放导致OOM；②应用的某些逻辑操作疯狂的消耗掉大量内存（譬如加载一张不经过处理的超大超高清图片等）导致超过阈值OOM</li>
<li>解决思路①在内存引用上做些处理，常用的有软引用、弱引用 ②在内存中加载图片时直接在内存中做处理，如：边界压缩 ③动态回收内存，手动recyle bitmap，回收对象 ④优化Dalvik虚拟机的堆内存分配 ⑤自定义堆内存大小</li>
</ul>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/27/media-terminology/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/27/media-terminology/" itemprop="url">
                  多媒体之术语
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T22:29:35+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一-编解码术语"><a href="#一-编解码术语" class="headerlink" title="一.编解码术语"></a>一.编解码术语</h2><h3 id="1-GOP-码流-比特率-帧速率-分辨率"><a href="#1-GOP-码流-比特率-帧速率-分辨率" class="headerlink" title="1.GOP/码流/比特率/帧速率/分辨率"></a>1.GOP/码流/比特率/帧速率/分辨率</h3><h4 id="1-1GOP（Group-of-picture）"><a href="#1-1GOP（Group-of-picture）" class="headerlink" title="1.1GOP（Group of picture）"></a>1.1GOP（Group of picture）</h4><p>关键帧的周期，也就是两个IDR帧之间的距离，一个帧组的最大帧数，一般而言，每一秒视频至少需要使用 1 个关键帧。增加关键帧个数可改善质量，但是同时增加带宽和网络负载。</p>
<p>需要说明的是，通过提高GOP值来提高图像质量是有限度的，在遇到场景切换的情况时，H.264编码器会自动强制插入一个I帧，此时实际的GOP值被缩短了。另一方面，在一个GOP中，P、B帧是由I帧预测得到的，当I帧的图像质量比较差时，会影响到一个GOP中后续P、B帧的图像质量，直到下一个GOP开始才有可能得以恢复，所以GOP值也不宜设置过大。</p>
<p>同时，由于P、B帧的复杂度大于I帧，所以过多的P、B帧会影响编码效率，使编码效率降低。另外，过长的GOP还会影响Seek操作的响应速度，由于P、B帧是由前面的I或P帧预测得到的，所以Seek操作需要直接定位，解码某一个P或B帧时，需要先解码得到本GOP内的I帧及之前的N个预测帧才可以，GOP值越长，需要解码的预测帧就越多，seek响应的时间也越长。</p>
<h5 id="1-12CABAC-CAVLC"><a href="#1-12CABAC-CAVLC" class="headerlink" title="1.12CABAC/CAVLC"></a>1.12CABAC/CAVLC</h5><p>H.264/AVC标准中两种熵编码方法，CABAC叫自适应二进制算数编码，CAVLC叫前后自适应可变长度编码，</p>
<ol>
<li>CABAC：是一种无损编码方式，画质好，X264就会舍弃一些较小的DCT系数，码率降低，可以将码率再降低10-15%（特别是在高码率情况下），会降低编码和解码的速速。</li>
<li>CAVLC将占用更少的CPU资源，但会影响压缩性能。</li>
</ol>
<p>其他:</p>
<ul>
<li>帧：当采样视频信号时，如果是通过逐行扫描，那么得到的信号就是一帧图像，通常帧频为25帧每秒（PAL制）、30帧每秒（NTSC制）；</li>
<li>场：当采样视频信号时，如果是通过隔行扫描（奇、偶数行），那么一帧图像就被分成了两场，通常场频为50Hz（PAL制）、60Hz（NTSC制）；</li>
<li>帧频、场频的由来：最早由于抗干扰和滤波技术的限制，电视图像的场频通常与电网频率（交流电）相一致，于是根据各地交流电频率不同就有了欧洲和中国等PAL制的50Hz和北美等NTSC制的60Hz，但是现在并没有这样的限制了，帧频可以和场频一样，或者场频可以更高。</li>
<li>帧编码、场编码方式：逐行视频帧内邻近行空间相关性较强，因此当活动量非常小或者静止的图像比较适宜采用帧编码方式；而场内相邻行之间的时间相关性较强，对运动量较大的运动图像则适宜采用场编码方式。</li>
</ul>
<h5 id="1-1-3Deblocking"><a href="#1-1-3Deblocking" class="headerlink" title="1.1.3Deblocking"></a>1.1.3Deblocking</h5><p>开启会减少块效应.</p>
<h5 id="1-1-4FORCE-IDR"><a href="#1-1-4FORCE-IDR" class="headerlink" title="1.1.4FORCE_IDR"></a>1.1.4FORCE_IDR</h5><p>是否让每个I帧变成IDR帧，如果是IDR帧，支持随机访问。</p>
<h5 id="1-1-5frame-tff-bff"><a href="#1-1-5frame-tff-bff" class="headerlink" title="1.1.5frame,tff,bff"></a>1.1.5frame,tff,bff</h5><p>–frame 将两场合并作为一帧进行编码,–tff Enable interlaced mode (开启隔行编码并设置上半场在前),–bff Enable interlaced mode。</p>
<p>PAFF 和MBAFF：当对隔行扫描图像进行编码时，每帧包括两个场，由于两个场之间存在较大的扫描间隔，这样，对运动图像来说，帧中相邻两行之间的空间相关性相对于逐行扫描时就会减小，因此这时对两个场分别进行编码会更节省码流。</p>
<p>对帧来说，存在三种可选的编码方式：将两场合并作为一帧进行编码(frame 方式)或将两场分别编码(field 方式)或将两场合并起来作为一帧，但不同的是将帧中垂直相邻的两个宏块合并为宏块对进行编码；前两种称为PAFF 编码，对运动区域进行编码时field 方式有效，对非运区域编码时，由于相邻两行有较大的相关性，因而frame 方式会更有效。当图像同时存在运动区域和非运动区域时，在MB 层次上，对运动区域采取field 方式，对非运动区域采取frame 方式会更加有效，这种方式就称为MBAFF，预测的单位是宏块对。</p>
<h4 id="1-2码流-码率"><a href="#1-2码流-码率" class="headerlink" title="1.2码流/码率"></a>1.2码流/码率</h4><p>码流(Data Rate)是指视频文件在单位时间内使用的数据流量，也叫码率或码流率，通俗一点的理解就是取样率,是视频编码中画面质量控制中最重要的部分，一般我们用的单位是kb/s或者Mb/s。一般来说同样分辨率下，视频文件的码流越大，压缩比就越小，画面质量就越高。码流越大，说明单位时间内取样率越大，数据流，精度就越高，处理出来的文件就越接近原始文件，图像质量越好，画质越清晰，要求播放设备的解码能力也越高。</p>
<p>当然，码流越大，文件体积也越大，其计算公式是文件体积=时间X码率/8。例如，网络上常见的一部90分钟1Mbps码流的720P RMVB文件，其体积就=5400秒×1Mb/8=675MB。</p>
<p>通常来说，一个视频文件包括了画面及声音，例如一个RMVB的视频文件，里面包含了视频信息和音频信息，音频及视频都有各自不同的采样方式和比特率，也就是说，同一个视频文件音频和视频的比特率并不是一样的。而我们所说的一个视频文件码流率大小，一般是指视频文件中音频及视频信息码流率的总和。</p>
<p>以以国内最流行，大家最熟悉的RMVB视频文件为例，RMVB中的VB，指的是VBR，即Variable Bit Rate的缩写，中文含义是可变比特率，它表示RMVB采用的是动态编码的方式，把较高的采样率用于复杂的动态画面(歌舞、飞车、战争、动作等)，而把较低的采样率用于静态画面，合理利用资源，达到画质与体积可兼得的效果。</p>
<p>码率和取样率最根本的差别就是码率是针对源文件来讲的。</p>
<h4 id="1-3采样率"><a href="#1-3采样率" class="headerlink" title="1.3采样率"></a>1.3采样率</h4><p>采样率（也称为采样速度或者采样频率）定义了每秒从连续信号中提取并组成离散信号的采样个数，它用赫兹（Hz）来表示。采样率是指将模拟信号转换成数字信号时的采样频率，也就是单位时间内采样多少点。一个采样点数据有多少个比特。比特率是指每秒传送的比特(bit)数。单位为 bps(Bit Per Second)，比特率越高，传送的数据越大，音质越好.比特率 =采样率 x 采用位数 x声道数.</p>
<p>采样率类似于动态影像的帧数，比如电影的采样率是24赫兹，PAL制式的采样率是25赫兹，NTSC制式的采样率是30赫兹。当我们把采样到的一个个静止画面再以采样率同样的速度回放时，看到的就是连续的画面。同样的道理，把以44.1kHZ采样率记录的CD以同样的速率播放时，就能听到连续的声音。显然，这个采样率越高，听到的声音和看到的图像就越连贯。当然，人的听觉和视觉器官能分辨的采样率是有限的，基本上高于44.1kHZ采样的声音，绝大部分人已经觉察不到其中的分别了。</p>
<p>而声音的位数就相当于画面的颜色数，表示每个取样的数据量，当然数据量越大，回放的声音越准确，不至于把开水壶的叫声和火车的鸣笛混淆。同样的道理，对于画面来说就是更清晰和准确，不至于把血和西红柿酱混淆。不过受人的器官的机能限制，16位的声音和24位的画面基本已经是普通人类的极限了，更高位数就只能靠仪器才能分辨出来了。比如电话就是3kHZ取样的7位声音，而CD是44.1kHZ取样的16位声音，所以CD就比电话更清楚。</p>
<p>当你理解了以上这两个概念，比特率就很容易理解了。以电话为例，每秒3000次取样，每个取样是7比特，那么电话的比特率是21000。 而CD是每秒 44100次取样，两个声道，每个取样是13位PCM编码，所以CD的比特率是44100<em>2</em>13=1146600，也就是说CD每秒的数据量大约是 144KB，而一张CD的容量是74分等于4440秒，就是639360KB＝640MB。</p>
<p>码率和取样率最根本的差别就是码率是针对源文件来讲的</p>
<h4 id="1-4比特率"><a href="#1-4比特率" class="headerlink" title="1.4比特率"></a>1.4比特率</h4><p>比特率是指每秒传送的比特(bit)数。单位为bps(Bit Per Second)，比特率越高，传送的数据越大。在视频领域,比特率常翻译为码率 !!!</p>
<p>比特率表示经过编码（压缩）后的音、视频数据每秒钟需要用多少个比特来表示，而比特就是二进制里面最小的单位，要么是0，要么是1。比特率与音、视频压缩的关系，简单的说就是比特率越高，音、视频的质量就越好，但编码后的文件就越大；如果比特率越少则情况刚好相反。</p>
<p>比特率是指将数字声音、视频由模拟格式转化成数字格式的采样率，采样率越高，还原后的音质、画质就越好。</p>
<p>常见编码模式：</p>
<ul>
<li>VBR（Variable Bitrate）动态比特率 也就是没有固定的比特率，压缩软件在压缩时根据音频数据即时确定使用什么比特率，这是以质量为前提兼顾文件大小的方式，推荐编码模式；</li>
<li>ABR（Average Bitrate）平均比特率 是VBR的一种插值参数。LAME针对CBR不佳的文件体积比和VBR生成文件大小不定的特点独创了这种编码模式。ABR在指定的文件大小内，以每50帧（30帧约1秒）为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量，可以做为VBR和CBR的一种折衷选择。</li>
<li>CBR（Constant Bitrate），常数比特率 指文件从头到尾都是一种位速率。相对于VBR和ABR来讲，它压缩出来的文件体积很大，而且音质相对于VBR和ABR不会有明显的提高。</li>
</ul>
<h4 id="1-5帧速率"><a href="#1-5帧速率" class="headerlink" title="1.5帧速率"></a>1.5帧速率</h4><p>帧速率也称为FPS(Frames PerSecond)的缩写——帧/秒。是指每秒钟刷新的图片的帧数，也可以理解为图形处理器每秒钟能够刷新几次。越高的帧速率可以得到更流畅、更逼真的动画。每秒钟帧数(FPS)越多，所显示的动作就会越流畅。</p>
<h4 id="1-6分辨率"><a href="#1-6分辨率" class="headerlink" title="1.6分辨率"></a>1.6分辨率</h4><p>就是帧大小每一帧就是一副图像。</p>
<p>640*480分辨率的视频，建议视频的码速率设置在700以上，音频采样率44100就行了</p>
<p>一个音频编码率为128Kbps，视频编码率为800Kbps的文件，其总编码率为928Kbps，意思是经过编码后的数据每秒钟需要用928K比特来表示。</p>
<p>视频分辨率是指视频成像产品所成图像的大小或尺寸。常见的视像分辨率有352×288，176×144，640×480，1024×768。在成像的两组数字中，前者为图片长度，后者为图片的宽度，两者相乘得出的是图片的像素，长宽比一般为4：3. 　目前监控行业中主要使用Qcif(176×144）、CIF(352×288）、HALF D1(704×288）、D1(704×576）等几种分辨率。
D1是数字电视系统显示格式的标准，共分为以下5种规格：</p>
<ol>
<li>D1：480i格式（525i）：720×480（水平480线，隔行扫描），和NTSC模拟电视清晰度相同，行频为15.25kHz，相当于我们所说的4CIF(720×576)</li>
<li>D2：480P格式（525p）：720×480（水平480线，逐行扫描），较D1隔行扫描要清晰不少，和逐行扫描DVD规格相同，行频为31.5kHz</li>
<li>D3：1080i格式（1125i）：1920×1080（水平1080线，隔行扫描），高清方式采用最多的一种分辨率，分辨率为1920×1080i/60Hz，行频为33.75kHz</li>
<li>D4：720p格式（750p）：1280×720（水平720线，逐行扫描），虽然分辨率较D3要低，但是因为逐行扫描，市面上更多人感觉相对于1080I（实际逐次540线）视觉效果更加清晰。不过个人感觉来说，在最大分辨率达到1920×1080的情况下，D3要比D4感觉更加清晰，尤其是文字表现力上，分辨率为1280×720p/60Hz，行频为45kHz</li>
<li>D5：1080p格式（1125p）：1920×1080（水平1080线，逐行扫描），目前民用高清视频的最高标准，分辨率为1920×1080P/60Hz，行频为67.5KHZ。</li>
</ol>
<p>其中D1 和D2标准是我们一般模拟电视的最高标准，并不能称的上高清晰，D3的1080i标准是高清晰电视的基本标准，它可以兼容720p格式，而D5的1080P只是专业上的标准。</p>
<p>计算输出文件大小公式：
（音频编码率（KBit为单位）/8 +视频编码率（KBit为单位）/8）×影片总长度（秒为单位）=文件大小（MB为单位）</p>
<h3 id="2-高清视频"><a href="#2-高清视频" class="headerlink" title="2.高清视频"></a>2.高清视频</h3><p>目前的720P以及1080P采用了很多种编码，例如主流的MPEG2，VC-1以及H.264，还有Divx以及Xvid，至于封装格式更多到令人发指，ts、mkv、wmv以及蓝光专用等等。</p>
<p>720和1080代表视频流的分辨率，前者1280<em>720，后者1920</em>1080，不同的编码需要不同的系统资源，大概可以认为是H.264&gt;VC-1&gt;MPEG2。 　</p>
<p>VC-1是最后被认可的高清编码格式，不过因为有微软的后台，所以这种编码格式不能小窥。相对于MPEG2，VC-1的压缩比更高，但相对于H.264而言，编码解码的计算则要稍小一些，目前来看，VC-1可能是一个比较好的平衡，辅以微软的支持，应该是一只不可忽视的力量。一般来说，VC-1多为 “.wmv”后缀，但这都不是绝对的，具体的编码格式还是要通过软件来查询。</p>
<p>总的来说，从压缩比上来看，H.264的压缩比率更高一些，也就是同样的视频，通过H.264编码算法压出来的视频容量要比VC-1的更小，但是VC-1 格式的视频在解码计算方面则更小一些，一般通过高性能的CPU就可以很流畅的观看高清视频。相信这也是目前NVIDIA Geforce 8系列显卡不能完全解码VC-1视频的主要原因。</p>
<p>PS&amp;TS是两种视频或影片封装格式，常用于高清片。扩展名分别为VOB/EVO和TS等；其文件编码一般用MPEG2/VC-1/H.264</p>
<p> 高清，英文为“High Definition”，即指“高分辨率”。 高清电视(HDTV)，是由美国电影电视工程师协会确定的高清晰度电视标准格式。现在的大屏幕液晶电视机，一般都支持1080i和720P，而一些俗称的“全高清”(Full HD)，则是指支持1080P输出的电视机。</p>
<p>目前的高清视频编码格式主要有H.264、VC-1、MPEG-2、MPEG-4、DivX、XviD、WMA-HD以及X264。事实上，现在网络上流传的高清视频主要以两类文件的方式存在：一类是经过MPEG-2标准压缩，以tp和ts为后缀的视频流文件;一类是经过WMV-HD(Windows Media Video HighDefinition)标准压缩过的wmv文件，还有少数文件后缀为avi或mpg，其性质与wmv是一样的。真正效果好的高清视频更多地以H.264与VC-1这两种主流的编码格式流传。</p>
<p>一般来说，H.264格式以“.avi”、“.mkv”以及“.ts”封装比较常见。</p>
<h3 id="3-位率（定码率，变码率）"><a href="#3-位率（定码率，变码率）" class="headerlink" title="3.位率（定码率，变码率）"></a>3.位率（定码率，变码率）</h3><p>位率又称为“码率”。指单位时间内，单个录像通道所产生的数据量，其单位通常是bps、Kbps或Mbps。可以根据录像的时间与位率估算出一定时间内的录像文件大小。 　位率是一个可调参数，不同的分辨率模式下和监控场景下，合适的位率大小是不同的。在设置时，要综合考虑三个因素： 　　</p>
<ol>
<li>分辨率:分辨率是决定位率（码率）的主要因素，不同的分辨率要采用不同的位率。总体而言，录像的分辨率越高，所要求的位率（码率）也越大，但并不总是如此，图1说明了不同分辨率的合理的码率选择范围。所谓“合理的范围”指的是，如果低于这个范围，图像质量看起来会变得不可接受；如果高于这个范围，则显得没有必要，对于网络资源以及存储资源来说是一种浪费。 　　</li>
<li>场景:监控的场景是设置码率时要考虑的第二个因素。在视频监控中，图像的运动剧烈程度还与位率有一定的关系，运动越剧烈，编码所要求的码率就越高。反之则越低。因此在同样的图像分辨率条件下，监控人多的场景和人少的场景，所要求的位率也是不同的。 　　</li>
<li>存储空间:最后需要考量的因素是存储空间，这个因素主要是决定了录像系统的成本。位率设置得越高，画质相对会越好，但所要求的存储空间就越大。所以在工程实施中，设置合适的位率即可以保证良好的回放图像质量，又可以避免不必要的资源浪费。
　　
QP(quantizer parameter)
介于0~31之间，值越小，量化越精细，图像质量就越高，而产生的码流也越长。</li>
</ol>
<p>PSNR
允许计算峰值信噪比(PSNR,Peak signal-to-noise ratio),编码结束后在屏幕上显示PSNR计算结果。开启与否与输出的视频质量无关，关闭后会带来微小的速度提升。</p>
<p>profile level
分别是BP、EP、MP、HP：</p>
<ol>
<li>BP-Baseline Profile：基本画质。支持I/P 帧，只支持无交错（Progressive）和CAVLC；</li>
<li>EP-Extended profile：进阶画质。支持I/P/B/SP/SI 帧，只支持无交错（Progressive）和CAVLC；</li>
<li>MP-Main profile：主流画质。提供I/P/B 帧，支持无交错（Progressive）和交错（Interlaced），也支持CAVLC 和CABAC 的支持；</li>
<li>HP-High profile：高级画质。在main Profile 的基础上增加了8x8内部预测、自定义量化、无损视频编码和更多的YUV 格式；</li>
</ol>
<p>H.264规定了三种档次，每个档次支持一组特定的编码功能，并支持一类特定的应用。</p>
<ol>
<li>基本档次：利用I片和P片支持帧内和帧间编码，支持利用基于上下文的自适应的变长编码进行的熵编码（CAVLC）。主要用于可视电话、会议电视、无线通信等实时视频通信；</li>
<li>主要档次：支持隔行视频，采用B片的帧间编码和采用加权预测的帧内编码；支持利用基于上下文的自适应的算术编码（CABAC）。主要用于数字广播电视与数字视频存储；</li>
<li>扩展档次：支持码流之间有效的切换（SP和SI片）、改进误码性能（数据分割），但不支持隔行视频和CABAC。主要用于网络的视频流，如视频点播。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/27/media-graphic-image-stride/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/27/media-graphic-image-stride/" itemprop="url">
                  Image Stride(内存图像行跨度)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T15:00:14+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>When a video image is stored in memory, the memory buffer might contain extra padding bytes after each row of pixels. The padding bytes affect how the image is store in memory, but do not affect how the image is displayed.</p>
<p>当视频图像存储在内存时，图像的每一行末尾也许包含一些扩展的内容，这些扩展的内容只影响图像如何存储在内存中，但是不影响图像如何显示出来；</p>
<p>The stride is the number of bytes from one row of pixels in memory to the next row of pixels in memory. Stride is also called pitch. If padding bytes are present, the stride is wider than the width of the image, as shown in the following illustration.</p>
<p>Stride 就是这些扩展内容的名称，Stride 也被称作 Pitch，如果图像的每一行像素末尾拥有扩展内容，Stride 的值一定大于图像的宽度值，就像下图所示：
<img src="http://images.wodekouwei.com/media/imagestride1.png" alt="image"></p>
<p>Two buffers that contain video frames with equal dimensions can have two different strides. If you process a video image, you must take into the stride into account.</p>
<p>两个缓冲区包含同样大小（宽度和高度）的视频帧，却不一定拥有同样的 Stride 值，如果你处理一个视频帧，你必须在计算的时候把 Stride 考虑进去；</p>
<p>In addition, there are two ways that an image can be arranged in memory. In a top-down image, the top row of pixels in the image appears first in memory. In a bottom-up image, the last row of pixels appears first in memory. The following illustration shows the difference between a top-down image and a bottom-up image.</p>
<p>另外，一张图像在内存中有两种不同的存储序列（arranged），对于一个从上而下存储（Top-Down） 的图像，最顶行的像素保存在内存中最开头的部分，对于一张从下而上存储（Bottom-Up）的图像，最后一行的像素保存在内存中最开头的部分，下面图示展示了这两种情况：
<img src="http://images.wodekouwei.com/media/imagestride2.png" alt="image"></p>
<p>A bottom-up image has a negative stride, because stride is defined as the number of bytes need to move down a row of pixels, relative to the displayed image. YUV images should always be top-down, and any image that is contained in a Direct3D surface must be top-down. RGB images in system memory are usually bottom-up.</p>
<p>一张从下而上的图像拥有一个负的 Stride 值，因为 Stride 被定义为[从一行像素移动到下一行像素时需要跨过多少个像素]，仅相对于被显示出来的图像而言；而 YUV 图像永远都是从上而下表示的，以及任何包含在 Direct3D Surface 中的图像必须是从上而下，RGB 图像保存在系统内存时通常是从下而上；</p>
<p>Video transforms in particular need to handle buffers with mismatched strides, because the input buffer might not match the output buffer. For example, suppose that you want to convert a source image and write the result to a destination image. Assume that both images have the same width and height, but might not have the same pixel format or the same image stride.</p>
<p>尤其是视频变换，特别需要处理不同 Stride 值的图像，因为输入缓冲也许与输出缓冲不匹配，举个例子，假设你想要将源图像转换并且将结果写入到目标图像，假设两个图像拥有相同的宽度和高度，但是其像素格式与 Stride 值也许不同；</p>
<p>The following example code shows a generalized approach for writing this kind of function. This is not a complete working example, because it abstracts many of the specific details.</p>
<p>下面代码演示了一种通用方法来编写这种功能，这段代码并不完整，因为这只是一个抽象的算法，没有完全考虑到真实需求中的所有细节；
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">void ProcessVideoImage(</div><div class="line">    BYTE*       pDestScanLine0,    </div><div class="line">    LONG        lDestStride,       </div><div class="line">    const BYTE* pSrcScanLine0,     </div><div class="line">    LONG        lSrcStride,        </div><div class="line">    DWORD       dwWidthInPixels,    </div><div class="line">    DWORD       dwHeightInPixels</div><div class="line">    )</div><div class="line">&#123;</div><div class="line">    for (DWORD y = 0; y &lt; dwHeightInPixels; y++)</div><div class="line">    &#123;</div><div class="line">        SOURCE_PIXEL_TYPE *pSrcPixel = (SOURCE_PIXEL_TYPE*)pDestScanLine0;</div><div class="line">        DEST_PIXEL_TYPE *pDestPixel = (DEST_PIXEL_TYPE*)pSrcScanLine0;</div><div class="line"></div><div class="line">        for (DWORD x = 0; x &lt; dwWidthInPixels; x +=2)</div><div class="line">        &#123;</div><div class="line">            pDestPixel[x] = TransformPixelValue(pSrcPixel[x]);</div><div class="line">        &#125;</div><div class="line">        pDestScanLine0 += lDestStride;</div><div class="line">        pSrcScanLine0 += lSrcStride;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>This function takes six parameters:</p>
<ul>
<li>A pointer to the start of scan line 0 in the destination image.</li>
<li>The stride of the destination image.</li>
<li>A pointer to the start of scan line 0 in the source image.</li>
<li>The stride of the source image.</li>
<li>The width of the image in pixels.</li>
<li>The height of the image in pixels.</li>
</ul>
<p>这个函数需要六个参数：</p>
<ul>
<li>目标图像的起始扫描行的内存指针</li>
<li>目标图像的 Stride 值</li>
<li>源图像的起始扫描行的内存指针</li>
<li>源图像的 Stride 值</li>
<li>图像的宽度值（以像素为单位）</li>
<li>图像的高度值（以像素为单位）
The general idea is to process one row at a time, iterating over each pixel in the row. Assume that SOURCE_PIXEL_TYPE and DEST_PIXEL_TYPE are structures representing the pixel layout for the source and destination images, respectively. (For example, 32-bit RGB uses the RGBQUAD structure. Not every pixel format has a pre-defined structure.) Casting the array pointer to the structure type enables you to access the RGB or YUV components of each pixel. At the start of each row, the function stores a pointer to the row. At the end of the row, it increments the pointer by the width of the image stride, which advances the pointer to the next row.</li>
</ul>
<p>这里的要点是如何一次处理一行像素，遍历一行里面的每一个像素，假设源像素类型与目标像素类型各自在像素的层面上已经结构化来表示一个源图像与目标图像的像素，（举个例子，32 位 RGB 像素使用 RGBQUAD 结构体，并不是每一种像素类型都有预定义结构体的）强制转换数组指针到这样的结构体指针，可以方便你直接读写每一个像素的 RGB 或者 YUV 值，在每一行的开头，这个函数保存了一个指向这行像素的指针，函数的最后一行，通过图像的 Stride 值直接将指针跳转到图像的下一行像素的起始点；</p>
<p>This example calls a hypothetical function named TransformPixelValue for each pixel. This could be any function that calculates a target pixel from a source pixel. Of course, the exact details will depend on the particular task. For example, if you have a planar YUV format, you must access the chroma planes independently from the luma plane; with interlaced video, you might need to process the fields separately; and so forth.</p>
<p>To give a more concrete example, the following code converts a 32-bit RGB image into an AYUV image. The RGB pixels are accessed using an RGBQUAD structure, and the AYUV pixels are accessed using aDXVA2_AYUVSample8 Structure structure.</p>
<blockquote>
<p>引用:
如果你用的是 MSDN Library For Visual Studio 2008 SP1，那么你应该能够在下面地址中找到这篇文章的原文：
ms-help://MS.MSDNQTR.v90.chs/medfound/html/13cd1106-48b3-4522-ac09-8efbaab5c31d.htm</p>
<p><a href="http://blog.csdn.net/g0ose/article/details/52116453" target="_blank" rel="external">http://blog.csdn.net/g0ose/article/details/52116453</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/27/gl-glBlendFunc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/27/gl-glBlendFunc/" itemprop="url">
                  OpenGL混色
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T10:44:39+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OpenGL/" itemprop="url" rel="index">
                    <span itemprop="name">OpenGL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>混合就是把两种颜色混在一起。具体一点，就是把某一像素位置原来的颜色和将要画上去的颜色，通过某种方式混在一起，从而实现特殊的效果。
假设我们需要绘制这样一个场景：透过红色的玻璃去看绿色的物体，那么可以先绘制绿色的物体，再绘制红色玻璃。在绘制红色玻璃的时候，利用“混合”功能，把将要绘制上去的红色和原来的绿色进行混合，于是得到一种新的颜色，看上去就好像玻璃是半透明的。
要使用OpenGL的混合功能，只需要调用：<code>glEnable(GL_BLEND);</code>即可。要关闭OpenGL的混合功能，只需要调用：<code>glDisable(GL_BLEND);</code>即可。
<strong>注意：</strong> 只有在RGBA模式下，才可以使用混合功能，颜色索引模式下是无法使用混合功能的。</p>
<h3 id="1-源因子和目标因子"><a href="#1-源因子和目标因子" class="headerlink" title="1.源因子和目标因子"></a>1.源因子和目标因子</h3><p>混合需要把原来的颜色和将要画上去的颜色找出来，经过某种方式处理后得到一种新的颜色。这里把将要画上去的颜色称为“源颜色”，把原来的颜色称为“目标颜色”。
OpenGL 会把源颜色和目标颜色各自取出，并乘以一个系数（源颜色乘以的系数称为“源因子”，目标颜色乘以的系数称为“目标因子”），然后相加，这样就得到了新的颜 色。（也可以不是相加，新版本的OpenGL可以设置运算方式，包括加、减、取两者中较大的、取两者中较小的、逻辑运算等）
下面用数学公式来表达一下这个运算方式。假设源颜色的四个分量（指红色，绿色，蓝色，alpha值）是(Rs, Gs, Bs,  As)，目标颜色的四个分量是(Rd, Gd, Bd, Ad)，又设源因子为(Sr, Sg, Sb, Sa)，目标因子为(Dr, Dg, Db,  Da)。则混合产生的新颜色可以表示为：
<code>(Rs*Sr+Rd*Dr, Gs*Sg+Gd*Dg, Bs*Sb+Bd*Db, As*Sa+Ad*Da)</code>
如果颜色的某一分量超过了1.0，则它会被自动截取为1.0，不需要考虑越界的问题。</p>
<p>源因子和目标因子是可以通过<code>glBlendFunc</code>函数来进行设置的。glBlendFunc有两个参数，前者表示源因子，后者表示目标因子。这两个参数可以是多种值，下面介绍比较常用的几种。</p>
<ul>
<li>GL_ZERO：表示使用0.0作为因子，实际上相当于不使用这种颜色参与混合运算。</li>
<li>GL_ONE：表示使用1.0作为因子，实际上相当于完全的使用了这种颜色参与混合运算。</li>
<li>GL_SRC_ALPHA：表示使用源颜色的alpha值来作为因子。</li>
<li>GL_DST_ALPHA：表示使用目标颜色的alpha值来作为因子。</li>
<li>GL_ONE_MINUS_SRC_ALPHA：表示用1.0减去源颜色的alpha值来作为因子。</li>
<li>GL_ONE_MINUS_DST_ALPHA：表示用1.0减去目标颜色的alpha值来作为因子。</li>
<li>GL_SRC_COLOR: 把源颜色的四个分量分别作为因子的四个分量</li>
<li>GL_ONE_MINUS_SRC_COLOR</li>
<li>GL_DST_COLOR</li>
<li>GL_ONE_MINUS_DST_COLOR
GL_SRC_COLOR与GL_ONE_MINUS_SRC_COLOR在OpenGL旧版本中只能用于设置目标因子，GL_DST_COLOR与GL_ONE_MINUS_DST_COLOR在OpenGL 旧版本中只能用于设置源因子。新版本的OpenGL则没有这个限制，并且支持新的GL_CONST_COLOR（设定一种常数颜色，将其四个分量分别作为 因子的四个分量）、GL_ONE_MINUS_CONST_COLOR、GL_CONST_ALPHA、 GL_ONE_MINUS_CONST_ALPHA。另外还有GL_SRC_ALPHA_SATURATE。新版本的OpenGL还允许颜色的alpha 值和RGB值采用不同的混合因子。</li>
</ul>
<h3 id="2-模式示例"><a href="#2-模式示例" class="headerlink" title="2.模式示例"></a>2.模式示例</h3><ul>
<li>如果设置了glBlendFunc(GL_ONE, GL_ZERO);，则表示完全使用源颜色，完全不使用目标颜色，因此画面效果和不使用混合的时候一致（当然效率可能会低一点点）。如果没有设置源因子和目标因子，则默认情况就是这样的设置。</li>
<li>如果设置了glBlendFunc(GL_ZERO, GL_ONE);，则表示完全不使用源颜色，因此无论你想画什么，最后都不会被画上去了。（但这并不是说这样设置就没有用，有些时候可能有特殊用途）</li>
<li>如果设置了glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);，则表示源颜色乘以自身的alpha 值，目标颜色乘以1.0减去源颜色的alpha值，这样一来，源颜色的alpha值越大，则产生的新颜色中源颜色所占比例就越大，而目标颜色所占比例则减 小。这种情况下，我们可以简单的将源颜色的alpha值理解为“不透明度”。这也是混合时最常用的方式。</li>
<li>如果设置了glBlendFunc(GL_ONE, GL_ONE);，则表示完全使用源颜色和目标颜色，最终的颜色实际上就是两种颜色的简单相加。例如红色(1, 0, 0)和绿色(0, 1, 0)相加得到(1, 1, 0)，结果为黄色。
注意：
所谓源颜色和目标颜色，是跟绘制的顺序有关的。假如先绘制了一个红色的物体，再在其上绘制绿色的物体。则绿色是源颜色，红色是目标颜色。如果顺序反过来，则 红色就是源颜色，绿色才是目标颜色。在绘制时，应该注意顺序，使得绘制的源颜色与设置的源因子对应，目标颜色与设置的目标因子对应。</li>
</ul>
<h3 id="3-对两种示例模式的具体解释"><a href="#3-对两种示例模式的具体解释" class="headerlink" title="3.对两种示例模式的具体解释:"></a>3.对两种示例模式的具体解释:</h3><p>模式一:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">GLES20.glEnable(GLES20.GL_BLEND);  </div><div class="line">GLES20.glBlendFunc(GLES20.GL_SRC_ALPHA, GLES20.GL_ONE_MINUS_SRC_ALPHA);</div></pre></td></tr></table></figure></p>
<p>模式二:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">GLES20.glEnable(GLES20.GL_BLEND);  </div><div class="line">GLES20.glBlendFunc(GLES20.GL_ONE, GLES20.GL_ONE_MINUS_SRC_ALPHA);</div></pre></td></tr></table></figure></p>
<p>模式一是传统的alpha通道混合，这种模式下颜色和alpha值是分立的，rgb决定颜色，alpha决定..（英文是决定how solid it is 水平有限找不到准确的中文来表达）
在数学上表达式是：<code>blend(source, dest) = (source.rgb * source.a) + (dest.rgb * (1 – source.a)).</code>要注意的是这种模式下，透明只跟alpha有关，跟rgb值无关，一个透明的颜色，不透明的颜色有相同的rgb值，只要alpha=0即可。</p>
<p>模式二是alpha预乘的混合（Premultiplied Alpha Blending），这种模式下rgb与alpha是联系在一起的，数学上的表达式是
<code>blend(source, dest) = source.rgb + (dest.rgb * (1 – source.a))</code>,在这种模式下，透明的表示是rgb值都为0.</p>
<h3 id="4-EGLSurface背景透明设置"><a href="#4-EGLSurface背景透明设置" class="headerlink" title="4.EGLSurface背景透明设置"></a>4.EGLSurface背景透明设置</h3><p>在OpenGL绘制中,除了设置混色外,还要设置EGLSurface配置支持Alpha,如果不设置EGL相关的EGLSurface支持透明,就算OpenGL函数中开启混色,绘制完成后仍是有黑色背景.</p>
<h4 id="4-1GLSurfaceView"><a href="#4-1GLSurfaceView" class="headerlink" title="4.1GLSurfaceView"></a>4.1GLSurfaceView</h4><p>在onSurfaceCreated里，调用GLES20.glClearColor(0f, 0f, 0f, 0f);alpha为0，即透明。</p>
<p>然后，对surfaceview要作一定处理：
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mGLSurfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0);</div><div class="line">TestRenderer renderer = new TestRenderer();</div><div class="line">mGLSurfaceView.setRender(renderer);</div><div class="line">mGLSurfaceView.getHolder().setFormat(PixelFormat.TRANSLUCENT);</div><div class="line">mGLSurfaceView.setZOrderOnTop(true);</div></pre></td></tr></table></figure></p>
<h4 id="4-2SurfaceTexture或Surface构造的Surface"><a href="#4-2SurfaceTexture或Surface构造的Surface" class="headerlink" title="4.2SurfaceTexture或Surface构造的Surface"></a>4.2SurfaceTexture或Surface构造的Surface</h4><p>EGL14.eglChooseConfig中config数组增加EGL10.EGL_ALPHA_SIZE配置:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">int[] CONFIG_RGBA = &#123;</div><div class="line">          EGL10.EGL_RED_SIZE, 8,</div><div class="line">          EGL10.EGL_GREEN_SIZE, 8,</div><div class="line">          EGL10.EGL_BLUE_SIZE, 8,</div><div class="line">          EGL10.EGL_ALPHA_SIZE, 8,</div><div class="line">          EGL10.EGL_RENDERABLE_TYPE, EGL_OPENGL_ES2_BIT,</div><div class="line">          EGL10.EGL_NONE</div><div class="line">  &#125;;</div></pre></td></tr></table></figure></p>
<h3 id="5-实现三维混合"><a href="#5-实现三维混合" class="headerlink" title="5.实现三维混合"></a>5.实现三维混合</h3><p>在进行三维场景的混合时必须注意的是深度缓冲。</p>
<p>深度缓冲是这样一段数据，它记录了每一个像素距离观察者有多近。在启用深度缓冲测试的情况下，如果将要绘制的像素比原来的像素更近，则像素将被绘制。否则,像素就会被忽略掉，不进行绘制。这在绘制不透明的物体时非常有用——不管是先绘制近的物体再绘制远的物体，还是先绘制远的物体再绘制近的物体，或者干脆以 混乱的顺序进行绘制，最后的显示结果总是近的物体遮住远的物体。
然而在你需要实现半透明效果时，发现一切都不是那么美好了。如果你绘制了一个近距离的半透明物体，则它在深度缓冲区内保留了一些信息，使得远处的物体将无法再被绘制出来。虽然半透明的物体仍然半透明，但透过它看到的却不是正确的内容了。
要 解决以上问题，需要在绘制半透明物体时将深度缓冲区设置为只读，这样一来，虽然半透明物体被绘制上去了，深度缓冲区还保持在原来的状态。如果再有一个物体 出现在半透明物体之后，在不透明物体之前，则它也可以被绘制（因为此时深度缓冲区中记录的是那个不透明物体的深度）。以后再要绘制不透明物体时，只需要再 将深度缓冲区设置为可读可写的形式即可。怎么绘制一个一部分半透明一部分不透明的物体？这个好办，只需要把物体分为两个部分，一部分全是半透明 的，一部分全是不透明的，分别绘制就可以了。
即使使用了以上技巧，我们仍然不能随心所欲的按照混乱顺序来进行绘制。必须是先绘制不透明的物体，然 后绘制透明的物体。否则，假设背景为蓝色，近处一块红色玻璃，中间一个绿色物体。如果先绘制红色半透明玻璃的话，它先和蓝色背景进行混合，则以后绘制中间 的绿色物体时，想单独与红色玻璃混合已经不能实现了。
总结起来，绘制顺序就是：首先绘制所有不透明的物体。如果两个物体都是不透明的，则谁先谁后 都没有关系。然后，将深度缓冲区设置为只读。接下来，绘制所有半透明的物体。如果两个物体都是半透明的，则谁先谁后只需要根据自己的意愿（注意了，先绘制 的将成为“目标颜色”，后绘制的将成为“源颜色”，所以绘制的顺序将会对结果造成一些影响）。最后，将深度缓冲区设置为可读可写形式。
调用glDepthMask(GL_FALSE);可将深度缓冲区设置为只读形式。调用glDepthMask(GL_TRUE);可将深度缓冲区设置为可读可写形式。</p>
<blockquote>
<p><a href="https://www.khronos.org/registry/OpenGL-Refpages/es2.0/xhtml/glBlendFunc.xml" target="_blank" rel="external">glBlendFunc函数官网文档</a></p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/25/tips-android-mediacodec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/25/tips-android-mediacodec/" itemprop="url">
                  android系统编码MediaCodec
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-25T16:03:24+08:00">
                2017-06-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Android/" itemprop="url" rel="index">
                    <span itemprop="name">Android</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="android编码器支持参数"><a href="#android编码器支持参数" class="headerlink" title="android编码器支持参数"></a>android编码器支持参数</h3><h4 id="Supported-Media-Formats"><a href="#Supported-Media-Formats" class="headerlink" title="Supported Media Formats"></a><a href="https://developer.android.com/guide/topics/media/media-formats.html" target="_blank" rel="external">Supported Media Formats</a></h4><p><strong>Video encoding recommendations</strong>
The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the H.264 Baseline Profile codec. The same recommendations apply to the Main Profile codec, which is only available in Android 6.0 and later.</p>
<table>
<thead>
<tr>
<th></th>
<th>SD (Low quality)</th>
<th>SD (High quality)</th>
<th>HD 720p (N/A on all devices)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Video resolution</td>
<td>176 x 144 px</td>
<td>480 x 360 px</td>
<td>1280 x 720 px</td>
</tr>
<tr>
<td>Video frame rate</td>
<td>12 fps</td>
<td>30 fps</td>
<td>30 fps</td>
</tr>
<tr>
<td>Video bitrate</td>
<td>56 Kbps</td>
<td>500 Kbps</td>
<td>2 Mbps</td>
</tr>
<tr>
<td>Audio codec</td>
<td>AAC-LC</td>
<td>AAC-LC</td>
<td>AAC-LC</td>
</tr>
<tr>
<td>Audio channels</td>
<td>1 (mono)</td>
<td>2 (stereo)</td>
<td>2 (stereo)</td>
</tr>
<tr>
<td>Audio bitrate</td>
<td>24 Kbps</td>
<td>128 Kbps</td>
<td>192 Kbps</td>
</tr>
</tbody>
</table>
<p>The table below lists the Android media framework video encoding profiles and parameters recommended for playback using the VP8 media codec.</p>
<table>
<thead>
<tr>
<th></th>
<th>SD (Low quality)</th>
<th>SD (High quality)</th>
<th>HD 720p (N/A on all devices)</th>
<th>HD 1080p (N/A on all devices)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Video resolution</td>
<td>320 x 180 px</td>
<td>640 x 360 px</td>
<td>1280 x 720 px</td>
<td>1920 x 1080 px</td>
</tr>
<tr>
<td>Video frame rate</td>
<td>30 fps</td>
<td>30 fps</td>
<td>30 fps</td>
<td>30 fps</td>
</tr>
<tr>
<td>Video bitrate</td>
<td>800 Kbps</td>
<td>2 Mbps</td>
<td>4 Mbps</td>
<td>10 Mbps</td>
</tr>
</tbody>
</table>
<h4 id="CamcorderProfile"><a href="#CamcorderProfile" class="headerlink" title="CamcorderProfile"></a><a href="https://developer.android.com/reference/android/media/CamcorderProfile.html" target="_blank" rel="external">CamcorderProfile</a></h4><p>Retrieves the predefined camcorder profile settings for camcorder applications. These settings are read-only.</p>
<p>The compressed output from a recording session with a given CamcorderProfile contains two tracks: one for audio and one for video.</p>
<p>Each profile specifies the following set of parameters:</p>
<ul>
<li>The file output format</li>
<li>Video codec format</li>
<li>Video bit rate in bits per second</li>
<li>Video frame rate in frames per second</li>
<li>Video frame width and height,</li>
<li>Audio codec format</li>
<li>Audio bit rate in bits per second,</li>
<li>Audio sample rate</li>
<li>Number of audio channels for recording.</li>
</ul>
<h3 id="Android编码器常见问题"><a href="#Android编码器常见问题" class="headerlink" title="Android编码器常见问题"></a>Android编码器常见问题</h3><h4 id="MediaCodec-KEY-FRAME-RATE-seems-to-be-ignored"><a href="#MediaCodec-KEY-FRAME-RATE-seems-to-be-ignored" class="headerlink" title="MediaCodec KEY_FRAME_RATE seems to be ignored"></a><a href="https://stackoverflow.com/questions/22336604/mediacodec-key-frame-rate-seems-to-be-ignored" target="_blank" rel="external">MediaCodec KEY_FRAME_RATE seems to be ignored</a></h4><p><strong>总结起来就是和输入编码器的帧率有关系</strong></p>
<p>I am trying to modify the source for screenrecord in android 4.4 and lower the captured frame rate, but no matter what value I put in:
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">format-&gt;setFloat(&quot;frame-rate&quot;, 5);</div></pre></td></tr></table></figure></p>
<p>the result is always the same ( a very high frame rate )
Is the encoder ignoring this property ? how can I control the frame rate ?</p>
<p>The frame-rate value is not ignored, but it doesn’t do what you want.</p>
<p>The combination of frame-rate and i-frame-interval determines how often I-frames (also called “sync frames”) appear in the encoded output. The frame rate value might also play a role in meeting the bitrate target on some devices, but I’m not sure about that (see e.g. this post).</p>
<p>The MediaCodec encoder does not drop frames. If you want to reduce the frame rate, you have to do so by sending fewer frames to it.</p>
<p>The screenrecord command doesn’t “sample” the screen at a fixed frame rate. Instead, every frame it receives from the surface compositor (SurfaceFlinger) is sent to the encoder, with an appropriate time stamp. If screenrecord receives 60 frames per seconds, you’ll have 60fps output. If it receives 10 frames in quick succession, followed by nothing for 5 seconds, followed by a couple more, you’ll have exactly that in the output file.</p>
<p>You can modify screenrecord to drop frames, but you have to be a bit careful. If you try to reduce the maximum frame rate from 60fps to 30fps by dropping every-other frame, you run the risk that in a “frame0 - frame1 - long_pause - frame2” sequence you’ll drop frame1, and the video will hold on frame0 instead, showing a not-quite-complete animation. So you need to buffer up a frame, and then encode or drop frame N-1 if the difference in presentation times between that and frame N is ~17ms.</p>
<p>The tricky part is that screenrecord, in its default operating mode, directs the frames to the encoder without touching them, so all you see is the encoded output. You can’t arbitrarily drop individual frames of encoded data, so you really want to prevent the encoder from seeing them in the first place. If you use the screenrecord v1.1 sources you can tap into “overlay” mode, used for –bugreport, to have the frames pass through screenrecord on their way to the encoder.</p>
<p>In some respects it might be simpler to write a post-processor that reduces the frame rate. I don’t know how much quality would be lost by decoding and re-encoding the video.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-storage-and-transfer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-storage-and-transfer/" itemprop="url">
                  media-storage-and-transfer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:10:09+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-compress/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-compress/" itemprop="url">
                  media-compress
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:09:04+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-video/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-video/" itemprop="url">
                  media-video
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:08:35+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-audio/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-audio/" itemprop="url">
                  media-audio
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:08:29+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wodekouwei.com/2017/06/20/media-graphic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="轻口味">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="老司机种菜">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/20/media-graphic/" itemprop="url">
                  多媒体技术(一)之图形图像
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-20T23:07:54+08:00">
                2017-06-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/media/" itemprop="url" rel="index">
                    <span itemprop="name">media</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-图形与图像的基本概念"><a href="#1-图形与图像的基本概念" class="headerlink" title="1.图形与图像的基本概念"></a>1.图形与图像的基本概念</h2><h3 id="1-1图形与图像的颜色模型"><a href="#1-1图形与图像的颜色模型" class="headerlink" title="1.1图形与图像的颜色模型"></a>1.1图形与图像的颜色模型</h3><h4 id="1-1-1颜色的基本概念"><a href="#1-1-1颜色的基本概念" class="headerlink" title="1.1.1颜色的基本概念"></a>1.1.1颜色的基本概念</h4><h5 id="1-1-1-1-物体的颜色"><a href="#1-1-1-1-物体的颜色" class="headerlink" title="1.1.1.1 物体的颜色"></a>1.1.1.1 物体的颜色</h5><p>物体的颜色不同是因为他们对光的吸收和反射的属性不同.物体的颜色是由该物体所反射的光的波长来决定的.</p>
<p>人眼看到的物体的颜色不仅取决于该物体所反射的光的波长,还与照射它的光源有关.如果用单一蓝色去照射绿色的树叶,
则此时的树叶只能是黑色的.因为蓝色光源中没有绿色成分,树叶吸收了全部蓝色而呈现黑色.</p>
<p>在彩色显示器中,为了使颜色具有较好的还原度和真实感,通常采用类似自然光作为照明光源.</p>
<h5 id="1-1-1-2-彩色三要素"><a href="#1-1-1-2-彩色三要素" class="headerlink" title="1.1.1.2 彩色三要素"></a>1.1.1.2 彩色三要素</h5><p>颜色信息对人的视觉反应,可通过色调,色饱和度和亮度这三个参量来表示:</p>
<ul>
<li>色调:用来描述颜色的不同类别的物理量称为色调,如红,橙,黄,绿,青,蓝,紫.色调取决于该种颜色的主要波长.</li>
<li>色饱和度:色饱和度则是描述颜色的深浅程度的物理量,它按该种颜色混入白光的比例来表示,当某色光的饱和度为100%时,就是表示该色光是完全没有混入白色光的单色光饱和度越高则颜色也越浓.如果大量混入白色光使饱和度降低,人视觉会感到颜色变淡.例如,在浓的的红色光中混入大量的白光,由于饱和度降低就变成了粉红色,但是因为红色是基本色,所以色调并不改变.在某颜色中混入白光与增强白光对某颜色物体的照射是不同的.前者是在摄入人眼的眸色光中混入白光,而后者的结果则是加强了某色物体的反射光的强度,在摄入人眼的反射光中并没有混入白光,因此它并没有改变该色的饱和度.</li>
<li>亮度:用来描述色光的明暗变化的强度的物理量成为亮度.亮度是色光能量的一种描述,是指色调和色饱和度已经固定的光,当它的全部能量增强时感觉明亮,否则感觉暗淡.</li>
</ul>
<p>色调和色饱和度统称为色度.</p>
<h5 id="1-1-1-3-三基色原理"><a href="#1-1-1-3-三基色原理" class="headerlink" title="1.1.1.3 三基色原理"></a>1.1.1.3 三基色原理</h5><p>三基色原理认为自然界中景物的绝大多数的彩色光,能分解为互相独立的红(R),绿(G),蓝(B)三种基色光;反之,用互相独立的红,绿,蓝3种基色光以不同的比例混合,可模拟出自然界中绝大多数景色的光.RGB三基色相互独立的含义是指,任一种基色都不能由另外两种基色混合而产生.三基色的选择并不是唯一的.</p>
<h5 id="1-1-1-4-像素-pixel"><a href="#1-1-1-4-像素-pixel" class="headerlink" title="1.1.1.4 像素(pixel)"></a>1.1.1.4 像素(pixel)</h5><p>像素是计算机图形与图像中能被单独处理的最小基本单元.
从像素的视觉属性看,它是一个最小可是单位.一幅彩色图像可以看成是由许多很小的可是点组成的,这个点就是像素.每个像素点都有确定的颜色和亮度,这个颜色就是有互相独立的红,绿,蓝三种基色光以不同的比例混合而成的.
从像素的量值属性看,它的数据结构应同时显示地址,色彩,亮度等数据信息,这些数据就称为像素值.</p>
<h4 id="1-1-2-颜色模型"><a href="#1-1-2-颜色模型" class="headerlink" title="1.1.2 颜色模型"></a>1.1.2 颜色模型</h4><p>颜色模型(或称色彩模型)就是定量颜色方法.在不同的领域应用于图像时,为了尽可能多地,有效地描述各种颜色,往往采用不同的颜色模型,例如,用显示器这类发光物体显示时采用的是RGB模型,用打印机这类吸光物体输出图像时用CMY模型,进行彩色电视信号的显示与传输时采用YUV模型,从事艺术绘画时习惯采用HSL模型.</p>
<h5 id="1-1-2-1-RGB模型"><a href="#1-1-2-1-RGB模型" class="headerlink" title="1.1.2.1 RGB模型"></a>1.1.2.1 RGB模型</h5><p>RGB模型也称为加色法混色模型.其混色规律是:以等量的红,绿,蓝基色光混合时:</p>
<ul>
<li>红 + 绿 = 黄色</li>
<li>红 + 蓝 = 品红色</li>
<li>绿 + 蓝 = 青色</li>
<li>红 + 绿 + 蓝 = 白色</li>
<li>3种基色光全无 = 黑色</li>
</ul>
<p>加色法的混色规律可以使用下图表示,3个圆分别红绿蓝3种基色,圆与圆的叠加区域表示以等量的基色相混合时所合成的颜色,其色调如该区域的文字表示.当3种基色等量相加时,就会得到白色.其中,又尝尝把品红色成为绿色的补色,青色称为红色的补色,黄色称为蓝色的补色.
<img src="http://images.wodekouwei.com/media/rgb.png" alt="image">
物体的颜色是丰富多彩的,任何一种颜色和这3种基色之间的关系可以用下面的配色方程式来描述:
F(物体颜色)=R(红色的百分比) + G(绿色的百分比) + B(蓝色的百分比)</p>
<p>由于人类的视觉特性,两种或3种基色产生混色效果,不一定要同时和同一空间位置混合.例如,在心理学实验中有一个色轮实验,它是在可旋转的圆盘上按扇形面积均等的分成3部分,并涂上3种基色,当圆盘慢慢旋转时能够分辨出3中基色,但当圆盘旋转的频率提高到闪光融合频率以上时,人眼不再能分辨出3种基色,而产生白颜色的感觉,以达到混色的效果.这就是 <strong>“时间混色法”</strong> .最初的顺序制彩色电视就应用了人的这一视觉效果.例如,很细小的红点和旅店均匀间置互相靠的很近,只有在近距离仔细观看才能区分出来,当观看距离很远时就只感觉到黄色的一篇了,这就是 <strong>“空间混色法”</strong> .目前广泛使用的彩色显像管以及大型LED真彩色广告屏就是利用了这一混色视觉效应.</p>
<p>在多媒体技术中,RGB颜色模型是最基本的模型,因为彩色显示器只有按RGB分量式输入,才能在显示屏幕上合成任意颜色.</p>
<h5 id="1-1-2-2-CMY模型"><a href="#1-1-2-2-CMY模型" class="headerlink" title="1.1.2.2 CMY模型"></a>1.1.2.2 CMY模型</h5><p>CMY(Cyan Magenta Yellow)模型是采用青,品红,黄色3种基本颜色按一定比例合成颜色的方法.CMY模型又称为减色法混色模型,因为色彩的显示不是直接来自于光线的色彩,而是光线被物体吸收掉一部分之后发射回来的剩余光线所产生的.光线都被吸收时称为黑色,当光线都被反射时成为白色.这种模式适合于彩色打印机等用彩色墨水或颜料进行混合显示的情况.</p>
<p>在相减混色中,当3种基本颜色等量相减时得到黑色;等量黄色(Y)和品红(M)相减而青色为0时,等到红色(R);等量青色(C)和品红(M)相减而黄色为0时,得到蓝色(B);等量黄色(Y)和青色(C)相减而品红(M)为0时,得到绿色(G).</p>
<p>由于颜料的化学特性,实际上等量的CMY混合后并不能产生真正的黑色,因此在印刷时通常再加上黑色(Black),这样又称为CMYK模式,四色印刷便是由此而来.</p>
<p>显然,RGB与CMY模型是颜色互补的模型,它们之间可以互相转换.如果按每个像素每种颜色用一位二进制数表示的话,RGB与CMY模型之间的颜色关系如下表所示.利用它们之间的关系,可以把显示器显示的颜色转换成打印的颜色.但实际上因为发射光与反射光的性质完全不同,显示器上的颜色不可能精确地在打印机上复制出来,因此实际的转换过程会利用一定的算法进行一定程度上的失真补偿.
|RGB|CMY|颜色|
|—|—|—|
|000|111|黑|
|001|110|蓝|
|010|101|绿|
|011|100|青|
|100|011|红|
|101|010|品红|
|110|001|黄|
|111|000|白|</p>
<h5 id="1-1-2-3-YUV与YIQ模型"><a href="#1-1-2-3-YUV与YIQ模型" class="headerlink" title="1.1.2.3 YUV与YIQ模型"></a>1.1.2.3 YUV与YIQ模型</h5><p>在彩色电视系统中不采用RGB颜色模型,而采用YUV或YIQ模型表示彩色图像.YUV适用于PAL(Phase Altermation Line,同行倒相制式)和SECAM(法文)(Sequential C欧了让Memo,顺序传送彩色与存储制式)彩色电视制式,而YIQ适用于美国国家电视标准委员会(NTSC,National Television System Committee)彩色电视制式.</p>
<p>Y是亮度信号,U和V则是两个色差信号,分别传送红基色分量和蓝基色分量与亮度分量的差值信号.</p>
<p>采用YUV颜色模型的好处是:其一,亮度信号Y解决了彩色电视与黑白电视的兼容性问题;其二,由于人眼对颜色细节的分辨率低于对亮度细节的分辨率,所以可以用一个通道来传送,Y,U,V这3个信号,给亮度信号较大的带宽(6MHz)来传送图像的细节,而给色差信号较小的带宽(1.3MHz)来进行大面积涂色.这样,总的传输数据量和RGB模型相比,要明显小一些,起到了一种数据压缩节省存储空间的作用,而对于这种数据压缩带来的画面变化人眼一般是感觉不到的.</p>
<p>电视系统通常采用摄像机把摄得的彩色图像信号经分色,放大和校正分成RGB这3个分量的信号,再经过矩阵变换电路将彩色信号分解成亮度信号Y和色差信号,U,V,而后对其进行编码,用同一信道发送出去.接收端再通过编码及矩阵逆变换还原成3个基色显示.</p>
<p>在NTSC彩色电视制式中使用YIQ模型,其特性与YUV模型相近.其中的Y表示亮度,I,Q也是两个色差分量,但它们在色度矢量图中与U,V的位置不同.Q,I正交坐标轴与U,V正交坐标轴之间有33度夹角,如图所示:</p>
<p><img src="http://images.wodekouwei.com/media/yuv_yiq.bmp" alt="image"></p>
<p>I,Q与U,V之间的关系如下:
I = Vcos33 - Usin33
Q = Vsin33 + Ucos33</p>
<p>人眼的彩色视觉特性表明,人眼分辨红与黄之间的颜色变化的能力最强,而分辨蓝,紫之间颜色变化的能力最弱.因此YIQ模型在色度矢量图中,选择I轴正好处于夹角123度处,即人眼具有最大彩色分辨率的红与黄之间的橙色和青色(相角为303度)处,选择与I轴正交的色度信号轴为Q轴(相角为33度),正是人眼最不敏感的色轴位置.因而YIQ模型传送分辨力较强的I信号时,用较宽的频带(1.3MHz~1.5MHz),传送分辨力弱的Q信号时,可用较窄的频带(0.5MHz),这就可以在保证较好的颜色传输特性情况下,最大限度地节省存储空间.</p>
<h5 id="1-1-2-4-HSI颜色模型"><a href="#1-1-2-4-HSI颜色模型" class="headerlink" title="1.1.2.4 HSI颜色模型"></a>1.1.2.4 HSI颜色模型</h5><p>HSI或HSL是Hue Saturation Intensity(Lightness)的英文缩写,颜色模型用H,S,I这三个参数描述颜色特性,其中H定义颜色的波长,称为色调;S表示颜色的深浅程度,称为饱和度;I表示强度或亮度,这正是颜色的三要素.</p>
<p>HSI模型更接近人对颜色更接近人对彩色的认识,符合人眼对颜色的感知方式,是一种从事艺术绘画的画家们习惯使用的描述色彩的方法.它比RGB模型使用更方便,从而能减少彩色图像处理的复杂性,增加快速性,因此一般的图像处理软件中,都提供了这种定量色彩的方式.</p>
<h4 id="1-1-3-颜色模型的转换"><a href="#1-1-3-颜色模型的转换" class="headerlink" title="1.1.3 颜色模型的转换"></a>1.1.3 颜色模型的转换</h4><p>无论采用什么颜色模型来表示彩色图形与图像,由于所有的显示器都需要RGB值来驱动,所以在显示每个像素之前,必须要把彩色分量值转换成RGB值.</p>
<h5 id="1-1-3-1-YUV与RGB颜色模型变换"><a href="#1-1-3-1-YUV与RGB颜色模型变换" class="headerlink" title="1.1.3.1 YUV与RGB颜色模型变换"></a>1.1.3.1 YUV与RGB颜色模型变换</h5><p>RGB与YUV的对应关系可以近似地用下面的方程表示:</p>
<ul>
<li>Y = 0.299R + 0.587G + 0.114B</li>
<li>U = -0.147R - 0.289G + 0.436B</li>
<li>V = 0.615R - 0.515G - 0.096B<h5 id="1-1-3-2-YIQ与RGB颜色模型变换"><a href="#1-1-3-2-YIQ与RGB颜色模型变换" class="headerlink" title="1.1.3.2 YIQ与RGB颜色模型变换"></a>1.1.3.2 YIQ与RGB颜色模型变换</h5>YIQ与RGB的对应关系可以近似地用下面的方程表示:</li>
<li>Y = 0.229R + 0.587G + 0.114B</li>
<li>I = 0.596R - 0.275G - 0.321B</li>
<li>Q = 0.212R - 0.523G + 0.311B</li>
</ul>
<h5 id="HSI-与-RGB颜色变换"><a href="#HSI-与-RGB颜色变换" class="headerlink" title="HSI 与 RGB颜色变换"></a>HSI 与 RGB颜色变换</h5><p>HSI与RGB空间的转换关系可以用下面的方程表示:</p>
<ul>
<li>H = [90 - arctan(F/sqr(3)) + [0, G&gt;B;180,G&lt;B]]/360</li>
<li>S = 1 - min(R,G,B)/I</li>
<li>I = (R+G+B)/3
其中,F=(2R-G-B)/(G-B),sqr为求平方根</li>
</ul>
<h3 id="1-2图形与图像的基本属性"><a href="#1-2图形与图像的基本属性" class="headerlink" title="1.2图形与图像的基本属性"></a>1.2图形与图像的基本属性</h3><p>一幅彩色图像可以看成二维连续函数f(x,y),其彩色幅度是位置(x,y)的函数.计算机多媒体技术从其图像的生成,显示,处理和存储的机制出发,需要对彩色图像数字化.数字化一幅彩色图像就是要把连续函数f(x,y)在空间的坐标和彩色幅度进行离散和量化.空间坐标x,y的离散化通常以分辨率来表征,而彩色幅度的离散化则由像素的颜色深度来表征.</p>
<h4 id="1-2-1分辨率"><a href="#1-2-1分辨率" class="headerlink" title="1.2.1分辨率"></a>1.2.1分辨率</h4><p>分辨率是一个统称,分为显示分辨率,图像分辨率,扫描分辨率和打印分辨率等.</p>
<h5 id="1-2-1-1显示分辨率"><a href="#1-2-1-1显示分辨率" class="headerlink" title="1.2.1.1显示分辨率"></a>1.2.1.1显示分辨率</h5><p>是指某一种显示方式下,显示屏上能够显示出的像素数目,以水平和垂直的像素表示.例如,显示分辨率为640*480表示显示屏分成480行,每行显示640个像素,整个显示屏就含有307200个显像点.屏幕上的像素越多,分辨率就越高,显示出来的图像也就越细腻,显示的图像质量也就约高.屏幕能够显示的最大像素数目越多,也说明显示设备的最大分辨率越高.显示屏上的每个彩色像素由代表R,G,B这3种模拟信号的相对强度决定,这些彩色像素点就构成一幅彩色图像.</p>
<h5 id="1-2-1-2图像分辨率"><a href="#1-2-1-2图像分辨率" class="headerlink" title="1.2.1.2图像分辨率"></a>1.2.1.2图像分辨率</h5><p>图像分辨率指数字化图像的大小,以水平和垂直的像素数表示.如果组成图像的像素数目越多,则说明图像的分辨率越高,看起来就越逼真,图像分辨率实际上决定了图像的显示质量,也就是说,即使提高了显示分辨率,也无法真正改善图像的质量.图像分辨率与显示分辨率是两个不同的概念.图像分辨率的确定组成一幅图像的像素数目,而显示分辨率是确定显示图像的区域大小.当图像分辨率与屏幕分辨率一致时,图像正好占据满屏;当图像分辨率小于屏幕分辨率时,图像占据屏幕的一部分;当图像分辨率大于屏幕分辨率时,则屏幕仅能显示图像的一部分.</p>
<h5 id="1-2-1-3扫描分辨率和打印分辨率"><a href="#1-2-1-3扫描分辨率和打印分辨率" class="headerlink" title="1.2.1.3扫描分辨率和打印分辨率"></a>1.2.1.3扫描分辨率和打印分辨率</h5><p>在用于扫描仪扫描图像时,通常要指定扫描的分辨率,用每英寸包含的点(d/i,dots per inch)表示.如果用300d/i来扫描一幅8<em>6的彩色图像,就得到一幅2400</em>1800个像素的图像.分辨率越高,像素就越多.</p>
<p>打印分辨率是指图像打印时每英寸可识别的点数,也使用d/i(dots per inch)为衡量单位.两种分辨率之间是有区别的,扫描分辨率反映了扫描后的图像与原始图像之间的差异程度,分辨率越高,差异越小.打印分辨率反映了打印的图像与原数字图像之间的差异程度,分辨率越接近原图像的分辨率,打印质量越高.两种分辨率的最高值都受到设备的限制.</p>
<h4 id="1-2-2颜色深度"><a href="#1-2-2颜色深度" class="headerlink" title="1.2.2颜色深度"></a>1.2.2颜色深度</h4><p>颜色深度是指图像中每个像素的颜色(或亮度)信息所占的二进制数位数,记做位/像素(b/p,bits per pixel).屏幕上的每一个像素都占有一个或多个位,用于存放与它相关的颜色信息.颜色深度决定了构成图像的每个像素可能出现的最大颜色数,因而颜色深度值越高,显示的图像色彩越丰富.反之,颜色深度太浅,会影响图像的质量,图像看起来让人觉得很粗糙和很不自然.常见颜色深度有一下5种:</p>
<ol>
<li>4bit:这是VGA标准支持的颜色深度,共2的四次方16种颜色;</li>
<li>8bit:这是多媒体应用中的最低颜色深度,共2的8次方256种颜色,称为索引彩色图(由颜色查找决定);</li>
<li>16bit:在16bit中,用其中的15bit表示RGB这3种颜色,每种颜色5bit,用剩余的以为表示图像的其他属性,如透明度.所以16bit的颜色深度实际可以表示为2的15次方32<em>32</em>32共32768种颜色.称为HI-Color(高彩色)图像.</li>
<li>24bit:用3个8bit分别表示RGB,可生成的颜色数2的24次16777216种,约16M种颜色,这已经成为真彩色;</li>
<li>32bit:同24bit颜色深度一样,也是用3个bit分别表示RGB这三种颜色,剩余的8bit用来表示图像的其他属性,如透明度等.</li>
</ol>
<p>虽然像素的颜色颜色深度值越大图像色彩越丰富,但由于设备的限制,人眼分辨率的限制,不一定要追求特别深的颜色深度,一般来说,32bit的颜色深度已经足够.此外,像素颜色深度越深,所占用的存储空间越大.</p>
<p>一个像素的颜色深度位数除R,G,B分量占用固定bit数表示颜色外,一般要腾出1bit或几bit作为属性(Attribute)位.属性位用来指定该像素应具有的性质.例如,像素的颜色深度为32bit时,R,G,B分别用8bit表示,那么余下的8bit常称为a通道(Alpha Channel)位,或称为覆盖(Overlay)位,中断位,属性位,它用来控制该像素点的透明度.假如定义一个像素值(A,R,G,B)的4个分量(其中A为Alpha属性位数值)都用归一化的数值表示,那么像素91,1,0,0)时显示红色.当像素为(0.5,1,0,0)时,预乘的结果就变成了(0.5.0.5,0,0),这表示现在显示的红色的强度减低一半.用这种定义像素属性的办法可以实现两幅彩色图像之间的透明叠加效果.当Alpha数值很小时,渲染出来的效果是几乎透明的,如玻璃;当Alpha数值处于中间的位置时,则可以得到一种半透明的效果;当Alpha数值接近255时,是几乎不透明的效果.这种属性位的加入为实现透明和半透明的显示掉过带来了方便.</p>
<h4 id="1-2-3文件的大小"><a href="#1-2-3文件的大小" class="headerlink" title="1.2.3文件的大小"></a>1.2.3文件的大小</h4><h3 id="1-3图形与图像的基本类型"><a href="#1-3图形与图像的基本类型" class="headerlink" title="1.3图形与图像的基本类型"></a>1.3图形与图像的基本类型</h3><h2 id="2-图形与图像的处理"><a href="#2-图形与图像的处理" class="headerlink" title="2.图形与图像的处理"></a>2.图形与图像的处理</h2><h3 id="2-1图形与图像的获取"><a href="#2-1图形与图像的获取" class="headerlink" title="2.1图形与图像的获取"></a>2.1图形与图像的获取</h3><h3 id="2-2图形与图像的存储"><a href="#2-2图形与图像的存储" class="headerlink" title="2.2图形与图像的存储"></a>2.2图形与图像的存储</h3><h3 id="2-3图形与图像的显示"><a href="#2-3图形与图像的显示" class="headerlink" title="2.3图形与图像的显示"></a>2.3图形与图像的显示</h3><h3 id="2-4图形与图像的处理"><a href="#2-4图形与图像的处理" class="headerlink" title="2.4图形与图像的处理"></a>2.4图形与图像的处理</h3><h2 id="3-计算机动画"><a href="#3-计算机动画" class="headerlink" title="3.计算机动画"></a>3.计算机动画</h2><h3 id="3-1计算机动画的原理"><a href="#3-1计算机动画的原理" class="headerlink" title="3.1计算机动画的原理"></a>3.1计算机动画的原理</h3><h3 id="3-2计算机动画的类型"><a href="#3-2计算机动画的类型" class="headerlink" title="3.2计算机动画的类型"></a>3.2计算机动画的类型</h3><h3 id="3-3计算机动画的制作"><a href="#3-3计算机动画的制作" class="headerlink" title="3.3计算机动画的制作"></a>3.3计算机动画的制作</h3><h3 id="3-4虚拟现实动画技术"><a href="#3-4虚拟现实动画技术" class="headerlink" title="3.4虚拟现实动画技术"></a>3.4虚拟现实动画技术</h3>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://images.wodekouwei.com/avatar/winnle_the_pooh.jpg"
               alt="轻口味" />
          <p class="site-author-name" itemprop="name">轻口味</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/qingkouwei" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/LightTaste" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.douban.com/people/turnpp/" target="_blank" title="豆瓣">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  豆瓣
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/shen-jun-wei-9/" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/ossrs/srs" title="SRS" target="_blank">SRS</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">轻口味</span>
</div>

<div>
<a href="http://www.miitbeian.gov.cn/">京ICP备17018543号</a>

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  
    
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "bb46b146831e4e34808d09cd94c85f50",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

</body>
</html>
